nohup: ignoring input
[W1123 12:51:27.394889444 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 42
设置随机种子为: 42
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 42
设置随机种子为: 42
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.38it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.35it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.87it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.21it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.99it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.75it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.83it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.57it/s]
[W1123 12:51:33.869592293 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1123 12:51:33.879192551 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1123 12:51:33.882917517 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1123 12:51:33.896111952 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2_truncation.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2_truncation.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
初始化 CustomSymPOTrainer.../rlhf_code/code/implement_final_v3_no_kl_term2_truncation.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)

/rlhf_code/code/implement_final_v3_no_kl_term2_truncation.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /root/wandb/offline-run-20251123_125140-n0p20ugh
  0%|          | 0/3753 [00:00<?, ?it/s]--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -50.5
Sample 0 - pi_logp_chosen:  -50.24790573120117
Sample 0 - Difference (pi - ref): 0.2520942687988281
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -108.0
Sample 0 - pi_logp_chosen:  -107.10874938964844
Sample 0 - Difference (pi - ref): 0.8912506103515625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -126.5
Sample 0 - pi_logp_chosen:  -125.88667297363281
Sample 0 - Difference (pi - ref): 0.6133270263671875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -242.0
Sample 0 - pi_logp_chosen:  -242.8450927734375
Sample 0 - Difference (pi - ref): -0.8450927734375
---------------------------------
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -76.0
Sample 0 - pi_logp_chosen:  -75.99889373779297
Sample 0 - Difference (pi - ref): 0.00110626220703125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -258.0
Sample 0 - pi_logp_chosen:  -257.1895446777344
Sample 0 - Difference (pi - ref): 0.810455322265625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -217.0
Sample 0 - pi_logp_chosen:  -217.67721557617188
Sample 0 - Difference (pi - ref): -0.677215576171875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -394.0
Sample 0 - pi_logp_chosen:  -394.5501708984375
Sample 0 - Difference (pi - ref): -0.5501708984375
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -78.0
Sample 0 - pi_logp_chosen:  -77.8389892578125
Sample 0 - Difference (pi - ref): 0.1610107421875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -174.0
Sample 0 - pi_logp_chosen:  -174.40147399902344
Sample 0 - Difference (pi - ref): -0.4014739990234375
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -362.0
Sample 0 - pi_logp_chosen:  -359.7122802734375
Sample 0 - Difference (pi - ref): 2.2877197265625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -468.0
Sample 0 - pi_logp_chosen:  -465.5644836425781
Sample 0 - Difference (pi - ref): 2.435516357421875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -88.0
Sample 0 - pi_logp_chosen:  -88.28606414794922
Sample 0 - Difference (pi - ref): -0.28606414794921875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -106.0
Sample 0 - pi_logp_chosen:  -105.8554916381836
Sample 0 - Difference (pi - ref): 0.14450836181640625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -255.0
Sample 0 - pi_logp_chosen:  -255.6888885498047
Sample 0 - Difference (pi - ref): -0.6888885498046875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -260.0
Sample 0 - pi_logp_chosen:  -259.95977783203125
Sample 0 - Difference (pi - ref): 0.04022216796875
---------------------------------
  0%|          | 1/3753 [00:04<4:54:34,  4.71s/it]{'loss': 0.1199, 'grad_norm': 1761.6629638671875, 'learning_rate': 0.0, 'mean_ratio_chosen': 0.502133846282959, 'mean_ratio_rejected': 0.48519444465637207, 'weight_chosen': 1.2663661241531372, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': -0.34444427490234375, 'epoch': 0.0002664890073284477}
                                                  {'loss': 0.1199, 'grad_norm': 1761.6629638671875, 'learning_rate': 0.0, 'mean_ratio_chosen': 0.502133846282959, 'mean_ratio_rejected': 0.48519444465637207, 'weight_chosen': 1.2663661241531372, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': -0.34444427490234375, 'epoch': 0.0}
  0%|          | 1/3753 [00:04<4:54:34,  4.71s/it]  0%|          | 2/3753 [00:10<5:22:23,  5.16s/it]  0%|          | 3/3753 [00:14<5:07:35,  4.92s/it]  0%|          | 4/3753 [00:18<4:43:18,  4.53s/it]  0%|          | 5/3753 [00:22<4:31:06,  4.34s/it]  0%|          | 6/3753 [00:28<4:53:27,  4.70s/it]  0%|          | 7/3753 [00:32<4:42:11,  4.52s/it]  0%|          | 8/3753 [00:36<4:39:32,  4.48s/it]  0%|          | 9/3753 [00:40<4:22:29,  4.21s/it]  0%|          | 10/3753 [00:43<4:10:50,  4.02s/it]{'loss': -0.4475, 'grad_norm': 1588.264892578125, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 1.5355114936828613, 'mean_ratio_rejected': 0.714776873588562, 'weight_chosen': 0.03065323829650879, 'weight_rejected': 0.4163219630718231, 'kl_term_chosen': 0.2144317626953125, 'epoch': 0.002664890073284477}
                                                   {'loss': -0.4475, 'grad_norm': 1588.264892578125, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 1.5355114936828613, 'mean_ratio_rejected': 0.714776873588562, 'weight_chosen': 0.03065323829650879, 'weight_rejected': 0.4163219630718231, 'kl_term_chosen': 0.2144317626953125, 'epoch': 0.0}
  0%|          | 10/3753 [00:44<4:10:50,  4.02s/it]  0%|          | 11/3753 [00:48<4:21:10,  4.19s/it]  0%|          | 12/3753 [00:53<4:34:33,  4.40s/it]  0%|          | 13/3753 [00:57<4:32:35,  4.37s/it]  0%|          | 14/3753 [01:01<4:26:25,  4.28s/it]  0%|          | 15/3753 [01:05<4:16:14,  4.11s/it]  0%|          | 16/3753 [01:09<4:10:49,  4.03s/it]  0%|          | 17/3753 [01:13<4:05:14,  3.94s/it]  0%|          | 18/3753 [01:17<4:21:55,  4.21s/it]  1%|          | 19/3753 [01:21<4:05:40,  3.95s/it]  1%|          | 20/3753 [01:25<4:04:05,  3.92s/it]{'loss': -0.408, 'grad_norm': 1948.93359375, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 1.586055874824524, 'mean_ratio_rejected': 1.0004197359085083, 'weight_chosen': 0.501966655254364, 'weight_rejected': 0.29665425419807434, 'kl_term_chosen': 0.23062515258789062, 'epoch': 0.005329780146568954}
                                                   {'loss': -0.408, 'grad_norm': 1948.93359375, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 1.586055874824524, 'mean_ratio_rejected': 1.0004197359085083, 'weight_chosen': 0.501966655254364, 'weight_rejected': 0.29665425419807434, 'kl_term_chosen': 0.23062515258789062, 'epoch': 0.01}
  1%|          | 20/3753 [01:25<4:04:05,  3.92s/it]  1%|          | 21/3753 [01:29<4:05:00,  3.94s/it]  1%|          | 22/3753 [01:35<4:56:09,  4.76s/it]  1%|          | 23/3753 [01:40<4:59:06,  4.81s/it]  1%|          | 24/3753 [01:43<4:30:21,  4.35s/it]  1%|          | 25/3753 [01:48<4:27:45,  4.31s/it]  1%|          | 26/3753 [01:51<4:03:47,  3.92s/it]  1%|          | 27/3753 [01:55<4:05:05,  3.95s/it]  1%|          | 28/3753 [01:59<4:04:23,  3.94s/it]  1%|          | 29/3753 [02:02<4:02:04,  3.90s/it]  1%|          | 30/3753 [02:07<4:06:55,  3.98s/it]{'loss': -0.2638, 'grad_norm': 2132.66943359375, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 2.739152193069458, 'mean_ratio_rejected': 1.3164072036743164, 'weight_chosen': 0.12412697076797485, 'weight_rejected': 0.5987815260887146, 'kl_term_chosen': 0.5038242340087891, 'epoch': 0.007994670219853431}
                                                   {'loss': -0.2638, 'grad_norm': 2132.66943359375, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 2.739152193069458, 'mean_ratio_rejected': 1.3164072036743164, 'weight_chosen': 0.12412697076797485, 'weight_rejected': 0.5987815260887146, 'kl_term_chosen': 0.5038242340087891, 'epoch': 0.01}
  1%|          | 30/3753 [02:07<4:06:55,  3.98s/it]  1%|          | 31/3753 [02:12<4:30:27,  4.36s/it]  1%|          | 32/3753 [02:15<4:14:20,  4.10s/it]  1%|          | 33/3753 [02:19<4:04:52,  3.95s/it]  1%|          | 34/3753 [02:23<4:07:54,  4.00s/it]  1%|          | 35/3753 [02:27<4:13:22,  4.09s/it]  1%|          | 36/3753 [02:32<4:25:54,  4.29s/it]  1%|          | 37/3753 [02:38<4:51:39,  4.71s/it]  1%|          | 38/3753 [02:42<4:45:08,  4.61s/it]  1%|          | 39/3753 [02:47<4:48:03,  4.65s/it]  1%|          | 40/3753 [02:51<4:36:13,  4.46s/it]{'loss': 0.317, 'grad_norm': 1564.8380126953125, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 0.735684871673584, 'mean_ratio_rejected': 2.5167441368103027, 'weight_chosen': 0.9112710952758789, 'weight_rejected': 0.1276526302099228, 'kl_term_chosen': -0.15347671508789062, 'epoch': 0.010659560293137908}
                                                   {'loss': 0.317, 'grad_norm': 1564.8380126953125, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 0.735684871673584, 'mean_ratio_rejected': 2.5167441368103027, 'weight_chosen': 0.9112710952758789, 'weight_rejected': 0.1276526302099228, 'kl_term_chosen': -0.15347671508789062, 'epoch': 0.01}
  1%|          | 40/3753 [02:51<4:36:13,  4.46s/it]  1%|          | 41/3753 [02:55<4:33:54,  4.43s/it]  1%|          | 42/3753 [02:58<4:06:54,  3.99s/it]  1%|          | 43/3753 [03:03<4:16:41,  4.15s/it]  1%|          | 44/3753 [03:07<4:11:08,  4.06s/it]  1%|          | 45/3753 [03:12<4:30:41,  4.38s/it]  1%|          | 46/3753 [03:17<4:41:25,  4.55s/it]  1%|▏         | 47/3753 [03:20<4:11:12,  4.07s/it]  1%|▏         | 48/3753 [03:24<4:10:43,  4.06s/it]  1%|▏         | 49/3753 [03:28<4:13:04,  4.10s/it]  1%|▏         | 50/3753 [03:32<4:04:38,  3.96s/it]{'loss': 0.8987, 'grad_norm': 1903.9207763671875, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 1.498157262802124, 'mean_ratio_rejected': 2.8511266708374023, 'weight_chosen': 0.661273717880249, 'weight_rejected': 0.6851073503494263, 'kl_term_chosen': 0.202117919921875, 'epoch': 0.013324450366422385}
                                                   {'loss': 0.8987, 'grad_norm': 1903.9207763671875, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 1.498157262802124, 'mean_ratio_rejected': 2.8511266708374023, 'weight_chosen': 0.661273717880249, 'weight_rejected': 0.6851073503494263, 'kl_term_chosen': 0.202117919921875, 'epoch': 0.01}
  1%|▏         | 50/3753 [03:32<4:04:38,  3.96s/it]  1%|▏         | 51/3753 [03:36<4:12:33,  4.09s/it]  1%|▏         | 52/3753 [03:41<4:23:11,  4.27s/it]  1%|▏         | 53/3753 [03:46<4:51:57,  4.73s/it]  1%|▏         | 54/3753 [03:50<4:28:28,  4.35s/it]  1%|▏         | 55/3753 [03:55<4:50:00,  4.71s/it]  1%|▏         | 56/3753 [04:00<4:47:09,  4.66s/it]  2%|▏         | 57/3753 [04:05<4:48:29,  4.68s/it]  2%|▏         | 58/3753 [04:08<4:25:51,  4.32s/it]  2%|▏         | 59/3753 [04:12<4:08:51,  4.04s/it]  2%|▏         | 60/3753 [04:15<3:51:45,  3.77s/it]{'loss': 0.6355, 'grad_norm': 2256.829833984375, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 1.243736982345581, 'mean_ratio_rejected': 0.6716039180755615, 'weight_chosen': -0.07884567975997925, 'weight_rejected': 0.937210738658905, 'kl_term_chosen': 0.10906028747558594, 'epoch': 0.015989340439706862}
                                                   {'loss': 0.6355, 'grad_norm': 2256.829833984375, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 1.243736982345581, 'mean_ratio_rejected': 0.6716039180755615, 'weight_chosen': -0.07884567975997925, 'weight_rejected': 0.937210738658905, 'kl_term_chosen': 0.10906028747558594, 'epoch': 0.02}
  2%|▏         | 60/3753 [04:15<3:51:45,  3.77s/it]  2%|▏         | 61/3753 [04:20<4:15:37,  4.15s/it]  2%|▏         | 62/3753 [04:24<4:23:06,  4.28s/it]  2%|▏         | 63/3753 [04:29<4:22:25,  4.27s/it]  2%|▏         | 64/3753 [04:33<4:25:40,  4.32s/it]  2%|▏         | 65/3753 [04:37<4:17:58,  4.20s/it]  2%|▏         | 66/3753 [04:42<4:26:21,  4.33s/it]  2%|▏         | 67/3753 [04:46<4:33:54,  4.46s/it]  2%|▏         | 68/3753 [04:50<4:19:49,  4.23s/it]  2%|▏         | 69/3753 [04:55<4:26:00,  4.33s/it]  2%|▏         | 70/3753 [04:58<4:14:02,  4.14s/it]{'loss': 0.5604, 'grad_norm': 1971.7943115234375, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.21334415674209595, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 1.17657470703125, 'epoch': 0.018654230512991338}
                                                   {'loss': 0.5604, 'grad_norm': 1971.7943115234375, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.21334415674209595, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 1.17657470703125, 'epoch': 0.02}
  2%|▏         | 70/3753 [04:58<4:14:02,  4.14s/it]  2%|▏         | 71/3753 [05:03<4:22:38,  4.28s/it]  2%|▏         | 72/3753 [05:07<4:28:22,  4.37s/it]  2%|▏         | 73/3753 [05:11<4:17:07,  4.19s/it]  2%|▏         | 74/3753 [05:15<4:08:38,  4.05s/it]  2%|▏         | 75/3753 [05:19<4:00:54,  3.93s/it]  2%|▏         | 76/3753 [05:23<4:14:48,  4.16s/it]  2%|▏         | 77/3753 [05:26<3:56:38,  3.86s/it]  2%|▏         | 78/3753 [05:31<4:14:20,  4.15s/it]  2%|▏         | 79/3753 [05:36<4:19:26,  4.24s/it]  2%|▏         | 80/3753 [05:41<4:33:30,  4.47s/it]{'loss': 0.3315, 'grad_norm': 1400.9471435546875, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 4.5544891357421875, 'mean_ratio_rejected': 3.7448770999908447, 'weight_chosen': 0.17035216093063354, 'weight_rejected': 0.10230471193790436, 'kl_term_chosen': 0.758056640625, 'epoch': 0.021319120586275817}
                                                   {'loss': 0.3315, 'grad_norm': 1400.9471435546875, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 4.5544891357421875, 'mean_ratio_rejected': 3.7448770999908447, 'weight_chosen': 0.17035216093063354, 'weight_rejected': 0.10230471193790436, 'kl_term_chosen': 0.758056640625, 'epoch': 0.02}
  2%|▏         | 80/3753 [05:41<4:33:30,  4.47s/it]  2%|▏         | 81/3753 [05:45<4:38:48,  4.56s/it]  2%|▏         | 82/3753 [05:49<4:24:50,  4.33s/it]  2%|▏         | 83/3753 [05:54<4:37:21,  4.53s/it]  2%|▏         | 84/3753 [05:59<4:43:21,  4.63s/it]  2%|▏         | 85/3753 [06:03<4:21:33,  4.28s/it]  2%|▏         | 86/3753 [06:06<4:04:32,  4.00s/it]  2%|▏         | 87/3753 [06:11<4:23:23,  4.31s/it]  2%|▏         | 88/3753 [06:15<4:14:37,  4.17s/it]  2%|▏         | 89/3753 [06:19<4:13:44,  4.16s/it]  2%|▏         | 90/3753 [06:23<4:13:46,  4.16s/it]{'loss': 1.0028, 'grad_norm': 1243.48046875, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.48423433303833, 'weight_rejected': 0.15002880990505219, 'kl_term_chosen': 2.273468017578125, 'epoch': 0.023984010659560292}
                                                   {'loss': 1.0028, 'grad_norm': 1243.48046875, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.48423433303833, 'weight_rejected': 0.15002880990505219, 'kl_term_chosen': 2.273468017578125, 'epoch': 0.02}
  2%|▏         | 90/3753 [06:23<4:13:46,  4.16s/it]  2%|▏         | 91/3753 [06:26<3:58:15,  3.90s/it]  2%|▏         | 92/3753 [06:30<3:59:03,  3.92s/it]  2%|▏         | 93/3753 [06:35<4:07:27,  4.06s/it]  3%|▎         | 94/3753 [06:39<4:01:42,  3.96s/it]  3%|▎         | 95/3753 [06:45<4:49:39,  4.75s/it]  3%|▎         | 96/3753 [06:49<4:38:25,  4.57s/it]  3%|▎         | 97/3753 [06:53<4:32:35,  4.47s/it]  3%|▎         | 98/3753 [06:59<4:56:59,  4.88s/it]  3%|▎         | 99/3753 [07:03<4:30:48,  4.45s/it]  3%|▎         | 100/3753 [07:06<4:15:58,  4.20s/it]{'loss': 1.2033, 'grad_norm': 2184.13232421875, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 2.4005415439605713, 'mean_ratio_rejected': 0.9007749557495117, 'weight_chosen': 0.19010406732559204, 'weight_rejected': 0.14414885640144348, 'kl_term_chosen': 0.4378471374511719, 'epoch': 0.02664890073284477}
                                                    {'loss': 1.2033, 'grad_norm': 2184.13232421875, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 2.4005415439605713, 'mean_ratio_rejected': 0.9007749557495117, 'weight_chosen': 0.19010406732559204, 'weight_rejected': 0.14414885640144348, 'kl_term_chosen': 0.4378471374511719, 'epoch': 0.03}
  3%|▎         | 100/3753 [07:06<4:15:58,  4.20s/it]  3%|▎         | 101/3753 [07:11<4:20:54,  4.29s/it]  3%|▎         | 102/3753 [07:15<4:18:07,  4.24s/it]  3%|▎         | 103/3753 [07:19<4:08:28,  4.08s/it]  3%|▎         | 104/3753 [07:24<4:36:35,  4.55s/it]  3%|▎         | 105/3753 [07:28<4:26:51,  4.39s/it]  3%|▎         | 106/3753 [07:34<4:43:13,  4.66s/it]  3%|▎         | 107/3753 [07:38<4:45:17,  4.69s/it]  3%|▎         | 108/3753 [07:42<4:32:42,  4.49s/it]  3%|▎         | 109/3753 [07:46<4:22:27,  4.32s/it]  3%|▎         | 110/3753 [07:50<4:15:11,  4.20s/it]{'loss': 0.2306, 'grad_norm': 1912.3814697265625, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 3.5235466957092285, 'mean_ratio_rejected': 7.838770866394043, 'weight_chosen': 0.28394246101379395, 'weight_rejected': 0.04146226868033409, 'kl_term_chosen': 0.6297340393066406, 'epoch': 0.029313790806129246}
                                                    {'loss': 0.2306, 'grad_norm': 1912.3814697265625, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 3.5235466957092285, 'mean_ratio_rejected': 7.838770866394043, 'weight_chosen': 0.28394246101379395, 'weight_rejected': 0.04146226868033409, 'kl_term_chosen': 0.6297340393066406, 'epoch': 0.03}
  3%|▎         | 110/3753 [07:50<4:15:11,  4.20s/it]  3%|▎         | 111/3753 [07:56<4:33:42,  4.51s/it]  3%|▎         | 112/3753 [07:59<4:22:32,  4.33s/it]  3%|▎         | 113/3753 [08:03<4:04:00,  4.02s/it]  3%|▎         | 114/3753 [08:06<3:55:33,  3.88s/it]  3%|▎         | 115/3753 [08:10<3:53:56,  3.86s/it]  3%|▎         | 116/3753 [08:14<4:03:19,  4.01s/it]  3%|▎         | 117/3753 [08:19<4:04:35,  4.04s/it]  3%|▎         | 118/3753 [08:23<4:12:43,  4.17s/it]  3%|▎         | 119/3753 [08:27<4:03:32,  4.02s/it]  3%|▎         | 120/3753 [08:31<4:12:07,  4.16s/it]{'loss': 0.9774, 'grad_norm': 2323.094970703125, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 1.6071410179138184, 'mean_ratio_rejected': 0.11893829703330994, 'weight_chosen': 0.5993261337280273, 'weight_rejected': 0.49502578377723694, 'kl_term_chosen': 0.2372283935546875, 'epoch': 0.031978680879413725}
                                                    {'loss': 0.9774, 'grad_norm': 2323.094970703125, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 1.6071410179138184, 'mean_ratio_rejected': 0.11893829703330994, 'weight_chosen': 0.5993261337280273, 'weight_rejected': 0.49502578377723694, 'kl_term_chosen': 0.2372283935546875, 'epoch': 0.03}
  3%|▎         | 120/3753 [08:31<4:12:07,  4.16s/it]  3%|▎         | 121/3753 [08:36<4:14:31,  4.20s/it]  3%|▎         | 122/3753 [08:40<4:19:19,  4.29s/it]  3%|▎         | 123/3753 [08:44<4:22:28,  4.34s/it]  3%|▎         | 124/3753 [08:48<4:14:59,  4.22s/it]  3%|▎         | 125/3753 [08:53<4:20:11,  4.30s/it]  3%|▎         | 126/3753 [08:58<4:30:46,  4.48s/it]  3%|▎         | 127/3753 [09:01<4:15:11,  4.22s/it]  3%|▎         | 128/3753 [09:06<4:17:49,  4.27s/it]  3%|▎         | 129/3753 [09:12<4:45:08,  4.72s/it]  3%|▎         | 130/3753 [09:16<4:42:00,  4.67s/it]{'loss': 0.654, 'grad_norm': 1062.0714111328125, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.8374841809272766, 'weight_chosen': -1.4737093448638916, 'weight_rejected': 0.10970578342676163, 'kl_term_chosen': 1.77117919921875, 'epoch': 0.034643570952698204}
                                                    {'loss': 0.654, 'grad_norm': 1062.0714111328125, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.8374841809272766, 'weight_chosen': -1.4737093448638916, 'weight_rejected': 0.10970578342676163, 'kl_term_chosen': 1.77117919921875, 'epoch': 0.03}
  3%|▎         | 130/3753 [09:16<4:42:00,  4.67s/it]  3%|▎         | 131/3753 [09:20<4:28:26,  4.45s/it]  4%|▎         | 132/3753 [09:23<4:07:43,  4.10s/it]  4%|▎         | 133/3753 [09:28<4:13:35,  4.20s/it]  4%|▎         | 134/3753 [09:32<4:18:49,  4.29s/it]  4%|▎         | 135/3753 [09:36<4:10:47,  4.16s/it]  4%|▎         | 136/3753 [09:40<3:59:31,  3.97s/it]  4%|▎         | 137/3753 [09:43<3:54:52,  3.90s/it]  4%|▎         | 138/3753 [09:48<4:05:58,  4.08s/it]  4%|▎         | 139/3753 [09:52<3:59:24,  3.97s/it]  4%|▎         | 140/3753 [09:56<4:13:59,  4.22s/it]{'loss': 0.5934, 'grad_norm': 1682.317626953125, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 1.25045907497406, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.747908353805542, 'weight_rejected': 0.14706450700759888, 'kl_term_chosen': 0.11175537109375, 'epoch': 0.037308461025982675}
                                                    {'loss': 0.5934, 'grad_norm': 1682.317626953125, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 1.25045907497406, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.747908353805542, 'weight_rejected': 0.14706450700759888, 'kl_term_chosen': 0.11175537109375, 'epoch': 0.04}
  4%|▎         | 140/3753 [09:57<4:13:59,  4.22s/it]  4%|▍         | 141/3753 [10:00<4:09:36,  4.15s/it]  4%|▍         | 142/3753 [10:05<4:26:00,  4.42s/it]  4%|▍         | 143/3753 [10:10<4:20:06,  4.32s/it]  4%|▍         | 144/3753 [10:15<4:47:22,  4.78s/it]  4%|▍         | 145/3753 [10:20<4:40:26,  4.66s/it]  4%|▍         | 146/3753 [10:25<4:46:21,  4.76s/it]  4%|▍         | 147/3753 [10:28<4:11:32,  4.19s/it]  4%|▍         | 148/3753 [10:33<4:24:27,  4.40s/it]  4%|▍         | 149/3753 [10:36<4:13:25,  4.22s/it]  4%|▍         | 150/3753 [10:41<4:14:20,  4.24s/it]{'loss': 1.4452, 'grad_norm': 1773.8948974609375, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 0.41550305485725403, 'mean_ratio_rejected': 0.2703399956226349, 'weight_chosen': 0.774592399597168, 'weight_rejected': 0.5903069972991943, 'kl_term_chosen': -0.4391326904296875, 'epoch': 0.039973351099267154}
                                                    {'loss': 1.4452, 'grad_norm': 1773.8948974609375, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 0.41550305485725403, 'mean_ratio_rejected': 0.2703399956226349, 'weight_chosen': 0.774592399597168, 'weight_rejected': 0.5903069972991943, 'kl_term_chosen': -0.4391326904296875, 'epoch': 0.04}
  4%|▍         | 150/3753 [10:41<4:14:20,  4.24s/it]  4%|▍         | 151/3753 [10:46<4:28:18,  4.47s/it]  4%|▍         | 152/3753 [10:50<4:20:20,  4.34s/it]  4%|▍         | 153/3753 [10:54<4:25:53,  4.43s/it]  4%|▍         | 154/3753 [10:59<4:24:39,  4.41s/it]  4%|▍         | 155/3753 [11:03<4:18:29,  4.31s/it]  4%|▍         | 156/3753 [11:07<4:17:08,  4.29s/it]  4%|▍         | 157/3753 [11:11<4:09:17,  4.16s/it]  4%|▍         | 158/3753 [11:15<4:16:32,  4.28s/it]  4%|▍         | 159/3753 [11:19<4:11:35,  4.20s/it]  4%|▍         | 160/3753 [11:24<4:14:34,  4.25s/it]{'loss': 1.19, 'grad_norm': 3049.799072265625, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 7.739293575286865, 'mean_ratio_rejected': 2.231123924255371, 'weight_chosen': -0.34312593936920166, 'weight_rejected': 0.3372035324573517, 'kl_term_chosen': 1.0231552124023438, 'epoch': 0.04263824117255163}
                                                    {'loss': 1.19, 'grad_norm': 3049.799072265625, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 7.739293575286865, 'mean_ratio_rejected': 2.231123924255371, 'weight_chosen': -0.34312593936920166, 'weight_rejected': 0.3372035324573517, 'kl_term_chosen': 1.0231552124023438, 'epoch': 0.04}
  4%|▍         | 160/3753 [11:24<4:14:34,  4.25s/it]  4%|▍         | 161/3753 [11:28<4:06:20,  4.11s/it]  4%|▍         | 162/3753 [11:32<4:05:42,  4.11s/it]  4%|▍         | 163/3753 [11:35<3:53:55,  3.91s/it]  4%|▍         | 164/3753 [11:41<4:22:10,  4.38s/it]  4%|▍         | 165/3753 [11:45<4:26:21,  4.45s/it]  4%|▍         | 166/3753 [11:49<4:07:17,  4.14s/it]  4%|▍         | 167/3753 [11:53<4:20:18,  4.36s/it]  4%|▍         | 168/3753 [11:59<4:34:07,  4.59s/it]  5%|▍         | 169/3753 [12:02<4:15:41,  4.28s/it]  5%|▍         | 170/3753 [12:05<3:57:52,  3.98s/it]{'loss': 0.8199, 'grad_norm': 1666.4461669921875, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 2.9423046112060547, 'mean_ratio_rejected': 1.5605016946792603, 'weight_chosen': 0.3327507972717285, 'weight_rejected': 0.13568955659866333, 'kl_term_chosen': 0.5395965576171875, 'epoch': 0.04530313124583611}
                                                    {'loss': 0.8199, 'grad_norm': 1666.4461669921875, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 2.9423046112060547, 'mean_ratio_rejected': 1.5605016946792603, 'weight_chosen': 0.3327507972717285, 'weight_rejected': 0.13568955659866333, 'kl_term_chosen': 0.5395965576171875, 'epoch': 0.05}
  5%|▍         | 170/3753 [12:06<3:57:52,  3.98s/it]  5%|▍         | 171/3753 [12:10<4:07:43,  4.15s/it]  5%|▍         | 172/3753 [12:14<4:13:00,  4.24s/it]  5%|▍         | 173/3753 [12:18<4:07:47,  4.15s/it]  5%|▍         | 174/3753 [12:23<4:10:52,  4.21s/it]  5%|▍         | 175/3753 [12:27<4:14:28,  4.27s/it]  5%|▍         | 176/3753 [12:31<4:00:43,  4.04s/it]  5%|▍         | 177/3753 [12:35<4:06:58,  4.14s/it]  5%|▍         | 178/3753 [12:40<4:18:11,  4.33s/it]  5%|▍         | 179/3753 [12:43<4:02:51,  4.08s/it]  5%|▍         | 180/3753 [12:47<4:04:22,  4.10s/it]{'loss': 1.4121, 'grad_norm': 2238.92041015625, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 4.17834997177124, 'mean_ratio_rejected': 8.665217399597168, 'weight_chosen': 0.2203882932662964, 'weight_rejected': 0.09268777817487717, 'kl_term_chosen': 0.7149581909179688, 'epoch': 0.047968021319120584}
                                                    {'loss': 1.4121, 'grad_norm': 2238.92041015625, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 4.17834997177124, 'mean_ratio_rejected': 8.665217399597168, 'weight_chosen': 0.2203882932662964, 'weight_rejected': 0.09268777817487717, 'kl_term_chosen': 0.7149581909179688, 'epoch': 0.05}
  5%|▍         | 180/3753 [12:48<4:04:22,  4.10s/it]  5%|▍         | 181/3753 [12:52<4:11:57,  4.23s/it]  5%|▍         | 182/3753 [12:58<4:46:37,  4.82s/it]  5%|▍         | 183/3753 [13:03<4:41:21,  4.73s/it]  5%|▍         | 184/3753 [13:08<4:50:36,  4.89s/it]  5%|▍         | 185/3753 [13:13<4:47:53,  4.84s/it]  5%|▍         | 186/3753 [13:17<4:33:41,  4.60s/it]  5%|▍         | 187/3753 [13:21<4:21:17,  4.40s/it]  5%|▌         | 188/3753 [13:25<4:12:39,  4.25s/it]  5%|▌         | 189/3753 [13:31<4:45:55,  4.81s/it]  5%|▌         | 190/3753 [13:35<4:36:49,  4.66s/it]{'loss': 0.6447, 'grad_norm': 1294.99755859375, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 7.943282604217529, 'mean_ratio_rejected': 0.11562070995569229, 'weight_chosen': -0.15536624193191528, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 1.036163330078125, 'epoch': 0.05063291139240506}
                                                    {'loss': 0.6447, 'grad_norm': 1294.99755859375, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 7.943282604217529, 'mean_ratio_rejected': 0.11562070995569229, 'weight_chosen': -0.15536624193191528, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 1.036163330078125, 'epoch': 0.05}
  5%|▌         | 190/3753 [13:35<4:36:49,  4.66s/it]  5%|▌         | 191/3753 [13:39<4:21:05,  4.40s/it]  5%|▌         | 192/3753 [13:42<4:04:16,  4.12s/it]  5%|▌         | 193/3753 [13:46<4:03:19,  4.10s/it]  5%|▌         | 194/3753 [13:51<4:20:49,  4.40s/it]  5%|▌         | 195/3753 [13:56<4:18:29,  4.36s/it]  5%|▌         | 196/3753 [13:59<4:02:50,  4.10s/it]  5%|▌         | 197/3753 [14:05<4:32:53,  4.60s/it]  5%|▌         | 198/3753 [14:09<4:20:11,  4.39s/it]  5%|▌         | 199/3753 [14:14<4:33:22,  4.62s/it]  5%|▌         | 200/3753 [14:18<4:31:22,  4.58s/it]{'loss': 1.7696, 'grad_norm': 2395.972412109375, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.7217681407928467, 'weight_chosen': -1.0648921728134155, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 2.00823974609375, 'epoch': 0.05329780146568954}
                                                    {'loss': 1.7696, 'grad_norm': 2395.972412109375, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.7217681407928467, 'weight_chosen': -1.0648921728134155, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 2.00823974609375, 'epoch': 0.05}
  5%|▌         | 200/3753 [14:19<4:31:22,  4.58s/it]  5%|▌         | 201/3753 [14:23<4:24:59,  4.48s/it]  5%|▌         | 202/3753 [14:26<4:10:30,  4.23s/it]  5%|▌         | 203/3753 [14:30<4:07:11,  4.18s/it]  5%|▌         | 204/3753 [14:34<3:57:26,  4.01s/it]  5%|▌         | 205/3753 [14:38<3:51:22,  3.91s/it]  5%|▌         | 206/3753 [14:43<4:20:19,  4.40s/it]  6%|▌         | 207/3753 [14:47<4:13:03,  4.28s/it]  6%|▌         | 208/3753 [14:52<4:26:18,  4.51s/it]  6%|▌         | 209/3753 [14:56<4:20:11,  4.41s/it]  6%|▌         | 210/3753 [15:01<4:21:07,  4.42s/it]{'loss': 1.8001, 'grad_norm': 1110.85107421875, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 1.601131796836853, 'mean_ratio_rejected': 1.3019790649414062, 'weight_chosen': 0.5833814144134521, 'weight_rejected': 0.15304215252399445, 'kl_term_chosen': 0.23535537719726562, 'epoch': 0.05596269153897402}
                                                    {'loss': 1.8001, 'grad_norm': 1110.85107421875, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 1.601131796836853, 'mean_ratio_rejected': 1.3019790649414062, 'weight_chosen': 0.5833814144134521, 'weight_rejected': 0.15304215252399445, 'kl_term_chosen': 0.23535537719726562, 'epoch': 0.06}
  6%|▌         | 210/3753 [15:01<4:21:07,  4.42s/it]  6%|▌         | 211/3753 [15:06<4:34:56,  4.66s/it]  6%|▌         | 212/3753 [15:10<4:19:11,  4.39s/it]  6%|▌         | 213/3753 [15:14<4:20:33,  4.42s/it]  6%|▌         | 214/3753 [15:20<4:44:06,  4.82s/it]  6%|▌         | 215/3753 [15:24<4:29:41,  4.57s/it]  6%|▌         | 216/3753 [15:28<4:23:01,  4.46s/it]  6%|▌         | 217/3753 [15:32<4:08:21,  4.21s/it]  6%|▌         | 218/3753 [15:37<4:20:19,  4.42s/it]  6%|▌         | 219/3753 [15:41<4:07:46,  4.21s/it]  6%|▌         | 220/3753 [15:44<3:59:46,  4.07s/it]{'loss': 0.7952, 'grad_norm': 1506.220947265625, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 0.7940401434898376, 'mean_ratio_rejected': 0.25124356150627136, 'weight_chosen': 0.7970374822616577, 'weight_rejected': 0.1200256198644638, 'kl_term_chosen': -0.1153106689453125, 'epoch': 0.05862758161225849}
                                                    {'loss': 0.7952, 'grad_norm': 1506.220947265625, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 0.7940401434898376, 'mean_ratio_rejected': 0.25124356150627136, 'weight_chosen': 0.7970374822616577, 'weight_rejected': 0.1200256198644638, 'kl_term_chosen': -0.1153106689453125, 'epoch': 0.06}
  6%|▌         | 220/3753 [15:44<3:59:46,  4.07s/it]  6%|▌         | 221/3753 [15:48<3:52:39,  3.95s/it]  6%|▌         | 222/3753 [15:52<3:56:16,  4.01s/it]  6%|▌         | 223/3753 [15:56<3:50:10,  3.91s/it]  6%|▌         | 224/3753 [16:00<3:47:57,  3.88s/it]  6%|▌         | 225/3753 [16:04<3:55:40,  4.01s/it]  6%|▌         | 226/3753 [16:08<3:50:36,  3.92s/it]  6%|▌         | 227/3753 [16:13<4:13:41,  4.32s/it]  6%|▌         | 228/3753 [16:16<3:59:06,  4.07s/it]  6%|▌         | 229/3753 [16:21<4:12:14,  4.29s/it]  6%|▌         | 230/3753 [16:27<4:38:09,  4.74s/it]{'loss': 1.7564, 'grad_norm': 1431.741943359375, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 0.9955695271492004, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.9394309520721436, 'weight_rejected': 0.1490352898836136, 'kl_term_chosen': -0.00222015380859375, 'epoch': 0.06129247168554297}
                                                    {'loss': 1.7564, 'grad_norm': 1431.741943359375, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 0.9955695271492004, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.9394309520721436, 'weight_rejected': 0.1490352898836136, 'kl_term_chosen': -0.00222015380859375, 'epoch': 0.06}
  6%|▌         | 230/3753 [16:27<4:38:09,  4.74s/it]  6%|▌         | 231/3753 [16:31<4:29:15,  4.59s/it]  6%|▌         | 232/3753 [16:35<4:21:40,  4.46s/it]  6%|▌         | 233/3753 [16:40<4:25:59,  4.53s/it]  6%|▌         | 234/3753 [16:45<4:40:49,  4.79s/it]  6%|▋         | 235/3753 [16:50<4:34:06,  4.68s/it]  6%|▋         | 236/3753 [16:54<4:24:33,  4.51s/it]  6%|▋         | 237/3753 [16:57<4:05:58,  4.20s/it]  6%|▋         | 238/3753 [17:02<4:06:03,  4.20s/it]  6%|▋         | 239/3753 [17:07<4:17:01,  4.39s/it]  6%|▋         | 240/3753 [17:12<4:27:57,  4.58s/it]{'loss': 1.6583, 'grad_norm': 1671.48583984375, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 1.3733396530151367, 'mean_ratio_rejected': 0.3820266127586365, 'weight_chosen': 0.6725202798843384, 'weight_rejected': 0.17781086266040802, 'kl_term_chosen': 0.15862274169921875, 'epoch': 0.06395736175882745}
                                                    {'loss': 1.6583, 'grad_norm': 1671.48583984375, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 1.3733396530151367, 'mean_ratio_rejected': 0.3820266127586365, 'weight_chosen': 0.6725202798843384, 'weight_rejected': 0.17781086266040802, 'kl_term_chosen': 0.15862274169921875, 'epoch': 0.06}
  6%|▋         | 240/3753 [17:12<4:27:57,  4.58s/it]  6%|▋         | 241/3753 [17:15<4:16:00,  4.37s/it]  6%|▋         | 242/3753 [17:20<4:13:57,  4.34s/it]  6%|▋         | 243/3753 [17:24<4:14:58,  4.36s/it]  7%|▋         | 244/3753 [17:28<4:15:12,  4.36s/it]  7%|▋         | 245/3753 [17:33<4:12:27,  4.32s/it]  7%|▋         | 246/3753 [17:36<4:01:53,  4.14s/it]  7%|▋         | 247/3753 [17:41<4:03:41,  4.17s/it]  7%|▋         | 248/3753 [17:44<3:46:19,  3.87s/it]  7%|▋         | 249/3753 [17:49<4:03:30,  4.17s/it]  7%|▋         | 250/3753 [17:54<4:22:23,  4.49s/it]{'loss': 1.4364, 'grad_norm': 1962.7674560546875, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 3.9612371921539307, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.2065112590789795, 'weight_rejected': 0.14804719388484955, 'kl_term_chosen': 0.6882781982421875, 'epoch': 0.06662225183211193}
                                                    {'loss': 1.4364, 'grad_norm': 1962.7674560546875, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 3.9612371921539307, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.2065112590789795, 'weight_rejected': 0.14804719388484955, 'kl_term_chosen': 0.6882781982421875, 'epoch': 0.07}
  7%|▋         | 250/3753 [17:54<4:22:23,  4.49s/it]  7%|▋         | 251/3753 [18:00<4:47:44,  4.93s/it]  7%|▋         | 252/3753 [18:05<4:49:40,  4.96s/it]  7%|▋         | 253/3753 [18:10<4:46:42,  4.91s/it]  7%|▋         | 254/3753 [18:13<4:20:55,  4.47s/it]  7%|▋         | 255/3753 [18:17<4:10:23,  4.29s/it]  7%|▋         | 256/3753 [18:21<3:58:20,  4.09s/it]  7%|▋         | 257/3753 [18:25<4:05:23,  4.21s/it]  7%|▋         | 258/3753 [18:29<3:59:36,  4.11s/it]  7%|▋         | 259/3753 [18:33<3:49:12,  3.94s/it]  7%|▋         | 260/3753 [18:37<4:02:19,  4.16s/it]{'loss': 2.2046, 'grad_norm': 1850.831787109375, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 0.4753890037536621, 'mean_ratio_rejected': 2.1003329753875732, 'weight_chosen': 1.2590155601501465, 'weight_rejected': 0.13386748731136322, 'kl_term_chosen': -0.3718109130859375, 'epoch': 0.06928714190539641}
                                                    {'loss': 2.2046, 'grad_norm': 1850.831787109375, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 0.4753890037536621, 'mean_ratio_rejected': 2.1003329753875732, 'weight_chosen': 1.2590155601501465, 'weight_rejected': 0.13386748731136322, 'kl_term_chosen': -0.3718109130859375, 'epoch': 0.07}
  7%|▋         | 260/3753 [18:37<4:02:19,  4.16s/it]  7%|▋         | 261/3753 [18:42<4:06:46,  4.24s/it]  7%|▋         | 262/3753 [18:46<4:06:36,  4.24s/it]  7%|▋         | 263/3753 [18:51<4:15:49,  4.40s/it]  7%|▋         | 264/3753 [18:55<4:08:04,  4.27s/it]  7%|▋         | 265/3753 [18:59<4:03:31,  4.19s/it]  7%|▋         | 266/3753 [19:02<3:55:26,  4.05s/it]  7%|▋         | 267/3753 [19:06<3:50:48,  3.97s/it]  7%|▋         | 268/3753 [19:11<4:09:42,  4.30s/it]  7%|▋         | 269/3753 [19:15<3:56:30,  4.07s/it]  7%|▋         | 270/3753 [19:19<4:03:49,  4.20s/it]{'loss': 1.5914, 'grad_norm': 1001.1183471679688, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.1715483665466309, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': 2.147125244140625, 'epoch': 0.07195203197868089}
                                                    {'loss': 1.5914, 'grad_norm': 1001.1183471679688, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.1715483665466309, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': 2.147125244140625, 'epoch': 0.07}
  7%|▋         | 270/3753 [19:19<4:03:49,  4.20s/it]  7%|▋         | 271/3753 [19:24<4:11:14,  4.33s/it]  7%|▋         | 272/3753 [19:28<4:10:26,  4.32s/it]  7%|▋         | 273/3753 [19:32<3:56:26,  4.08s/it]  7%|▋         | 274/3753 [19:36<3:54:11,  4.04s/it]  7%|▋         | 275/3753 [19:40<3:53:52,  4.03s/it]  7%|▋         | 276/3753 [19:43<3:46:02,  3.90s/it]  7%|▋         | 277/3753 [19:48<3:58:15,  4.11s/it]  7%|▋         | 278/3753 [19:51<3:43:56,  3.87s/it]  7%|▋         | 279/3753 [19:56<3:57:59,  4.11s/it]  7%|▋         | 280/3753 [20:01<4:14:03,  4.39s/it]{'loss': 2.8368, 'grad_norm': 946.3424072265625, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.3719675540924072, 'weight_rejected': 0.07263670116662979, 'kl_term_chosen': -1.4415092468261719, 'epoch': 0.07461692205196535}
                                                    {'loss': 2.8368, 'grad_norm': 946.3424072265625, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.3719675540924072, 'weight_rejected': 0.07263670116662979, 'kl_term_chosen': -1.4415092468261719, 'epoch': 0.07}
  7%|▋         | 280/3753 [20:01<4:14:03,  4.39s/it]  7%|▋         | 281/3753 [20:05<4:07:07,  4.27s/it]  8%|▊         | 282/3753 [20:10<4:19:22,  4.48s/it]  8%|▊         | 283/3753 [20:14<4:14:13,  4.40s/it]  8%|▊         | 284/3753 [20:18<4:08:16,  4.29s/it]  8%|▊         | 285/3753 [20:24<4:36:02,  4.78s/it]  8%|▊         | 286/3753 [20:28<4:21:27,  4.52s/it]  8%|▊         | 287/3753 [20:32<4:07:18,  4.28s/it]  8%|▊         | 288/3753 [20:36<4:11:06,  4.35s/it]  8%|▊         | 289/3753 [20:41<4:15:27,  4.42s/it]  8%|▊         | 290/3753 [20:47<4:38:33,  4.83s/it]{'loss': 3.7484, 'grad_norm': 2614.4287109375, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 0.6211225986480713, 'mean_ratio_rejected': 0.16709637641906738, 'weight_chosen': 0.991580069065094, 'weight_rejected': 0.20946967601776123, 'kl_term_chosen': -0.2381134033203125, 'epoch': 0.07728181212524983}
                                                    {'loss': 3.7484, 'grad_norm': 2614.4287109375, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 0.6211225986480713, 'mean_ratio_rejected': 0.16709637641906738, 'weight_chosen': 0.991580069065094, 'weight_rejected': 0.20946967601776123, 'kl_term_chosen': -0.2381134033203125, 'epoch': 0.08}
  8%|▊         | 290/3753 [20:47<4:38:33,  4.83s/it]  8%|▊         | 291/3753 [20:50<4:20:46,  4.52s/it]  8%|▊         | 292/3753 [20:56<4:34:53,  4.77s/it]  8%|▊         | 293/3753 [20:59<4:15:16,  4.43s/it]  8%|▊         | 294/3753 [21:03<4:10:49,  4.35s/it]  8%|▊         | 295/3753 [21:08<4:18:30,  4.49s/it]  8%|▊         | 296/3753 [21:12<4:05:47,  4.27s/it]  8%|▊         | 297/3753 [21:17<4:12:45,  4.39s/it]  8%|▊         | 298/3753 [21:22<4:29:03,  4.67s/it]  8%|▊         | 299/3753 [21:26<4:24:46,  4.60s/it]  8%|▊         | 300/3753 [21:31<4:15:00,  4.43s/it]{'loss': 2.5712, 'grad_norm': 1276.855224609375, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.5070714950561523, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 2.43121337890625, 'epoch': 0.07994670219853431}
                                                    {'loss': 2.5712, 'grad_norm': 1276.855224609375, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.5070714950561523, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 2.43121337890625, 'epoch': 0.08}
  8%|▊         | 300/3753 [21:31<4:15:00,  4.43s/it]  8%|▊         | 301/3753 [21:35<4:09:33,  4.34s/it]  8%|▊         | 302/3753 [21:40<4:21:22,  4.54s/it]  8%|▊         | 303/3753 [21:44<4:24:19,  4.60s/it]  8%|▊         | 304/3753 [21:47<3:57:34,  4.13s/it]  8%|▊         | 305/3753 [21:51<3:56:12,  4.11s/it]  8%|▊         | 306/3753 [21:55<3:51:23,  4.03s/it]  8%|▊         | 307/3753 [22:00<3:57:28,  4.13s/it]  8%|▊         | 308/3753 [22:05<4:12:54,  4.40s/it]  8%|▊         | 309/3753 [22:09<4:14:14,  4.43s/it]  8%|▊         | 310/3753 [22:13<4:06:28,  4.30s/it]{'loss': 3.9355, 'grad_norm': 1793.9176025390625, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.5187920331954956, 'weight_chosen': -0.6670920252799988, 'weight_rejected': 0.22815649211406708, 'kl_term_chosen': 1.3307609558105469, 'epoch': 0.08261159227181879}
                                                    {'loss': 3.9355, 'grad_norm': 1793.9176025390625, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.5187920331954956, 'weight_chosen': -0.6670920252799988, 'weight_rejected': 0.22815649211406708, 'kl_term_chosen': 1.3307609558105469, 'epoch': 0.08}
  8%|▊         | 310/3753 [22:13<4:06:28,  4.30s/it]  8%|▊         | 311/3753 [22:18<4:08:39,  4.33s/it]  8%|▊         | 312/3753 [22:22<4:01:01,  4.20s/it]  8%|▊         | 313/3753 [22:26<4:02:06,  4.22s/it]  8%|▊         | 314/3753 [22:31<4:21:44,  4.57s/it]  8%|▊         | 315/3753 [22:35<4:05:02,  4.28s/it]  8%|▊         | 316/3753 [22:38<3:55:07,  4.10s/it]  8%|▊         | 317/3753 [22:42<3:51:49,  4.05s/it]  8%|▊         | 318/3753 [22:47<3:58:01,  4.16s/it]  8%|▊         | 319/3753 [22:51<4:00:21,  4.20s/it]  9%|▊         | 320/3753 [22:56<4:07:49,  4.33s/it]{'loss': 3.5732, 'grad_norm': 1964.6253662109375, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.9175761938095093, 'weight_chosen': -0.4900047779083252, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': 1.427215576171875, 'epoch': 0.08527648234510327}
                                                    {'loss': 3.5732, 'grad_norm': 1964.6253662109375, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.9175761938095093, 'weight_chosen': -0.4900047779083252, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': 1.427215576171875, 'epoch': 0.09}
  9%|▊         | 320/3753 [22:56<4:07:49,  4.33s/it]  9%|▊         | 321/3753 [23:00<4:09:13,  4.36s/it]  9%|▊         | 322/3753 [23:04<4:02:33,  4.24s/it]  9%|▊         | 323/3753 [23:07<3:47:05,  3.97s/it]  9%|▊         | 324/3753 [23:13<4:13:45,  4.44s/it]  9%|▊         | 325/3753 [23:17<4:11:25,  4.40s/it]  9%|▊         | 326/3753 [23:21<3:57:16,  4.15s/it]  9%|▊         | 327/3753 [23:25<3:57:02,  4.15s/it]  9%|▊         | 328/3753 [23:29<3:50:56,  4.05s/it]  9%|▉         | 329/3753 [23:33<3:56:02,  4.14s/it]  9%|▉         | 330/3753 [23:38<4:12:31,  4.43s/it]{'loss': 5.4134, 'grad_norm': 745.2462158203125, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 5.733567714691162, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.011630713939666748, 'weight_rejected': 0.22135066986083984, 'kl_term_chosen': 0.8731689453125, 'epoch': 0.08794137241838774}
                                                    {'loss': 5.4134, 'grad_norm': 745.2462158203125, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 5.733567714691162, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.011630713939666748, 'weight_rejected': 0.22135066986083984, 'kl_term_chosen': 0.8731689453125, 'epoch': 0.09}
  9%|▉         | 330/3753 [23:38<4:12:31,  4.43s/it]  9%|▉         | 331/3753 [23:42<4:04:10,  4.28s/it]  9%|▉         | 332/3753 [23:46<3:56:56,  4.16s/it]  9%|▉         | 333/3753 [23:50<4:00:57,  4.23s/it]  9%|▉         | 334/3753 [23:55<4:00:52,  4.23s/it]  9%|▉         | 335/3753 [23:59<4:09:14,  4.38s/it]  9%|▉         | 336/3753 [24:03<3:55:28,  4.13s/it]  9%|▉         | 337/3753 [24:08<4:02:16,  4.26s/it]  9%|▉         | 338/3753 [24:11<3:47:33,  4.00s/it]  9%|▉         | 339/3753 [24:14<3:39:56,  3.87s/it]  9%|▉         | 340/3753 [24:19<3:46:27,  3.98s/it]{'loss': 6.0851, 'grad_norm': 1893.551025390625, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.4899269342422485, 'weight_rejected': 0.7826625108718872, 'kl_term_chosen': -1.2462844848632812, 'epoch': 0.09060626249167222}
                                                    {'loss': 6.0851, 'grad_norm': 1893.551025390625, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.4899269342422485, 'weight_rejected': 0.7826625108718872, 'kl_term_chosen': -1.2462844848632812, 'epoch': 0.09}
  9%|▉         | 340/3753 [24:19<3:46:27,  3.98s/it]  9%|▉         | 341/3753 [24:23<3:45:30,  3.97s/it]  9%|▉         | 342/3753 [24:27<3:46:01,  3.98s/it]  9%|▉         | 343/3753 [24:31<3:54:12,  4.12s/it]  9%|▉         | 344/3753 [24:35<3:50:21,  4.05s/it]  9%|▉         | 345/3753 [24:40<4:11:09,  4.42s/it]  9%|▉         | 346/3753 [24:44<4:06:13,  4.34s/it]  9%|▉         | 347/3753 [24:49<4:12:11,  4.44s/it]  9%|▉         | 348/3753 [24:54<4:24:30,  4.66s/it]  9%|▉         | 349/3753 [24:58<4:07:21,  4.36s/it]  9%|▉         | 350/3753 [25:02<4:08:39,  4.38s/it]{'loss': 7.6605, 'grad_norm': 698.5905151367188, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 0.45020607113838196, 'mean_ratio_rejected': 4.98589563369751, 'weight_chosen': 1.2334318161010742, 'weight_rejected': 0.2186693549156189, 'kl_term_chosen': -0.39902496337890625, 'epoch': 0.09327115256495669}
                                                    {'loss': 7.6605, 'grad_norm': 698.5905151367188, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 0.45020607113838196, 'mean_ratio_rejected': 4.98589563369751, 'weight_chosen': 1.2334318161010742, 'weight_rejected': 0.2186693549156189, 'kl_term_chosen': -0.39902496337890625, 'epoch': 0.09}
  9%|▉         | 350/3753 [25:03<4:08:39,  4.38s/it]  9%|▉         | 351/3753 [25:06<4:00:58,  4.25s/it]  9%|▉         | 352/3753 [25:10<3:46:04,  3.99s/it]  9%|▉         | 353/3753 [25:14<3:51:16,  4.08s/it]  9%|▉         | 354/3753 [25:18<3:54:14,  4.13s/it]  9%|▉         | 355/3753 [25:23<4:07:46,  4.38s/it]  9%|▉         | 356/3753 [25:27<4:04:16,  4.31s/it] 10%|▉         | 357/3753 [25:32<4:03:05,  4.29s/it] 10%|▉         | 358/3753 [25:36<4:07:51,  4.38s/it] 10%|▉         | 359/3753 [25:40<4:03:01,  4.30s/it] 10%|▉         | 360/3753 [25:44<3:52:59,  4.12s/it]{'loss': 6.7093, 'grad_norm': 1514.8995361328125, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.15126334130764008, 'weight_chosen': -0.7125380039215088, 'weight_rejected': 0.16667540371418, 'kl_term_chosen': 1.2568550109863281, 'epoch': 0.09593604263824117}
                                                    {'loss': 6.7093, 'grad_norm': 1514.8995361328125, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.15126334130764008, 'weight_chosen': -0.7125380039215088, 'weight_rejected': 0.16667540371418, 'kl_term_chosen': 1.2568550109863281, 'epoch': 0.1}
 10%|▉         | 360/3753 [25:44<3:52:59,  4.12s/it] 10%|▉         | 361/3753 [25:48<3:58:44,  4.22s/it] 10%|▉         | 362/3753 [25:53<3:58:58,  4.23s/it] 10%|▉         | 363/3753 [25:57<4:00:49,  4.26s/it] 10%|▉         | 364/3753 [26:02<4:04:13,  4.32s/it] 10%|▉         | 365/3753 [26:05<3:45:28,  3.99s/it] 10%|▉         | 366/3753 [26:08<3:36:16,  3.83s/it] 10%|▉         | 367/3753 [26:12<3:38:36,  3.87s/it] 10%|▉         | 368/3753 [26:17<3:58:04,  4.22s/it] 10%|▉         | 369/3753 [26:22<4:02:12,  4.29s/it] 10%|▉         | 370/3753 [26:26<3:59:47,  4.25s/it]{'loss': 6.5611, 'grad_norm': 725.2748413085938, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 1.1952555179595947, 'weight_chosen': 3.6227829456329346, 'weight_rejected': 0.20561504364013672, 'kl_term_chosen': -2.758472442626953, 'epoch': 0.09860093271152565}
                                                    {'loss': 6.5611, 'grad_norm': 725.2748413085938, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 1.1952555179595947, 'weight_chosen': 3.6227829456329346, 'weight_rejected': 0.20561504364013672, 'kl_term_chosen': -2.758472442626953, 'epoch': 0.1}
 10%|▉         | 370/3753 [26:26<3:59:47,  4.25s/it] 10%|▉         | 371/3753 [26:29<3:46:18,  4.01s/it] 10%|▉         | 372/3753 [26:34<3:56:53,  4.20s/it] 10%|▉         | 373/3753 [26:38<3:49:24,  4.07s/it] 10%|▉         | 374/3753 [26:42<3:56:20,  4.20s/it] 10%|▉         | 375/3753 [26:48<4:16:52,  4.56s/it] 10%|█         | 376/3753 [26:53<4:26:04,  4.73s/it] 10%|█         | 377/3753 [26:57<4:18:16,  4.59s/it] 10%|█         | 378/3753 [27:00<3:58:15,  4.24s/it] 10%|█         | 379/3753 [27:04<3:43:02,  3.97s/it] 10%|█         | 380/3753 [27:09<3:56:44,  4.21s/it]{'loss': 9.6621, 'grad_norm': 803.9131469726562, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.5489619374275208, 'weight_rejected': 0.02595735713839531, 'kl_term_chosen': 1.5093231201171875, 'epoch': 0.10126582278481013}
                                                    {'loss': 9.6621, 'grad_norm': 803.9131469726562, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.5489619374275208, 'weight_rejected': 0.02595735713839531, 'kl_term_chosen': 1.5093231201171875, 'epoch': 0.1}
 10%|█         | 380/3753 [27:09<3:56:44,  4.21s/it] 10%|█         | 381/3753 [27:13<3:56:15,  4.20s/it] 10%|█         | 382/3753 [27:17<3:55:54,  4.20s/it] 10%|█         | 383/3753 [27:21<3:51:06,  4.11s/it] 10%|█         | 384/3753 [27:26<4:08:34,  4.43s/it] 10%|█         | 385/3753 [27:31<4:22:11,  4.67s/it] 10%|█         | 386/3753 [27:35<4:06:14,  4.39s/it] 10%|█         | 387/3753 [27:39<4:03:28,  4.34s/it] 10%|█         | 388/3753 [27:43<4:02:51,  4.33s/it] 10%|█         | 389/3753 [27:48<4:04:37,  4.36s/it] 10%|█         | 390/3753 [27:52<4:04:50,  4.37s/it]{'loss': 13.4585, 'grad_norm': 1638.77294921875, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.1016478538513184, 'weight_rejected': 0.8164063692092896, 'kl_term_chosen': -2.4628124237060547, 'epoch': 0.1039307128580946}
                                                    {'loss': 13.4585, 'grad_norm': 1638.77294921875, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.1016478538513184, 'weight_rejected': 0.8164063692092896, 'kl_term_chosen': -2.4628124237060547, 'epoch': 0.1}
 10%|█         | 390/3753 [27:52<4:04:50,  4.37s/it] 10%|█         | 391/3753 [27:57<4:08:28,  4.43s/it] 10%|█         | 392/3753 [28:01<3:59:24,  4.27s/it] 10%|█         | 393/3753 [28:05<3:59:59,  4.29s/it] 10%|█         | 394/3753 [28:09<3:59:56,  4.29s/it] 11%|█         | 395/3753 [28:14<4:05:36,  4.39s/it] 11%|█         | 396/3753 [28:18<4:07:03,  4.42s/it] 11%|█         | 397/3753 [28:22<3:52:15,  4.15s/it] 11%|█         | 398/3753 [28:26<3:50:21,  4.12s/it] 11%|█         | 399/3753 [28:31<3:57:29,  4.25s/it] 11%|█         | 400/3753 [28:35<3:52:54,  4.17s/it]{'loss': 4.5564, 'grad_norm': 446.6420593261719, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 7.000543117523193, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.2778627276420593, 'weight_rejected': 0.25091278553009033, 'kl_term_chosen': 0.9729938507080078, 'epoch': 0.10659560293137908}
                                                    {'loss': 4.5564, 'grad_norm': 446.6420593261719, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 7.000543117523193, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.2778627276420593, 'weight_rejected': 0.25091278553009033, 'kl_term_chosen': 0.9729938507080078, 'epoch': 0.11}
 11%|█         | 400/3753 [28:35<3:52:54,  4.17s/it] 11%|█         | 401/3753 [28:39<3:50:09,  4.12s/it] 11%|█         | 402/3753 [28:43<4:02:31,  4.34s/it] 11%|█         | 403/3753 [28:47<3:45:17,  4.03s/it] 11%|█         | 404/3753 [28:51<3:45:37,  4.04s/it] 11%|█         | 405/3753 [28:55<3:52:48,  4.17s/it] 11%|█         | 406/3753 [28:59<3:52:27,  4.17s/it] 11%|█         | 407/3753 [29:03<3:46:18,  4.06s/it] 11%|█         | 408/3753 [29:08<4:03:50,  4.37s/it] 11%|█         | 409/3753 [29:12<3:58:51,  4.29s/it] 11%|█         | 410/3753 [29:17<4:00:19,  4.31s/it]{'loss': 6.4778, 'grad_norm': 1001.5651245117188, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 12.956389427185059, 'weight_rejected': 0.28776782751083374, 'kl_term_chosen': -12.30948257446289, 'epoch': 0.10926049300466356}
                                                    {'loss': 6.4778, 'grad_norm': 1001.5651245117188, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 12.956389427185059, 'weight_rejected': 0.28776782751083374, 'kl_term_chosen': -12.30948257446289, 'epoch': 0.11}
 11%|█         | 410/3753 [29:17<4:00:19,  4.31s/it] 11%|█         | 411/3753 [29:22<4:07:56,  4.45s/it] 11%|█         | 412/3753 [29:26<3:59:04,  4.29s/it] 11%|█         | 413/3753 [29:31<4:20:25,  4.68s/it] 11%|█         | 414/3753 [29:36<4:22:35,  4.72s/it] 11%|█         | 415/3753 [29:40<4:10:51,  4.51s/it] 11%|█         | 416/3753 [29:44<4:08:28,  4.47s/it] 11%|█         | 417/3753 [29:48<3:57:53,  4.28s/it] 11%|█         | 418/3753 [29:52<3:51:35,  4.17s/it] 11%|█         | 419/3753 [29:56<3:52:01,  4.18s/it] 11%|█         | 420/3753 [30:00<3:45:53,  4.07s/it]{'loss': 1.8508, 'grad_norm': 787.2106323242188, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 0.1287168264389038, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.6764250993728638, 'weight_rejected': 0.2727987766265869, 'kl_term_chosen': -1.0250701904296875, 'epoch': 0.11192538307794804}
                                                    {'loss': 1.8508, 'grad_norm': 787.2106323242188, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 0.1287168264389038, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.6764250993728638, 'weight_rejected': 0.2727987766265869, 'kl_term_chosen': -1.0250701904296875, 'epoch': 0.11}
 11%|█         | 420/3753 [30:00<3:45:53,  4.07s/it] 11%|█         | 421/3753 [30:04<3:50:32,  4.15s/it] 11%|█         | 422/3753 [30:09<3:49:45,  4.14s/it] 11%|█▏        | 423/3753 [30:12<3:42:07,  4.00s/it] 11%|█▏        | 424/3753 [30:15<3:29:01,  3.77s/it] 11%|█▏        | 425/3753 [30:20<3:38:16,  3.94s/it] 11%|█▏        | 426/3753 [30:24<3:43:41,  4.03s/it] 11%|█▏        | 427/3753 [30:29<3:51:48,  4.18s/it] 11%|█▏        | 428/3753 [30:33<3:55:09,  4.24s/it] 11%|█▏        | 429/3753 [30:37<3:51:43,  4.18s/it] 11%|█▏        | 430/3753 [30:42<4:03:41,  4.40s/it]{'loss': 26.5927, 'grad_norm': 1899.8521728515625, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.6392375230789185, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.7873578071594238, 'weight_rejected': 0.27125170826911926, 'kl_term_chosen': -0.2237396240234375, 'epoch': 0.1145902731512325}
                                                    {'loss': 26.5927, 'grad_norm': 1899.8521728515625, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.6392375230789185, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.7873578071594238, 'weight_rejected': 0.27125170826911926, 'kl_term_chosen': -0.2237396240234375, 'epoch': 0.11}
 11%|█▏        | 430/3753 [30:42<4:03:41,  4.40s/it] 11%|█▏        | 431/3753 [30:46<3:53:32,  4.22s/it] 12%|█▏        | 432/3753 [30:51<4:05:35,  4.44s/it] 12%|█▏        | 433/3753 [30:55<3:59:37,  4.33s/it] 12%|█▏        | 434/3753 [30:58<3:50:25,  4.17s/it] 12%|█▏        | 435/3753 [31:02<3:45:32,  4.08s/it] 12%|█▏        | 436/3753 [31:07<3:54:09,  4.24s/it] 12%|█▏        | 437/3753 [31:11<3:52:58,  4.22s/it] 12%|█▏        | 438/3753 [31:16<3:58:39,  4.32s/it] 12%|█▏        | 439/3753 [31:20<3:56:21,  4.28s/it] 12%|█▏        | 440/3753 [31:24<3:51:19,  4.19s/it]{'loss': 8.8553, 'grad_norm': 478.23382568359375, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 0.4030943810939789, 'mean_ratio_rejected': 0.3740834593772888, 'weight_chosen': 1.4089397192001343, 'weight_rejected': 0.048136770725250244, 'kl_term_chosen': -0.45429229736328125, 'epoch': 0.11725516322451698}
                                                    {'loss': 8.8553, 'grad_norm': 478.23382568359375, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 0.4030943810939789, 'mean_ratio_rejected': 0.3740834593772888, 'weight_chosen': 1.4089397192001343, 'weight_rejected': 0.048136770725250244, 'kl_term_chosen': -0.45429229736328125, 'epoch': 0.12}
 12%|█▏        | 440/3753 [31:24<3:51:19,  4.19s/it] 12%|█▏        | 441/3753 [31:28<3:44:17,  4.06s/it] 12%|█▏        | 442/3753 [31:32<3:52:38,  4.22s/it] 12%|█▏        | 443/3753 [31:35<3:25:21,  3.72s/it] 12%|█▏        | 444/3753 [31:39<3:37:36,  3.95s/it] 12%|█▏        | 445/3753 [31:43<3:28:00,  3.77s/it] 12%|█▏        | 446/3753 [31:47<3:40:51,  4.01s/it] 12%|█▏        | 447/3753 [31:52<3:52:00,  4.21s/it] 12%|█▏        | 448/3753 [31:55<3:37:09,  3.94s/it] 12%|█▏        | 449/3753 [32:00<3:50:42,  4.19s/it] 12%|█▏        | 450/3753 [32:04<3:51:35,  4.21s/it]{'loss': 1.6641, 'grad_norm': 653.83837890625, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 1.8081154823303223, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.5971668362617493, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 0.296142578125, 'epoch': 0.11992005329780146}
                                                    {'loss': 1.6641, 'grad_norm': 653.83837890625, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 1.8081154823303223, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.5971668362617493, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 0.296142578125, 'epoch': 0.12}
 12%|█▏        | 450/3753 [32:04<3:51:35,  4.21s/it] 12%|█▏        | 451/3753 [32:08<3:51:14,  4.20s/it] 12%|█▏        | 452/3753 [32:13<3:53:42,  4.25s/it] 12%|█▏        | 453/3753 [32:16<3:44:37,  4.08s/it] 12%|█▏        | 454/3753 [32:22<4:09:53,  4.54s/it] 12%|█▏        | 455/3753 [32:26<4:03:18,  4.43s/it] 12%|█▏        | 456/3753 [32:30<3:51:32,  4.21s/it] 12%|█▏        | 457/3753 [32:34<3:49:39,  4.18s/it] 12%|█▏        | 458/3753 [32:38<3:45:52,  4.11s/it] 12%|█▏        | 459/3753 [32:42<3:51:17,  4.21s/it] 12%|█▏        | 460/3753 [32:48<4:14:35,  4.64s/it]{'loss': 17.0286, 'grad_norm': 471.18145751953125, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.274094104766846, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': -5.355613708496094, 'epoch': 0.12258494337108594}
                                                    {'loss': 17.0286, 'grad_norm': 471.18145751953125, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.274094104766846, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': -5.355613708496094, 'epoch': 0.12}
 12%|█▏        | 460/3753 [32:48<4:14:35,  4.64s/it] 12%|█▏        | 461/3753 [32:51<3:53:51,  4.26s/it] 12%|█▏        | 462/3753 [32:54<3:29:40,  3.82s/it] 12%|█▏        | 463/3753 [32:59<3:39:30,  4.00s/it] 12%|█▏        | 464/3753 [33:03<3:45:14,  4.11s/it] 12%|█▏        | 465/3753 [33:07<3:45:19,  4.11s/it] 12%|█▏        | 466/3753 [33:11<3:45:00,  4.11s/it] 12%|█▏        | 467/3753 [33:15<3:46:44,  4.14s/it] 12%|█▏        | 468/3753 [33:20<3:51:54,  4.24s/it] 12%|█▏        | 469/3753 [33:25<4:09:58,  4.57s/it] 13%|█▎        | 470/3753 [33:31<4:29:55,  4.93s/it]{'loss': 22.0985, 'grad_norm': 413.4122619628906, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 3.3763556480407715, 'weight_chosen': -8.243847846984863, 'weight_rejected': 0.08151976019144058, 'kl_term_chosen': 9.1888427734375, 'epoch': 0.1252498334443704}
                                                    {'loss': 22.0985, 'grad_norm': 413.4122619628906, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 3.3763556480407715, 'weight_chosen': -8.243847846984863, 'weight_rejected': 0.08151976019144058, 'kl_term_chosen': 9.1888427734375, 'epoch': 0.13}
 13%|█▎        | 470/3753 [33:31<4:29:55,  4.93s/it] 13%|█▎        | 471/3753 [33:37<4:40:40,  5.13s/it] 13%|█▎        | 472/3753 [33:40<4:11:48,  4.60s/it] 13%|█▎        | 473/3753 [33:43<3:42:28,  4.07s/it] 13%|█▎        | 474/3753 [33:47<3:51:10,  4.23s/it] 13%|█▎        | 475/3753 [33:52<3:59:34,  4.39s/it] 13%|█▎        | 476/3753 [33:56<3:53:57,  4.28s/it] 13%|█▎        | 477/3753 [34:01<3:54:15,  4.29s/it] 13%|█▎        | 478/3753 [34:04<3:47:34,  4.17s/it] 13%|█▎        | 479/3753 [34:10<4:06:26,  4.52s/it] 13%|█▎        | 480/3753 [34:15<4:10:34,  4.59s/it]{'loss': 9.1637, 'grad_norm': 182.143798828125, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.94449234008789, 'weight_rejected': 0.23792988061904907, 'kl_term_chosen': -11.367950439453125, 'epoch': 0.1279147235176549}
                                                    {'loss': 9.1637, 'grad_norm': 182.143798828125, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.94449234008789, 'weight_rejected': 0.23792988061904907, 'kl_term_chosen': -11.367950439453125, 'epoch': 0.13}
 13%|█▎        | 480/3753 [34:15<4:10:34,  4.59s/it] 13%|█▎        | 481/3753 [34:20<4:18:55,  4.75s/it] 13%|█▎        | 482/3753 [34:24<4:05:01,  4.49s/it] 13%|█▎        | 483/3753 [34:27<3:52:19,  4.26s/it] 13%|█▎        | 484/3753 [34:31<3:45:29,  4.14s/it] 13%|█▎        | 485/3753 [34:35<3:36:56,  3.98s/it] 13%|█▎        | 486/3753 [34:39<3:44:33,  4.12s/it] 13%|█▎        | 487/3753 [34:44<3:58:30,  4.38s/it] 13%|█▎        | 488/3753 [34:48<3:44:54,  4.13s/it] 13%|█▎        | 489/3753 [34:53<3:55:31,  4.33s/it] 13%|█▎        | 490/3753 [34:57<4:02:18,  4.46s/it]{'loss': 7.3549, 'grad_norm': 515.5626831054688, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.6494823694229126, 'weight_chosen': 7.207375526428223, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': -6.2631988525390625, 'epoch': 0.13057961359093936}
                                                    {'loss': 7.3549, 'grad_norm': 515.5626831054688, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.6494823694229126, 'weight_chosen': 7.207375526428223, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': -6.2631988525390625, 'epoch': 0.13}
 13%|█▎        | 490/3753 [34:57<4:02:18,  4.46s/it] 13%|█▎        | 491/3753 [35:02<4:12:56,  4.65s/it] 13%|█▎        | 492/3753 [35:06<4:00:19,  4.42s/it] 13%|█▎        | 493/3753 [35:12<4:24:40,  4.87s/it] 13%|█▎        | 494/3753 [35:16<4:07:25,  4.56s/it] 13%|█▎        | 495/3753 [35:19<3:47:33,  4.19s/it] 13%|█▎        | 496/3753 [35:24<3:58:28,  4.39s/it] 13%|█▎        | 497/3753 [35:28<3:51:44,  4.27s/it] 13%|█▎        | 498/3753 [35:33<4:05:01,  4.52s/it] 13%|█▎        | 499/3753 [35:38<4:16:06,  4.72s/it] 13%|█▎        | 500/3753 [35:43<4:11:45,  4.64s/it]{'loss': 41.0309, 'grad_norm': 314.140869140625, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 8.478377342224121, 'weight_rejected': 0.22270013391971588, 'kl_term_chosen': -7.835945129394531, 'epoch': 0.13324450366422386}
                                                    {'loss': 41.0309, 'grad_norm': 314.140869140625, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 8.478377342224121, 'weight_rejected': 0.22270013391971588, 'kl_term_chosen': -7.835945129394531, 'epoch': 0.13}
 13%|█▎        | 500/3753 [35:43<4:11:45,  4.64s/it] 13%|█▎        | 501/3753 [35:47<4:04:56,  4.52s/it] 13%|█▎        | 502/3753 [35:52<4:10:07,  4.62s/it] 13%|█▎        | 503/3753 [35:57<4:09:17,  4.60s/it] 13%|█▎        | 504/3753 [36:00<3:56:37,  4.37s/it] 13%|█▎        | 505/3753 [36:04<3:47:51,  4.21s/it] 13%|█▎        | 506/3753 [36:08<3:40:06,  4.07s/it] 14%|█▎        | 507/3753 [36:13<3:51:06,  4.27s/it] 14%|█▎        | 508/3753 [36:18<4:07:22,  4.57s/it] 14%|█▎        | 509/3753 [36:22<4:00:54,  4.46s/it] 14%|█▎        | 510/3753 [36:27<4:04:26,  4.52s/it]{'loss': 63.1498, 'grad_norm': 2.334725856781006, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -10.949124336242676, 'weight_rejected': 0.03358950838446617, 'kl_term_chosen': 11.905105590820312, 'epoch': 0.13590939373750832}
                                                    {'loss': 63.1498, 'grad_norm': 2.334725856781006, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -10.949124336242676, 'weight_rejected': 0.03358950838446617, 'kl_term_chosen': 11.905105590820312, 'epoch': 0.14}
 14%|█▎        | 510/3753 [36:27<4:04:26,  4.52s/it] 14%|█▎        | 511/3753 [36:31<4:01:17,  4.47s/it] 14%|█▎        | 512/3753 [36:35<3:48:45,  4.24s/it] 14%|█▎        | 513/3753 [36:38<3:33:48,  3.96s/it] 14%|█▎        | 514/3753 [36:43<3:53:09,  4.32s/it] 14%|█▎        | 515/3753 [36:48<4:05:18,  4.55s/it] 14%|█▎        | 516/3753 [36:53<4:03:50,  4.52s/it] 14%|█▍        | 517/3753 [36:56<3:48:25,  4.24s/it] 14%|█▍        | 518/3753 [37:00<3:43:02,  4.14s/it] 14%|█▍        | 519/3753 [37:05<3:56:38,  4.39s/it] 14%|█▍        | 520/3753 [37:11<4:14:01,  4.71s/it]{'loss': 39.8971, 'grad_norm': 2718.761962890625, 'learning_rate': 9.955821687527552e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.714503765106201, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 7.637542724609375, 'epoch': 0.13857428381079281}
                                                    {'loss': 39.8971, 'grad_norm': 2718.761962890625, 'learning_rate': 9.955821687527552e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.714503765106201, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 7.637542724609375, 'epoch': 0.14}
 14%|█▍        | 520/3753 [37:11<4:14:01,  4.71s/it] 14%|█▍        | 521/3753 [37:15<4:11:03,  4.66s/it] 14%|█▍        | 522/3753 [37:20<4:05:21,  4.56s/it] 14%|█▍        | 523/3753 [37:24<4:01:34,  4.49s/it] 14%|█▍        | 524/3753 [37:29<4:02:23,  4.50s/it] 14%|█▍        | 525/3753 [37:33<3:59:29,  4.45s/it] 14%|█▍        | 526/3753 [37:36<3:39:21,  4.08s/it] 14%|█▍        | 527/3753 [37:40<3:35:22,  4.01s/it] 14%|█▍        | 528/3753 [37:44<3:44:34,  4.18s/it] 14%|█▍        | 529/3753 [37:48<3:31:39,  3.94s/it] 14%|█▍        | 530/3753 [37:52<3:35:23,  4.01s/it]{'loss': 26.0458, 'grad_norm': 770.171142578125, 'learning_rate': 9.94943765952491e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.145801544189453, 'weight_rejected': 0.332852303981781, 'kl_term_chosen': -10.70989990234375, 'epoch': 0.14123917388407728}
                                                    {'loss': 26.0458, 'grad_norm': 770.171142578125, 'learning_rate': 9.94943765952491e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.145801544189453, 'weight_rejected': 0.332852303981781, 'kl_term_chosen': -10.70989990234375, 'epoch': 0.14}
 14%|█▍        | 530/3753 [37:52<3:35:23,  4.01s/it] 14%|█▍        | 531/3753 [37:56<3:30:39,  3.92s/it] 14%|█▍        | 532/3753 [38:00<3:40:59,  4.12s/it] 14%|█▍        | 533/3753 [38:04<3:40:49,  4.11s/it] 14%|█▍        | 534/3753 [38:08<3:30:31,  3.92s/it] 14%|█▍        | 535/3753 [38:12<3:37:40,  4.06s/it] 14%|█▍        | 536/3753 [38:17<3:50:52,  4.31s/it] 14%|█▍        | 537/3753 [38:22<3:58:09,  4.44s/it] 14%|█▍        | 538/3753 [38:25<3:42:48,  4.16s/it] 14%|█▍        | 539/3753 [38:29<3:31:38,  3.95s/it] 14%|█▍        | 540/3753 [38:32<3:19:19,  3.72s/it]{'loss': 21.9435, 'grad_norm': 171.4720001220703, 'learning_rate': 9.942625289827702e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.420254707336426, 'weight_rejected': 0.1233656257390976, 'kl_term_chosen': 8.348663330078125, 'epoch': 0.14390406395736177}
                                                    {'loss': 21.9435, 'grad_norm': 171.4720001220703, 'learning_rate': 9.942625289827702e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.420254707336426, 'weight_rejected': 0.1233656257390976, 'kl_term_chosen': 8.348663330078125, 'epoch': 0.14}
 14%|█▍        | 540/3753 [38:32<3:19:19,  3.72s/it] 14%|█▍        | 541/3753 [38:36<3:16:59,  3.68s/it] 14%|█▍        | 542/3753 [38:40<3:26:31,  3.86s/it] 14%|█▍        | 543/3753 [38:43<3:14:47,  3.64s/it] 14%|█▍        | 544/3753 [38:48<3:30:47,  3.94s/it] 15%|█▍        | 545/3753 [38:52<3:29:10,  3.91s/it] 15%|█▍        | 546/3753 [38:55<3:21:22,  3.77s/it] 15%|█▍        | 547/3753 [38:59<3:30:27,  3.94s/it] 15%|█▍        | 548/3753 [39:04<3:45:21,  4.22s/it] 15%|█▍        | 549/3753 [39:08<3:38:58,  4.10s/it] 15%|█▍        | 550/3753 [39:13<3:51:44,  4.34s/it]{'loss': 40.457, 'grad_norm': 175.61875915527344, 'learning_rate': 9.935385168002298e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.626211166381836, 'weight_rejected': 0.07585817575454712, 'kl_term_chosen': -3.6899261474609375, 'epoch': 0.14656895403064624}
                                                    {'loss': 40.457, 'grad_norm': 175.61875915527344, 'learning_rate': 9.935385168002298e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.626211166381836, 'weight_rejected': 0.07585817575454712, 'kl_term_chosen': -3.6899261474609375, 'epoch': 0.15}
 15%|█▍        | 550/3753 [39:13<3:51:44,  4.34s/it] 15%|█▍        | 551/3753 [39:17<3:53:32,  4.38s/it] 15%|█▍        | 552/3753 [39:21<3:36:09,  4.05s/it] 15%|█▍        | 553/3753 [39:25<3:38:34,  4.10s/it] 15%|█▍        | 554/3753 [39:29<3:43:21,  4.19s/it] 15%|█▍        | 555/3753 [39:34<3:48:42,  4.29s/it] 15%|█▍        | 556/3753 [39:38<3:43:08,  4.19s/it] 15%|█▍        | 557/3753 [39:42<3:43:29,  4.20s/it] 15%|█▍        | 558/3753 [39:46<3:43:21,  4.19s/it] 15%|█▍        | 559/3753 [39:51<3:46:18,  4.25s/it] 15%|█▍        | 560/3753 [39:54<3:37:15,  4.08s/it]{'loss': 50.2823, 'grad_norm': 94.94416046142578, 'learning_rate': 9.927717920634233e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.836224555969238, 'weight_rejected': 0.18713268637657166, 'kl_term_chosen': 10.71453857421875, 'epoch': 0.1492338441039307}
                                                    {'loss': 50.2823, 'grad_norm': 94.94416046142578, 'learning_rate': 9.927717920634233e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.836224555969238, 'weight_rejected': 0.18713268637657166, 'kl_term_chosen': 10.71453857421875, 'epoch': 0.15}
 15%|█▍        | 560/3753 [39:54<3:37:15,  4.08s/it] 15%|█▍        | 561/3753 [39:58<3:35:32,  4.05s/it] 15%|█▍        | 562/3753 [40:03<3:49:33,  4.32s/it] 15%|█▌        | 563/3753 [40:07<3:46:56,  4.27s/it] 15%|█▌        | 564/3753 [40:12<3:48:29,  4.30s/it] 15%|█▌        | 565/3753 [40:17<4:00:50,  4.53s/it] 15%|█▌        | 566/3753 [40:21<3:58:10,  4.48s/it] 15%|█▌        | 567/3753 [40:26<4:04:57,  4.61s/it] 15%|█▌        | 568/3753 [40:30<3:51:09,  4.35s/it] 15%|█▌        | 569/3753 [40:34<3:50:54,  4.35s/it] 15%|█▌        | 570/3753 [40:38<3:37:42,  4.10s/it]{'loss': 36.5261, 'grad_norm': 156.18502807617188, 'learning_rate': 9.919624211273986e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.23123404383659363, 'weight_chosen': -3.1744232177734375, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': 4.145111083984375, 'epoch': 0.1518987341772152}
                                                    {'loss': 36.5261, 'grad_norm': 156.18502807617188, 'learning_rate': 9.919624211273986e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.23123404383659363, 'weight_chosen': -3.1744232177734375, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': 4.145111083984375, 'epoch': 0.15}
 15%|█▌        | 570/3753 [40:38<3:37:42,  4.10s/it] 15%|█▌        | 571/3753 [40:43<3:55:59,  4.45s/it] 15%|█▌        | 572/3753 [40:46<3:38:29,  4.12s/it] 15%|█▌        | 573/3753 [40:50<3:32:26,  4.01s/it] 15%|█▌        | 574/3753 [40:54<3:31:28,  3.99s/it] 15%|█▌        | 575/3753 [40:58<3:33:23,  4.03s/it] 15%|█▌        | 576/3753 [41:03<3:41:30,  4.18s/it] 15%|█▌        | 577/3753 [41:07<3:49:30,  4.34s/it] 15%|█▌        | 578/3753 [41:12<3:52:30,  4.39s/it] 15%|█▌        | 579/3753 [41:15<3:33:27,  4.04s/it] 15%|█▌        | 580/3753 [41:20<3:41:53,  4.20s/it]{'loss': 21.0427, 'grad_norm': 1099.3201904296875, 'learning_rate': 9.911104740379551e-07, 'mean_ratio_chosen': 0.23988375067710876, 'mean_ratio_rejected': 0.3581969439983368, 'weight_chosen': 0.8235061764717102, 'weight_rejected': 0.8499711751937866, 'kl_term_chosen': -0.7138004302978516, 'epoch': 0.15456362425049966}
                                                    {'loss': 21.0427, 'grad_norm': 1099.3201904296875, 'learning_rate': 9.911104740379551e-07, 'mean_ratio_chosen': 0.23988375067710876, 'mean_ratio_rejected': 0.3581969439983368, 'weight_chosen': 0.8235061764717102, 'weight_rejected': 0.8499711751937866, 'kl_term_chosen': -0.7138004302978516, 'epoch': 0.15}
 15%|█▌        | 580/3753 [41:20<3:41:53,  4.20s/it] 15%|█▌        | 581/3753 [41:24<3:37:41,  4.12s/it] 16%|█▌        | 582/3753 [41:28<3:38:40,  4.14s/it] 16%|█▌        | 583/3753 [41:31<3:31:09,  4.00s/it] 16%|█▌        | 584/3753 [41:35<3:22:13,  3.83s/it] 16%|█▌        | 585/3753 [41:39<3:24:56,  3.88s/it] 16%|█▌        | 586/3753 [41:43<3:25:23,  3.89s/it] 16%|█▌        | 587/3753 [41:47<3:36:50,  4.11s/it] 16%|█▌        | 588/3753 [41:52<3:45:55,  4.28s/it] 16%|█▌        | 589/3753 [41:58<4:06:51,  4.68s/it] 16%|█▌        | 590/3753 [42:01<3:47:52,  4.32s/it]{'loss': 9.441, 'grad_norm': 0.0, 'learning_rate': 9.902160245255826e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.936980724334717, 'weight_rejected': 0.12592275440692902, 'kl_term_chosen': 7.811058044433594, 'epoch': 0.15722851432378415}
                                                    {'loss': 9.441, 'grad_norm': 0.0, 'learning_rate': 9.902160245255826e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.936980724334717, 'weight_rejected': 0.12592275440692902, 'kl_term_chosen': 7.811058044433594, 'epoch': 0.16}
 16%|█▌        | 590/3753 [42:01<3:47:52,  4.32s/it] 16%|█▌        | 591/3753 [42:05<3:46:41,  4.30s/it] 16%|█▌        | 592/3753 [42:10<3:43:44,  4.25s/it] 16%|█▌        | 593/3753 [42:15<4:00:35,  4.57s/it] 16%|█▌        | 594/3753 [42:19<3:55:24,  4.47s/it] 16%|█▌        | 595/3753 [42:23<3:41:14,  4.20s/it] 16%|█▌        | 596/3753 [42:27<3:37:35,  4.14s/it] 16%|█▌        | 597/3753 [42:31<3:34:17,  4.07s/it] 16%|█▌        | 598/3753 [42:35<3:38:00,  4.15s/it] 16%|█▌        | 599/3753 [42:40<3:47:07,  4.32s/it] 16%|█▌        | 600/3753 [42:45<3:57:27,  4.52s/it]{'loss': -0.2536, 'grad_norm': 447.255859375, 'learning_rate': 9.892791499990784e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 13.996644020080566, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': -13.035110473632812, 'epoch': 0.15989340439706862}
                                                    {'loss': -0.2536, 'grad_norm': 447.255859375, 'learning_rate': 9.892791499990784e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 13.996644020080566, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': -13.035110473632812, 'epoch': 0.16}
 16%|█▌        | 600/3753 [42:45<3:57:27,  4.52s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 16%|█▌        | 601/3753 [43:48<19:22:34, 22.13s/it] 16%|█▌        | 602/3753 [43:53<14:47:12, 16.89s/it] 16%|█▌        | 603/3753 [43:57<11:35:41, 13.25s/it] 16%|█▌        | 604/3753 [44:01<9:12:16, 10.52s/it]  16%|█▌        | 605/3753 [44:05<7:28:34,  8.55s/it] 16%|█▌        | 606/3753 [44:09<6:18:39,  7.22s/it] 16%|█▌        | 607/3753 [44:13<5:15:55,  6.03s/it] 16%|█▌        | 608/3753 [44:17<4:54:10,  5.61s/it] 16%|█▌        | 609/3753 [44:22<4:40:51,  5.36s/it] 16%|█▋        | 610/3753 [44:26<4:10:13,  4.78s/it]{'loss': 6.415, 'grad_norm': 81.19513702392578, 'learning_rate': 9.882999315388504e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.3038675785064697, 'weight_rejected': 0.14033624529838562, 'kl_term_chosen': -1.46624755859375, 'epoch': 0.1625582944703531}
                                                    {'loss': 6.415, 'grad_norm': 81.19513702392578, 'learning_rate': 9.882999315388504e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.3038675785064697, 'weight_rejected': 0.14033624529838562, 'kl_term_chosen': -1.46624755859375, 'epoch': 0.16}
 16%|█▋        | 610/3753 [44:26<4:10:13,  4.78s/it] 16%|█▋        | 611/3753 [44:29<3:43:18,  4.26s/it] 16%|█▋        | 612/3753 [44:34<4:04:32,  4.67s/it] 16%|█▋        | 613/3753 [44:38<3:52:50,  4.45s/it] 16%|█▋        | 614/3753 [44:43<4:05:36,  4.69s/it] 16%|█▋        | 615/3753 [44:48<3:58:24,  4.56s/it] 16%|█▋        | 616/3753 [44:52<3:57:31,  4.54s/it] 16%|█▋        | 617/3753 [44:56<3:45:00,  4.31s/it] 16%|█▋        | 618/3753 [44:59<3:30:04,  4.02s/it] 16%|█▋        | 619/3753 [45:03<3:21:44,  3.86s/it] 17%|█▋        | 620/3753 [45:08<3:50:08,  4.41s/it]{'loss': 0.9026, 'grad_norm': 227.86891174316406, 'learning_rate': 9.872784538898985e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 19.232202529907227, 'weight_rejected': 0.46295860409736633, 'kl_term_chosen': -18.891498565673828, 'epoch': 0.16522318454363757}
                                                    {'loss': 0.9026, 'grad_norm': 227.86891174316406, 'learning_rate': 9.872784538898985e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 19.232202529907227, 'weight_rejected': 0.46295860409736633, 'kl_term_chosen': -18.891498565673828, 'epoch': 0.17}
 17%|█▋        | 620/3753 [45:09<3:50:08,  4.41s/it] 17%|█▋        | 621/3753 [45:14<4:00:58,  4.62s/it] 17%|█▋        | 622/3753 [45:17<3:43:01,  4.27s/it] 17%|█▋        | 623/3753 [45:21<3:35:24,  4.13s/it] 17%|█▋        | 624/3753 [45:25<3:37:01,  4.16s/it] 17%|█▋        | 625/3753 [45:29<3:36:47,  4.16s/it] 17%|█▋        | 626/3753 [45:33<3:31:32,  4.06s/it] 17%|█▋        | 627/3753 [45:38<3:41:39,  4.25s/it] 17%|█▋        | 628/3753 [45:42<3:43:06,  4.28s/it]