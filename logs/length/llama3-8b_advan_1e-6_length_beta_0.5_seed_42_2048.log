nohup: ignoring input
[W1124 10:59:58.102009020 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.11it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 99.69it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.65it/s]
加载作为参考的SFT模型 (Reference Model)...
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]⚙️  Running in WANDB offline mode
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.18it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 100.92it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.59it/s]
设置随机种子为: 42
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 82.10it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 82.41it/s]
[W1124 11:00:04.677995632 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1124 11:00:04.692335663 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1124 11:00:04.693561492 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1124 11:00:04.755265006 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_length.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_length.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_length.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_length.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...开始分布式训练...

开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /root/wandb/offline-run-20251124_110014-nqyrky36
  0%|          | 0/1877 [00:00<?, ?it/s]--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -44.25
Sample 0 - pi_logp_chosen:  -44.264652252197266
Sample 0 - Difference (pi - ref): -0.014652252197265625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -232.0
Sample 0 - pi_logp_chosen:  -233.0531463623047
Sample 0 - Difference (pi - ref): -1.0531463623046875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -209.0
Sample 0 - pi_logp_chosen:  -208.26136779785156
Sample 0 - Difference (pi - ref): 0.7386322021484375
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -382.0
Sample 0 - pi_logp_chosen:  -380.2176818847656
Sample 0 - Difference (pi - ref): 1.782318115234375
---------------------------------
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -251.0
Sample 0 - pi_logp_chosen:  -250.19369506835938
Sample 0 - Difference (pi - ref): 0.806304931640625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -167.0
Sample 0 - pi_logp_chosen:  -167.0938720703125
Sample 0 - Difference (pi - ref): -0.0938720703125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -452.0
Sample 0 - pi_logp_chosen:  -451.6322021484375
Sample 0 - Difference (pi - ref): 0.3677978515625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -81.5
Sample 0 - pi_logp_chosen:  -82.41392517089844
Sample 0 - Difference (pi - ref): -0.9139251708984375
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -176.0
Sample 0 - pi_logp_chosen:  -175.74853515625
Sample 0 - Difference (pi - ref): 0.25146484375
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -89.0
Sample 0 - pi_logp_chosen:  -88.872802734375
Sample 0 - Difference (pi - ref): 0.127197265625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -286.0
Sample 0 - pi_logp_chosen:  -286.11871337890625
Sample 0 - Difference (pi - ref): -0.11871337890625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -141.0
Sample 0 - pi_logp_chosen:  -140.46493530273438
Sample 0 - Difference (pi - ref): 0.535064697265625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -124.5
Sample 0 - pi_logp_chosen:  -124.90826416015625
Sample 0 - Difference (pi - ref): -0.40826416015625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -48.5
Sample 0 - pi_logp_chosen:  -48.33993148803711
Sample 0 - Difference (pi - ref): 0.16006851196289062
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -86.5
Sample 0 - pi_logp_chosen:  -86.63549041748047
Sample 0 - Difference (pi - ref): -0.13549041748046875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -195.0
Sample 0 - pi_logp_chosen:  -194.40797424316406
Sample 0 - Difference (pi - ref): 0.5920257568359375
---------------------------------
  0%|          | 1/1877 [00:10<5:22:54, 10.33s/it]{'loss': -0.0009, 'grad_norm': 6.905063152313232, 'learning_rate': 0.0, 'mean_ratio_chosen': 0.4463617205619812, 'mean_ratio_rejected': 1.3110102415084839, 'weight_chosen': 0.0021752547472715378, 'weight_rejected': 0.0012185233645141125, 'kl_term_chosen': -0.4717559814453125, 'mean_len_chosen': 519.5, 'mean_len_rejected': 482.0, 'epoch': 0.0005329780146568954}
                                                  {'loss': -0.0009, 'grad_norm': 6.905063152313232, 'learning_rate': 0.0, 'mean_ratio_chosen': 0.4463617205619812, 'mean_ratio_rejected': 1.3110102415084839, 'weight_chosen': 0.0021752547472715378, 'weight_rejected': 0.0012185233645141125, 'kl_term_chosen': -0.4717559814453125, 'mean_len_chosen': 519.5, 'mean_len_rejected': 482.0, 'epoch': 0.0}
  0%|          | 1/1877 [00:10<5:22:54, 10.33s/it]  0%|          | 2/1877 [00:19<4:58:25,  9.55s/it]  0%|          | 3/1877 [00:29<5:06:31,  9.81s/it]  0%|          | 4/1877 [00:40<5:15:25, 10.10s/it]  0%|          | 5/1877 [00:46<4:39:11,  8.95s/it]  0%|          | 6/1877 [00:58<5:06:48,  9.84s/it]  0%|          | 7/1877 [01:06<4:50:28,  9.32s/it]  0%|          | 8/1877 [01:14<4:33:23,  8.78s/it]  0%|          | 9/1877 [01:23<4:34:13,  8.81s/it]  1%|          | 10/1877 [01:31<4:28:26,  8.63s/it]{'loss': -0.0006, 'grad_norm': 35.92897033691406, 'learning_rate': 4.787234042553191e-08, 'mean_ratio_chosen': 0.7164077758789062, 'mean_ratio_rejected': 1.6208341121673584, 'weight_chosen': 0.0016549791907891631, 'weight_rejected': 0.000438944436609745, 'kl_term_chosen': -0.17113113403320312, 'mean_len_chosen': 644.5, 'mean_len_rejected': 626.5, 'epoch': 0.005329780146568954}
                                                   {'loss': -0.0006, 'grad_norm': 35.92897033691406, 'learning_rate': 4.787234042553191e-08, 'mean_ratio_chosen': 0.7164077758789062, 'mean_ratio_rejected': 1.6208341121673584, 'weight_chosen': 0.0016549791907891631, 'weight_rejected': 0.000438944436609745, 'kl_term_chosen': -0.17113113403320312, 'mean_len_chosen': 644.5, 'mean_len_rejected': 626.5, 'epoch': 0.01}
  1%|          | 10/1877 [01:31<4:28:26,  8.63s/it]  1%|          | 11/1877 [01:44<5:09:23,  9.95s/it]  1%|          | 12/1877 [01:53<4:58:55,  9.62s/it]  1%|          | 13/1877 [02:01<4:50:02,  9.34s/it]  1%|          | 14/1877 [02:09<4:32:25,  8.77s/it]  1%|          | 15/1877 [02:18<4:34:52,  8.86s/it]  1%|          | 16/1877 [02:29<4:54:33,  9.50s/it]  1%|          | 17/1877 [02:39<4:59:28,  9.66s/it]  1%|          | 18/1877 [02:51<5:25:19, 10.50s/it]  1%|          | 19/1877 [03:03<5:37:33, 10.90s/it]  1%|          | 20/1877 [03:15<5:42:24, 11.06s/it]{'loss': -0.0007, 'grad_norm': 7.506097316741943, 'learning_rate': 1.0106382978723404e-07, 'mean_ratio_chosen': 0.8069804310798645, 'mean_ratio_rejected': 2.2677204608917236, 'weight_chosen': 0.00149816763587296, 'weight_rejected': 0.0008874626946635544, 'kl_term_chosen': -0.2037353515625, 'mean_len_chosen': 703.5, 'mean_len_rejected': 687.5, 'epoch': 0.010659560293137908}
                                                   {'loss': -0.0007, 'grad_norm': 7.506097316741943, 'learning_rate': 1.0106382978723404e-07, 'mean_ratio_chosen': 0.8069804310798645, 'mean_ratio_rejected': 2.2677204608917236, 'weight_chosen': 0.00149816763587296, 'weight_rejected': 0.0008874626946635544, 'kl_term_chosen': -0.2037353515625, 'mean_len_chosen': 703.5, 'mean_len_rejected': 687.5, 'epoch': 0.01}
  1%|          | 20/1877 [03:15<5:42:24, 11.06s/it]  1%|          | 21/1877 [03:24<5:21:57, 10.41s/it]  1%|          | 22/1877 [03:34<5:17:53, 10.28s/it]  1%|          | 23/1877 [03:45<5:25:41, 10.54s/it]  1%|▏         | 24/1877 [03:52<4:54:13,  9.53s/it]  1%|▏         | 25/1877 [04:01<4:46:55,  9.30s/it]  1%|▏         | 26/1877 [04:11<4:58:40,  9.68s/it]  1%|▏         | 27/1877 [04:22<5:05:03,  9.89s/it]  1%|▏         | 28/1877 [04:35<5:39:02, 11.00s/it]  2%|▏         | 29/1877 [04:44<5:18:23, 10.34s/it]  2%|▏         | 30/1877 [04:53<5:06:02,  9.94s/it]{'loss': 0.0021, 'grad_norm': 29.250659942626953, 'learning_rate': 1.5425531914893615e-07, 'mean_ratio_chosen': 1.3382959365844727, 'mean_ratio_rejected': 2.1707966327667236, 'weight_chosen': 0.005723653826862574, 'weight_rejected': 0.0032618946861475706, 'kl_term_chosen': 0.14409255981445312, 'mean_len_chosen': 435.5, 'mean_len_rejected': 425.0, 'epoch': 0.015989340439706862}
                                                   {'loss': 0.0021, 'grad_norm': 29.250659942626953, 'learning_rate': 1.5425531914893615e-07, 'mean_ratio_chosen': 1.3382959365844727, 'mean_ratio_rejected': 2.1707966327667236, 'weight_chosen': 0.005723653826862574, 'weight_rejected': 0.0032618946861475706, 'kl_term_chosen': 0.14409255981445312, 'mean_len_chosen': 435.5, 'mean_len_rejected': 425.0, 'epoch': 0.02}
  2%|▏         | 30/1877 [04:53<5:06:02,  9.94s/it]  2%|▏         | 31/1877 [05:04<5:15:38, 10.26s/it]  2%|▏         | 32/1877 [05:15<5:18:34, 10.36s/it]  2%|▏         | 33/1877 [05:25<5:16:11, 10.29s/it]  2%|▏         | 34/1877 [05:34<5:02:55,  9.86s/it]  2%|▏         | 35/1877 [05:43<4:56:06,  9.65s/it]  2%|▏         | 36/1877 [05:53<4:57:36,  9.70s/it]  2%|▏         | 37/1877 [06:00<4:40:13,  9.14s/it]  2%|▏         | 38/1877 [06:12<5:02:30,  9.87s/it]  2%|▏         | 39/1877 [06:20<4:47:21,  9.38s/it]  2%|▏         | 40/1877 [06:31<5:04:32,  9.95s/it]{'loss': -0.0003, 'grad_norm': 26.825565338134766, 'learning_rate': 2.074468085106383e-07, 'mean_ratio_chosen': 0.8921909928321838, 'mean_ratio_rejected': 2.4122681617736816, 'weight_chosen': 0.003483467036858201, 'weight_rejected': 0.0012072506360709667, 'kl_term_chosen': -0.06372642517089844, 'mean_len_chosen': 253.5, 'mean_len_rejected': 438.5, 'epoch': 0.021319120586275817}
                                                   {'loss': -0.0003, 'grad_norm': 26.825565338134766, 'learning_rate': 2.074468085106383e-07, 'mean_ratio_chosen': 0.8921909928321838, 'mean_ratio_rejected': 2.4122681617736816, 'weight_chosen': 0.003483467036858201, 'weight_rejected': 0.0012072506360709667, 'kl_term_chosen': -0.06372642517089844, 'mean_len_chosen': 253.5, 'mean_len_rejected': 438.5, 'epoch': 0.02}
  2%|▏         | 40/1877 [06:32<5:04:32,  9.95s/it]  2%|▏         | 41/1877 [06:41<4:59:44,  9.80s/it]  2%|▏         | 42/1877 [06:52<5:14:51, 10.30s/it]  2%|▏         | 43/1877 [07:00<4:50:05,  9.49s/it]  2%|▏         | 44/1877 [07:12<5:14:08, 10.28s/it]  2%|▏         | 45/1877 [07:20<4:55:17,  9.67s/it]  2%|▏         | 46/1877 [07:29<4:44:08,  9.31s/it]  3%|▎         | 47/1877 [07:38<4:40:46,  9.21s/it]  3%|▎         | 48/1877 [07:50<5:08:59, 10.14s/it]  3%|▎         | 49/1877 [08:03<5:35:36, 11.02s/it]  3%|▎         | 50/1877 [08:11<5:02:21,  9.93s/it]{'loss': 0.0023, 'grad_norm': 14.929107666015625, 'learning_rate': 2.6063829787234044e-07, 'mean_ratio_chosen': 2.178502082824707, 'mean_ratio_rejected': 2.109484910964966, 'weight_chosen': 0.0013702637515962124, 'weight_rejected': 0.0012593537103384733, 'kl_term_chosen': 0.3795032501220703, 'mean_len_chosen': 443.5, 'mean_len_rejected': 465.0, 'epoch': 0.02664890073284477}
                                                   {'loss': 0.0023, 'grad_norm': 14.929107666015625, 'learning_rate': 2.6063829787234044e-07, 'mean_ratio_chosen': 2.178502082824707, 'mean_ratio_rejected': 2.109484910964966, 'weight_chosen': 0.0013702637515962124, 'weight_rejected': 0.0012593537103384733, 'kl_term_chosen': 0.3795032501220703, 'mean_len_chosen': 443.5, 'mean_len_rejected': 465.0, 'epoch': 0.03}
  3%|▎         | 50/1877 [08:11<5:02:21,  9.93s/it]  3%|▎         | 51/1877 [08:22<5:13:54, 10.31s/it]  3%|▎         | 52/1877 [08:32<5:16:58, 10.42s/it]  3%|▎         | 53/1877 [08:43<5:16:37, 10.42s/it]  3%|▎         | 54/1877 [08:53<5:11:13, 10.24s/it]  3%|▎         | 55/1877 [09:03<5:07:54, 10.14s/it]  3%|▎         | 56/1877 [09:13<5:06:25, 10.10s/it]  3%|▎         | 57/1877 [09:19<4:35:23,  9.08s/it]  3%|▎         | 58/1877 [09:28<4:31:21,  8.95s/it]  3%|▎         | 59/1877 [09:37<4:29:02,  8.88s/it]  3%|▎         | 60/1877 [09:48<4:55:16,  9.75s/it]{'loss': 0.0036, 'grad_norm': 23.41058921813965, 'learning_rate': 3.1382978723404253e-07, 'mean_ratio_chosen': 1.173708200454712, 'mean_ratio_rejected': 1.3100533485412598, 'weight_chosen': 0.0009911658708006144, 'weight_rejected': 0.0021644853986799717, 'kl_term_chosen': -0.0037841796875, 'mean_len_chosen': 919.0, 'mean_len_rejected': 700.0, 'epoch': 0.031978680879413725}
                                                   {'loss': 0.0036, 'grad_norm': 23.41058921813965, 'learning_rate': 3.1382978723404253e-07, 'mean_ratio_chosen': 1.173708200454712, 'mean_ratio_rejected': 1.3100533485412598, 'weight_chosen': 0.0009911658708006144, 'weight_rejected': 0.0021644853986799717, 'kl_term_chosen': -0.0037841796875, 'mean_len_chosen': 919.0, 'mean_len_rejected': 700.0, 'epoch': 0.03}
  3%|▎         | 60/1877 [09:49<4:55:16,  9.75s/it]  3%|▎         | 61/1877 [09:58<4:52:14,  9.66s/it]  3%|▎         | 62/1877 [10:07<4:48:02,  9.52s/it]  3%|▎         | 63/1877 [10:18<5:02:26, 10.00s/it]  3%|▎         | 64/1877 [10:27<4:51:02,  9.63s/it]  3%|▎         | 65/1877 [10:39<5:09:23, 10.24s/it]  4%|▎         | 66/1877 [10:46<4:44:05,  9.41s/it]  4%|▎         | 67/1877 [10:56<4:45:00,  9.45s/it]  4%|▎         | 68/1877 [11:04<4:31:56,  9.02s/it]  4%|▎         | 69/1877 [11:12<4:28:06,  8.90s/it]  4%|▎         | 70/1877 [11:22<4:32:57,  9.06s/it]{'loss': 0.0153, 'grad_norm': 16.941972732543945, 'learning_rate': 3.6702127659574467e-07, 'mean_ratio_chosen': 1.583092451095581, 'mean_ratio_rejected': 0.7505733966827393, 'weight_chosen': 0.026914024725556374, 'weight_rejected': 0.1011769101023674, 'kl_term_chosen': 0.21055889129638672, 'mean_len_chosen': 22.5, 'mean_len_rejected': 88.5, 'epoch': 0.037308461025982675}
                                                   {'loss': 0.0153, 'grad_norm': 16.941972732543945, 'learning_rate': 3.6702127659574467e-07, 'mean_ratio_chosen': 1.583092451095581, 'mean_ratio_rejected': 0.7505733966827393, 'weight_chosen': 0.026914024725556374, 'weight_rejected': 0.1011769101023674, 'kl_term_chosen': 0.21055889129638672, 'mean_len_chosen': 22.5, 'mean_len_rejected': 88.5, 'epoch': 0.04}
  4%|▎         | 70/1877 [11:22<4:32:57,  9.06s/it]  4%|▍         | 71/1877 [11:34<5:05:30, 10.15s/it]  4%|▍         | 72/1877 [11:45<5:13:10, 10.41s/it]  4%|▍         | 73/1877 [11:57<5:20:13, 10.65s/it]  4%|▍         | 74/1877 [12:08<5:26:35, 10.87s/it]  4%|▍         | 75/1877 [12:18<5:21:21, 10.70s/it]  4%|▍         | 76/1877 [12:28<5:11:15, 10.37s/it]  4%|▍         | 77/1877 [12:39<5:15:28, 10.52s/it]  4%|▍         | 78/1877 [12:49<5:11:55, 10.40s/it]  4%|▍         | 79/1877 [12:59<5:08:33, 10.30s/it]  4%|▍         | 80/1877 [13:08<4:59:31, 10.00s/it]{'loss': -0.0024, 'grad_norm': 18.915897369384766, 'learning_rate': 4.202127659574468e-07, 'mean_ratio_chosen': 1.0298668146133423, 'mean_ratio_rejected': 0.9778766632080078, 'weight_chosen': 0.0013504656963050365, 'weight_rejected': 7.130719313863665e-05, 'kl_term_chosen': -0.019439697265625, 'mean_len_chosen': 658.0, 'mean_len_rejected': 639.5, 'epoch': 0.04263824117255163}
                                                   {'loss': -0.0024, 'grad_norm': 18.915897369384766, 'learning_rate': 4.202127659574468e-07, 'mean_ratio_chosen': 1.0298668146133423, 'mean_ratio_rejected': 0.9778766632080078, 'weight_chosen': 0.0013504656963050365, 'weight_rejected': 7.130719313863665e-05, 'kl_term_chosen': -0.019439697265625, 'mean_len_chosen': 658.0, 'mean_len_rejected': 639.5, 'epoch': 0.04}
  4%|▍         | 80/1877 [13:09<4:59:31, 10.00s/it]  4%|▍         | 81/1877 [13:17<4:47:11,  9.59s/it]  4%|▍         | 82/1877 [13:28<5:01:38, 10.08s/it]  4%|▍         | 83/1877 [13:38<5:00:44, 10.06s/it]  4%|▍         | 84/1877 [13:49<5:05:45, 10.23s/it]  5%|▍         | 85/1877 [13:55<4:33:14,  9.15s/it]  5%|▍         | 86/1877 [14:07<4:56:57,  9.95s/it]  5%|▍         | 87/1877 [14:16<4:44:23,  9.53s/it]  5%|▍         | 88/1877 [14:25<4:45:48,  9.59s/it]  5%|▍         | 89/1877 [14:37<4:58:29, 10.02s/it]  5%|▍         | 90/1877 [14:45<4:44:07,  9.54s/it]{'loss': -0.0028, 'grad_norm': 9.538643836975098, 'learning_rate': 4.734042553191489e-07, 'mean_ratio_chosen': 0.8303400278091431, 'mean_ratio_rejected': 2.6900570392608643, 'weight_chosen': 0.02667837403714657, 'weight_rejected': 0.012005291879177094, 'kl_term_chosen': -0.1211395263671875, 'mean_len_chosen': 321.5, 'mean_len_rejected': 344.0, 'epoch': 0.047968021319120584}
                                                   {'loss': -0.0028, 'grad_norm': 9.538643836975098, 'learning_rate': 4.734042553191489e-07, 'mean_ratio_chosen': 0.8303400278091431, 'mean_ratio_rejected': 2.6900570392608643, 'weight_chosen': 0.02667837403714657, 'weight_rejected': 0.012005291879177094, 'kl_term_chosen': -0.1211395263671875, 'mean_len_chosen': 321.5, 'mean_len_rejected': 344.0, 'epoch': 0.05}
  5%|▍         | 90/1877 [14:45<4:44:07,  9.54s/it]  5%|▍         | 91/1877 [14:58<5:19:02, 10.72s/it]  5%|▍         | 92/1877 [15:10<5:30:40, 11.11s/it]  5%|▍         | 93/1877 [15:20<5:19:22, 10.74s/it]  5%|▌         | 94/1877 [15:29<4:58:25, 10.04s/it]  5%|▌         | 95/1877 [15:42<5:23:45, 10.90s/it]  5%|▌         | 96/1877 [15:52<5:17:54, 10.71s/it]  5%|▌         | 97/1877 [16:02<5:12:21, 10.53s/it]  5%|▌         | 98/1877 [16:09<4:44:14,  9.59s/it]  5%|▌         | 99/1877 [16:23<5:20:34, 10.82s/it]  5%|▌         | 100/1877 [16:34<5:24:17, 10.95s/it]{'loss': 0.0042, 'grad_norm': 11.3504638671875, 'learning_rate': 5.26595744680851e-07, 'mean_ratio_chosen': 0.9154231548309326, 'mean_ratio_rejected': 2.3035900592803955, 'weight_chosen': 0.003327582497149706, 'weight_rejected': -0.00128069834318012, 'kl_term_chosen': -0.18922042846679688, 'mean_len_chosen': 323.5, 'mean_len_rejected': 316.5, 'epoch': 0.05329780146568954}
                                                    {'loss': 0.0042, 'grad_norm': 11.3504638671875, 'learning_rate': 5.26595744680851e-07, 'mean_ratio_chosen': 0.9154231548309326, 'mean_ratio_rejected': 2.3035900592803955, 'weight_chosen': 0.003327582497149706, 'weight_rejected': -0.00128069834318012, 'kl_term_chosen': -0.18922042846679688, 'mean_len_chosen': 323.5, 'mean_len_rejected': 316.5, 'epoch': 0.05}
  5%|▌         | 100/1877 [16:34<5:24:17, 10.95s/it]  5%|▌         | 101/1877 [16:45<5:21:02, 10.85s/it]  5%|▌         | 102/1877 [16:55<5:16:08, 10.69s/it]  5%|▌         | 103/1877 [17:07<5:24:30, 10.98s/it]  6%|▌         | 104/1877 [17:17<5:20:18, 10.84s/it]  6%|▌         | 105/1877 [17:28<5:20:36, 10.86s/it]  6%|▌         | 106/1877 [17:38<5:07:04, 10.40s/it]  6%|▌         | 107/1877 [17:51<5:31:29, 11.24s/it]  6%|▌         | 108/1877 [18:00<5:17:02, 10.75s/it]  6%|▌         | 109/1877 [18:09<4:59:46, 10.17s/it]  6%|▌         | 110/1877 [18:17<4:41:48,  9.57s/it]{'loss': 0.009, 'grad_norm': 82.55171966552734, 'learning_rate': 5.797872340425531e-07, 'mean_ratio_chosen': 1.421616554260254, 'mean_ratio_rejected': 1.2210794687271118, 'weight_chosen': -0.021366171538829803, 'weight_rejected': 0.09888707101345062, 'kl_term_chosen': -0.09374046325683594, 'mean_len_chosen': 258.5, 'mean_len_rejected': 286.5, 'epoch': 0.05862758161225849}
                                                    {'loss': 0.009, 'grad_norm': 82.55171966552734, 'learning_rate': 5.797872340425531e-07, 'mean_ratio_chosen': 1.421616554260254, 'mean_ratio_rejected': 1.2210794687271118, 'weight_chosen': -0.021366171538829803, 'weight_rejected': 0.09888707101345062, 'kl_term_chosen': -0.09374046325683594, 'mean_len_chosen': 258.5, 'mean_len_rejected': 286.5, 'epoch': 0.06}
  6%|▌         | 110/1877 [18:18<4:41:48,  9.57s/it]  6%|▌         | 111/1877 [18:27<4:37:43,  9.44s/it]  6%|▌         | 112/1877 [18:34<4:22:26,  8.92s/it]  6%|▌         | 113/1877 [18:44<4:29:06,  9.15s/it]  6%|▌         | 114/1877 [18:54<4:38:59,  9.49s/it]  6%|▌         | 115/1877 [19:07<5:08:00, 10.49s/it]  6%|▌         | 116/1877 [19:17<5:06:40, 10.45s/it]  6%|▌         | 117/1877 [19:29<5:16:15, 10.78s/it]  6%|▋         | 118/1877 [19:42<5:31:30, 11.31s/it]  6%|▋         | 119/1877 [19:50<5:02:22, 10.32s/it]  6%|▋         | 120/1877 [20:00<5:07:23, 10.50s/it]{'loss': 0.012, 'grad_norm': 10.252785682678223, 'learning_rate': 6.329787234042553e-07, 'mean_ratio_chosen': 1.568088173866272, 'mean_ratio_rejected': 1.0394086837768555, 'weight_chosen': 0.012307725846767426, 'weight_rejected': 0.012707339599728584, 'kl_term_chosen': -0.10209846496582031, 'mean_len_chosen': 200.5, 'mean_len_rejected': 190.5, 'epoch': 0.06395736175882745}
                                                    {'loss': 0.012, 'grad_norm': 10.252785682678223, 'learning_rate': 6.329787234042553e-07, 'mean_ratio_chosen': 1.568088173866272, 'mean_ratio_rejected': 1.0394086837768555, 'weight_chosen': 0.012307725846767426, 'weight_rejected': 0.012707339599728584, 'kl_term_chosen': -0.10209846496582031, 'mean_len_chosen': 200.5, 'mean_len_rejected': 190.5, 'epoch': 0.06}
  6%|▋         | 120/1877 [20:01<5:07:23, 10.50s/it]  6%|▋         | 121/1877 [20:10<5:01:15, 10.29s/it]  6%|▋         | 122/1877 [20:21<5:05:48, 10.45s/it]  7%|▋         | 123/1877 [20:30<4:49:20,  9.90s/it]  7%|▋         | 124/1877 [20:42<5:10:17, 10.62s/it]  7%|▋         | 125/1877 [20:54<5:22:33, 11.05s/it]  7%|▋         | 126/1877 [21:07<5:39:15, 11.62s/it]  7%|▋         | 127/1877 [21:17<5:22:28, 11.06s/it]  7%|▋         | 128/1877 [21:26<5:02:22, 10.37s/it]  7%|▋         | 129/1877 [21:36<4:59:49, 10.29s/it]  7%|▋         | 130/1877 [21:45<4:52:41, 10.05s/it]{'loss': 0.0216, 'grad_norm': 47.403018951416016, 'learning_rate': 6.861702127659574e-07, 'mean_ratio_chosen': 3.436756134033203, 'mean_ratio_rejected': 4.71871280670166, 'weight_chosen': 0.000422282493673265, 'weight_rejected': 0.0011992186773568392, 'kl_term_chosen': 0.6033477783203125, 'mean_len_chosen': 762.5, 'mean_len_rejected': 745.0, 'epoch': 0.06928714190539641}
                                                    {'loss': 0.0216, 'grad_norm': 47.403018951416016, 'learning_rate': 6.861702127659574e-07, 'mean_ratio_chosen': 3.436756134033203, 'mean_ratio_rejected': 4.71871280670166, 'weight_chosen': 0.000422282493673265, 'weight_rejected': 0.0011992186773568392, 'kl_term_chosen': 0.6033477783203125, 'mean_len_chosen': 762.5, 'mean_len_rejected': 745.0, 'epoch': 0.07}
  7%|▋         | 130/1877 [21:45<4:52:41, 10.05s/it]  7%|▋         | 131/1877 [21:57<5:04:12, 10.45s/it]  7%|▋         | 132/1877 [22:08<5:14:34, 10.82s/it]  7%|▋         | 133/1877 [22:17<4:54:48, 10.14s/it]  7%|▋         | 134/1877 [22:26<4:45:56,  9.84s/it]  7%|▋         | 135/1877 [22:34<4:32:55,  9.40s/it]  7%|▋         | 136/1877 [22:44<4:32:52,  9.40s/it]  7%|▋         | 137/1877 [22:51<4:18:31,  8.91s/it]  7%|▋         | 138/1877 [23:00<4:13:06,  8.73s/it]  7%|▋         | 139/1877 [23:09<4:17:51,  8.90s/it]  7%|▋         | 140/1877 [23:21<4:45:47,  9.87s/it]{'loss': 0.007, 'grad_norm': 24.360563278198242, 'learning_rate': 7.393617021276596e-07, 'mean_ratio_chosen': 4.837796211242676, 'mean_ratio_rejected': 2.870433807373047, 'weight_chosen': -0.00023083534324541688, 'weight_rejected': 0.0030776814091950655, 'kl_term_chosen': 0.7815361022949219, 'mean_len_chosen': 332.0, 'mean_len_rejected': 308.0, 'epoch': 0.07461692205196535}
                                                    {'loss': 0.007, 'grad_norm': 24.360563278198242, 'learning_rate': 7.393617021276596e-07, 'mean_ratio_chosen': 4.837796211242676, 'mean_ratio_rejected': 2.870433807373047, 'weight_chosen': -0.00023083534324541688, 'weight_rejected': 0.0030776814091950655, 'kl_term_chosen': 0.7815361022949219, 'mean_len_chosen': 332.0, 'mean_len_rejected': 308.0, 'epoch': 0.07}
  7%|▋         | 140/1877 [23:21<4:45:47,  9.87s/it]  8%|▊         | 141/1877 [23:31<4:48:04,  9.96s/it]  8%|▊         | 142/1877 [23:41<4:47:22,  9.94s/it]  8%|▊         | 143/1877 [23:54<5:11:26, 10.78s/it]  8%|▊         | 144/1877 [24:05<5:12:04, 10.80s/it]  8%|▊         | 145/1877 [24:18<5:28:48, 11.39s/it]  8%|▊         | 146/1877 [24:28<5:18:10, 11.03s/it]  8%|▊         | 147/1877 [24:37<4:59:28, 10.39s/it]  8%|▊         | 148/1877 [24:48<5:03:28, 10.53s/it]  8%|▊         | 149/1877 [25:00<5:22:31, 11.20s/it]  8%|▊         | 150/1877 [25:10<5:05:55, 10.63s/it]{'loss': 0.1267, 'grad_norm': 1161.14794921875, 'learning_rate': 7.925531914893616e-07, 'mean_ratio_chosen': 1.0233047008514404, 'mean_ratio_rejected': 0.8016351461410522, 'weight_chosen': 0.0026422240771353245, 'weight_rejected': -0.002187537495046854, 'kl_term_chosen': -0.11785316467285156, 'mean_len_chosen': 594.5, 'mean_len_rejected': 830.5, 'epoch': 0.07994670219853431}
                                                    {'loss': 0.1267, 'grad_norm': 1161.14794921875, 'learning_rate': 7.925531914893616e-07, 'mean_ratio_chosen': 1.0233047008514404, 'mean_ratio_rejected': 0.8016351461410522, 'weight_chosen': 0.0026422240771353245, 'weight_rejected': -0.002187537495046854, 'kl_term_chosen': -0.11785316467285156, 'mean_len_chosen': 594.5, 'mean_len_rejected': 830.5, 'epoch': 0.08}
  8%|▊         | 150/1877 [25:10<5:05:55, 10.63s/it]  8%|▊         | 151/1877 [25:20<5:02:23, 10.51s/it]  8%|▊         | 152/1877 [25:29<4:47:03,  9.98s/it]  8%|▊         | 153/1877 [25:36<4:26:08,  9.26s/it]  8%|▊         | 154/1877 [25:48<4:50:43, 10.12s/it]  8%|▊         | 155/1877 [25:58<4:42:39,  9.85s/it]  8%|▊         | 156/1877 [26:09<4:52:11, 10.19s/it]  8%|▊         | 157/1877 [26:20<5:00:59, 10.50s/it]  8%|▊         | 158/1877 [26:27<4:36:51,  9.66s/it]  8%|▊         | 159/1877 [26:38<4:40:28,  9.80s/it]  9%|▊         | 160/1877 [26:48<4:44:57,  9.96s/it]{'loss': 0.0044, 'grad_norm': 8.677777290344238, 'learning_rate': 8.457446808510637e-07, 'mean_ratio_chosen': 7.464907169342041, 'mean_ratio_rejected': 2.258028030395508, 'weight_chosen': -0.000911519571673125, 'weight_rejected': 0.0012660089414566755, 'kl_term_chosen': 1.1599807739257812, 'mean_len_chosen': 505.0, 'mean_len_rejected': 537.5, 'epoch': 0.08527648234510327}
                                                    {'loss': 0.0044, 'grad_norm': 8.677777290344238, 'learning_rate': 8.457446808510637e-07, 'mean_ratio_chosen': 7.464907169342041, 'mean_ratio_rejected': 2.258028030395508, 'weight_chosen': -0.000911519571673125, 'weight_rejected': 0.0012660089414566755, 'kl_term_chosen': 1.1599807739257812, 'mean_len_chosen': 505.0, 'mean_len_rejected': 537.5, 'epoch': 0.09}
  9%|▊         | 160/1877 [26:48<4:44:57,  9.96s/it]  9%|▊         | 161/1877 [26:57<4:39:40,  9.78s/it]  9%|▊         | 162/1877 [27:09<4:59:47, 10.49s/it]  9%|▊         | 163/1877 [27:19<4:49:51, 10.15s/it]  9%|▊         | 164/1877 [27:27<4:36:36,  9.69s/it]  9%|▉         | 165/1877 [27:38<4:43:28,  9.93s/it]  9%|▉         | 166/1877 [27:46<4:29:24,  9.45s/it]  9%|▉         | 167/1877 [27:58<4:47:25, 10.09s/it]  9%|▉         | 168/1877 [28:08<4:48:32, 10.13s/it]  9%|▉         | 169/1877 [28:16<4:32:31,  9.57s/it]  9%|▉         | 170/1877 [28:25<4:26:55,  9.38s/it]{'loss': 0.0231, 'grad_norm': 59.49836730957031, 'learning_rate': 8.989361702127659e-07, 'mean_ratio_chosen': 1.3265048265457153, 'mean_ratio_rejected': 1.3741093873977661, 'weight_chosen': 0.030806027352809906, 'weight_rejected': 0.08128391206264496, 'kl_term_chosen': -0.04645252227783203, 'mean_len_chosen': 137.5, 'mean_len_rejected': 145.0, 'epoch': 0.09060626249167222}
                                                    {'loss': 0.0231, 'grad_norm': 59.49836730957031, 'learning_rate': 8.989361702127659e-07, 'mean_ratio_chosen': 1.3265048265457153, 'mean_ratio_rejected': 1.3741093873977661, 'weight_chosen': 0.030806027352809906, 'weight_rejected': 0.08128391206264496, 'kl_term_chosen': -0.04645252227783203, 'mean_len_chosen': 137.5, 'mean_len_rejected': 145.0, 'epoch': 0.09}
  9%|▉         | 170/1877 [28:25<4:26:55,  9.38s/it]  9%|▉         | 171/1877 [28:34<4:17:58,  9.07s/it]  9%|▉         | 172/1877 [28:44<4:29:32,  9.49s/it]  9%|▉         | 173/1877 [28:55<4:43:37,  9.99s/it]  9%|▉         | 174/1877 [29:06<4:47:33, 10.13s/it]  9%|▉         | 175/1877 [29:15<4:37:38,  9.79s/it]  9%|▉         | 176/1877 [29:23<4:25:57,  9.38s/it]  9%|▉         | 177/1877 [29:34<4:36:03,  9.74s/it]  9%|▉         | 178/1877 [29:44<4:40:54,  9.92s/it] 10%|▉         | 179/1877 [29:55<4:46:26, 10.12s/it] 10%|▉         | 180/1877 [30:03<4:32:31,  9.64s/it]{'loss': 0.0503, 'grad_norm': 57.4228630065918, 'learning_rate': 9.52127659574468e-07, 'mean_ratio_chosen': 5.037220001220703, 'mean_ratio_rejected': 1.0023410320281982, 'weight_chosen': 0.017625315114855766, 'weight_rejected': -0.006400594487786293, 'kl_term_chosen': -0.3321189880371094, 'mean_len_chosen': 319.5, 'mean_len_rejected': 343.0, 'epoch': 0.09593604263824117}
                                                    {'loss': 0.0503, 'grad_norm': 57.4228630065918, 'learning_rate': 9.52127659574468e-07, 'mean_ratio_chosen': 5.037220001220703, 'mean_ratio_rejected': 1.0023410320281982, 'weight_chosen': 0.017625315114855766, 'weight_rejected': -0.006400594487786293, 'kl_term_chosen': -0.3321189880371094, 'mean_len_chosen': 319.5, 'mean_len_rejected': 343.0, 'epoch': 0.1}
 10%|▉         | 180/1877 [30:03<4:32:31,  9.64s/it] 10%|▉         | 181/1877 [30:14<4:46:00, 10.12s/it] 10%|▉         | 182/1877 [30:25<4:53:43, 10.40s/it] 10%|▉         | 183/1877 [30:32<4:22:30,  9.30s/it] 10%|▉         | 184/1877 [30:43<4:34:56,  9.74s/it] 10%|▉         | 185/1877 [30:53<4:34:25,  9.73s/it] 10%|▉         | 186/1877 [31:01<4:19:27,  9.21s/it] 10%|▉         | 187/1877 [31:10<4:22:20,  9.31s/it] 10%|█         | 188/1877 [31:25<5:05:53, 10.87s/it] 10%|█         | 189/1877 [31:35<4:58:40, 10.62s/it] 10%|█         | 190/1877 [31:43<4:42:18, 10.04s/it]{'loss': 0.0086, 'grad_norm': 8.722809791564941, 'learning_rate': 9.99999135071257e-07, 'mean_ratio_chosen': 2.0236313343048096, 'mean_ratio_rejected': 2.7095961570739746, 'weight_chosen': 0.0012644634116441011, 'weight_rejected': -1.493009040132165e-05, 'kl_term_chosen': 0.3424224853515625, 'mean_len_chosen': 422.0, 'mean_len_rejected': 495.0, 'epoch': 0.10126582278481013}
                                                    {'loss': 0.0086, 'grad_norm': 8.722809791564941, 'learning_rate': 9.99999135071257e-07, 'mean_ratio_chosen': 2.0236313343048096, 'mean_ratio_rejected': 2.7095961570739746, 'weight_chosen': 0.0012644634116441011, 'weight_rejected': -1.493009040132165e-05, 'kl_term_chosen': 0.3424224853515625, 'mean_len_chosen': 422.0, 'mean_len_rejected': 495.0, 'epoch': 0.1}
 10%|█         | 190/1877 [31:43<4:42:18, 10.04s/it] 10%|█         | 191/1877 [31:54<4:45:55, 10.18s/it] 10%|█         | 192/1877 [32:04<4:43:57, 10.11s/it] 10%|█         | 193/1877 [32:14<4:45:04, 10.16s/it] 10%|█         | 194/1877 [32:24<4:42:33, 10.07s/it] 10%|█         | 195/1877 [32:36<4:57:19, 10.61s/it] 10%|█         | 196/1877 [32:46<4:56:10, 10.57s/it] 10%|█         | 197/1877 [32:56<4:46:52, 10.25s/it] 11%|█         | 198/1877 [33:09<5:11:19, 11.13s/it] 11%|█         | 199/1877 [33:18<4:57:52, 10.65s/it] 11%|█         | 200/1877 [33:30<5:04:34, 10.90s/it]{'loss': 0.0222, 'grad_norm': 67.78519439697266, 'learning_rate': 9.998953472428504e-07, 'mean_ratio_chosen': 0.25421687960624695, 'mean_ratio_rejected': 0.1927841454744339, 'weight_chosen': 0.01640130765736103, 'weight_rejected': -0.005838066339492798, 'kl_term_chosen': -0.693324089050293, 'mean_len_chosen': 79.0, 'mean_len_rejected': 124.0, 'epoch': 0.10659560293137908}
                                                    {'loss': 0.0222, 'grad_norm': 67.78519439697266, 'learning_rate': 9.998953472428504e-07, 'mean_ratio_chosen': 0.25421687960624695, 'mean_ratio_rejected': 0.1927841454744339, 'weight_chosen': 0.01640130765736103, 'weight_rejected': -0.005838066339492798, 'kl_term_chosen': -0.693324089050293, 'mean_len_chosen': 79.0, 'mean_len_rejected': 124.0, 'epoch': 0.11}
 11%|█         | 200/1877 [33:30<5:04:34, 10.90s/it] 11%|█         | 201/1877 [33:40<4:58:02, 10.67s/it] 11%|█         | 202/1877 [33:47<4:26:24,  9.54s/it] 11%|█         | 203/1877 [33:58<4:40:06, 10.04s/it] 11%|█         | 204/1877 [34:09<4:46:12, 10.26s/it] 11%|█         | 205/1877 [34:19<4:46:13, 10.27s/it] 11%|█         | 206/1877 [34:29<4:42:55, 10.16s/it] 11%|█         | 207/1877 [34:42<5:05:18, 10.97s/it] 11%|█         | 208/1877 [34:51<4:46:13, 10.29s/it] 11%|█         | 209/1877 [35:00<4:33:55,  9.85s/it] 11%|█         | 210/1877 [35:08<4:17:53,  9.28s/it]{'loss': -0.0007, 'grad_norm': 8.705102920532227, 'learning_rate': 9.996186148090817e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.1596778929233551, 'weight_rejected': -0.17662420868873596, 'kl_term_chosen': -2.3620595932006836, 'mean_len_chosen': 24.5, 'mean_len_rejected': 19.5, 'epoch': 0.11192538307794804}
                                                    {'loss': -0.0007, 'grad_norm': 8.705102920532227, 'learning_rate': 9.996186148090817e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.1596778929233551, 'weight_rejected': -0.17662420868873596, 'kl_term_chosen': -2.3620595932006836, 'mean_len_chosen': 24.5, 'mean_len_rejected': 19.5, 'epoch': 0.11}
 11%|█         | 210/1877 [35:08<4:17:53,  9.28s/it] 11%|█         | 211/1877 [35:18<4:27:09,  9.62s/it] 11%|█▏        | 212/1877 [35:26<4:11:09,  9.05s/it] 11%|█▏        | 213/1877 [35:36<4:20:16,  9.38s/it] 11%|█▏        | 214/1877 [35:46<4:25:22,  9.57s/it] 11%|█▏        | 215/1877 [35:57<4:35:49,  9.96s/it] 12%|█▏        | 216/1877 [36:07<4:41:13, 10.16s/it] 12%|█▏        | 217/1877 [36:16<4:29:04,  9.73s/it] 12%|█▏        | 218/1877 [36:25<4:21:06,  9.44s/it] 12%|█▏        | 219/1877 [36:36<4:33:52,  9.91s/it] 12%|█▏        | 220/1877 [36:46<4:32:09,  9.85s/it]{'loss': 0.0063, 'grad_norm': 15.585409164428711, 'learning_rate': 9.991690335087527e-07, 'mean_ratio_chosen': 5.554305076599121, 'mean_ratio_rejected': 0.17952239513397217, 'weight_chosen': -0.0009463255410082638, 'weight_rejected': -0.0009458641288802028, 'kl_term_chosen': 1.0951042175292969, 'mean_len_chosen': 923.0, 'mean_len_rejected': 1113.5, 'epoch': 0.11725516322451698}
                                                    {'loss': 0.0063, 'grad_norm': 15.585409164428711, 'learning_rate': 9.991690335087527e-07, 'mean_ratio_chosen': 5.554305076599121, 'mean_ratio_rejected': 0.17952239513397217, 'weight_chosen': -0.0009463255410082638, 'weight_rejected': -0.0009458641288802028, 'kl_term_chosen': 1.0951042175292969, 'mean_len_chosen': 923.0, 'mean_len_rejected': 1113.5, 'epoch': 0.12}
 12%|█▏        | 220/1877 [36:46<4:32:09,  9.85s/it] 12%|█▏        | 221/1877 [36:56<4:37:38, 10.06s/it] 12%|█▏        | 222/1877 [37:05<4:29:40,  9.78s/it] 12%|█▏        | 223/1877 [37:14<4:24:55,  9.61s/it] 12%|█▏        | 224/1877 [37:23<4:17:25,  9.34s/it] 12%|█▏        | 225/1877 [37:36<4:43:41, 10.30s/it] 12%|█▏        | 226/1877 [37:47<4:49:51, 10.53s/it] 12%|█▏        | 227/1877 [37:57<4:47:40, 10.46s/it] 12%|█▏        | 228/1877 [38:08<4:54:17, 10.71s/it] 12%|█▏        | 229/1877 [38:17<4:41:15, 10.24s/it] 12%|█▏        | 230/1877 [38:29<4:48:32, 10.51s/it]{'loss': -0.0023, 'grad_norm': 12.952160835266113, 'learning_rate': 9.98546758879739e-07, 'mean_ratio_chosen': 0.42697376012802124, 'mean_ratio_rejected': 0.8705810904502869, 'weight_chosen': 0.019935553893446922, 'weight_rejected': -0.005509056616574526, 'kl_term_chosen': -1.0442132949829102, 'mean_len_chosen': 158.0, 'mean_len_rejected': 175.5, 'epoch': 0.12258494337108594}
                                                    {'loss': -0.0023, 'grad_norm': 12.952160835266113, 'learning_rate': 9.98546758879739e-07, 'mean_ratio_chosen': 0.42697376012802124, 'mean_ratio_rejected': 0.8705810904502869, 'weight_chosen': 0.019935553893446922, 'weight_rejected': -0.005509056616574526, 'kl_term_chosen': -1.0442132949829102, 'mean_len_chosen': 158.0, 'mean_len_rejected': 175.5, 'epoch': 0.12}
 12%|█▏        | 230/1877 [38:29<4:48:32, 10.51s/it] 12%|█▏        | 231/1877 [38:34<4:09:56,  9.11s/it] 12%|█▏        | 232/1877 [38:45<4:18:52,  9.44s/it] 12%|█▏        | 233/1877 [38:53<4:12:02,  9.20s/it] 12%|█▏        | 234/1877 [39:04<4:25:51,  9.71s/it] 13%|█▎        | 235/1877 [39:18<4:59:04, 10.93s/it] 13%|█▎        | 236/1877 [39:27<4:46:32, 10.48s/it] 13%|█▎        | 237/1877 [39:36<4:29:03,  9.84s/it] 13%|█▎        | 238/1877 [39:47<4:40:55, 10.28s/it] 13%|█▎        | 239/1877 [39:57<4:34:52, 10.07s/it] 13%|█▎        | 240/1877 [40:09<4:55:36, 10.83s/it]{'loss': 0.0545, 'grad_norm': 0.41803497076034546, 'learning_rate': 9.977520062051814e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.027963927015662193, 'weight_rejected': -0.013330137357115746, 'kl_term_chosen': -4.31158447265625, 'mean_len_chosen': 265.0, 'mean_len_rejected': 343.0, 'epoch': 0.1279147235176549}
                                                    {'loss': 0.0545, 'grad_norm': 0.41803497076034546, 'learning_rate': 9.977520062051814e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.027963927015662193, 'weight_rejected': -0.013330137357115746, 'kl_term_chosen': -4.31158447265625, 'mean_len_chosen': 265.0, 'mean_len_rejected': 343.0, 'epoch': 0.13}
 13%|█▎        | 240/1877 [40:09<4:55:36, 10.83s/it] 13%|█▎        | 241/1877 [40:19<4:47:43, 10.55s/it] 13%|█▎        | 242/1877 [40:29<4:37:49, 10.20s/it] 13%|█▎        | 243/1877 [40:38<4:30:38,  9.94s/it] 13%|█▎        | 244/1877 [40:48<4:29:13,  9.89s/it] 13%|█▎        | 245/1877 [41:01<4:58:26, 10.97s/it] 13%|█▎        | 246/1877 [41:12<4:58:19, 10.97s/it] 13%|█▎        | 247/1877 [41:23<5:01:08, 11.08s/it] 13%|█▎        | 248/1877 [41:33<4:46:32, 10.55s/it] 13%|█▎        | 249/1877 [41:43<4:44:58, 10.50s/it] 13%|█▎        | 250/1877 [41:54<4:47:56, 10.62s/it]{'loss': -0.0138, 'grad_norm': 57.242164611816406, 'learning_rate': 9.967850504390044e-07, 'mean_ratio_chosen': 3.9462342262268066, 'mean_ratio_rejected': 0.4231316149234772, 'weight_chosen': 0.00045249436516314745, 'weight_rejected': -0.0006602315115742385, 'kl_term_chosen': 0.6661224365234375, 'mean_len_chosen': 603.0, 'mean_len_rejected': 710.5, 'epoch': 0.13324450366422386}
                                                    {'loss': -0.0138, 'grad_norm': 57.242164611816406, 'learning_rate': 9.967850504390044e-07, 'mean_ratio_chosen': 3.9462342262268066, 'mean_ratio_rejected': 0.4231316149234772, 'weight_chosen': 0.00045249436516314745, 'weight_rejected': -0.0006602315115742385, 'kl_term_chosen': 0.6661224365234375, 'mean_len_chosen': 603.0, 'mean_len_rejected': 710.5, 'epoch': 0.13}
 13%|█▎        | 250/1877 [41:54<4:47:56, 10.62s/it] 13%|█▎        | 251/1877 [42:05<4:53:24, 10.83s/it] 13%|█▎        | 252/1877 [42:14<4:39:18, 10.31s/it] 13%|█▎        | 253/1877 [42:23<4:25:54,  9.82s/it] 14%|█▎        | 254/1877 [42:36<4:47:37, 10.63s/it] 14%|█▎        | 255/1877 [42:45<4:35:21, 10.19s/it] 14%|█▎        | 256/1877 [42:54<4:23:50,  9.77s/it] 14%|█▎        | 257/1877 [43:06<4:44:13, 10.53s/it] 14%|█▎        | 258/1877 [43:17<4:50:04, 10.75s/it] 14%|█▍        | 259/1877 [43:26<4:32:25, 10.10s/it] 14%|█▍        | 260/1877 [43:37<4:42:51, 10.50s/it]{'loss': 0.0448, 'grad_norm': 14.332840919494629, 'learning_rate': 9.956462261107932e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 8.073183059692383, 'weight_chosen': -0.00745126698166132, 'weight_rejected': 0.005521805491298437, 'kl_term_chosen': 2.5593185424804688, 'mean_len_chosen': 249.5, 'mean_len_rejected': 241.5, 'epoch': 0.13857428381079281}
                                                    {'loss': 0.0448, 'grad_norm': 14.332840919494629, 'learning_rate': 9.956462261107932e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 8.073183059692383, 'weight_chosen': -0.00745126698166132, 'weight_rejected': 0.005521805491298437, 'kl_term_chosen': 2.5593185424804688, 'mean_len_chosen': 249.5, 'mean_len_rejected': 241.5, 'epoch': 0.14}
 14%|█▍        | 260/1877 [43:37<4:42:51, 10.50s/it] 14%|█▍        | 261/1877 [43:47<4:36:04, 10.25s/it] 14%|█▍        | 262/1877 [43:58<4:47:03, 10.66s/it] 14%|█▍        | 263/1877 [44:06<4:21:53,  9.74s/it] 14%|█▍        | 264/1877 [44:16<4:23:25,  9.80s/it] 14%|█▍        | 265/1877 [44:24<4:08:08,  9.24s/it] 14%|█▍        | 266/1877 [44:33<4:09:40,  9.30s/it] 14%|█▍        | 267/1877 [44:44<4:20:40,  9.71s/it] 14%|█▍        | 268/1877 [44:56<4:38:12, 10.37s/it] 14%|█▍        | 269/1877 [45:04<4:21:26,  9.76s/it] 14%|█▍        | 270/1877 [45:11<3:58:47,  8.92s/it]{'loss': 0.2304, 'grad_norm': 3.583770990371704, 'learning_rate': 9.943359272100607e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 4.589070796966553, 'weight_chosen': 0.5243272185325623, 'weight_rejected': -0.406061053276062, 'kl_term_chosen': -2.055678367614746, 'mean_len_chosen': 475.0, 'mean_len_rejected': 459.0, 'epoch': 0.14390406395736177}
                                                    {'loss': 0.2304, 'grad_norm': 3.583770990371704, 'learning_rate': 9.943359272100607e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 4.589070796966553, 'weight_chosen': 0.5243272185325623, 'weight_rejected': -0.406061053276062, 'kl_term_chosen': -2.055678367614746, 'mean_len_chosen': 475.0, 'mean_len_rejected': 459.0, 'epoch': 0.14}
 14%|█▍        | 270/1877 [45:11<3:58:47,  8.92s/it] 14%|█▍        | 271/1877 [45:19<3:49:16,  8.57s/it] 14%|█▍        | 272/1877 [45:26<3:35:43,  8.06s/it] 15%|█▍        | 273/1877 [45:34<3:33:56,  8.00s/it] 15%|█▍        | 274/1877 [45:48<4:24:00,  9.88s/it] 15%|█▍        | 275/1877 [45:58<4:23:53,  9.88s/it] 15%|█▍        | 276/1877 [46:06<4:10:14,  9.38s/it] 15%|█▍        | 277/1877 [46:15<4:03:26,  9.13s/it] 15%|█▍        | 278/1877 [46:24<4:06:20,  9.24s/it] 15%|█▍        | 279/1877 [46:35<4:21:52,  9.83s/it] 15%|█▍        | 280/1877 [46:43<4:05:12,  9.21s/it]{'loss': 0.0194, 'grad_norm': 0.18561755120754242, 'learning_rate': 9.928546070499403e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.0739660263061523, 'weight_rejected': -0.6569562554359436, 'kl_term_chosen': -14.548480987548828, 'mean_len_chosen': 36.0, 'mean_len_rejected': 65.5, 'epoch': 0.1492338441039307}
                                                    {'loss': 0.0194, 'grad_norm': 0.18561755120754242, 'learning_rate': 9.928546070499403e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.0739660263061523, 'weight_rejected': -0.6569562554359436, 'kl_term_chosen': -14.548480987548828, 'mean_len_chosen': 36.0, 'mean_len_rejected': 65.5, 'epoch': 0.15}
 15%|█▍        | 280/1877 [46:43<4:05:12,  9.21s/it] 15%|█▍        | 281/1877 [46:53<4:07:48,  9.32s/it] 15%|█▌        | 282/1877 [47:01<4:02:27,  9.12s/it] 15%|█▌        | 283/1877 [47:12<4:16:22,  9.65s/it] 15%|█▌        | 284/1877 [47:25<4:38:32, 10.49s/it] 15%|█▌        | 285/1877 [47:33<4:21:14,  9.85s/it] 15%|█▌        | 286/1877 [47:43<4:21:16,  9.85s/it] 15%|█▌        | 287/1877 [47:52<4:11:28,  9.49s/it] 15%|█▌        | 288/1877 [48:02<4:20:51,  9.85s/it] 15%|█▌        | 289/1877 [48:13<4:26:39, 10.08s/it] 15%|█▌        | 290/1877 [48:21<4:14:22,  9.62s/it]{'loss': -0.0219, 'grad_norm': 0.0, 'learning_rate': 9.912027781103574e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.014630037359893322, 'weight_rejected': -0.025249699130654335, 'kl_term_chosen': -7.7771453857421875, 'mean_len_chosen': 631.5, 'mean_len_rejected': 572.5, 'epoch': 0.15456362425049966}
                                                    {'loss': -0.0219, 'grad_norm': 0.0, 'learning_rate': 9.912027781103574e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.014630037359893322, 'weight_rejected': -0.025249699130654335, 'kl_term_chosen': -7.7771453857421875, 'mean_len_chosen': 631.5, 'mean_len_rejected': 572.5, 'epoch': 0.15}
 15%|█▌        | 290/1877 [48:22<4:14:22,  9.62s/it] 16%|█▌        | 291/1877 [48:32<4:21:32,  9.89s/it] 16%|█▌        | 292/1877 [48:39<3:57:33,  8.99s/it] 16%|█▌        | 293/1877 [48:48<3:59:13,  9.06s/it] 16%|█▌        | 294/1877 [48:58<4:05:01,  9.29s/it] 16%|█▌        | 295/1877 [49:08<4:07:45,  9.40s/it] 16%|█▌        | 296/1877 [49:16<4:02:23,  9.20s/it] 16%|█▌        | 297/1877 [49:28<4:20:07,  9.88s/it] 16%|█▌        | 298/1877 [49:35<3:58:49,  9.08s/it] 16%|█▌        | 299/1877 [49:44<3:59:56,  9.12s/it] 16%|█▌        | 300/1877 [49:56<4:20:10,  9.90s/it]{'loss': -0.0291, 'grad_norm': 1.4024707078933716, 'learning_rate': 9.893810118607323e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.011735147796571255, 'weight_rejected': -0.015260810032486916, 'kl_term_chosen': -4.727069854736328, 'mean_len_chosen': 592.5, 'mean_len_rejected': 550.5, 'epoch': 0.15989340439706862}
                                                    {'loss': -0.0291, 'grad_norm': 1.4024707078933716, 'learning_rate': 9.893810118607323e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.011735147796571255, 'weight_rejected': -0.015260810032486916, 'kl_term_chosen': -4.727069854736328, 'mean_len_chosen': 592.5, 'mean_len_rejected': 550.5, 'epoch': 0.16}
 16%|█▌        | 300/1877 [49:56<4:20:10,  9.90s/it] 16%|█▌        | 301/1877 [50:07<4:29:51, 10.27s/it] 16%|█▌        | 302/1877 [50:17<4:26:25, 10.15s/it] 16%|█▌        | 303/1877 [50:25<4:07:06,  9.42s/it] 16%|█▌        | 304/1877 [50:32<3:53:46,  8.92s/it] 16%|█▌        | 305/1877 [50:41<3:51:29,  8.84s/it] 16%|█▋        | 306/1877 [50:51<4:02:07,  9.25s/it] 16%|█▋        | 307/1877 [51:02<4:14:47,  9.74s/it] 16%|█▋        | 308/1877 [51:12<4:15:08,  9.76s/it] 16%|█▋        | 309/1877 [51:19<3:58:02,  9.11s/it] 17%|█▋        | 310/1877 [51:28<3:55:05,  9.00s/it]{'loss': 0.1642, 'grad_norm': 1.766880989074707, 'learning_rate': 9.873899385622721e-07, 'mean_ratio_chosen': 0.2041095793247223, 'mean_ratio_rejected': 5.4230055809021, 'weight_chosen': 0.003275063121691346, 'weight_rejected': 0.005393011495471001, 'kl_term_chosen': -0.8016204833984375, 'mean_len_chosen': 543.5, 'mean_len_rejected': 463.5, 'epoch': 0.16522318454363757}
                                                    {'loss': 0.1642, 'grad_norm': 1.766880989074707, 'learning_rate': 9.873899385622721e-07, 'mean_ratio_chosen': 0.2041095793247223, 'mean_ratio_rejected': 5.4230055809021, 'weight_chosen': 0.003275063121691346, 'weight_rejected': 0.005393011495471001, 'kl_term_chosen': -0.8016204833984375, 'mean_len_chosen': 543.5, 'mean_len_rejected': 463.5, 'epoch': 0.17}
 17%|█▋        | 310/1877 [51:28<3:55:05,  9.00s/it] 17%|█▋        | 311/1877 [51:37<3:55:56,  9.04s/it] 17%|█▋        | 312/1877 [51:47<3:56:51,  9.08s/it] 17%|█▋        | 313/1877 [51:56<3:58:16,  9.14s/it] 17%|█▋        | 314/1877 [52:07<4:15:11,  9.80s/it] 17%|█▋        | 315/1877 [52:18<4:24:45, 10.17s/it] 17%|█▋        | 316/1877 [52:28<4:23:11, 10.12s/it] 17%|█▋        | 317/1877 [52:38<4:21:18, 10.05s/it] 17%|█▋        | 318/1877 [52:47<4:14:12,  9.78s/it] 17%|█▋        | 319/1877 [52:55<3:57:26,  9.14s/it] 17%|█▋        | 320/1877 [53:07<4:22:56, 10.13s/it]{'loss': 0.0765, 'grad_norm': 5.935796737670898, 'learning_rate': 9.852302470499256e-07, 'mean_ratio_chosen': 2.9379870891571045, 'mean_ratio_rejected': 5.037220001220703, 'weight_chosen': 0.03675422444939613, 'weight_rejected': -0.013084245845675468, 'kl_term_chosen': -8.600034713745117, 'mean_len_chosen': 174.5, 'mean_len_rejected': 106.0, 'epoch': 0.17055296469020653}
                                                    {'loss': 0.0765, 'grad_norm': 5.935796737670898, 'learning_rate': 9.852302470499256e-07, 'mean_ratio_chosen': 2.9379870891571045, 'mean_ratio_rejected': 5.037220001220703, 'weight_chosen': 0.03675422444939613, 'weight_rejected': -0.013084245845675468, 'kl_term_chosen': -8.600034713745117, 'mean_len_chosen': 174.5, 'mean_len_rejected': 106.0, 'epoch': 0.17}
 17%|█▋        | 320/1877 [53:07<4:22:56, 10.13s/it] 17%|█▋        | 321/1877 [53:19<4:35:51, 10.64s/it] 17%|█▋        | 322/1877 [53:29<4:26:01, 10.26s/it] 17%|█▋        | 323/1877 [53:38<4:16:11,  9.89s/it] 17%|█▋        | 324/1877 [53:45<4:00:43,  9.30s/it] 17%|█▋        | 325/1877 [53:53<3:50:15,  8.90s/it] 17%|█▋        | 326/1877 [54:07<4:24:19, 10.23s/it] 17%|█▋        | 327/1877 [54:21<4:55:02, 11.42s/it] 17%|█▋        | 328/1877 [54:30<4:33:45, 10.60s/it] 18%|█▊        | 329/1877 [54:40<4:31:08, 10.51s/it] 18%|█▊        | 330/1877 [54:48<4:12:55,  9.81s/it]{'loss': 0.2441, 'grad_norm': 5.1774725914001465, 'learning_rate': 9.829026844940726e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.13080231845378876, 'weight_rejected': -0.12088638544082642, 'kl_term_chosen': -7.442745208740234, 'mean_len_chosen': 344.0, 'mean_len_rejected': 348.0, 'epoch': 0.1758827448367755}
                                                    {'loss': 0.2441, 'grad_norm': 5.1774725914001465, 'learning_rate': 9.829026844940726e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.13080231845378876, 'weight_rejected': -0.12088638544082642, 'kl_term_chosen': -7.442745208740234, 'mean_len_chosen': 344.0, 'mean_len_rejected': 348.0, 'epoch': 0.18}
 18%|█▊        | 330/1877 [54:48<4:12:55,  9.81s/it] 18%|█▊        | 331/1877 [54:58<4:15:48,  9.93s/it] 18%|█▊        | 332/1877 [55:07<4:03:46,  9.47s/it] 18%|█▊        | 333/1877 [55:20<4:33:53, 10.64s/it] 18%|█▊        | 334/1877 [55:28<4:08:51,  9.68s/it] 18%|█▊        | 335/1877 [55:38<4:12:36,  9.83s/it] 18%|█▊        | 336/1877 [55:50<4:28:20, 10.45s/it] 18%|█▊        | 337/1877 [55:59<4:19:02, 10.09s/it] 18%|█▊        | 338/1877 [56:08<4:11:07,  9.79s/it] 18%|█▊        | 339/1877 [56:17<4:06:54,  9.63s/it] 18%|█▊        | 340/1877 [56:29<4:26:30, 10.40s/it]{'loss': 0.0652, 'grad_norm': 4.071986198425293, 'learning_rate': 9.804080561420307e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.03229731693863869, 'weight_rejected': -0.038101036101579666, 'kl_term_chosen': -6.3948974609375, 'mean_len_chosen': 470.0, 'mean_len_rejected': 499.5, 'epoch': 0.18121252498334445}
                                                    {'loss': 0.0652, 'grad_norm': 4.071986198425293, 'learning_rate': 9.804080561420307e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.03229731693863869, 'weight_rejected': -0.038101036101579666, 'kl_term_chosen': -6.3948974609375, 'mean_len_chosen': 470.0, 'mean_len_rejected': 499.5, 'epoch': 0.18}
 18%|█▊        | 340/1877 [56:30<4:26:30, 10.40s/it] 18%|█▊        | 341/1877 [56:41<4:34:55, 10.74s/it] 18%|█▊        | 342/1877 [56:50<4:19:20, 10.14s/it] 18%|█▊        | 343/1877 [56:59<4:16:40, 10.04s/it] 18%|█▊        | 344/1877 [57:10<4:24:04, 10.34s/it] 18%|█▊        | 345/1877 [57:22<4:34:32, 10.75s/it] 18%|█▊        | 346/1877 [57:31<4:17:37, 10.10s/it] 18%|█▊        | 347/1877 [57:46<4:55:05, 11.57s/it] 19%|█▊        | 348/1877 [57:56<4:40:35, 11.01s/it] 19%|█▊        | 349/1877 [58:04<4:19:31, 10.19s/it] 19%|█▊        | 350/1877 [58:13<4:13:46,  9.97s/it]{'loss': 0.044, 'grad_norm': 13.866496086120605, 'learning_rate': 9.777472250394718e-07, 'mean_ratio_chosen': 1.788828730583191, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.007948360405862331, 'weight_rejected': -0.017900800332427025, 'kl_term_chosen': -2.953664779663086, 'mean_len_chosen': 311.0, 'mean_len_rejected': 414.0, 'epoch': 0.18654230512991338}
                                                    {'loss': 0.044, 'grad_norm': 13.866496086120605, 'learning_rate': 9.777472250394718e-07, 'mean_ratio_chosen': 1.788828730583191, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.007948360405862331, 'weight_rejected': -0.017900800332427025, 'kl_term_chosen': -2.953664779663086, 'mean_len_chosen': 311.0, 'mean_len_rejected': 414.0, 'epoch': 0.19}
 19%|█▊        | 350/1877 [58:14<4:13:46,  9.97s/it] 19%|█▊        | 351/1877 [58:22<4:06:19,  9.69s/it] 19%|█▉        | 352/1877 [58:33<4:12:27,  9.93s/it] 19%|█▉        | 353/1877 [58:45<4:29:59, 10.63s/it] 19%|█▉        | 354/1877 [58:54<4:19:36, 10.23s/it] 19%|█▉        | 355/1877 [59:03<4:06:44,  9.73s/it] 19%|█▉        | 356/1877 [59:13<4:08:53,  9.82s/it] 19%|█▉        | 357/1877 [59:22<4:03:44,  9.62s/it] 19%|█▉        | 358/1877 [59:35<4:28:21, 10.60s/it] 19%|█▉        | 359/1877 [59:47<4:38:50, 11.02s/it] 19%|█▉        | 360/1877 [59:56<4:23:28, 10.42s/it]{'loss': 0.0126, 'grad_norm': 0.11958043277263641, 'learning_rate': 9.749211117318413e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 5.037220001220703, 'weight_chosen': 0.03597104921936989, 'weight_rejected': -0.006569191813468933, 'kl_term_chosen': -9.780393600463867, 'mean_len_chosen': 401.0, 'mean_len_rejected': 408.5, 'epoch': 0.19187208527648233}
                                                    {'loss': 0.0126, 'grad_norm': 0.11958043277263641, 'learning_rate': 9.749211117318413e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 5.037220001220703, 'weight_chosen': 0.03597104921936989, 'weight_rejected': -0.006569191813468933, 'kl_term_chosen': -9.780393600463867, 'mean_len_chosen': 401.0, 'mean_len_rejected': 408.5, 'epoch': 0.19}
 19%|█▉        | 360/1877 [59:56<4:23:28, 10.42s/it] 19%|█▉        | 361/1877 [1:00:07<4:28:50, 10.64s/it] 19%|█▉        | 362/1877 [1:00:19<4:37:41, 11.00s/it] 19%|█▉        | 363/1877 [1:00:27<4:16:59, 10.18s/it] 19%|█▉        | 364/1877 [1:00:37<4:16:56, 10.19s/it] 19%|█▉        | 365/1877 [1:00:47<4:09:51,  9.91s/it] 19%|█▉        | 366/1877 [1:00:58<4:21:25, 10.38s/it] 20%|█▉        | 367/1877 [1:01:09<4:25:12, 10.54s/it] 20%|█▉        | 368/1877 [1:01:17<4:06:09,  9.79s/it] 20%|█▉        | 369/1877 [1:01:28<4:13:02, 10.07s/it] 20%|█▉        | 370/1877 [1:01:35<3:54:26,  9.33s/it]{'loss': -0.0064, 'grad_norm': 0.3904930055141449, 'learning_rate': 9.719306939458845e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.17494595050811768, 'weight_rejected': -0.16589294373989105, 'kl_term_chosen': -9.450238227844238, 'mean_len_chosen': 104.0, 'mean_len_rejected': 161.0, 'epoch': 0.1972018654230513}
                                                      {'loss': -0.0064, 'grad_norm': 0.3904930055141449, 'learning_rate': 9.719306939458845e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.17494595050811768, 'weight_rejected': -0.16589294373989105, 'kl_term_chosen': -9.450238227844238, 'mean_len_chosen': 104.0, 'mean_len_rejected': 161.0, 'epoch': 0.2}
 20%|█▉        | 370/1877 [1:01:36<3:54:26,  9.33s/it] 20%|█▉        | 371/1877 [1:01:44<3:45:55,  9.00s/it] 20%|█▉        | 372/1877 [1:01:52<3:39:33,  8.75s/it] 20%|█▉        | 373/1877 [1:02:00<3:31:36,  8.44s/it] 20%|█▉        | 374/1877 [1:02:10<3:44:04,  8.95s/it] 20%|█▉        | 375/1877 [1:02:19<3:44:13,  8.96s/it] 20%|██        | 376/1877 [1:02:28<3:50:11,  9.20s/it] 20%|██        | 377/1877 [1:02:36<3:37:57,  8.72s/it] 20%|██        | 378/1877 [1:02:45<3:38:39,  8.75s/it] 20%|██        | 379/1877 [1:02:54<3:38:21,  8.75s/it] 20%|██        | 380/1877 [1:03:05<4:00:04,  9.62s/it]{'loss': -0.0124, 'grad_norm': 0.5035319328308105, 'learning_rate': 9.687770062513896e-07, 'mean_ratio_chosen': 0.7528456449508667, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.006094807293266058, 'weight_rejected': -0.04161440581083298, 'kl_term_chosen': -0.4272480010986328, 'mean_len_chosen': 175.0, 'mean_len_rejected': 206.5, 'epoch': 0.20253164556962025}
                                                      {'loss': -0.0124, 'grad_norm': 0.5035319328308105, 'learning_rate': 9.687770062513896e-07, 'mean_ratio_chosen': 0.7528456449508667, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.006094807293266058, 'weight_rejected': -0.04161440581083298, 'kl_term_chosen': -0.4272480010986328, 'mean_len_chosen': 175.0, 'mean_len_rejected': 206.5, 'epoch': 0.2}
 20%|██        | 380/1877 [1:03:05<4:00:04,  9.62s/it] 20%|██        | 381/1877 [1:03:16<4:10:09, 10.03s/it] 20%|██        | 382/1877 [1:03:27<4:18:31, 10.38s/it] 20%|██        | 383/1877 [1:03:37<4:11:47, 10.11s/it] 20%|██        | 384/1877 [1:03:49<4:27:30, 10.75s/it] 21%|██        | 385/1877 [1:03:59<4:20:22, 10.47s/it] 21%|██        | 386/1877 [1:04:09<4:14:08, 10.23s/it] 21%|██        | 387/1877 [1:04:19<4:18:07, 10.39s/it] 21%|██        | 388/1877 [1:04:28<4:05:29,  9.89s/it] 21%|██        | 389/1877 [1:04:37<3:57:07,  9.56s/it] 21%|██        | 390/1877 [1:04:47<4:02:02,  9.77s/it]{'loss': 0.4009, 'grad_norm': 9.821188926696777, 'learning_rate': 9.654611397032684e-07, 'mean_ratio_chosen': 0.10669547319412231, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.004674319643527269, 'weight_rejected': -0.012258344329893589, 'kl_term_chosen': -1.6168022155761719, 'mean_len_chosen': 629.5, 'mean_len_rejected': 584.0, 'epoch': 0.2078614257161892}
                                                      {'loss': 0.4009, 'grad_norm': 9.821188926696777, 'learning_rate': 9.654611397032684e-07, 'mean_ratio_chosen': 0.10669547319412231, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.004674319643527269, 'weight_rejected': -0.012258344329893589, 'kl_term_chosen': -1.6168022155761719, 'mean_len_chosen': 629.5, 'mean_len_rejected': 584.0, 'epoch': 0.21}
 21%|██        | 390/1877 [1:04:47<4:02:02,  9.77s/it] 21%|██        | 391/1877 [1:04:58<4:08:00, 10.01s/it] 21%|██        | 392/1877 [1:05:09<4:16:29, 10.36s/it] 21%|██        | 393/1877 [1:05:17<3:58:44,  9.65s/it] 21%|██        | 394/1877 [1:05:25<3:50:05,  9.31s/it] 21%|██        | 395/1877 [1:05:34<3:46:56,  9.19s/it] 21%|██        | 396/1877 [1:05:43<3:41:43,  8.98s/it] 21%|██        | 397/1877 [1:05:54<3:55:01,  9.53s/it] 21%|██        | 398/1877 [1:06:05<4:04:43,  9.93s/it] 21%|██▏       | 399/1877 [1:06:14<4:00:14,  9.75s/it] 21%|██▏       | 400/1877 [1:06:24<4:03:50,  9.91s/it]{'loss': 0.4326, 'grad_norm': 22.66953468322754, 'learning_rate': 9.619842414640914e-07, 'mean_ratio_chosen': 0.7251226902008057, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.0041582174599170685, 'weight_rejected': -0.0049686068668961525, 'kl_term_chosen': -1.7992668151855469, 'mean_len_chosen': 581.0, 'mean_len_rejected': 504.0, 'epoch': 0.21319120586275817}
                                                      {'loss': 0.4326, 'grad_norm': 22.66953468322754, 'learning_rate': 9.619842414640914e-07, 'mean_ratio_chosen': 0.7251226902008057, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.0041582174599170685, 'weight_rejected': -0.0049686068668961525, 'kl_term_chosen': -1.7992668151855469, 'mean_len_chosen': 581.0, 'mean_len_rejected': 504.0, 'epoch': 0.21}
 21%|██▏       | 400/1877 [1:06:24<4:03:50,  9.91s/it] 21%|██▏       | 401/1877 [1:06:33<3:55:54,  9.59s/it] 21%|██▏       | 402/1877 [1:06:42<3:48:50,  9.31s/it] 21%|██▏       | 403/1877 [1:06:51<3:51:09,  9.41s/it] 22%|██▏       | 404/1877 [1:07:02<3:58:19,  9.71s/it] 22%|██▏       | 405/1877 [1:07:11<3:57:40,  9.69s/it] 22%|██▏       | 406/1877 [1:07:21<4:00:14,  9.80s/it] 22%|██▏       | 407/1877 [1:07:29<3:45:31,  9.21s/it] 22%|██▏       | 408/1877 [1:07:40<3:58:36,  9.75s/it] 22%|██▏       | 409/1877 [1:07:50<3:56:16,  9.66s/it] 22%|██▏       | 410/1877 [1:08:01<4:11:27, 10.28s/it]{'loss': 0.3793, 'grad_norm': 43.45769119262695, 'learning_rate': 9.583475144072147e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.17352892458438873, 'weight_rejected': -0.1427481770515442, 'kl_term_chosen': -9.238495826721191, 'mean_len_chosen': 55.5, 'mean_len_rejected': 65.0, 'epoch': 0.21852098600932712}
                                                      {'loss': 0.3793, 'grad_norm': 43.45769119262695, 'learning_rate': 9.583475144072147e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.17352892458438873, 'weight_rejected': -0.1427481770515442, 'kl_term_chosen': -9.238495826721191, 'mean_len_chosen': 55.5, 'mean_len_rejected': 65.0, 'epoch': 0.22}
 22%|██▏       | 410/1877 [1:08:01<4:11:27, 10.28s/it] 22%|██▏       | 411/1877 [1:08:11<4:04:40, 10.01s/it] 22%|██▏       | 412/1877 [1:08:20<4:02:01,  9.91s/it] 22%|██▏       | 413/1877 [1:08:31<4:02:36,  9.94s/it] 22%|██▏       | 414/1877 [1:08:39<3:49:44,  9.42s/it] 22%|██▏       | 415/1877 [1:08:47<3:39:13,  9.00s/it] 22%|██▏       | 416/1877 [1:08:56<3:44:41,  9.23s/it] 22%|██▏       | 417/1877 [1:09:06<3:44:51,  9.24s/it] 22%|██▏       | 418/1877 [1:09:15<3:45:13,  9.26s/it] 22%|██▏       | 419/1877 [1:09:25<3:50:41,  9.49s/it] 22%|██▏       | 420/1877 [1:09:35<3:51:49,  9.55s/it]{'loss': 0.0233, 'grad_norm': 0.4867404103279114, 'learning_rate': 9.545522167006303e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.0846765786409378, 'weight_rejected': -0.06431815028190613, 'kl_term_chosen': -14.374885559082031, 'mean_len_chosen': 760.5, 'mean_len_rejected': 677.0, 'epoch': 0.22385076615589608}
                                                      {'loss': 0.0233, 'grad_norm': 0.4867404103279114, 'learning_rate': 9.545522167006303e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.0846765786409378, 'weight_rejected': -0.06431815028190613, 'kl_term_chosen': -14.374885559082031, 'mean_len_chosen': 760.5, 'mean_len_rejected': 677.0, 'epoch': 0.22}
 22%|██▏       | 420/1877 [1:09:35<3:51:49,  9.55s/it] 22%|██▏       | 421/1877 [1:09:43<3:45:28,  9.29s/it] 22%|██▏       | 422/1877 [1:09:51<3:33:56,  8.82s/it] 23%|██▎       | 423/1877 [1:10:00<3:32:31,  8.77s/it] 23%|██▎       | 424/1877 [1:10:08<3:29:36,  8.66s/it] 23%|██▎       | 425/1877 [1:10:18<3:36:19,  8.94s/it] 23%|██▎       | 426/1877 [1:10:28<3:42:00,  9.18s/it] 23%|██▎       | 427/1877 [1:10:38<3:52:09,  9.61s/it] 23%|██▎       | 428/1877 [1:10:50<4:04:34, 10.13s/it] 23%|██▎       | 429/1877 [1:10:59<4:02:15, 10.04s/it] 23%|██▎       | 430/1877 [1:11:13<4:27:59, 11.11s/it]{'loss': -0.0317, 'grad_norm': 0.0, 'learning_rate': 9.505996613716911e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.03815530985593796, 'weight_rejected': -0.027792686596512794, 'kl_term_chosen': -12.224815368652344, 'mean_len_chosen': 966.0, 'mean_len_rejected': 1131.5, 'epoch': 0.229180546302465}
                                                      {'loss': -0.0317, 'grad_norm': 0.0, 'learning_rate': 9.505996613716911e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.03815530985593796, 'weight_rejected': -0.027792686596512794, 'kl_term_chosen': -12.224815368652344, 'mean_len_chosen': 966.0, 'mean_len_rejected': 1131.5, 'epoch': 0.23}
 23%|██▎       | 430/1877 [1:11:13<4:27:59, 11.11s/it] 23%|██▎       | 431/1877 [1:11:24<4:30:27, 11.22s/it] 23%|██▎       | 432/1877 [1:11:32<4:00:36,  9.99s/it] 23%|██▎       | 433/1877 [1:11:39<3:43:55,  9.30s/it] 23%|██▎       | 434/1877 [1:11:53<4:12:26, 10.50s/it] 23%|██▎       | 435/1877 [1:12:04<4:22:04, 10.90s/it] 23%|██▎       | 436/1877 [1:12:13<4:05:16, 10.21s/it] 23%|██▎       | 437/1877 [1:12:21<3:47:48,  9.49s/it] 23%|██▎       | 438/1877 [1:12:30<3:47:14,  9.48s/it] 23%|██▎       | 439/1877 [1:12:39<3:40:56,  9.22s/it] 23%|██▎       | 440/1877 [1:12:48<3:40:29,  9.21s/it]{'loss': -0.0462, 'grad_norm': 0.0, 'learning_rate': 9.464912158528509e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.023523880168795586, 'weight_rejected': -0.020908363163471222, 'kl_term_chosen': -17.594409942626953, 'mean_len_chosen': 930.0, 'mean_len_rejected': 1056.0, 'epoch': 0.23451032644903397}
                                                      {'loss': -0.0462, 'grad_norm': 0.0, 'learning_rate': 9.464912158528509e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.023523880168795586, 'weight_rejected': -0.020908363163471222, 'kl_term_chosen': -17.594409942626953, 'mean_len_chosen': 930.0, 'mean_len_rejected': 1056.0, 'epoch': 0.23}
 23%|██▎       | 440/1877 [1:12:48<3:40:29,  9.21s/it] 23%|██▎       | 441/1877 [1:12:56<3:34:53,  8.98s/it] 24%|██▎       | 442/1877 [1:13:08<3:54:50,  9.82s/it] 24%|██▎       | 443/1877 [1:13:17<3:45:09,  9.42s/it] 24%|██▎       | 444/1877 [1:13:25<3:38:47,  9.16s/it] 24%|██▎       | 445/1877 [1:13:34<3:34:28,  8.99s/it] 24%|██▍       | 446/1877 [1:13:42<3:27:03,  8.68s/it] 24%|██▍       | 447/1877 [1:13:51<3:26:38,  8.67s/it] 24%|██▍       | 448/1877 [1:14:01<3:42:24,  9.34s/it] 24%|██▍       | 449/1877 [1:14:12<3:54:13,  9.84s/it] 24%|██▍       | 450/1877 [1:14:21<3:44:24,  9.44s/it]{'loss': -0.0469, 'grad_norm': 0.0, 'learning_rate': 9.422283015085868e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.9390612840652466, 'weight_rejected': -2.828035831451416, 'kl_term_chosen': -12.956456184387207, 'mean_len_chosen': 100.0, 'mean_len_rejected': 128.0, 'epoch': 0.23984010659560293}
                                                      {'loss': -0.0469, 'grad_norm': 0.0, 'learning_rate': 9.422283015085868e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.9390612840652466, 'weight_rejected': -2.828035831451416, 'kl_term_chosen': -12.956456184387207, 'mean_len_chosen': 100.0, 'mean_len_rejected': 128.0, 'epoch': 0.24}
 24%|██▍       | 450/1877 [1:14:21<3:44:24,  9.44s/it] 24%|██▍       | 451/1877 [1:14:30<3:39:21,  9.23s/it] 24%|██▍       | 452/1877 [1:14:39<3:38:05,  9.18s/it] 24%|██▍       | 453/1877 [1:14:47<3:34:45,  9.05s/it] 24%|██▍       | 454/1877 [1:14:56<3:34:00,  9.02s/it] 24%|██▍       | 455/1877 [1:15:08<3:54:06,  9.88s/it] 24%|██▍       | 456/1877 [1:15:18<3:50:47,  9.75s/it] 24%|██▍       | 457/1877 [1:15:26<3:37:23,  9.19s/it] 24%|██▍       | 458/1877 [1:15:38<4:02:37, 10.26s/it] 24%|██▍       | 459/1877 [1:15:50<4:15:16, 10.80s/it] 25%|██▍       | 460/1877 [1:16:00<4:04:13, 10.34s/it]{'loss': -0.0481, 'grad_norm': 0.0, 'learning_rate': 9.378123931436619e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.11721307039260864, 'weight_rejected': -0.08976268023252487, 'kl_term_chosen': -18.81904411315918, 'mean_len_chosen': 336.5, 'mean_len_rejected': 392.0, 'epoch': 0.24516988674217188}
                                                      {'loss': -0.0481, 'grad_norm': 0.0, 'learning_rate': 9.378123931436619e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.11721307039260864, 'weight_rejected': -0.08976268023252487, 'kl_term_chosen': -18.81904411315918, 'mean_len_chosen': 336.5, 'mean_len_rejected': 392.0, 'epoch': 0.25}
 25%|██▍       | 460/1877 [1:16:00<4:04:13, 10.34s/it] 25%|██▍       | 461/1877 [1:16:11<4:09:28, 10.57s/it] 25%|██▍       | 462/1877 [1:16:22<4:13:45, 10.76s/it] 25%|██▍       | 463/1877 [1:16:32<4:09:43, 10.60s/it] 25%|██▍       | 464/1877 [1:16:41<3:58:53, 10.14s/it] 25%|██▍       | 465/1877 [1:16:53<4:08:10, 10.55s/it] 25%|██▍       | 466/1877 [1:17:02<3:56:22, 10.05s/it] 25%|██▍       | 467/1877 [1:17:10<3:43:22,  9.51s/it] 25%|██▍       | 468/1877 [1:17:19<3:43:08,  9.50s/it] 25%|██▍       | 469/1877 [1:17:28<3:33:09,  9.08s/it] 25%|██▌       | 470/1877 [1:17:37<3:35:51,  9.20s/it]{'loss': -0.0404, 'grad_norm': 0.0, 'learning_rate': 9.332450184928984e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.44493311643600464, 'weight_rejected': -0.40545210242271423, 'kl_term_chosen': -15.691246032714844, 'mean_len_chosen': 213.5, 'mean_len_rejected': 291.0, 'epoch': 0.2504996668887408}
                                                      {'loss': -0.0404, 'grad_norm': 0.0, 'learning_rate': 9.332450184928984e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.44493311643600464, 'weight_rejected': -0.40545210242271423, 'kl_term_chosen': -15.691246032714844, 'mean_len_chosen': 213.5, 'mean_len_rejected': 291.0, 'epoch': 0.25}
 25%|██▌       | 470/1877 [1:17:37<3:35:51,  9.20s/it] 25%|██▌       | 471/1877 [1:17:48<3:47:51,  9.72s/it] 25%|██▌       | 472/1877 [1:17:56<3:39:10,  9.36s/it] 25%|██▌       | 473/1877 [1:18:04<3:24:56,  8.76s/it] 25%|██▌       | 474/1877 [1:18:15<3:44:48,  9.61s/it] 25%|██▌       | 475/1877 [1:18:26<3:49:20,  9.81s/it] 25%|██▌       | 476/1877 [1:18:34<3:40:39,  9.45s/it] 25%|██▌       | 477/1877 [1:18:43<3:33:23,  9.15s/it] 25%|██▌       | 478/1877 [1:18:52<3:35:44,  9.25s/it] 26%|██▌       | 479/1877 [1:19:04<3:51:48,  9.95s/it] 26%|██▌       | 480/1877 [1:19:13<3:48:00,  9.79s/it]{'loss': -0.0591, 'grad_norm': 0.0, 'learning_rate': 9.285277576926402e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.03689311072230339, 'weight_rejected': -0.039209675043821335, 'kl_term_chosen': -25.343887329101562, 'mean_len_chosen': 817.5, 'mean_len_rejected': 895.5, 'epoch': 0.2558294470353098}
                                                      {'loss': -0.0591, 'grad_norm': 0.0, 'learning_rate': 9.285277576926402e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.03689311072230339, 'weight_rejected': -0.039209675043821335, 'kl_term_chosen': -25.343887329101562, 'mean_len_chosen': 817.5, 'mean_len_rejected': 895.5, 'epoch': 0.26}
 26%|██▌       | 480/1877 [1:19:13<3:48:00,  9.79s/it] 26%|██▌       | 481/1877 [1:19:20<3:26:26,  8.87s/it] 26%|██▌       | 482/1877 [1:19:29<3:25:31,  8.84s/it] 26%|██▌       | 483/1877 [1:19:39<3:35:10,  9.26s/it] 26%|██▌       | 484/1877 [1:19:48<3:35:23,  9.28s/it] 26%|██▌       | 485/1877 [1:20:00<3:51:40,  9.99s/it] 26%|██▌       | 486/1877 [1:20:08<3:40:45,  9.52s/it] 26%|██▌       | 487/1877 [1:20:20<3:54:07, 10.11s/it] 26%|██▌       | 488/1877 [1:20:28<3:41:12,  9.56s/it] 26%|██▌       | 489/1877 [1:20:41<4:03:30, 10.53s/it] 26%|██▌       | 490/1877 [1:20:52<4:06:35, 10.67s/it]{'loss': -0.0503, 'grad_norm': 0.0, 'learning_rate': 9.236622427340876e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.23816080391407013, 'weight_rejected': -0.12346084415912628, 'kl_term_chosen': -16.04946517944336, 'mean_len_chosen': 285.0, 'mean_len_rejected': 343.0, 'epoch': 0.26115922718187873}
                                                      {'loss': -0.0503, 'grad_norm': 0.0, 'learning_rate': 9.236622427340876e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.23816080391407013, 'weight_rejected': -0.12346084415912628, 'kl_term_chosen': -16.04946517944336, 'mean_len_chosen': 285.0, 'mean_len_rejected': 343.0, 'epoch': 0.26}
 26%|██▌       | 490/1877 [1:20:52<4:06:35, 10.67s/it] 26%|██▌       | 491/1877 [1:21:01<3:55:28, 10.19s/it] 26%|██▌       | 492/1877 [1:21:12<3:59:37, 10.38s/it] 26%|██▋       | 493/1877 [1:21:21<3:48:17,  9.90s/it] 26%|██▋       | 494/1877 [1:21:31<3:50:17,  9.99s/it] 26%|██▋       | 495/1877 [1:21:42<3:59:30, 10.40s/it] 26%|██▋       | 496/1877 [1:21:51<3:51:40, 10.07s/it] 26%|██▋       | 497/1877 [1:22:03<4:01:13, 10.49s/it] 27%|██▋       | 498/1877 [1:22:12<3:53:38, 10.17s/it] 27%|██▋       | 499/1877 [1:22:21<3:43:49,  9.75s/it] 27%|██▋       | 500/1877 [1:22:30<3:34:53,  9.36s/it]{'loss': -0.0507, 'grad_norm': 0.0, 'learning_rate': 9.186501568986891e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.28771984577178955, 'weight_rejected': -0.2943560481071472, 'kl_term_chosen': -21.933860778808594, 'mean_len_chosen': 79.0, 'mean_len_rejected': 80.0, 'epoch': 0.2664890073284477}
                                                      {'loss': -0.0507, 'grad_norm': 0.0, 'learning_rate': 9.186501568986891e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.28771984577178955, 'weight_rejected': -0.2943560481071472, 'kl_term_chosen': -21.933860778808594, 'mean_len_chosen': 79.0, 'mean_len_rejected': 80.0, 'epoch': 0.27}
 27%|██▋       | 500/1877 [1:22:30<3:34:53,  9.36s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 27%|██▋       | 501/1877 [1:23:36<10:07:17, 26.48s/it]