nohup: ignoring input
[W1021 18:32:05.997890223 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
`torch_dtype` is deprecated! Use `dtype` instead!
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
加载用于训练的策略模型 (Policy Model)...
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.52it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.91it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 88.86it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.36it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.74it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 98.54it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 90.20it/s]
[W1021 18:32:14.025779390 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.40it/s]
[W1021 18:32:14.036013252 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1021 18:32:14.059018784 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1021 18:32:14.062798228 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_term2.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
WARNING:accelerate.utils.other:Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_term2.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_term2.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_term2.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /root/wandb/offline-run-20251021_183223-05g5vtdm
  0%|          | 0/3753 [00:00<?, ?it/s]--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -101.0
Sample 0 - pi_logp_chosen:  -100.28032684326172
Sample 0 - Difference (pi - ref): 0.7196731567382812
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -44.25
Sample 0 - pi_logp_chosen:  -44.228355407714844
Sample 0 - Difference (pi - ref): 0.02164459228515625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -111.5
Sample 0 - pi_logp_chosen:  -112.77057647705078
Sample 0 - Difference (pi - ref): -1.2705764770507812
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -233.0
Sample 0 - pi_logp_chosen:  -233.77731323242188
Sample 0 - Difference (pi - ref): -0.777313232421875
---------------------------------
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -66.0
Sample 0 - pi_logp_chosen:  -66.13370513916016
Sample 0 - Difference (pi - ref): -0.13370513916015625
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -248.0
Sample 0 - ref_logp_chosen: -210.0Sample 0 - pi_logp_chosen:  -246.30413818359375
Sample 0 - Difference (pi - ref): 1.69586181640625
---------------------------------

Sample 0 - pi_logp_chosen:  -208.75222778320312
Sample 0 - Difference (pi - ref): 1.247772216796875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -380.0
Sample 0 - pi_logp_chosen:  -379.6788330078125
Sample 0 - Difference (pi - ref): 0.3211669921875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -70.5
Sample 0 - pi_logp_chosen:  -70.52078247070312
Sample 0 - Difference (pi - ref): -0.020782470703125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -167.0
Sample 0 - pi_logp_chosen:  -167.49078369140625
Sample 0 - Difference (pi - ref): -0.49078369140625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -350.0
Sample 0 - pi_logp_chosen:  -349.9153747558594
Sample 0 - Difference (pi - ref): 0.084625244140625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -454.0
Sample 0 - pi_logp_chosen:  -452.25799560546875
Sample 0 - Difference (pi - ref): 1.74200439453125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -81.5
Sample 0 - pi_logp_chosen:  -81.52965545654297
Sample 0 - Difference (pi - ref): -0.02965545654296875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -98.5
Sample 0 - pi_logp_chosen:  -98.7940673828125
Sample 0 - Difference (pi - ref): -0.2940673828125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -252.0
Sample 0 - pi_logp_chosen:  -251.3794403076172
Sample 0 - Difference (pi - ref): 0.6205596923828125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -243.0
Sample 0 - pi_logp_chosen:  -242.4936981201172
Sample 0 - Difference (pi - ref): 0.5063018798828125
---------------------------------
  0%|          | 1/3753 [00:02<3:00:24,  2.89s/it]{'loss': -0.6325, 'grad_norm': 2701.806884765625, 'learning_rate': 0.0, 'mean_ratio_chosen': 1.859968662261963, 'weight_chosen': 0.6116420030593872, 'kl_term_chosen': 0.31027984619140625, 'epoch': 0.0002664890073284477}
                                                  {'loss': -0.6325, 'grad_norm': 2701.806884765625, 'learning_rate': 0.0, 'mean_ratio_chosen': 1.859968662261963, 'weight_chosen': 0.6116420030593872, 'kl_term_chosen': 0.31027984619140625, 'epoch': 0.0}
  0%|          | 1/3753 [00:02<3:00:24,  2.89s/it]  0%|          | 2/3753 [00:05<3:03:05,  2.93s/it]  0%|          | 3/3753 [00:08<2:56:27,  2.82s/it]  0%|          | 4/3753 [00:11<2:48:47,  2.70s/it]  0%|          | 5/3753 [00:13<2:45:38,  2.65s/it]  0%|          | 6/3753 [00:16<2:48:47,  2.70s/it]  0%|          | 7/3753 [00:18<2:44:55,  2.64s/it]  0%|          | 8/3753 [00:21<2:45:29,  2.65s/it]  0%|          | 9/3753 [00:24<2:46:25,  2.67s/it]  0%|          | 10/3753 [00:26<2:44:27,  2.64s/it]{'loss': -0.7047, 'grad_norm': 2996.458740234375, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 1.123618483543396, 'weight_chosen': 0.18680787086486816, 'kl_term_chosen': 0.058277130126953125, 'epoch': 0.002664890073284477}
                                                   {'loss': -0.7047, 'grad_norm': 2996.458740234375, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 1.123618483543396, 'weight_chosen': 0.18680787086486816, 'kl_term_chosen': 0.058277130126953125, 'epoch': 0.0}
  0%|          | 10/3753 [00:26<2:44:27,  2.64s/it]  0%|          | 11/3753 [00:29<2:42:52,  2.61s/it]  0%|          | 12/3753 [00:32<2:50:09,  2.73s/it]  0%|          | 13/3753 [00:35<2:47:09,  2.68s/it]  0%|          | 14/3753 [00:37<2:43:35,  2.63s/it]  0%|          | 15/3753 [00:39<2:39:46,  2.56s/it]  0%|          | 16/3753 [00:42<2:34:45,  2.48s/it]  0%|          | 17/3753 [00:44<2:31:58,  2.44s/it]  0%|          | 18/3753 [00:47<2:38:47,  2.55s/it]  1%|          | 19/3753 [00:49<2:39:06,  2.56s/it]  1%|          | 20/3753 [00:52<2:42:23,  2.61s/it]{'loss': -0.6674, 'grad_norm': 2837.948486328125, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 1.3666189908981323, 'weight_chosen': 0.5764219164848328, 'kl_term_chosen': 0.15616989135742188, 'epoch': 0.005329780146568954}
                                                   {'loss': -0.6674, 'grad_norm': 2837.948486328125, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 1.3666189908981323, 'weight_chosen': 0.5764219164848328, 'kl_term_chosen': 0.15616989135742188, 'epoch': 0.01}
  1%|          | 20/3753 [00:52<2:42:23,  2.61s/it]  1%|          | 21/3753 [00:55<2:38:14,  2.54s/it]  1%|          | 22/3753 [00:58<2:51:27,  2.76s/it]  1%|          | 23/3753 [01:01<2:51:36,  2.76s/it]  1%|          | 24/3753 [01:03<2:42:21,  2.61s/it]  1%|          | 25/3753 [01:05<2:40:27,  2.58s/it]  1%|          | 26/3753 [01:08<2:33:48,  2.48s/it]  1%|          | 27/3753 [01:10<2:34:03,  2.48s/it]  1%|          | 28/3753 [01:13<2:35:18,  2.50s/it]  1%|          | 29/3753 [01:16<2:42:14,  2.61s/it]  1%|          | 30/3753 [01:18<2:41:30,  2.60s/it]{'loss': -0.3632, 'grad_norm': 3048.09228515625, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 4.857558250427246, 'weight_chosen': -0.16231673955917358, 'kl_term_chosen': 0.7902679443359375, 'epoch': 0.007994670219853431}
                                                   {'loss': -0.3632, 'grad_norm': 3048.09228515625, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 4.857558250427246, 'weight_chosen': -0.16231673955917358, 'kl_term_chosen': 0.7902679443359375, 'epoch': 0.01}
  1%|          | 30/3753 [01:18<2:41:30,  2.60s/it]  1%|          | 31/3753 [01:21<2:49:33,  2.73s/it]  1%|          | 32/3753 [01:24<2:43:12,  2.63s/it]  1%|          | 33/3753 [01:26<2:37:20,  2.54s/it]  1%|          | 34/3753 [01:28<2:35:22,  2.51s/it]  1%|          | 35/3753 [01:31<2:36:54,  2.53s/it]  1%|          | 36/3753 [01:34<2:50:19,  2.75s/it]  1%|          | 37/3753 [01:37<2:54:26,  2.82s/it]  1%|          | 38/3753 [01:40<2:54:22,  2.82s/it]  1%|          | 39/3753 [01:43<2:51:50,  2.78s/it]  1%|          | 40/3753 [01:45<2:47:34,  2.71s/it]{'loss': 2.4659, 'grad_norm': 2069.77099609375, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 9.274177551269531, 'weight_chosen': -0.3558225631713867, 'kl_term_chosen': 1.113616943359375, 'epoch': 0.010659560293137908}
                                                   {'loss': 2.4659, 'grad_norm': 2069.77099609375, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 9.274177551269531, 'weight_chosen': -0.3558225631713867, 'kl_term_chosen': 1.113616943359375, 'epoch': 0.01}
  1%|          | 40/3753 [01:45<2:47:34,  2.71s/it]  1%|          | 41/3753 [01:48<2:45:41,  2.68s/it]  1%|          | 42/3753 [01:50<2:36:18,  2.53s/it]  1%|          | 43/3753 [01:53<2:39:23,  2.58s/it]  1%|          | 44/3753 [01:55<2:37:11,  2.54s/it]  1%|          | 45/3753 [01:58<2:40:52,  2.60s/it]  1%|          | 46/3753 [02:01<2:46:12,  2.69s/it]  1%|▏         | 47/3753 [02:03<2:41:35,  2.62s/it]  1%|▏         | 48/3753 [02:06<2:43:01,  2.64s/it]  1%|▏         | 49/3753 [02:08<2:39:17,  2.58s/it]  1%|▏         | 50/3753 [02:11<2:34:05,  2.50s/it]{'loss': 0.3886, 'grad_norm': 2122.239013671875, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 1.7231650352478027, 'weight_chosen': 0.5913102626800537, 'kl_term_chosen': 0.2720813751220703, 'epoch': 0.013324450366422385}
                                                   {'loss': 0.3886, 'grad_norm': 2122.239013671875, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 1.7231650352478027, 'weight_chosen': 0.5913102626800537, 'kl_term_chosen': 0.2720813751220703, 'epoch': 0.01}
  1%|▏         | 50/3753 [02:11<2:34:05,  2.50s/it]  1%|▏         | 51/3753 [02:13<2:35:10,  2.52s/it]  1%|▏         | 52/3753 [02:16<2:37:38,  2.56s/it]  1%|▏         | 53/3753 [02:19<2:42:40,  2.64s/it]  1%|▏         | 54/3753 [02:21<2:37:52,  2.56s/it]  1%|▏         | 55/3753 [02:25<2:56:52,  2.87s/it]  1%|▏         | 56/3753 [02:27<2:51:34,  2.78s/it]  2%|▏         | 57/3753 [02:30<2:55:02,  2.84s/it]  2%|▏         | 58/3753 [02:33<2:47:14,  2.72s/it]  2%|▏         | 59/3753 [02:35<2:40:03,  2.60s/it]  2%|▏         | 60/3753 [02:37<2:34:24,  2.51s/it]{'loss': 1.4199, 'grad_norm': 1423.3443603515625, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 2.6835503578186035, 'weight_chosen': -0.4633557200431824, 'kl_term_chosen': 0.49357032775878906, 'epoch': 0.015989340439706862}
                                                   {'loss': 1.4199, 'grad_norm': 1423.3443603515625, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 2.6835503578186035, 'weight_chosen': -0.4633557200431824, 'kl_term_chosen': 0.49357032775878906, 'epoch': 0.02}
  2%|▏         | 60/3753 [02:37<2:34:24,  2.51s/it]  2%|▏         | 61/3753 [02:40<2:36:00,  2.54s/it]  2%|▏         | 62/3753 [02:42<2:37:57,  2.57s/it]  2%|▏         | 63/3753 [02:45<2:39:03,  2.59s/it]  2%|▏         | 64/3753 [02:48<2:43:22,  2.66s/it]  2%|▏         | 65/3753 [02:50<2:38:17,  2.58s/it]  2%|▏         | 66/3753 [02:53<2:40:40,  2.61s/it]  2%|▏         | 67/3753 [02:56<2:50:12,  2.77s/it]  2%|▏         | 68/3753 [02:59<2:43:30,  2.66s/it]  2%|▏         | 69/3753 [03:01<2:43:04,  2.66s/it]  2%|▏         | 70/3753 [03:04<2:38:17,  2.58s/it]{'loss': 1.4365, 'grad_norm': 3185.677978515625, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -0.19814640283584595, 'kl_term_chosen': 1.161376953125, 'epoch': 0.018654230512991338}
                                                   {'loss': 1.4365, 'grad_norm': 3185.677978515625, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -0.19814640283584595, 'kl_term_chosen': 1.161376953125, 'epoch': 0.02}
  2%|▏         | 70/3753 [03:04<2:38:17,  2.58s/it]  2%|▏         | 71/3753 [03:06<2:40:11,  2.61s/it]  2%|▏         | 72/3753 [03:09<2:38:37,  2.59s/it]  2%|▏         | 73/3753 [03:11<2:34:44,  2.52s/it]  2%|▏         | 74/3753 [03:14<2:33:52,  2.51s/it]  2%|▏         | 75/3753 [03:16<2:30:49,  2.46s/it]  2%|▏         | 76/3753 [03:19<2:46:54,  2.72s/it]  2%|▏         | 77/3753 [03:22<2:42:11,  2.65s/it]  2%|▏         | 78/3753 [03:24<2:42:06,  2.65s/it]  2%|▏         | 79/3753 [03:27<2:37:25,  2.57s/it]  2%|▏         | 80/3753 [03:30<2:39:48,  2.61s/it]{'loss': 0.816, 'grad_norm': 2239.1904296875, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 4.44827127456665, 'weight_chosen': 0.18215101957321167, 'kl_term_chosen': 0.7462577819824219, 'epoch': 0.021319120586275817}
                                                   {'loss': 0.816, 'grad_norm': 2239.1904296875, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 4.44827127456665, 'weight_chosen': 0.18215101957321167, 'kl_term_chosen': 0.7462577819824219, 'epoch': 0.02}
  2%|▏         | 80/3753 [03:30<2:39:48,  2.61s/it]  2%|▏         | 81/3753 [03:32<2:43:31,  2.67s/it]  2%|▏         | 82/3753 [03:35<2:39:44,  2.61s/it]  2%|▏         | 83/3753 [03:38<2:49:05,  2.76s/it]  2%|▏         | 84/3753 [03:41<2:49:21,  2.77s/it]  2%|▏         | 85/3753 [03:43<2:43:03,  2.67s/it]  2%|▏         | 86/3753 [03:46<2:45:11,  2.70s/it]  2%|▏         | 87/3753 [03:49<2:54:22,  2.85s/it]  2%|▏         | 88/3753 [03:51<2:43:44,  2.68s/it]  2%|▏         | 89/3753 [03:54<2:41:07,  2.64s/it]  2%|▏         | 90/3753 [03:56<2:38:21,  2.59s/it]{'loss': 0.97, 'grad_norm': 1957.125732421875, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -1.376659870147705, 'kl_term_chosen': 2.1658935546875, 'epoch': 0.023984010659560292}
                                                   {'loss': 0.97, 'grad_norm': 1957.125732421875, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -1.376659870147705, 'kl_term_chosen': 2.1658935546875, 'epoch': 0.02}
  2%|▏         | 90/3753 [03:57<2:38:21,  2.59s/it]  2%|▏         | 91/3753 [03:59<2:31:49,  2.49s/it]  2%|▏         | 92/3753 [04:01<2:30:18,  2.46s/it]  2%|▏         | 93/3753 [04:04<2:32:23,  2.50s/it]  3%|▎         | 94/3753 [04:06<2:29:03,  2.44s/it]  3%|▎         | 95/3753 [04:09<2:41:34,  2.65s/it]  3%|▎         | 96/3753 [04:12<2:49:34,  2.78s/it]  3%|▎         | 97/3753 [04:15<2:44:08,  2.69s/it]  3%|▎         | 98/3753 [04:18<2:50:34,  2.80s/it]  3%|▎         | 99/3753 [04:20<2:42:33,  2.67s/it]  3%|▎         | 100/3753 [04:22<2:36:38,  2.57s/it]{'loss': 1.5987, 'grad_norm': 1360.3623046875, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 5.562105178833008, 'weight_chosen': -0.2300371527671814, 'kl_term_chosen': 0.8579883575439453, 'epoch': 0.02664890073284477}
                                                    {'loss': 1.5987, 'grad_norm': 1360.3623046875, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 5.562105178833008, 'weight_chosen': -0.2300371527671814, 'kl_term_chosen': 0.8579883575439453, 'epoch': 0.03}
  3%|▎         | 100/3753 [04:23<2:36:38,  2.57s/it]  3%|▎         | 101/3753 [04:25<2:37:08,  2.58s/it]  3%|▎         | 102/3753 [04:27<2:33:42,  2.53s/it]  3%|▎         | 103/3753 [04:30<2:31:56,  2.50s/it]  3%|▎         | 104/3753 [04:33<2:42:33,  2.67s/it]  3%|▎         | 105/3753 [04:36<2:44:12,  2.70s/it]  3%|▎         | 106/3753 [04:39<2:52:33,  2.84s/it]  3%|▎         | 107/3753 [04:42<2:49:28,  2.79s/it]  3%|▎         | 108/3753 [04:44<2:43:27,  2.69s/it]  3%|▎         | 109/3753 [04:47<2:39:41,  2.63s/it]  3%|▎         | 110/3753 [04:49<2:38:22,  2.61s/it]{'loss': 2.2901, 'grad_norm': 1428.0643310546875, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -0.26308512687683105, 'kl_term_chosen': 1.1767616271972656, 'epoch': 0.029313790806129246}
                                                    {'loss': 2.2901, 'grad_norm': 1428.0643310546875, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -0.26308512687683105, 'kl_term_chosen': 1.1767616271972656, 'epoch': 0.03}
  3%|▎         | 110/3753 [04:49<2:38:22,  2.61s/it]  3%|▎         | 111/3753 [04:52<2:40:38,  2.65s/it]  3%|▎         | 112/3753 [04:54<2:35:56,  2.57s/it]  3%|▎         | 113/3753 [04:56<2:28:57,  2.46s/it]  3%|▎         | 114/3753 [04:59<2:26:36,  2.42s/it]  3%|▎         | 115/3753 [05:02<2:37:38,  2.60s/it]  3%|▎         | 116/3753 [05:04<2:37:05,  2.59s/it]  3%|▎         | 117/3753 [05:07<2:34:16,  2.55s/it]  3%|▎         | 118/3753 [05:09<2:32:53,  2.52s/it]  3%|▎         | 119/3753 [05:12<2:28:33,  2.45s/it]  3%|▎         | 120/3753 [05:14<2:33:10,  2.53s/it]{'loss': 1.844, 'grad_norm': 1444.1290283203125, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 2.4139482975006104, 'weight_chosen': 0.3959226608276367, 'kl_term_chosen': 0.4406318664550781, 'epoch': 0.031978680879413725}
                                                    {'loss': 1.844, 'grad_norm': 1444.1290283203125, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 2.4139482975006104, 'weight_chosen': 0.3959226608276367, 'kl_term_chosen': 0.4406318664550781, 'epoch': 0.03}
  3%|▎         | 120/3753 [05:14<2:33:10,  2.53s/it]  3%|▎         | 121/3753 [05:17<2:34:26,  2.55s/it]  3%|▎         | 122/3753 [05:20<2:36:33,  2.59s/it]  3%|▎         | 123/3753 [05:22<2:34:49,  2.56s/it]  3%|▎         | 124/3753 [05:25<2:34:38,  2.56s/it]  3%|▎         | 125/3753 [05:27<2:40:25,  2.65s/it]  3%|▎         | 126/3753 [05:30<2:38:10,  2.62s/it]  3%|▎         | 127/3753 [05:32<2:32:47,  2.53s/it]  3%|▎         | 128/3753 [05:35<2:29:53,  2.48s/it]  3%|▎         | 129/3753 [05:38<2:38:09,  2.62s/it]  3%|▎         | 130/3753 [05:40<2:39:21,  2.64s/it]{'loss': 1.0897, 'grad_norm': 5730.32373046875, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 9.600746154785156, 'weight_chosen': -0.8334504961967468, 'kl_term_chosen': 1.13092041015625, 'epoch': 0.034643570952698204}
                                                    {'loss': 1.0897, 'grad_norm': 5730.32373046875, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 9.600746154785156, 'weight_chosen': -0.8334504961967468, 'kl_term_chosen': 1.13092041015625, 'epoch': 0.03}
  3%|▎         | 130/3753 [05:40<2:39:21,  2.64s/it]  3%|▎         | 131/3753 [05:43<2:35:43,  2.58s/it]  4%|▎         | 132/3753 [05:45<2:30:53,  2.50s/it]  4%|▎         | 133/3753 [05:48<2:33:28,  2.54s/it]  4%|▎         | 134/3753 [05:51<2:43:39,  2.71s/it]  4%|▎         | 135/3753 [05:53<2:37:46,  2.62s/it]  4%|▎         | 136/3753 [05:55<2:32:07,  2.52s/it]  4%|▎         | 137/3753 [05:58<2:30:29,  2.50s/it]  4%|▎         | 138/3753 [06:01<2:33:11,  2.54s/it]  4%|▎         | 139/3753 [06:03<2:29:14,  2.48s/it]  4%|▎         | 140/3753 [06:06<2:31:47,  2.52s/it]{'loss': 0.7221, 'grad_norm': 2494.0537109375, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 2.4146666526794434, 'weight_chosen': 0.4188830852508545, 'kl_term_chosen': 0.4407806396484375, 'epoch': 0.037308461025982675}
                                                    {'loss': 0.7221, 'grad_norm': 2494.0537109375, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 2.4146666526794434, 'weight_chosen': 0.4188830852508545, 'kl_term_chosen': 0.4407806396484375, 'epoch': 0.04}
  4%|▎         | 140/3753 [06:06<2:31:47,  2.52s/it]  4%|▍         | 141/3753 [06:08<2:31:06,  2.51s/it]  4%|▍         | 142/3753 [06:11<2:32:09,  2.53s/it]  4%|▍         | 143/3753 [06:13<2:37:56,  2.63s/it]  4%|▍         | 144/3753 [06:17<2:49:24,  2.82s/it]  4%|▍         | 145/3753 [06:20<2:55:50,  2.92s/it]  4%|▍         | 146/3753 [06:23<2:51:32,  2.85s/it]  4%|▍         | 147/3753 [06:26<2:54:53,  2.91s/it]  4%|▍         | 148/3753 [06:28<2:53:26,  2.89s/it]  4%|▍         | 149/3753 [06:31<2:45:14,  2.75s/it]  4%|▍         | 150/3753 [06:34<2:52:47,  2.88s/it]{'loss': 3.8205, 'grad_norm': 1577.9759521484375, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 5.342315196990967, 'weight_chosen': -0.5023698806762695, 'kl_term_chosen': 0.83782958984375, 'epoch': 0.039973351099267154}
                                                    {'loss': 3.8205, 'grad_norm': 1577.9759521484375, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 5.342315196990967, 'weight_chosen': -0.5023698806762695, 'kl_term_chosen': 0.83782958984375, 'epoch': 0.04}
  4%|▍         | 150/3753 [06:34<2:52:47,  2.88s/it]  4%|▍         | 151/3753 [06:37<2:50:50,  2.85s/it]  4%|▍         | 152/3753 [06:39<2:42:41,  2.71s/it]  4%|▍         | 153/3753 [06:42<2:52:57,  2.88s/it]  4%|▍         | 154/3753 [06:45<2:42:02,  2.70s/it]  4%|▍         | 155/3753 [06:47<2:38:33,  2.64s/it]  4%|▍         | 156/3753 [06:50<2:35:23,  2.59s/it]  4%|▍         | 157/3753 [06:52<2:33:12,  2.56s/it]  4%|▍         | 158/3753 [06:55<2:35:11,  2.59s/it]  4%|▍         | 159/3753 [06:57<2:33:51,  2.57s/it]  4%|▍         | 160/3753 [07:00<2:36:08,  2.61s/it]{'loss': 4.3389, 'grad_norm': 1574.7303466796875, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -0.8282066583633423, 'kl_term_chosen': 1.5082359313964844, 'epoch': 0.04263824117255163}
                                                    {'loss': 4.3389, 'grad_norm': 1574.7303466796875, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -0.8282066583633423, 'kl_term_chosen': 1.5082359313964844, 'epoch': 0.04}
  4%|▍         | 160/3753 [07:00<2:36:08,  2.61s/it]  4%|▍         | 161/3753 [07:02<2:31:26,  2.53s/it]  4%|▍         | 162/3753 [07:05<2:30:13,  2.51s/it]  4%|▍         | 163/3753 [07:08<2:33:29,  2.57s/it]  4%|▍         | 164/3753 [07:11<2:45:06,  2.76s/it]  4%|▍         | 165/3753 [07:14<2:53:26,  2.90s/it]  4%|▍         | 166/3753 [07:16<2:41:32,  2.70s/it]  4%|▍         | 167/3753 [07:19<2:39:36,  2.67s/it]  4%|▍         | 168/3753 [07:22<2:41:13,  2.70s/it]  5%|▍         | 169/3753 [07:24<2:35:12,  2.60s/it]  5%|▍         | 170/3753 [07:26<2:29:01,  2.50s/it]{'loss': 5.2609, 'grad_norm': 1472.809326171875, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 8.511892318725586, 'weight_chosen': -0.19838476181030273, 'kl_term_chosen': 1.0707321166992188, 'epoch': 0.04530313124583611}
                                                    {'loss': 5.2609, 'grad_norm': 1472.809326171875, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 8.511892318725586, 'weight_chosen': -0.19838476181030273, 'kl_term_chosen': 1.0707321166992188, 'epoch': 0.05}
  5%|▍         | 170/3753 [07:26<2:29:01,  2.50s/it]  5%|▍         | 171/3753 [07:29<2:34:39,  2.59s/it]  5%|▍         | 172/3753 [07:32<2:40:49,  2.69s/it]  5%|▍         | 173/3753 [07:35<2:39:48,  2.68s/it]  5%|▍         | 174/3753 [07:37<2:35:51,  2.61s/it]  5%|▍         | 175/3753 [07:40<2:35:30,  2.61s/it]  5%|▍         | 176/3753 [07:42<2:29:42,  2.51s/it]  5%|▍         | 177/3753 [07:45<2:31:26,  2.54s/it]  5%|▍         | 178/3753 [07:47<2:34:48,  2.60s/it]  5%|▍         | 179/3753 [07:50<2:29:28,  2.51s/it]  5%|▍         | 180/3753 [07:52<2:29:33,  2.51s/it]{'loss': 3.2334, 'grad_norm': 824.0297241210938, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -0.6022511720657349, 'kl_term_chosen': 1.53759765625, 'epoch': 0.047968021319120584}
                                                    {'loss': 3.2334, 'grad_norm': 824.0297241210938, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -0.6022511720657349, 'kl_term_chosen': 1.53759765625, 'epoch': 0.05}
  5%|▍         | 180/3753 [07:52<2:29:33,  2.51s/it]  5%|▍         | 181/3753 [07:55<2:31:58,  2.55s/it]  5%|▍         | 182/3753 [07:59<2:53:24,  2.91s/it]  5%|▍         | 183/3753 [08:01<2:48:44,  2.84s/it]  5%|▍         | 184/3753 [08:04<2:48:35,  2.83s/it]  5%|▍         | 185/3753 [08:07<2:47:14,  2.81s/it]  5%|▍         | 186/3753 [08:09<2:42:48,  2.74s/it]  5%|▍         | 187/3753 [08:12<2:38:43,  2.67s/it]  5%|▌         | 188/3753 [08:14<2:35:56,  2.62s/it]  5%|▌         | 189/3753 [08:17<2:43:43,  2.76s/it]  5%|▌         | 190/3753 [08:20<2:38:35,  2.67s/it]{'loss': 3.4621, 'grad_norm': 575.7150268554688, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -1.3074047565460205, 'kl_term_chosen': 2.188201904296875, 'epoch': 0.05063291139240506}
                                                    {'loss': 3.4621, 'grad_norm': 575.7150268554688, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -1.3074047565460205, 'kl_term_chosen': 2.188201904296875, 'epoch': 0.05}
  5%|▌         | 190/3753 [08:20<2:38:35,  2.67s/it]  5%|▌         | 191/3753 [08:23<2:38:50,  2.68s/it]  5%|▌         | 192/3753 [08:25<2:36:47,  2.64s/it]  5%|▌         | 193/3753 [08:28<2:34:57,  2.61s/it]  5%|▌         | 194/3753 [08:30<2:37:17,  2.65s/it]  5%|▌         | 195/3753 [08:33<2:33:20,  2.59s/it]  5%|▌         | 196/3753 [08:35<2:26:40,  2.47s/it]  5%|▌         | 197/3753 [08:39<2:47:28,  2.83s/it]  5%|▌         | 198/3753 [08:41<2:39:24,  2.69s/it]  5%|▌         | 199/3753 [08:44<2:43:02,  2.75s/it]  5%|▌         | 200/3753 [08:47<2:40:47,  2.72s/it]{'loss': 3.0261, 'grad_norm': 1424.9222412109375, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -0.5929759740829468, 'kl_term_chosen': 1.5363235473632812, 'epoch': 0.05329780146568954}
                                                    {'loss': 3.0261, 'grad_norm': 1424.9222412109375, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -0.5929759740829468, 'kl_term_chosen': 1.5363235473632812, 'epoch': 0.05}
  5%|▌         | 200/3753 [08:47<2:40:47,  2.72s/it]  5%|▌         | 201/3753 [08:50<2:47:48,  2.83s/it]  5%|▌         | 202/3753 [08:52<2:39:09,  2.69s/it]  5%|▌         | 203/3753 [08:55<2:39:23,  2.69s/it]  5%|▌         | 204/3753 [08:57<2:33:34,  2.60s/it]  5%|▌         | 205/3753 [09:00<2:29:08,  2.52s/it]  5%|▌         | 206/3753 [09:03<2:37:30,  2.66s/it]  6%|▌         | 207/3753 [09:05<2:33:49,  2.60s/it]  6%|▌         | 208/3753 [09:08<2:31:41,  2.57s/it]  6%|▌         | 209/3753 [09:10<2:30:40,  2.55s/it]  6%|▌         | 210/3753 [09:13<2:34:36,  2.62s/it]{'loss': 14.4813, 'grad_norm': 313.38739013671875, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -2.3379557132720947, 'kl_term_chosen': 3.1566925048828125, 'epoch': 0.05596269153897402}
                                                    {'loss': 14.4813, 'grad_norm': 313.38739013671875, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -2.3379557132720947, 'kl_term_chosen': 3.1566925048828125, 'epoch': 0.06}
  6%|▌         | 210/3753 [09:13<2:34:36,  2.62s/it]  6%|▌         | 211/3753 [09:16<2:42:55,  2.76s/it]  6%|▌         | 212/3753 [09:18<2:35:07,  2.63s/it]  6%|▌         | 213/3753 [09:21<2:35:13,  2.63s/it]  6%|▌         | 214/3753 [09:24<2:35:50,  2.64s/it]  6%|▌         | 215/3753 [09:26<2:33:07,  2.60s/it]  6%|▌         | 216/3753 [09:29<2:33:02,  2.60s/it]  6%|▌         | 217/3753 [09:31<2:27:58,  2.51s/it]  6%|▌         | 218/3753 [09:34<2:31:11,  2.57s/it]  6%|▌         | 219/3753 [09:36<2:28:26,  2.52s/it]  6%|▌         | 220/3753 [09:39<2:33:38,  2.61s/it]{'loss': 25.7673, 'grad_norm': 1096.6815185546875, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -3.8902029991149902, 'kl_term_chosen': 4.571929931640625, 'epoch': 0.05862758161225849}
                                                    {'loss': 25.7673, 'grad_norm': 1096.6815185546875, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -3.8902029991149902, 'kl_term_chosen': 4.571929931640625, 'epoch': 0.06}
  6%|▌         | 220/3753 [09:39<2:33:38,  2.61s/it]  6%|▌         | 221/3753 [09:41<2:30:27,  2.56s/it]  6%|▌         | 222/3753 [09:44<2:30:24,  2.56s/it]  6%|▌         | 223/3753 [09:46<2:25:13,  2.47s/it]  6%|▌         | 224/3753 [09:48<2:23:45,  2.44s/it]  6%|▌         | 225/3753 [09:51<2:24:54,  2.46s/it]  6%|▌         | 226/3753 [09:53<2:23:59,  2.45s/it]  6%|▌         | 227/3753 [09:56<2:33:20,  2.61s/it]  6%|▌         | 228/3753 [09:59<2:26:13,  2.49s/it]  6%|▌         | 229/3753 [10:01<2:30:41,  2.57s/it]  6%|▌         | 230/3753 [10:05<2:49:07,  2.88s/it]{'loss': 24.3771, 'grad_norm': 689.5092163085938, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -1.3765404224395752, 'kl_term_chosen': 2.313751220703125, 'epoch': 0.06129247168554297}
                                                    {'loss': 24.3771, 'grad_norm': 689.5092163085938, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -1.3765404224395752, 'kl_term_chosen': 2.313751220703125, 'epoch': 0.06}
  6%|▌         | 230/3753 [10:05<2:49:07,  2.88s/it]  6%|▌         | 231/3753 [10:07<2:42:27,  2.77s/it]  6%|▌         | 232/3753 [10:10<2:38:14,  2.70s/it]  6%|▌         | 233/3753 [10:13<2:39:33,  2.72s/it]  6%|▌         | 234/3753 [10:16<2:41:04,  2.75s/it]  6%|▋         | 235/3753 [10:18<2:39:36,  2.72s/it]  6%|▋         | 236/3753 [10:21<2:36:45,  2.67s/it]  6%|▋         | 237/3753 [10:23<2:31:03,  2.58s/it]  6%|▋         | 238/3753 [10:26<2:31:14,  2.58s/it]  6%|▋         | 239/3753 [10:29<2:41:51,  2.76s/it]  6%|▋         | 240/3753 [10:31<2:36:29,  2.67s/it]{'loss': 12.5953, 'grad_norm': 1215.561279296875, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 0.10025884956121445, 'weight_chosen': 3.2950024604797363, 'kl_term_chosen': -2.4638595581054688, 'epoch': 0.06395736175882745}
                                                    {'loss': 12.5953, 'grad_norm': 1215.561279296875, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 0.10025884956121445, 'weight_chosen': 3.2950024604797363, 'kl_term_chosen': -2.4638595581054688, 'epoch': 0.06}
  6%|▋         | 240/3753 [10:31<2:36:29,  2.67s/it]  6%|▋         | 241/3753 [10:34<2:31:41,  2.59s/it]  6%|▋         | 242/3753 [10:36<2:30:48,  2.58s/it]  6%|▋         | 243/3753 [10:39<2:32:04,  2.60s/it]  7%|▋         | 244/3753 [10:42<2:39:09,  2.72s/it]  7%|▋         | 245/3753 [10:45<2:36:21,  2.67s/it]  7%|▋         | 246/3753 [10:47<2:29:16,  2.55s/it]  7%|▋         | 247/3753 [10:51<2:55:09,  3.00s/it]  7%|▋         | 248/3753 [10:54<2:51:18,  2.93s/it]  7%|▋         | 249/3753 [10:56<2:48:09,  2.88s/it]  7%|▋         | 250/3753 [10:59<2:51:41,  2.94s/it]{'loss': 14.9804, 'grad_norm': 313.59368896484375, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -1.4685604572296143, 'kl_term_chosen': 2.3633499145507812, 'epoch': 0.06662225183211193}
                                                    {'loss': 14.9804, 'grad_norm': 313.59368896484375, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -1.4685604572296143, 'kl_term_chosen': 2.3633499145507812, 'epoch': 0.07}
  7%|▋         | 250/3753 [11:00<2:51:41,  2.94s/it]  7%|▋         | 251/3753 [11:03<2:55:37,  3.01s/it]  7%|▋         | 252/3753 [11:05<2:48:38,  2.89s/it]  7%|▋         | 253/3753 [11:08<2:41:28,  2.77s/it]  7%|▋         | 254/3753 [11:10<2:32:20,  2.61s/it]  7%|▋         | 255/3753 [11:12<2:28:47,  2.55s/it]  7%|▋         | 256/3753 [11:15<2:24:30,  2.48s/it]  7%|▋         | 257/3753 [11:17<2:24:41,  2.48s/it]  7%|▋         | 258/3753 [11:20<2:23:35,  2.46s/it]  7%|▋         | 259/3753 [11:22<2:30:01,  2.58s/it]  7%|▋         | 260/3753 [11:25<2:32:51,  2.63s/it]{'loss': 24.2299, 'grad_norm': 322.53997802734375, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -1.1105828285217285, 'kl_term_chosen': 1.9977874755859375, 'epoch': 0.06928714190539641}
                                                    {'loss': 24.2299, 'grad_norm': 322.53997802734375, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -1.1105828285217285, 'kl_term_chosen': 1.9977874755859375, 'epoch': 0.07}
  7%|▋         | 260/3753 [11:25<2:32:51,  2.63s/it]  7%|▋         | 261/3753 [11:28<2:33:59,  2.65s/it]  7%|▋         | 262/3753 [11:30<2:31:57,  2.61s/it]  7%|▋         | 263/3753 [11:33<2:28:58,  2.56s/it]  7%|▋         | 264/3753 [11:35<2:27:45,  2.54s/it]  7%|▋         | 265/3753 [11:38<2:27:53,  2.54s/it]  7%|▋         | 266/3753 [11:40<2:25:27,  2.50s/it]  7%|▋         | 267/3753 [11:43<2:24:39,  2.49s/it]  7%|▋         | 268/3753 [11:46<2:33:39,  2.65s/it]  7%|▋         | 269/3753 [11:48<2:31:31,  2.61s/it]  7%|▋         | 270/3753 [11:51<2:31:52,  2.62s/it]{'loss': 29.3885, 'grad_norm': 2559.70751953125, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -4.646218776702881, 'kl_term_chosen': 5.621795654296875, 'epoch': 0.07195203197868089}
                                                    {'loss': 29.3885, 'grad_norm': 2559.70751953125, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -4.646218776702881, 'kl_term_chosen': 5.621795654296875, 'epoch': 0.07}
  7%|▋         | 270/3753 [11:51<2:31:52,  2.62s/it]  7%|▋         | 271/3753 [11:54<2:32:33,  2.63s/it]  7%|▋         | 272/3753 [11:56<2:30:30,  2.59s/it]  7%|▋         | 273/3753 [11:59<2:26:47,  2.53s/it]  7%|▋         | 274/3753 [12:01<2:25:13,  2.50s/it]  7%|▋         | 275/3753 [12:03<2:25:11,  2.50s/it]  7%|▋         | 276/3753 [12:06<2:22:39,  2.46s/it]  7%|▋         | 277/3753 [12:09<2:30:50,  2.60s/it]  7%|▋         | 278/3753 [12:12<2:33:22,  2.65s/it]  7%|▋         | 279/3753 [12:14<2:34:46,  2.67s/it]  7%|▋         | 280/3753 [12:17<2:34:13,  2.66s/it]{'loss': 33.1185, 'grad_norm': 0.0, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.10025884956121445, 'weight_chosen': 3.4068682193756104, 'kl_term_chosen': -2.476409912109375, 'epoch': 0.07461692205196535}
                                                    {'loss': 33.1185, 'grad_norm': 0.0, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.10025884956121445, 'weight_chosen': 3.4068682193756104, 'kl_term_chosen': -2.476409912109375, 'epoch': 0.07}
  7%|▋         | 280/3753 [12:17<2:34:13,  2.66s/it]  7%|▋         | 281/3753 [12:19<2:30:56,  2.61s/it]  8%|▊         | 282/3753 [12:22<2:34:25,  2.67s/it]  8%|▊         | 283/3753 [12:25<2:30:01,  2.59s/it]  8%|▊         | 284/3753 [12:27<2:25:16,  2.51s/it]  8%|▊         | 285/3753 [12:30<2:38:54,  2.75s/it]  8%|▊         | 286/3753 [12:32<2:29:40,  2.59s/it]  8%|▊         | 287/3753 [12:35<2:30:35,  2.61s/it]  8%|▊         | 288/3753 [12:38<2:34:52,  2.68s/it]  8%|▊         | 289/3753 [12:41<2:34:57,  2.68s/it]  8%|▊         | 290/3753 [12:44<2:41:46,  2.80s/it]{'loss': 69.6371, 'grad_norm': 0.0, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -7.613217353820801, 'kl_term_chosen': 8.366683959960938, 'epoch': 0.07728181212524983}
                                                    {'loss': 69.6371, 'grad_norm': 0.0, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -7.613217353820801, 'kl_term_chosen': 8.366683959960938, 'epoch': 0.08}
  8%|▊         | 290/3753 [12:44<2:41:46,  2.80s/it]  8%|▊         | 291/3753 [12:46<2:34:20,  2.67s/it]  8%|▊         | 292/3753 [12:49<2:37:28,  2.73s/it]  8%|▊         | 293/3753 [12:51<2:32:22,  2.64s/it]  8%|▊         | 294/3753 [12:54<2:27:26,  2.56s/it]  8%|▊         | 295/3753 [12:56<2:30:34,  2.61s/it]  8%|▊         | 296/3753 [12:59<2:27:04,  2.55s/it]  8%|▊         | 297/3753 [13:02<2:37:30,  2.73s/it]  8%|▊         | 298/3753 [13:05<2:39:54,  2.78s/it]  8%|▊         | 299/3753 [13:07<2:33:59,  2.68s/it]  8%|▊         | 300/3753 [13:10<2:27:51,  2.57s/it]{'loss': 88.8431, 'grad_norm': 0.0, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -10.171401023864746, 'kl_term_chosen': 11.095542907714844, 'epoch': 0.07994670219853431}
                                                    {'loss': 88.8431, 'grad_norm': 0.0, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -10.171401023864746, 'kl_term_chosen': 11.095542907714844, 'epoch': 0.08}
  8%|▊         | 300/3753 [13:10<2:27:51,  2.57s/it]  8%|▊         | 301/3753 [13:12<2:26:20,  2.54s/it]  8%|▊         | 302/3753 [13:15<2:29:01,  2.59s/it]  8%|▊         | 303/3753 [13:18<2:30:16,  2.61s/it]  8%|▊         | 304/3753 [13:20<2:22:15,  2.47s/it]  8%|▊         | 305/3753 [13:22<2:20:34,  2.45s/it]  8%|▊         | 306/3753 [13:24<2:20:07,  2.44s/it]  8%|▊         | 307/3753 [13:28<2:30:33,  2.62s/it]  8%|▊         | 308/3753 [13:30<2:33:55,  2.68s/it]  8%|▊         | 309/3753 [13:33<2:33:29,  2.67s/it]  8%|▊         | 310/3753 [13:36<2:30:50,  2.63s/it]{'loss': 97.1896, 'grad_norm': 0.0, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -9.280627250671387, 'kl_term_chosen': 9.944295883178711, 'epoch': 0.08261159227181879}
                                                    {'loss': 97.1896, 'grad_norm': 0.0, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -9.280627250671387, 'kl_term_chosen': 9.944295883178711, 'epoch': 0.08}
  8%|▊         | 310/3753 [13:36<2:30:50,  2.63s/it]  8%|▊         | 311/3753 [13:38<2:27:41,  2.57s/it]  8%|▊         | 312/3753 [13:40<2:22:42,  2.49s/it]  8%|▊         | 313/3753 [13:43<2:22:17,  2.48s/it]  8%|▊         | 314/3753 [13:46<2:33:36,  2.68s/it]  8%|▊         | 315/3753 [13:48<2:28:29,  2.59s/it]  8%|▊         | 316/3753 [13:51<2:34:27,  2.70s/it]  8%|▊         | 317/3753 [13:54<2:31:22,  2.64s/it]  8%|▊         | 318/3753 [13:56<2:29:31,  2.61s/it]  8%|▊         | 319/3753 [13:59<2:29:33,  2.61s/it]  9%|▊         | 320/3753 [14:02<2:30:47,  2.64s/it]{'loss': 102.2166, 'grad_norm': 0.0, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -10.814894676208496, 'kl_term_chosen': 11.752105712890625, 'epoch': 0.08527648234510327}
                                                    {'loss': 102.2166, 'grad_norm': 0.0, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -10.814894676208496, 'kl_term_chosen': 11.752105712890625, 'epoch': 0.09}
  9%|▊         | 320/3753 [14:02<2:30:47,  2.64s/it]  9%|▊         | 321/3753 [14:04<2:30:53,  2.64s/it]  9%|▊         | 322/3753 [14:07<2:26:00,  2.55s/it]  9%|▊         | 323/3753 [14:09<2:21:07,  2.47s/it]  9%|▊         | 324/3753 [14:12<2:30:22,  2.63s/it]  9%|▊         | 325/3753 [14:14<2:26:39,  2.57s/it]  9%|▊         | 326/3753 [14:17<2:27:43,  2.59s/it]  9%|▊         | 327/3753 [14:20<2:29:34,  2.62s/it]  9%|▊         | 328/3753 [14:22<2:27:13,  2.58s/it]  9%|▉         | 329/3753 [14:25<2:28:06,  2.60s/it]  9%|▉         | 330/3753 [14:28<2:31:26,  2.65s/it]{'loss': 102.4394, 'grad_norm': 0.0, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -9.844444274902344, 'kl_term_chosen': 10.705982208251953, 'epoch': 0.08794137241838774}
                                                    {'loss': 102.4394, 'grad_norm': 0.0, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -9.844444274902344, 'kl_term_chosen': 10.705982208251953, 'epoch': 0.09}
  9%|▉         | 330/3753 [14:28<2:31:26,  2.65s/it]  9%|▉         | 331/3753 [14:30<2:28:33,  2.60s/it]  9%|▉         | 332/3753 [14:33<2:27:01,  2.58s/it]  9%|▉         | 333/3753 [14:35<2:29:00,  2.61s/it]  9%|▉         | 334/3753 [14:38<2:28:00,  2.60s/it]  9%|▉         | 335/3753 [14:41<2:32:57,  2.68s/it]  9%|▉         | 336/3753 [14:43<2:30:32,  2.64s/it]  9%|▉         | 337/3753 [14:46<2:30:18,  2.64s/it]  9%|▉         | 338/3753 [14:48<2:24:22,  2.54s/it]  9%|▉         | 339/3753 [14:51<2:21:26,  2.49s/it]  9%|▉         | 340/3753 [14:53<2:24:45,  2.54s/it]{'loss': 101.6549, 'grad_norm': 0.0, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -8.575296401977539, 'kl_term_chosen': 8.818939208984375, 'epoch': 0.09060626249167222}
                                                    {'loss': 101.6549, 'grad_norm': 0.0, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -8.575296401977539, 'kl_term_chosen': 8.818939208984375, 'epoch': 0.09}
  9%|▉         | 340/3753 [14:53<2:24:45,  2.54s/it]  9%|▉         | 341/3753 [14:56<2:23:09,  2.52s/it]  9%|▉         | 342/3753 [14:58<2:21:28,  2.49s/it]  9%|▉         | 343/3753 [15:01<2:25:05,  2.55s/it]  9%|▉         | 344/3753 [15:03<2:23:51,  2.53s/it]  9%|▉         | 345/3753 [15:06<2:36:05,  2.75s/it]  9%|▉         | 346/3753 [15:09<2:31:34,  2.67s/it]  9%|▉         | 347/3753 [15:12<2:31:00,  2.66s/it]  9%|▉         | 348/3753 [15:14<2:34:20,  2.72s/it]  9%|▉         | 349/3753 [15:17<2:28:31,  2.62s/it]  9%|▉         | 350/3753 [15:19<2:28:42,  2.62s/it]{'loss': 103.6801, 'grad_norm': 0.0, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -10.695210456848145, 'kl_term_chosen': 11.529617309570312, 'epoch': 0.09327115256495669}
                                                    {'loss': 103.6801, 'grad_norm': 0.0, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -10.695210456848145, 'kl_term_chosen': 11.529617309570312, 'epoch': 0.09}
  9%|▉         | 350/3753 [15:20<2:28:42,  2.62s/it]  9%|▉         | 351/3753 [15:22<2:27:05,  2.59s/it]  9%|▉         | 352/3753 [15:24<2:21:37,  2.50s/it]  9%|▉         | 353/3753 [15:27<2:19:35,  2.46s/it]  9%|▉         | 354/3753 [15:29<2:21:42,  2.50s/it]  9%|▉         | 355/3753 [15:33<2:37:25,  2.78s/it]  9%|▉         | 356/3753 [15:35<2:34:05,  2.72s/it] 10%|▉         | 357/3753 [15:38<2:30:31,  2.66s/it] 10%|▉         | 358/3753 [15:40<2:30:20,  2.66s/it] 10%|▉         | 359/3753 [15:43<2:26:43,  2.59s/it] 10%|▉         | 360/3753 [15:45<2:22:25,  2.52s/it]{'loss': 102.8513, 'grad_norm': 0.0, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -11.070222854614258, 'kl_term_chosen': 11.614540100097656, 'epoch': 0.09593604263824117}
                                                    {'loss': 102.8513, 'grad_norm': 0.0, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -11.070222854614258, 'kl_term_chosen': 11.614540100097656, 'epoch': 0.1}
 10%|▉         | 360/3753 [15:45<2:22:25,  2.52s/it] 10%|▉         | 361/3753 [15:48<2:23:07,  2.53s/it] 10%|▉         | 362/3753 [15:50<2:24:30,  2.56s/it] 10%|▉         | 363/3753 [15:53<2:25:33,  2.58s/it] 10%|▉         | 364/3753 [15:56<2:30:26,  2.66s/it] 10%|▉         | 365/3753 [15:58<2:26:54,  2.60s/it] 10%|▉         | 366/3753 [16:01<2:21:24,  2.51s/it] 10%|▉         | 367/3753 [16:03<2:22:19,  2.52s/it] 10%|▉         | 368/3753 [16:06<2:27:12,  2.61s/it] 10%|▉         | 369/3753 [16:09<2:28:31,  2.63s/it] 10%|▉         | 370/3753 [16:11<2:28:02,  2.63s/it]{'loss': 103.8419, 'grad_norm': 0.0, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -11.479836463928223, 'kl_term_chosen': 12.344146728515625, 'epoch': 0.09860093271152565}
                                                    {'loss': 103.8419, 'grad_norm': 0.0, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -11.479836463928223, 'kl_term_chosen': 12.344146728515625, 'epoch': 0.1}
 10%|▉         | 370/3753 [16:11<2:28:02,  2.63s/it] 10%|▉         | 371/3753 [16:14<2:23:35,  2.55s/it] 10%|▉         | 372/3753 [16:16<2:25:03,  2.57s/it] 10%|▉         | 373/3753 [16:19<2:20:34,  2.50s/it] 10%|▉         | 374/3753 [16:22<2:42:47,  2.89s/it] 10%|▉         | 375/3753 [16:25<2:43:32,  2.90s/it] 10%|█         | 376/3753 [16:28<2:43:39,  2.91s/it] 10%|█         | 377/3753 [16:32<2:49:37,  3.01s/it] 10%|█         | 378/3753 [16:34<2:37:04,  2.79s/it] 10%|█         | 379/3753 [16:36<2:26:41,  2.61s/it] 10%|█         | 380/3753 [16:39<2:28:48,  2.65s/it]{'loss': 104.4265, 'grad_norm': 0.0, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -12.131450653076172, 'kl_term_chosen': 13.091812133789062, 'epoch': 0.10126582278481013}
                                                    {'loss': 104.4265, 'grad_norm': 0.0, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -12.131450653076172, 'kl_term_chosen': 13.091812133789062, 'epoch': 0.1}
 10%|█         | 380/3753 [16:39<2:28:48,  2.65s/it] 10%|█         | 381/3753 [16:41<2:25:48,  2.59s/it] 10%|█         | 382/3753 [16:44<2:26:18,  2.60s/it] 10%|█         | 383/3753 [16:47<2:28:12,  2.64s/it] 10%|█         | 384/3753 [16:50<2:34:09,  2.75s/it] 10%|█         | 385/3753 [16:53<2:43:43,  2.92s/it] 10%|█         | 386/3753 [16:55<2:33:45,  2.74s/it] 10%|█         | 387/3753 [16:58<2:30:54,  2.69s/it] 10%|█         | 388/3753 [17:00<2:27:03,  2.62s/it] 10%|█         | 389/3753 [17:03<2:23:17,  2.56s/it] 10%|█         | 390/3753 [17:05<2:25:25,  2.59s/it]{'loss': 102.6998, 'grad_norm': 0.0, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -11.018509864807129, 'kl_term_chosen': 11.657344818115234, 'epoch': 0.1039307128580946}
                                                    {'loss': 102.6998, 'grad_norm': 0.0, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -11.018509864807129, 'kl_term_chosen': 11.657344818115234, 'epoch': 0.1}
 10%|█         | 390/3753 [17:05<2:25:25,  2.59s/it] 10%|█         | 391/3753 [17:08<2:24:28,  2.58s/it] 10%|█         | 392/3753 [17:10<2:21:35,  2.53s/it] 10%|█         | 393/3753 [17:13<2:31:56,  2.71s/it] 10%|█         | 394/3753 [17:16<2:28:43,  2.66s/it] 11%|█         | 395/3753 [17:19<2:30:44,  2.69s/it] 11%|█         | 396/3753 [17:21<2:30:41,  2.69s/it] 11%|█         | 397/3753 [17:24<2:24:22,  2.58s/it] 11%|█         | 398/3753 [17:27<2:28:05,  2.65s/it] 11%|█         | 399/3753 [17:29<2:32:31,  2.73s/it] 11%|█         | 400/3753 [17:32<2:28:29,  2.66s/it]{'loss': 100.051, 'grad_norm': 0.0, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -10.762613296508789, 'kl_term_chosen': 11.457744598388672, 'epoch': 0.10659560293137908}
                                                    {'loss': 100.051, 'grad_norm': 0.0, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -10.762613296508789, 'kl_term_chosen': 11.457744598388672, 'epoch': 0.11}
 11%|█         | 400/3753 [17:32<2:28:29,  2.66s/it] 11%|█         | 401/3753 [17:35<2:26:48,  2.63s/it] 11%|█         | 402/3753 [17:37<2:31:41,  2.72s/it] 11%|█         | 403/3753 [17:40<2:23:15,  2.57s/it] 11%|█         | 404/3753 [17:42<2:27:45,  2.65s/it] 11%|█         | 405/3753 [17:45<2:32:58,  2.74s/it] 11%|█         | 406/3753 [17:48<2:30:44,  2.70s/it] 11%|█         | 407/3753 [17:50<2:26:08,  2.62s/it] 11%|█         | 408/3753 [17:53<2:29:37,  2.68s/it] 11%|█         | 409/3753 [17:56<2:26:13,  2.62s/it] 11%|█         | 410/3753 [17:58<2:25:22,  2.61s/it]{'loss': 100.9545, 'grad_norm': 0.0, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -1.1079648733139038, 'kl_term_chosen': 1.7548713684082031, 'epoch': 0.10926049300466356}
                                                    {'loss': 100.9545, 'grad_norm': 0.0, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -1.1079648733139038, 'kl_term_chosen': 1.7548713684082031, 'epoch': 0.11}
 11%|█         | 410/3753 [17:58<2:25:22,  2.61s/it] 11%|█         | 411/3753 [18:01<2:25:11,  2.61s/it] 11%|█         | 412/3753 [18:04<2:26:15,  2.63s/it] 11%|█         | 413/3753 [18:07<2:36:25,  2.81s/it] 11%|█         | 414/3753 [18:09<2:32:45,  2.75s/it] 11%|█         | 415/3753 [18:12<2:27:12,  2.65s/it] 11%|█         | 416/3753 [18:15<2:27:04,  2.64s/it] 11%|█         | 417/3753 [18:17<2:25:04,  2.61s/it] 11%|█         | 418/3753 [18:20<2:22:49,  2.57s/it] 11%|█         | 419/3753 [18:22<2:22:38,  2.57s/it] 11%|█         | 420/3753 [18:25<2:20:29,  2.53s/it]{'loss': 102.7315, 'grad_norm': 0.0, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -8.913641929626465, 'kl_term_chosen': 9.564996719360352, 'epoch': 0.11192538307794804}
                                                    {'loss': 102.7315, 'grad_norm': 0.0, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -8.913641929626465, 'kl_term_chosen': 9.564996719360352, 'epoch': 0.11}
 11%|█         | 420/3753 [18:25<2:20:29,  2.53s/it] 11%|█         | 421/3753 [18:27<2:25:18,  2.62s/it] 11%|█         | 422/3753 [18:30<2:26:59,  2.65s/it] 11%|█▏        | 423/3753 [18:32<2:22:47,  2.57s/it] 11%|█▏        | 424/3753 [18:35<2:16:47,  2.47s/it] 11%|█▏        | 425/3753 [18:37<2:19:32,  2.52s/it] 11%|█▏        | 426/3753 [18:40<2:19:05,  2.51s/it] 11%|█▏        | 427/3753 [18:43<2:22:15,  2.57s/it] 11%|█▏        | 428/3753 [18:45<2:23:26,  2.59s/it] 11%|█▏        | 429/3753 [18:48<2:22:55,  2.58s/it] 11%|█▏        | 430/3753 [18:50<2:25:22,  2.62s/it]{'loss': 106.3472, 'grad_norm': 0.0, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -10.98641586303711, 'kl_term_chosen': 11.550033569335938, 'epoch': 0.1145902731512325}
                                                    {'loss': 106.3472, 'grad_norm': 0.0, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -10.98641586303711, 'kl_term_chosen': 11.550033569335938, 'epoch': 0.11}
 11%|█▏        | 430/3753 [18:51<2:25:22,  2.62s/it] 11%|█▏        | 431/3753 [18:53<2:26:50,  2.65s/it] 12%|█▏        | 432/3753 [18:56<2:33:34,  2.77s/it] 12%|█▏        | 433/3753 [18:59<2:29:25,  2.70s/it] 12%|█▏        | 434/3753 [19:01<2:25:37,  2.63s/it] 12%|█▏        | 435/3753 [19:04<2:21:44,  2.56s/it] 12%|█▏        | 436/3753 [19:06<2:23:14,  2.59s/it] 12%|█▏        | 437/3753 [19:09<2:21:40,  2.56s/it] 12%|█▏        | 438/3753 [19:11<2:23:34,  2.60s/it] 12%|█▏        | 439/3753 [19:14<2:24:04,  2.61s/it] 12%|█▏        | 440/3753 [19:16<2:20:13,  2.54s/it]{'loss': 101.991, 'grad_norm': 0.0, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -11.020511627197266, 'kl_term_chosen': 11.97515869140625, 'epoch': 0.11725516322451698}
                                                    {'loss': 101.991, 'grad_norm': 0.0, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -11.020511627197266, 'kl_term_chosen': 11.97515869140625, 'epoch': 0.12}
 12%|█▏        | 440/3753 [19:17<2:20:13,  2.54s/it] 12%|█▏        | 441/3753 [19:19<2:26:22,  2.65s/it] 12%|█▏        | 442/3753 [19:22<2:24:17,  2.61s/it] 12%|█▏        | 443/3753 [19:24<2:13:08,  2.41s/it] 12%|█▏        | 444/3753 [19:26<2:14:36,  2.44s/it] 12%|█▏        | 445/3753 [19:29<2:12:42,  2.41s/it] 12%|█▏        | 446/3753 [19:31<2:17:23,  2.49s/it] 12%|█▏        | 447/3753 [19:34<2:15:50,  2.47s/it] 12%|█▏        | 448/3753 [19:36<2:11:28,  2.39s/it] 12%|█▏        | 449/3753 [19:39<2:18:22,  2.51s/it] 12%|█▏        | 450/3753 [19:41<2:17:33,  2.50s/it]{'loss': 90.526, 'grad_norm': 0.0, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -10.607254981994629, 'kl_term_chosen': 11.500564575195312, 'epoch': 0.11992005329780146}
                                                    {'loss': 90.526, 'grad_norm': 0.0, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -10.607254981994629, 'kl_term_chosen': 11.500564575195312, 'epoch': 0.12}
 12%|█▏        | 450/3753 [19:41<2:17:33,  2.50s/it] 12%|█▏        | 451/3753 [19:44<2:27:28,  2.68s/it] 12%|█▏        | 452/3753 [19:47<2:25:03,  2.64s/it] 12%|█▏        | 453/3753 [19:49<2:20:25,  2.55s/it] 12%|█▏        | 454/3753 [19:52<2:25:52,  2.65s/it] 12%|█▏        | 455/3753 [19:55<2:23:57,  2.62s/it] 12%|█▏        | 456/3753 [19:58<2:27:22,  2.68s/it] 12%|█▏        | 457/3753 [20:00<2:23:55,  2.62s/it] 12%|█▏        | 458/3753 [20:03<2:22:00,  2.59s/it] 12%|█▏        | 459/3753 [20:05<2:21:25,  2.58s/it] 12%|█▏        | 460/3753 [20:08<2:29:46,  2.73s/it]{'loss': 90.4243, 'grad_norm': 0.0, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -9.159309387207031, 'kl_term_chosen': 10.077789306640625, 'epoch': 0.12258494337108594}
                                                    {'loss': 90.4243, 'grad_norm': 0.0, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 9.974181175231934, 'weight_chosen': -9.159309387207031, 'kl_term_chosen': 10.077789306640625, 'epoch': 0.12}
 12%|█▏        | 460/3753 [20:08<2:29:46,  2.73s/it] 12%|█▏        | 461/3753 [20:11<2:26:33,  2.67s/it] 12%|█▏        | 462/3753 [20:13<2:17:04,  2.50s/it] 12%|█▏        | 463/3753 [20:15<2:20:20,  2.56s/it] 12%|█▏        | 464/3753 [20:18<2:18:26,  2.53s/it] 12%|█▏        | 465/3753 [20:20<2:16:40,  2.49s/it]