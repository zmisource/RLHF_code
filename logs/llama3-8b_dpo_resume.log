nohup: ignoring input
[W1028 20:22:37.056793573 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
wandb: WARNING Unable to verify login in offline mode.
wandb: WARNING Unable to verify login in offline mode.
wandb: WARNING Unable to verify login in offline mode.
wandb: WARNING Unable to verify login in offline mode.
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /wandb/offline-run-20251028_202244-c4npz5zb
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /wandb/offline-run-20251028_202244-qzf68761
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /wandb/offline-run-20251028_202244-6vk82zds
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /wandb/offline-run-20251028_202244-k5oc4fr1
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 92.77it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.66it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 89.07it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 92.75it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.38it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.97it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 90.71it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.84it/s]
[W1028 20:22:45.209286139 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1028 20:22:45.216736394 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1028 20:22:45.217178173 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1028 20:22:45.219228633 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1974: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/planner_helpers.py:418: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  device = getattr(value, "device", None)
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/planner_helpers.py:418: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  device = getattr(value, "device", None)
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/default_planner.py:479: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  and md.size != obj.size()
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/default_planner.py:479: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  and md.size != obj.size()
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/planner_helpers.py:418: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  device = getattr(value, "device", None)
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/planner_helpers.py:418: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  device = getattr(value, "device", None)
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/default_planner.py:479: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  and md.size != obj.size()
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/default_planner.py:479: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  and md.size != obj.size()
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:625: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  param_numel = param.size().numel()
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:625: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  param_numel = param.size().numel()
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:625: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  param_numel = param.size().numel()
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:625: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  param_numel = param.size().numel()
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:626: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  dim_0_size = param.size()[0]
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:626: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  dim_0_size = param.size()[0]
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:626: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  dim_0_size = param.size()[0]
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:626: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  dim_0_size = param.size()[0]
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:652: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor = tensor.narrow(0, 0, param_numel).reshape(param.size())
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:652: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor = tensor.narrow(0, 0, param_numel).reshape(param.size())
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:652: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor = tensor.narrow(0, 0, param_numel).reshape(param.size())
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:652: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor = tensor.narrow(0, 0, param_numel).reshape(param.size())
  0%|          | 0/3753 [00:00<?, ?it/s] 67%|██████▋   | 2501/3753 [00:05<00:02, 421.66it/s] 67%|██████▋   | 2504/3753 [00:16<00:02, 421.66it/s] 67%|██████▋   | 2505/3753 [00:20<00:13, 95.06it/s]  67%|██████▋   | 2506/3753 [00:25<00:18, 68.90it/s] 67%|██████▋   | 2508/3753 [00:36<00:18, 68.90it/s] 67%|██████▋   | 2509/3753 [00:38<00:36, 33.80it/s] 67%|██████▋   | 2510/3753 [00:41<00:44, 28.10it/s]                                                   {'loss': 0.3209, 'grad_norm': 24.77072525024414, 'learning_rate': 2.0935952223294743e-07, 'rewards/chosen': -2.8448779582977295, 'rewards/rejected': -6.482470512390137, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 3.6375927925109863, 'logps/chosen': -441.1729431152344, 'logps/rejected': -815.3330688476562, 'logits/chosen': 0.1417207568883896, 'logits/rejected': 0.3449140191078186, 'epoch': 0.67}
 67%|██████▋   | 2510/3753 [00:41<00:44, 28.10it/s] 67%|██████▋   | 2513/3753 [00:56<00:44, 28.10it/s] 67%|██████▋   | 2514/3753 [00:59<01:34, 13.07it/s] 67%|██████▋   | 2515/3753 [01:03<01:50, 11.16it/s] 67%|██████▋   | 2518/3753 [01:16<01:50, 11.16it/s] 67%|██████▋   | 2519/3753 [01:20<03:27,  5.95it/s] 67%|██████▋   | 2520/3753 [01:28<04:26,  4.63it/s]                                                   {'loss': 0.2938, 'grad_norm': 72.82231140136719, 'learning_rate': 2.0638406830770342e-07, 'rewards/chosen': -3.8177618980407715, 'rewards/rejected': -7.728532314300537, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.910771131515503, 'logps/chosen': -557.8047485351562, 'logps/rejected': -950.9959106445312, 'logits/chosen': 0.18886570632457733, 'logits/rejected': 0.31312620639801025, 'epoch': 0.67}
 67%|██████▋   | 2520/3753 [01:28<04:26,  4.63it/s] 67%|██████▋   | 2524/3753 [01:43<07:09,  2.86it/s] 67%|██████▋   | 2525/3753 [01:48<08:17,  2.47it/s] 67%|██████▋   | 2528/3753 [02:00<12:11,  1.68it/s] 67%|██████▋   | 2529/3753 [02:04<13:40,  1.49it/s]                                                   {'loss': 0.3231, 'grad_norm': 19.087444305419922, 'learning_rate': 2.034210434089023e-07, 'rewards/chosen': -3.7744300365448, 'rewards/rejected': -7.694695472717285, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.9202651977539062, 'logps/chosen': -533.1508178710938, 'logps/rejected': -929.5570068359375, 'logits/chosen': 0.258475124835968, 'logits/rejected': 0.36106348037719727, 'epoch': 0.67}
 67%|██████▋   | 2530/3753 [02:08<13:40,  1.49it/s] 67%|██████▋   | 2531/3753 [02:12<18:34,  1.10it/s] 67%|██████▋   | 2533/3753 [02:24<27:17,  1.34s/it] 68%|██████▊   | 2534/3753 [02:29<30:53,  1.52s/it] 68%|██████▊   | 2535/3753 [02:33<34:43,  1.71s/it] 68%|██████▊   | 2536/3753 [02:37<38:41,  1.91s/it] 68%|██████▊   | 2537/3753 [02:40<43:04,  2.13s/it] 68%|██████▊   | 2538/3753 [02:43<45:26,  2.24s/it] 68%|██████▊   | 2539/3753 [02:47<50:10,  2.48s/it] 68%|██████▊   | 2540/3753 [02:51<57:58,  2.87s/it]                                                   {'loss': 0.4222, 'grad_norm': 61.37190246582031, 'learning_rate': 2.0047070396711112e-07, 'rewards/chosen': -3.924760103225708, 'rewards/rejected': -8.694473266601562, 'rewards/accuracies': 0.875, 'rewards/margins': 4.769712924957275, 'logps/chosen': -548.4693603515625, 'logps/rejected': -1030.29931640625, 'logits/chosen': 0.1863337606191635, 'logits/rejected': 0.3318033516407013, 'epoch': 0.68}
 68%|██████▊   | 2540/3753 [02:51<57:58,  2.87s/it] 68%|██████▊   | 2541/3753 [02:54<58:32,  2.90s/it] 68%|██████▊   | 2542/3753 [02:58<1:01:47,  3.06s/it] 68%|██████▊   | 2543/3753 [03:03<1:10:53,  3.51s/it] 68%|██████▊   | 2544/3753 [03:07<1:15:08,  3.73s/it] 68%|██████▊   | 2545/3753 [03:11<1:14:43,  3.71s/it] 68%|██████▊   | 2546/3753 [03:15<1:20:03,  3.98s/it] 68%|██████▊   | 2547/3753 [03:20<1:22:04,  4.08s/it] 68%|██████▊   | 2548/3753 [03:23<1:18:52,  3.93s/it] 68%|██████▊   | 2549/3753 [03:27<1:20:28,  4.01s/it] 68%|██████▊   | 2550/3753 [03:32<1:23:19,  4.16s/it]                                                     {'loss': 0.3119, 'grad_norm': 65.57208251953125, 'learning_rate': 1.9753330531505316e-07, 'rewards/chosen': -4.554115295410156, 'rewards/rejected': -9.019136428833008, 'rewards/accuracies': 0.875, 'rewards/margins': 4.46502161026001, 'logps/chosen': -629.9351806640625, 'logps/rejected': -1075.604248046875, 'logits/chosen': 0.13817575573921204, 'logits/rejected': 0.3877682387828827, 'epoch': 0.68}
 68%|██████▊   | 2550/3753 [03:32<1:23:19,  4.16s/it] 68%|██████▊   | 2551/3753 [03:36<1:20:20,  4.01s/it] 68%|██████▊   | 2552/3753 [03:40<1:19:57,  3.99s/it] 68%|██████▊   | 2553/3753 [03:44<1:21:26,  4.07s/it] 68%|██████▊   | 2554/3753 [03:48<1:20:10,  4.01s/it] 68%|██████▊   | 2555/3753 [03:51<1:17:40,  3.89s/it] 68%|██████▊   | 2556/3753 [03:56<1:19:55,  4.01s/it] 68%|██████▊   | 2557/3753 [04:00<1:20:07,  4.02s/it] 68%|██████▊   | 2558/3753 [04:03<1:17:05,  3.87s/it] 68%|██████▊   | 2559/3753 [04:08<1:19:49,  4.01s/it] 68%|██████▊   | 2560/3753 [04:10<1:12:40,  3.66s/it]                                                     {'loss': 0.3125, 'grad_norm': 118.741455078125, 'learning_rate': 1.9460910166551041e-07, 'rewards/chosen': -4.109553813934326, 'rewards/rejected': -8.639567375183105, 'rewards/accuracies': 0.875, 'rewards/margins': 4.530013561248779, 'logps/chosen': -574.9197998046875, 'logps/rejected': -1027.5361328125, 'logits/chosen': 0.1813165247440338, 'logits/rejected': 0.32480424642562866, 'epoch': 0.68}
 68%|██████▊   | 2560/3753 [04:10<1:12:40,  3.66s/it] 68%|██████▊   | 2561/3753 [04:14<1:14:49,  3.77s/it] 68%|██████▊   | 2562/3753 [04:18<1:12:36,  3.66s/it] 68%|██████▊   | 2563/3753 [04:22<1:18:36,  3.96s/it] 68%|██████▊   | 2564/3753 [04:26<1:18:20,  3.95s/it] 68%|██████▊   | 2565/3753 [04:30<1:17:53,  3.93s/it] 68%|██████▊   | 2566/3753 [04:34<1:17:04,  3.90s/it] 68%|██████▊   | 2567/3753 [04:40<1:28:58,  4.50s/it] 68%|██████▊   | 2568/3753 [04:45<1:31:54,  4.65s/it] 68%|██████▊   | 2569/3753 [04:50<1:31:27,  4.63s/it] 68%|██████▊   | 2570/3753 [04:54<1:28:31,  4.49s/it]                                                     {'loss': 0.3182, 'grad_norm': 39.83763122558594, 'learning_rate': 1.9169834608932302e-07, 'rewards/chosen': -3.646117687225342, 'rewards/rejected': -8.270195007324219, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 4.624077796936035, 'logps/chosen': -534.12939453125, 'logps/rejected': -1003.7942504882812, 'logits/chosen': 0.15561546385288239, 'logits/rejected': 0.40802448987960815, 'epoch': 0.68}
 68%|██████▊   | 2570/3753 [04:54<1:28:31,  4.49s/it] 69%|██████▊   | 2571/3753 [04:58<1:28:11,  4.48s/it] 69%|██████▊   | 2572/3753 [05:03<1:28:23,  4.49s/it] 69%|██████▊   | 2573/3753 [05:07<1:25:58,  4.37s/it] 69%|██████▊   | 2574/3753 [05:10<1:20:56,  4.12s/it] 69%|██████▊   | 2575/3753 [05:17<1:34:11,  4.80s/it] 69%|██████▊   | 2576/3753 [05:24<1:50:16,  5.62s/it] 69%|██████▊   | 2577/3753 [05:28<1:40:35,  5.13s/it] 69%|██████▊   | 2578/3753 [05:37<1:59:14,  6.09s/it] 69%|██████▊   | 2579/3753 [05:40<1:45:46,  5.41s/it] 69%|██████▊   | 2580/3753 [05:44<1:36:28,  4.93s/it]                                                     {'loss': 0.4507, 'grad_norm': 43.012107849121094, 'learning_rate': 1.888012904934874e-07, 'rewards/chosen': -3.902721881866455, 'rewards/rejected': -9.637687683105469, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 5.7349653244018555, 'logps/chosen': -559.7459716796875, 'logps/rejected': -1133.244140625, 'logits/chosen': 0.24679537117481232, 'logits/rejected': 0.46561455726623535, 'epoch': 0.69}
 69%|██████▊   | 2580/3753 [05:44<1:36:28,  4.93s/it] 69%|██████▉   | 2581/3753 [05:49<1:32:57,  4.76s/it] 69%|██████▉   | 2582/3753 [05:52<1:26:01,  4.41s/it] 69%|██████▉   | 2583/3753 [05:57<1:26:43,  4.45s/it] 69%|██████▉   | 2584/3753 [06:00<1:22:39,  4.24s/it] 69%|██████▉   | 2585/3753 [06:04<1:17:29,  3.98s/it] 69%|██████▉   | 2586/3753 [06:09<1:22:41,  4.25s/it] 69%|██████▉   | 2587/3753 [06:13<1:21:43,  4.21s/it] 69%|██████▉   | 2588/3753 [06:18<1:29:30,  4.61s/it] 69%|██████▉   | 2589/3753 [06:26<1:44:15,  5.37s/it] 69%|██████▉   | 2590/3753 [06:30<1:37:15,  5.02s/it]                                                     {'loss': 0.2648, 'grad_norm': 23.996835708618164, 'learning_rate': 1.8591818559935598e-07, 'rewards/chosen': -3.713909864425659, 'rewards/rejected': -8.16249942779541, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 4.4485883712768555, 'logps/chosen': -525.595703125, 'logps/rejected': -968.3703002929688, 'logits/chosen': 0.24365004897117615, 'logits/rejected': 0.37760648131370544, 'epoch': 0.69}
 69%|██████▉   | 2590/3753 [06:30<1:37:15,  5.02s/it] 69%|██████▉   | 2591/3753 [06:34<1:31:20,  4.72s/it] 69%|██████▉   | 2592/3753 [06:38<1:28:34,  4.58s/it] 69%|██████▉   | 2593/3753 [06:45<1:40:58,  5.22s/it] 69%|██████▉   | 2594/3753 [06:49<1:37:22,  5.04s/it] 69%|██████▉   | 2595/3753 [06:53<1:31:30,  4.74s/it] 69%|██████▉   | 2596/3753 [06:58<1:33:17,  4.84s/it] 69%|██████▉   | 2597/3753 [07:02<1:27:25,  4.54s/it] 69%|██████▉   | 2598/3753 [07:06<1:21:43,  4.25s/it] 69%|██████▉   | 2599/3753 [07:10<1:19:10,  4.12s/it] 69%|██████▉   | 2600/3753 [07:14<1:20:22,  4.18s/it]                                                     {'loss': 0.2749, 'grad_norm': 84.41645050048828, 'learning_rate': 1.8304928092093858e-07, 'rewards/chosen': -3.358877182006836, 'rewards/rejected': -8.825807571411133, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 5.466931343078613, 'logps/chosen': -491.8759765625, 'logps/rejected': -1048.3746337890625, 'logits/chosen': 0.19400931894779205, 'logits/rejected': 0.38296934962272644, 'epoch': 0.69}
 69%|██████▉   | 2600/3753 [07:14<1:20:22,  4.18s/it] 69%|██████▉   | 2601/3753 [07:17<1:14:39,  3.89s/it] 69%|██████▉   | 2602/3753 [07:22<1:19:52,  4.16s/it] 69%|██████▉   | 2603/3753 [07:25<1:15:54,  3.96s/it] 69%|██████▉   | 2604/3753 [07:29<1:15:44,  3.96s/it] 69%|██████▉   | 2605/3753 [07:34<1:17:40,  4.06s/it] 69%|██████▉   | 2606/3753 [07:38<1:21:36,  4.27s/it] 69%|██████▉   | 2607/3753 [07:42<1:17:30,  4.06s/it] 69%|██████▉   | 2608/3753 [07:45<1:10:54,  3.72s/it] 70%|██████▉   | 2609/3753 [07:48<1:09:16,  3.63s/it] 70%|██████▉   | 2610/3753 [07:53<1:12:03,  3.78s/it]                                                     {'loss': 0.2986, 'grad_norm': 45.9732551574707, 'learning_rate': 1.8019482474330808e-07, 'rewards/chosen': -4.77523136138916, 'rewards/rejected': -10.90746784210205, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 6.132236003875732, 'logps/chosen': -638.1766357421875, 'logps/rejected': -1258.75927734375, 'logits/chosen': 0.2736890912055969, 'logits/rejected': 0.469353586435318, 'epoch': 0.7}
 70%|██████▉   | 2610/3753 [07:53<1:12:03,  3.78s/it] 70%|██████▉   | 2611/3753 [07:57<1:14:05,  3.89s/it] 70%|██████▉   | 2612/3753 [08:01<1:18:02,  4.10s/it] 70%|██████▉   | 2613/3753 [08:06<1:22:02,  4.32s/it] 70%|██████▉   | 2614/3753 [08:10<1:19:29,  4.19s/it] 70%|██████▉   | 2615/3753 [08:14<1:16:52,  4.05s/it] 70%|██████▉   | 2616/3753 [08:18<1:16:14,  4.02s/it] 70%|██████▉   | 2617/3753 [08:22<1:17:45,  4.11s/it] 70%|██████▉   | 2618/3753 [08:25<1:13:11,  3.87s/it] 70%|██████▉   | 2619/3753 [08:30<1:17:49,  4.12s/it] 70%|██████▉   | 2620/3753 [08:34<1:16:01,  4.03s/it]                                                     {'loss': 0.2828, 'grad_norm': 154.3310546875, 'learning_rate': 1.7735506410111388e-07, 'rewards/chosen': -4.222818374633789, 'rewards/rejected': -9.23489761352539, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 5.012079238891602, 'logps/chosen': -603.9365234375, 'logps/rejected': -1102.943359375, 'logits/chosen': 0.22652903199195862, 'logits/rejected': 0.4725862443447113, 'epoch': 0.7}
 70%|██████▉   | 2620/3753 [08:34<1:16:01,  4.03s/it] 70%|██████▉   | 2621/3753 [08:39<1:24:00,  4.45s/it] 70%|██████▉   | 2622/3753 [08:43<1:21:20,  4.32s/it] 70%|██████▉   | 2623/3753 [08:47<1:18:28,  4.17s/it] 70%|██████▉   | 2624/3753 [08:51<1:15:10,  4.00s/it] 70%|██████▉   | 2625/3753 [08:55<1:14:16,  3.95s/it] 70%|██████▉   | 2626/3753 [08:59<1:15:55,  4.04s/it] 70%|██████▉   | 2627/3753 [09:03<1:19:44,  4.25s/it] 70%|███████   | 2628/3753 [09:07<1:16:35,  4.08s/it] 70%|███████   | 2629/3753 [09:12<1:20:31,  4.30s/it] 70%|███████   | 2630/3753 [09:16<1:17:01,  4.12s/it]                                                     {'loss': 0.3079, 'grad_norm': 70.37177276611328, 'learning_rate': 1.7453024475720185e-07, 'rewards/chosen': -4.918392658233643, 'rewards/rejected': -10.486340522766113, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 5.5679473876953125, 'logps/chosen': -661.9841918945312, 'logps/rejected': -1216.589111328125, 'logits/chosen': 0.2778872847557068, 'logits/rejected': 0.4310552477836609, 'epoch': 0.7}
 70%|███████   | 2630/3753 [09:16<1:17:01,  4.12s/it] 70%|███████   | 2631/3753 [09:19<1:12:42,  3.89s/it] 70%|███████   | 2632/3753 [09:24<1:21:13,  4.35s/it] 70%|███████   | 2633/3753 [09:29<1:22:27,  4.42s/it] 70%|███████   | 2634/3753 [09:34<1:23:14,  4.46s/it] 70%|███████   | 2635/3753 [09:40<1:35:47,  5.14s/it] 70%|███████   | 2636/3753 [09:44<1:30:15,  4.85s/it] 70%|███████   | 2637/3753 [09:47<1:19:53,  4.30s/it] 70%|███████   | 2638/3753 [09:51<1:15:27,  4.06s/it] 70%|███████   | 2639/3753 [09:55<1:14:30,  4.01s/it] 70%|███████   | 2640/3753 [10:00<1:18:35,  4.24s/it]                                                     {'loss': 0.272, 'grad_norm': 21.790401458740234, 'learning_rate': 1.717206111813462e-07, 'rewards/chosen': -4.022684097290039, 'rewards/rejected': -10.083643913269043, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 6.060959815979004, 'logps/chosen': -579.3402099609375, 'logps/rejected': -1190.191162109375, 'logits/chosen': 0.21934469044208527, 'logits/rejected': 0.3724163770675659, 'epoch': 0.7}
 70%|███████   | 2640/3753 [10:00<1:18:35,  4.24s/it] 70%|███████   | 2641/3753 [10:04<1:16:55,  4.15s/it] 70%|███████   | 2642/3753 [10:07<1:11:24,  3.86s/it] 70%|███████   | 2643/3753 [10:11<1:11:13,  3.85s/it] 70%|███████   | 2644/3753 [10:15<1:14:52,  4.05s/it] 70%|███████   | 2645/3753 [10:19<1:15:29,  4.09s/it] 71%|███████   | 2646/3753 [10:24<1:17:03,  4.18s/it] 71%|███████   | 2647/3753 [10:27<1:14:27,  4.04s/it] 71%|███████   | 2648/3753 [10:36<1:38:49,  5.37s/it] 71%|███████   | 2649/3753 [10:41<1:35:03,  5.17s/it] 71%|███████   | 2650/3753 [10:45<1:31:22,  4.97s/it]                                                     {'loss': 0.2687, 'grad_norm': 52.284210205078125, 'learning_rate': 1.6892640652909056e-07, 'rewards/chosen': -4.544169902801514, 'rewards/rejected': -9.188879013061523, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 4.644709587097168, 'logps/chosen': -624.4213256835938, 'logps/rejected': -1093.94189453125, 'logits/chosen': 0.22053225338459015, 'logits/rejected': 0.3983524739742279, 'epoch': 0.71}
 71%|███████   | 2650/3753 [10:45<1:31:22,  4.97s/it] 71%|███████   | 2651/3753 [10:50<1:29:13,  4.86s/it] 71%|███████   | 2652/3753 [10:54<1:25:47,  4.68s/it] 71%|███████   | 2653/3753 [10:58<1:23:07,  4.53s/it] 71%|███████   | 2654/3753 [11:02<1:19:02,  4.32s/it] 71%|███████   | 2655/3753 [11:06<1:16:51,  4.20s/it] 71%|███████   | 2656/3753 [11:10<1:14:25,  4.07s/it] 71%|███████   | 2657/3753 [11:14<1:14:32,  4.08s/it] 71%|███████   | 2658/3753 [11:17<1:10:16,  3.85s/it] 71%|███████   | 2659/3753 [11:20<1:07:49,  3.72s/it] 71%|███████   | 2660/3753 [11:24<1:06:41,  3.66s/it]                                                     {'loss': 0.3286, 'grad_norm': 85.67262268066406, 'learning_rate': 1.66147872620706e-07, 'rewards/chosen': -3.1479878425598145, 'rewards/rejected': -7.130593776702881, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.9826061725616455, 'logps/chosen': -460.119140625, 'logps/rejected': -860.5715942382812, 'logits/chosen': 0.11253847926855087, 'logits/rejected': 0.38786566257476807, 'epoch': 0.71}
 71%|███████   | 2660/3753 [11:24<1:06:41,  3.66s/it] 71%|███████   | 2661/3753 [11:28<1:07:36,  3.72s/it] 71%|███████   | 2662/3753 [11:31<1:06:09,  3.64s/it] 71%|███████   | 2663/3753 [11:36<1:11:54,  3.96s/it] 71%|███████   | 2664/3753 [11:40<1:11:39,  3.95s/it] 71%|███████   | 2665/3753 [11:46<1:21:12,  4.48s/it] 71%|███████   | 2666/3753 [11:50<1:21:32,  4.50s/it] 71%|███████   | 2667/3753 [11:54<1:17:03,  4.26s/it] 71%|███████   | 2668/3753 [11:58<1:16:09,  4.21s/it] 71%|███████   | 2669/3753 [12:02<1:13:24,  4.06s/it] 71%|███████   | 2670/3753 [12:05<1:10:39,  3.91s/it]                                                     {'loss': 0.2885, 'grad_norm': 60.28480911254883, 'learning_rate': 1.6338524992026242e-07, 'rewards/chosen': -3.411503553390503, 'rewards/rejected': -7.894099235534668, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 4.482595920562744, 'logps/chosen': -509.6827697753906, 'logps/rejected': -956.4072265625, 'logits/chosen': 0.1592290699481964, 'logits/rejected': 0.33970826864242554, 'epoch': 0.71}
 71%|███████   | 2670/3753 [12:05<1:10:39,  3.91s/it] 71%|███████   | 2671/3753 [12:10<1:12:33,  4.02s/it] 71%|███████   | 2672/3753 [12:14<1:16:48,  4.26s/it] 71%|███████   | 2673/3753 [12:19<1:16:38,  4.26s/it] 71%|███████   | 2674/3753 [12:23<1:16:28,  4.25s/it] 71%|███████▏  | 2675/3753 [12:27<1:13:46,  4.11s/it] 71%|███████▏  | 2676/3753 [12:31<1:13:20,  4.09s/it] 71%|███████▏  | 2677/3753 [12:35<1:15:32,  4.21s/it] 71%|███████▏  | 2678/3753 [12:39<1:14:08,  4.14s/it] 71%|███████▏  | 2679/3753 [12:45<1:21:04,  4.53s/it] 71%|███████▏  | 2680/3753 [12:49<1:18:11,  4.37s/it]                                                     {'loss': 0.3857, 'grad_norm': 76.2072982788086, 'learning_rate': 1.6063877751481752e-07, 'rewards/chosen': -3.599381685256958, 'rewards/rejected': -7.839591979980469, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.240209579467773, 'logps/chosen': -527.3245239257812, 'logps/rejected': -959.6506958007812, 'logits/chosen': 0.15560230612754822, 'logits/rejected': 0.38864365220069885, 'epoch': 0.71}
 71%|███████▏  | 2680/3753 [12:49<1:18:11,  4.37s/it] 71%|███████▏  | 2681/3753 [12:53<1:20:18,  4.49s/it] 71%|███████▏  | 2682/3753 [12:57<1:17:56,  4.37s/it] 71%|███████▏  | 2683/3753 [13:01<1:13:55,  4.15s/it] 72%|███████▏  | 2684/3753 [13:06<1:17:39,  4.36s/it] 72%|███████▏  | 2685/3753 [13:10<1:17:09,  4.33s/it] 72%|███████▏  | 2686/3753 [13:15<1:17:23,  4.35s/it] 72%|███████▏  | 2687/3753 [13:18<1:11:07,  4.00s/it] 72%|███████▏  | 2688/3753 [13:25<1:25:45,  4.83s/it] 72%|███████▏  | 2689/3753 [13:29<1:21:22,  4.59s/it] 72%|███████▏  | 2690/3753 [13:34<1:24:27,  4.77s/it]                                                     {'loss': 0.3351, 'grad_norm': 34.058414459228516, 'learning_rate': 1.579086930937264e-07, 'rewards/chosen': -2.99757719039917, 'rewards/rejected': -6.988497257232666, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.9909205436706543, 'logps/chosen': -489.0596618652344, 'logps/rejected': -883.7091064453125, 'logits/chosen': 0.1435341238975525, 'logits/rejected': 0.33363527059555054, 'epoch': 0.72}
 72%|███████▏  | 2690/3753 [13:34<1:24:27,  4.77s/it] 72%|███████▏  | 2691/3753 [13:40<1:33:46,  5.30s/it] 72%|███████▏  | 2692/3753 [13:49<1:50:26,  6.25s/it] 72%|███████▏  | 2693/3753 [13:52<1:33:06,  5.27s/it] 72%|███████▏  | 2694/3753 [13:56<1:25:39,  4.85s/it] 72%|███████▏  | 2695/3753 [14:00<1:21:22,  4.61s/it] 72%|███████▏  | 2696/3753 [14:03<1:16:53,  4.36s/it] 72%|███████▏  | 2697/3753 [14:07<1:11:24,  4.06s/it] 72%|███████▏  | 2698/3753 [14:11<1:10:04,  3.98s/it] 72%|███████▏  | 2699/3753 [14:15<1:10:08,  3.99s/it] 72%|███████▏  | 2700/3753 [14:18<1:06:50,  3.81s/it]                                                     {'loss': 0.3266, 'grad_norm': 92.26544952392578, 'learning_rate': 1.5519523292807023e-07, 'rewards/chosen': -3.0536603927612305, 'rewards/rejected': -7.902787685394287, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.849126815795898, 'logps/chosen': -483.0934143066406, 'logps/rejected': -963.4177856445312, 'logits/chosen': 0.09166957437992096, 'logits/rejected': 0.30964532494544983, 'epoch': 0.72}
 72%|███████▏  | 2700/3753 [14:18<1:06:50,  3.81s/it] 72%|███████▏  | 2701/3753 [14:23<1:12:42,  4.15s/it] 72%|███████▏  | 2702/3753 [14:27<1:11:45,  4.10s/it] 72%|███████▏  | 2703/3753 [14:30<1:06:18,  3.79s/it] 72%|███████▏  | 2704/3753 [14:34<1:06:59,  3.83s/it] 72%|███████▏  | 2705/3753 [14:38<1:06:52,  3.83s/it] 72%|███████▏  | 2706/3753 [14:41<1:04:49,  3.72s/it] 72%|███████▏  | 2707/3753 [14:47<1:13:59,  4.24s/it] 72%|███████▏  | 2708/3753 [14:51<1:15:29,  4.33s/it] 72%|███████▏  | 2709/3753 [14:55<1:11:08,  4.09s/it] 72%|███████▏  | 2710/3753 [14:59<1:12:15,  4.16s/it]                                                     {'loss': 0.2395, 'grad_norm': 19.96657371520996, 'learning_rate': 1.5249863185020904e-07, 'rewards/chosen': -2.853583812713623, 'rewards/rejected': -6.915214538574219, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 4.061631202697754, 'logps/chosen': -445.1630859375, 'logps/rejected': -856.9152221679688, 'logits/chosen': 0.1345720738172531, 'logits/rejected': 0.3114156126976013, 'epoch': 0.72}
 72%|███████▏  | 2710/3753 [14:59<1:12:15,  4.16s/it] 72%|███████▏  | 2711/3753 [15:03<1:13:17,  4.22s/it] 72%|███████▏  | 2712/3753 [15:07<1:11:16,  4.11s/it] 72%|███████▏  | 2713/3753 [15:10<1:06:38,  3.84s/it] 72%|███████▏  | 2714/3753 [15:14<1:04:00,  3.70s/it] 72%|███████▏  | 2715/3753 [15:17<1:00:37,  3.50s/it] 72%|███████▏  | 2716/3753 [15:21<1:03:20,  3.66s/it] 72%|███████▏  | 2717/3753 [15:25<1:06:46,  3.87s/it] 72%|███████▏  | 2718/3753 [15:29<1:06:17,  3.84s/it] 72%|███████▏  | 2719/3753 [15:33<1:07:01,  3.89s/it] 72%|███████▏  | 2720/3753 [15:37<1:07:14,  3.91s/it]                                                     {'loss': 0.2805, 'grad_norm': 42.89209747314453, 'learning_rate': 1.498191232334577e-07, 'rewards/chosen': -3.4547982215881348, 'rewards/rejected': -7.314144134521484, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.8593459129333496, 'logps/chosen': -507.3719787597656, 'logps/rejected': -895.333984375, 'logits/chosen': 0.1775830090045929, 'logits/rejected': 0.2536088526248932, 'epoch': 0.72}
 72%|███████▏  | 2720/3753 [15:37<1:07:14,  3.91s/it] 73%|███████▎  | 2721/3753 [15:40<1:04:57,  3.78s/it] 73%|███████▎  | 2722/3753 [15:44<1:03:21,  3.69s/it] 73%|███████▎  | 2723/3753 [15:48<1:05:15,  3.80s/it] 73%|███████▎  | 2724/3753 [15:52<1:03:30,  3.70s/it] 73%|███████▎  | 2725/3753 [15:58<1:18:29,  4.58s/it] 73%|███████▎  | 2726/3753 [16:03<1:17:30,  4.53s/it] 73%|███████▎  | 2727/3753 [16:10<1:32:58,  5.44s/it] 73%|███████▎  | 2728/3753 [16:15<1:32:25,  5.41s/it] 73%|███████▎  | 2729/3753 [16:20<1:27:19,  5.12s/it] 73%|███████▎  | 2730/3753 [16:23<1:17:54,  4.57s/it]                                                     {'loss': 0.2782, 'grad_norm': 71.25688171386719, 'learning_rate': 1.471569389718902e-07, 'rewards/chosen': -3.5253548622131348, 'rewards/rejected': -9.695834159851074, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 6.1704792976379395, 'logps/chosen': -508.15972900390625, 'logps/rejected': -1129.2205810546875, 'logits/chosen': 0.128155916929245, 'logits/rejected': 0.3446330428123474, 'epoch': 0.73}
 73%|███████▎  | 2730/3753 [16:23<1:17:54,  4.57s/it] 73%|███████▎  | 2731/3753 [16:27<1:16:13,  4.48s/it] 73%|███████▎  | 2732/3753 [16:31<1:12:26,  4.26s/it] 73%|███████▎  | 2733/3753 [16:34<1:06:19,  3.90s/it] 73%|███████▎  | 2734/3753 [16:38<1:06:07,  3.89s/it] 73%|███████▎  | 2735/3753 [16:42<1:05:57,  3.89s/it] 73%|███████▎  | 2736/3753 [16:46<1:07:27,  3.98s/it] 73%|███████▎  | 2737/3753 [16:50<1:08:15,  4.03s/it] 73%|███████▎  | 2738/3753 [16:55<1:10:20,  4.16s/it] 73%|███████▎  | 2739/3753 [16:59<1:08:12,  4.04s/it] 73%|███████▎  | 2740/3753 [17:02<1:05:51,  3.90s/it]                                                     {'loss': 0.4144, 'grad_norm': 77.77310180664062, 'learning_rate': 1.4451230946026974e-07, 'rewards/chosen': -3.904545545578003, 'rewards/rejected': -8.203310012817383, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 4.298764228820801, 'logps/chosen': -556.211669921875, 'logps/rejected': -986.1497192382812, 'logits/chosen': 0.1568397879600525, 'logits/rejected': 0.3259972631931305, 'epoch': 0.73}
 73%|███████▎  | 2740/3753 [17:02<1:05:51,  3.90s/it] 73%|███████▎  | 2741/3753 [17:06<1:07:26,  4.00s/it] 73%|███████▎  | 2742/3753 [17:10<1:04:50,  3.85s/it] 73%|███████▎  | 2743/3753 [17:16<1:18:36,  4.67s/it] 73%|███████▎  | 2744/3753 [17:21<1:16:42,  4.56s/it] 73%|███████▎  | 2745/3753 [17:25<1:13:11,  4.36s/it] 73%|███████▎  | 2746/3753 [17:29<1:14:54,  4.46s/it] 73%|███████▎  | 2747/3753 [17:37<1:29:18,  5.33s/it] 73%|███████▎  | 2748/3753 [17:41<1:23:46,  5.00s/it] 73%|███████▎  | 2749/3753 [17:44<1:15:09,  4.49s/it] 73%|███████▎  | 2750/3753 [17:48<1:10:46,  4.23s/it]                                                     {'loss': 0.3906, 'grad_norm': 53.86486053466797, 'learning_rate': 1.4188546357411003e-07, 'rewards/chosen': -3.2128746509552, 'rewards/rejected': -8.873271942138672, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 5.660397529602051, 'logps/chosen': -483.15301513671875, 'logps/rejected': -1053.19482421875, 'logits/chosen': 0.14840123057365417, 'logits/rejected': 0.3165147006511688, 'epoch': 0.73}
 73%|███████▎  | 2750/3753 [17:48<1:10:46,  4.23s/it] 73%|███████▎  | 2751/3753 [17:52<1:10:35,  4.23s/it] 73%|███████▎  | 2752/3753 [17:56<1:11:20,  4.28s/it] 73%|███████▎  | 2753/3753 [18:01<1:11:54,  4.31s/it] 73%|███████▎  | 2754/3753 [18:05<1:09:21,  4.17s/it] 73%|███████▎  | 2755/3753 [18:11<1:18:47,  4.74s/it] 73%|███████▎  | 2756/3753 [18:14<1:11:44,  4.32s/it] 73%|███████▎  | 2757/3753 [18:17<1:06:47,  4.02s/it] 73%|███████▎  | 2758/3753 [18:21<1:06:46,  4.03s/it] 74%|███████▎  | 2759/3753 [18:25<1:03:40,  3.84s/it] 74%|███████▎  | 2760/3753 [18:29<1:04:50,  3.92s/it]                                                     {'loss': 0.3705, 'grad_norm': 30.785789489746094, 'learning_rate': 1.3927662864986706e-07, 'rewards/chosen': -2.922368288040161, 'rewards/rejected': -6.582608222961426, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 3.6602401733398438, 'logps/chosen': -445.0321350097656, 'logps/rejected': -818.2772827148438, 'logits/chosen': 0.12236632406711578, 'logits/rejected': 0.30119746923446655, 'epoch': 0.74}
 74%|███████▎  | 2760/3753 [18:29<1:04:50,  3.92s/it] 74%|███████▎  | 2761/3753 [18:38<1:27:38,  5.30s/it] 74%|███████▎  | 2762/3753 [18:42<1:25:32,  5.18s/it] 74%|███████▎  | 2763/3753 [18:46<1:20:03,  4.85s/it] 74%|███████▎  | 2764/3753 [18:51<1:17:33,  4.71s/it] 74%|███████▎  | 2765/3753 [18:54<1:09:28,  4.22s/it] 74%|███████▎  | 2766/3753 [18:58<1:07:46,  4.12s/it] 74%|███████▎  | 2767/3753 [19:01<1:05:26,  3.98s/it] 74%|███████▍  | 2768/3753 [19:05<1:04:04,  3.90s/it] 74%|███████▍  | 2769/3753 [19:10<1:06:20,  4.04s/it] 74%|███████▍  | 2770/3753 [19:13<1:05:36,  4.00s/it]                                                     {'loss': 0.3078, 'grad_norm': 54.932403564453125, 'learning_rate': 1.3668603046526568e-07, 'rewards/chosen': -2.4379630088806152, 'rewards/rejected': -8.158260345458984, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 5.720297336578369, 'logps/chosen': -404.0357360839844, 'logps/rejected': -974.1512451171875, 'logits/chosen': 0.03995976969599724, 'logits/rejected': 0.227464959025383, 'epoch': 0.74}
 74%|███████▍  | 2770/3753 [19:14<1:05:36,  4.00s/it] 74%|███████▍  | 2771/3753 [19:17<1:02:53,  3.84s/it] 74%|███████▍  | 2772/3753 [19:23<1:12:25,  4.43s/it] 74%|███████▍  | 2773/3753 [19:27<1:11:21,  4.37s/it] 74%|███████▍  | 2774/3753 [19:31<1:10:01,  4.29s/it] 74%|███████▍  | 2775/3753 [19:35<1:06:51,  4.10s/it] 74%|███████▍  | 2776/3753 [19:39<1:06:56,  4.11s/it] 74%|███████▍  | 2777/3753 [19:43<1:07:11,  4.13s/it] 74%|███████▍  | 2778/3753 [19:46<1:03:40,  3.92s/it] 74%|███████▍  | 2779/3753 [19:50<1:01:32,  3.79s/it] 74%|███████▍  | 2780/3753 [19:54<1:01:19,  3.78s/it]                                                     {'loss': 0.3789, 'grad_norm': 130.20579528808594, 'learning_rate': 1.34113893219759e-07, 'rewards/chosen': -3.102804660797119, 'rewards/rejected': -6.377384185791016, 'rewards/accuracies': 0.875, 'rewards/margins': 3.2745792865753174, 'logps/chosen': -473.91986083984375, 'logps/rejected': -801.284912109375, 'logits/chosen': 0.14896468818187714, 'logits/rejected': 0.3107723593711853, 'epoch': 0.74}
 74%|███████▍  | 2780/3753 [19:54<1:01:19,  3.78s/it] 74%|███████▍  | 2781/3753 [19:58<1:02:55,  3.88s/it] 74%|███████▍  | 2782/3753 [20:02<1:02:11,  3.84s/it] 74%|███████▍  | 2783/3753 [20:05<1:01:37,  3.81s/it] 74%|███████▍  | 2784/3753 [20:11<1:11:27,  4.43s/it] 74%|███████▍  | 2785/3753 [20:16<1:10:56,  4.40s/it] 74%|███████▍  | 2786/3753 [20:20<1:08:59,  4.28s/it] 74%|███████▍  | 2787/3753 [20:23<1:06:40,  4.14s/it] 74%|███████▍  | 2788/3753 [20:28<1:07:39,  4.21s/it] 74%|███████▍  | 2789/3753 [20:31<1:03:57,  3.98s/it] 74%|███████▍  | 2790/3753 [20:34<1:00:45,  3.79s/it]                                                     {'loss': 0.318, 'grad_norm': 25.041650772094727, 'learning_rate': 1.3156043951512542e-07, 'rewards/chosen': -3.269735813140869, 'rewards/rejected': -7.538542747497559, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.268807411193848, 'logps/chosen': -498.00018310546875, 'logps/rejected': -929.2464599609375, 'logits/chosen': 0.15653172135353088, 'logits/rejected': 0.33951759338378906, 'epoch': 0.74}
 74%|███████▍  | 2790/3753 [20:35<1:00:45,  3.79s/it] 74%|███████▍  | 2791/3753 [20:40<1:09:23,  4.33s/it] 74%|███████▍  | 2792/3753 [20:44<1:07:23,  4.21s/it] 74%|███████▍  | 2793/3753 [20:48<1:07:29,  4.22s/it] 74%|███████▍  | 2794/3753 [20:52<1:04:58,  4.07s/it] 74%|███████▍  | 2795/3753 [20:56<1:02:46,  3.93s/it] 75%|███████▍  | 2796/3753 [21:00<1:03:25,  3.98s/it] 75%|███████▍  | 2797/3753 [21:04<1:05:09,  4.09s/it] 75%|███████▍  | 2798/3753 [21:08<1:03:46,  4.01s/it] 75%|███████▍  | 2799/3753 [21:12<1:04:22,  4.05s/it] 75%|███████▍  | 2800/3753 [21:15<1:01:34,  3.88s/it]                                                     {'loss': 0.3071, 'grad_norm': 19.216819763183594, 'learning_rate': 1.2902589033620453e-07, 'rewards/chosen': -3.8754448890686035, 'rewards/rejected': -8.120244026184082, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 4.2447991371154785, 'logps/chosen': -555.5164184570312, 'logps/rejected': -990.4010009765625, 'logits/chosen': 0.19413982331752777, 'logits/rejected': 0.38548940420150757, 'epoch': 0.75}
 75%|███████▍  | 2800/3753 [21:16<1:01:34,  3.88s/it] 75%|███████▍  | 2801/3753 [21:20<1:02:43,  3.95s/it] 75%|███████▍  | 2802/3753 [21:24<1:04:05,  4.04s/it] 75%|███████▍  | 2803/3753 [21:28<1:05:00,  4.11s/it] 75%|███████▍  | 2804/3753 [21:33<1:08:26,  4.33s/it] 75%|███████▍  | 2805/3753 [21:36<1:03:22,  4.01s/it] 75%|███████▍  | 2806/3753 [21:41<1:06:01,  4.18s/it] 75%|███████▍  | 2807/3753 [21:45<1:07:02,  4.25s/it] 75%|███████▍  | 2808/3753 [21:49<1:05:34,  4.16s/it] 75%|███████▍  | 2809/3753 [21:53<1:05:47,  4.18s/it] 75%|███████▍  | 2810/3753 [21:57<1:02:14,  3.96s/it]                                                     {'loss': 0.3836, 'grad_norm': 34.75550842285156, 'learning_rate': 1.2651046503177195e-07, 'rewards/chosen': -3.58333158493042, 'rewards/rejected': -8.369002342224121, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 4.785670280456543, 'logps/chosen': -524.8461303710938, 'logps/rejected': -1004.4088745117188, 'logits/chosen': 0.12623515725135803, 'logits/rejected': 0.3263323903083801, 'epoch': 0.75}
 75%|███████▍  | 2810/3753 [21:57<1:02:14,  3.96s/it] 75%|███████▍  | 2811/3753 [22:01<1:01:41,  3.93s/it] 75%|███████▍  | 2812/3753 [22:05<1:03:24,  4.04s/it] 75%|███████▍  | 2813/3753 [22:09<1:02:01,  3.96s/it] 75%|███████▍  | 2814/3753 [22:14<1:06:21,  4.24s/it] 75%|███████▌  | 2815/3753 [22:17<1:04:23,  4.12s/it] 75%|███████▌  | 2816/3753 [22:21<59:45,  3.83s/it]   75%|███████▌  | 2817/3753 [22:24<56:54,  3.65s/it] 75%|███████▌  | 2818/3753 [22:27<56:36,  3.63s/it] 75%|███████▌  | 2819/3753 [22:31<58:08,  3.73s/it] 75%|███████▌  | 2820/3753 [22:35<59:16,  3.81s/it]                                                   {'loss': 0.2974, 'grad_norm': 36.9698371887207, 'learning_rate': 1.240143812955561e-07, 'rewards/chosen': -3.3513336181640625, 'rewards/rejected': -7.7306671142578125, 'rewards/accuracies': 0.875, 'rewards/margins': 4.379334449768066, 'logps/chosen': -471.41888427734375, 'logps/rejected': -917.2023315429688, 'logits/chosen': 0.16444900631904602, 'logits/rejected': 0.2929011583328247, 'epoch': 0.75}
 75%|███████▌  | 2820/3753 [22:36<59:16,  3.81s/it] 75%|███████▌  | 2821/3753 [22:39<58:19,  3.75s/it] 75%|███████▌  | 2822/3753 [22:47<1:15:39,  4.88s/it] 75%|███████▌  | 2823/3753 [22:50<1:07:59,  4.39s/it] 75%|███████▌  | 2824/3753 [22:54<1:07:08,  4.34s/it] 75%|███████▌  | 2825/3753 [22:59<1:08:02,  4.40s/it] 75%|███████▌  | 2826/3753 [23:03<1:09:29,  4.50s/it] 75%|███████▌  | 2827/3753 [23:08<1:09:16,  4.49s/it] 75%|███████▌  | 2828/3753 [23:15<1:23:10,  5.39s/it] 75%|███████▌  | 2829/3753 [23:19<1:17:03,  5.00s/it] 75%|███████▌  | 2830/3753 [23:23<1:10:15,  4.57s/it]                                                     {'loss': 0.2782, 'grad_norm': 29.490917205810547, 'learning_rate': 1.2153785514739802e-07, 'rewards/chosen': -3.9368767738342285, 'rewards/rejected': -9.20188045501709, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 5.265003681182861, 'logps/chosen': -551.2467041015625, 'logps/rejected': -1079.923583984375, 'logits/chosen': 0.18891721963882446, 'logits/rejected': 0.43672648072242737, 'epoch': 0.75}
 75%|███████▌  | 2830/3753 [23:23<1:10:15,  4.57s/it] 75%|███████▌  | 2831/3753 [23:27<1:07:15,  4.38s/it] 75%|███████▌  | 2832/3753 [23:32<1:08:35,  4.47s/it] 75%|███████▌  | 2833/3753 [23:36<1:07:51,  4.43s/it] 76%|███████▌  | 2834/3753 [23:40<1:04:15,  4.20s/it] 76%|███████▌  | 2835/3753 [23:43<1:02:44,  4.10s/it] 76%|███████▌  | 2836/3753 [23:49<1:11:17,  4.66s/it] 76%|███████▌  | 2837/3753 [23:53<1:07:10,  4.40s/it] 76%|███████▌  | 2838/3753 [23:57<1:02:48,  4.12s/it] 76%|███████▌  | 2839/3753 [24:02<1:06:33,  4.37s/it] 76%|███████▌  | 2840/3753 [24:08<1:16:04,  5.00s/it]                                                     {'loss': 0.262, 'grad_norm': 39.0067024230957, 'learning_rate': 1.1908110091455673e-07, 'rewards/chosen': -3.742849826812744, 'rewards/rejected': -8.751019477844238, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 5.008170127868652, 'logps/chosen': -530.363525390625, 'logps/rejected': -1031.425537109375, 'logits/chosen': 0.22353437542915344, 'logits/rejected': 0.38155627250671387, 'epoch': 0.76}
 76%|███████▌  | 2840/3753 [24:08<1:16:04,  5.00s/it] 76%|███████▌  | 2841/3753 [24:12<1:10:51,  4.66s/it] 76%|███████▌  | 2842/3753 [24:17<1:10:36,  4.65s/it] 76%|███████▌  | 2843/3753 [24:20<1:04:08,  4.23s/it] 76%|███████▌  | 2844/3753 [24:24<1:01:53,  4.08s/it] 76%|███████▌  | 2845/3753 [24:28<1:01:42,  4.08s/it] 76%|███████▌  | 2846/3753 [24:34<1:12:55,  4.82s/it] 76%|███████▌  | 2847/3753 [24:38<1:08:06,  4.51s/it] 76%|███████▌  | 2848/3753 [24:42<1:03:50,  4.23s/it] 76%|███████▌  | 2849/3753 [24:45<1:01:37,  4.09s/it] 76%|███████▌  | 2850/3753 [24:49<59:45,  3.97s/it]                                                     {'loss': 0.2855, 'grad_norm': 42.76845169067383, 'learning_rate': 1.166443312131603e-07, 'rewards/chosen': -3.946053981781006, 'rewards/rejected': -8.989729881286621, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 5.043675899505615, 'logps/chosen': -555.0889892578125, 'logps/rejected': -1060.6292724609375, 'logits/chosen': 0.15905484557151794, 'logits/rejected': 0.3295105993747711, 'epoch': 0.76}
 76%|███████▌  | 2850/3753 [24:49<59:45,  3.97s/it] 76%|███████▌  | 2851/3753 [24:52<56:17,  3.74s/it] 76%|███████▌  | 2852/3753 [24:56<56:35,  3.77s/it] 76%|███████▌  | 2853/3753 [25:01<59:57,  4.00s/it] 76%|███████▌  | 2854/3753 [25:04<57:01,  3.81s/it] 76%|███████▌  | 2855/3753 [25:08<58:25,  3.90s/it] 76%|███████▌  | 2856/3753 [25:12<57:19,  3.83s/it] 76%|███████▌  | 2857/3753 [25:15<56:37,  3.79s/it] 76%|███████▌  | 2858/3753 [25:22<1:09:53,  4.68s/it] 76%|███████▌  | 2859/3753 [25:26<1:07:09,  4.51s/it] 76%|███████▌  | 2860/3753 [25:31<1:06:00,  4.43s/it]                                                     {'loss': 0.2853, 'grad_norm': 177.36337280273438, 'learning_rate': 1.1422775692980551e-07, 'rewards/chosen': -4.5899858474731445, 'rewards/rejected': -9.790162086486816, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 5.200175762176514, 'logps/chosen': -619.3204956054688, 'logps/rejected': -1140.4833984375, 'logits/chosen': 0.2270575761795044, 'logits/rejected': 0.38812974095344543, 'epoch': 0.76}
 76%|███████▌  | 2860/3753 [25:31<1:06:00,  4.43s/it] 76%|███████▌  | 2861/3753 [25:34<1:02:42,  4.22s/it] 76%|███████▋  | 2862/3753 [25:38<1:01:27,  4.14s/it] 76%|███████▋  | 2863/3753 [25:42<1:00:20,  4.07s/it] 76%|███████▋  | 2864/3753 [25:45<56:37,  3.82s/it]   76%|███████▋  | 2865/3753 [25:49<56:29,  3.82s/it] 76%|███████▋  | 2866/3753 [25:53<55:54,  3.78s/it] 76%|███████▋  | 2867/3753 [25:56<53:51,  3.65s/it] 76%|███████▋  | 2868/3753 [26:01<59:29,  4.03s/it] 76%|███████▋  | 2869/3753 [26:05<56:43,  3.85s/it] 76%|███████▋  | 2870/3753 [26:09<57:30,  3.91s/it]                                                   {'loss': 0.3744, 'grad_norm': 15.599553108215332, 'learning_rate': 1.118315872033064e-07, 'rewards/chosen': -3.4713997840881348, 'rewards/rejected': -7.335862636566162, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 3.8644638061523438, 'logps/chosen': -500.4337463378906, 'logps/rejected': -890.1301879882812, 'logits/chosen': 0.1524714231491089, 'logits/rejected': 0.3360744118690491, 'epoch': 0.76}
 76%|███████▋  | 2870/3753 [26:09<57:30,  3.91s/it] 76%|███████▋  | 2871/3753 [26:13<1:00:07,  4.09s/it] 77%|███████▋  | 2872/3753 [26:17<59:39,  4.06s/it]   77%|███████▋  | 2873/3753 [26:21<59:03,  4.03s/it] 77%|███████▋  | 2874/3753 [26:25<58:00,  3.96s/it] 77%|███████▋  | 2875/3753 [26:28<54:32,  3.73s/it] 77%|███████▋  | 2876/3753 [26:32<53:34,  3.67s/it] 77%|███████▋  | 2877/3753 [26:35<54:00,  3.70s/it] 77%|███████▋  | 2878/3753 [26:39<55:11,  3.78s/it] 77%|███████▋  | 2879/3753 [26:45<1:03:12,  4.34s/it] 77%|███████▋  | 2880/3753 [26:50<1:06:01,  4.54s/it]                                                     {'loss': 0.3134, 'grad_norm': 18.204622268676758, 'learning_rate': 1.0945602940659543e-07, 'rewards/chosen': -4.210433006286621, 'rewards/rejected': -9.083788871765137, 'rewards/accuracies': 0.875, 'rewards/margins': 4.873355865478516, 'logps/chosen': -589.9078369140625, 'logps/rejected': -1072.789794921875, 'logits/chosen': 0.1478850096464157, 'logits/rejected': 0.4169902205467224, 'epoch': 0.77}
 77%|███████▋  | 2880/3753 [26:50<1:06:01,  4.54s/it] 77%|███████▋  | 2881/3753 [26:54<1:03:47,  4.39s/it] 77%|███████▋  | 2882/3753 [26:59<1:05:29,  4.51s/it] 77%|███████▋  | 2883/3753 [27:03<1:04:58,  4.48s/it] 77%|███████▋  | 2884/3753 [27:07<1:01:57,  4.28s/it] 77%|███████▋  | 2885/3753 [27:11<1:00:55,  4.21s/it] 77%|███████▋  | 2886/3753 [27:15<1:01:36,  4.26s/it] 77%|███████▋  | 2887/3753 [27:19<59:52,  4.15s/it]   77%|███████▋  | 2888/3753 [27:24<1:00:07,  4.17s/it] 77%|███████▋  | 2889/3753 [27:28<59:22,  4.12s/it]   77%|███████▋  | 2890/3753 [27:31<57:21,  3.99s/it]                                                   {'loss': 0.2547, 'grad_norm': 51.15252685546875, 'learning_rate': 1.0710128912877635e-07, 'rewards/chosen': -3.629939556121826, 'rewards/rejected': -8.719184875488281, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 5.089245319366455, 'logps/chosen': -533.1119384765625, 'logps/rejected': -1048.398193359375, 'logits/chosen': 0.11479966342449188, 'logits/rejected': 0.3826281726360321, 'epoch': 0.77}
 77%|███████▋  | 2890/3753 [27:31<57:21,  3.99s/it] 77%|███████▋  | 2891/3753 [27:35<57:50,  4.03s/it] 77%|███████▋  | 2892/3753 [27:40<59:26,  4.14s/it] 77%|███████▋  | 2893/3753 [27:44<1:01:52,  4.32s/it] 77%|███████▋  | 2894/3753 [27:48<56:46,  3.97s/it]   77%|███████▋  | 2895/3753 [27:52<57:12,  4.00s/it] 77%|███████▋  | 2896/3753 [27:56<59:36,  4.17s/it] 77%|███████▋  | 2897/3753 [28:00<57:54,  4.06s/it] 77%|███████▋  | 2898/3753 [28:05<1:00:39,  4.26s/it] 77%|███████▋  | 2899/3753 [28:12<1:13:49,  5.19s/it] 77%|███████▋  | 2900/3753 [28:16<1:07:26,  4.74s/it]                                                     {'loss': 0.3907, 'grad_norm': 53.2784309387207, 'learning_rate': 1.0476757015733168e-07, 'rewards/chosen': -4.207527160644531, 'rewards/rejected': -9.270358085632324, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 5.062830924987793, 'logps/chosen': -604.906982421875, 'logps/rejected': -1109.165771484375, 'logits/chosen': 0.16020938754081726, 'logits/rejected': 0.33587372303009033, 'epoch': 0.77}
 77%|███████▋  | 2900/3753 [28:16<1:07:26,  4.74s/it] 77%|███████▋  | 2901/3753 [28:20<1:06:40,  4.70s/it] 77%|███████▋  | 2902/3753 [28:24<1:03:46,  4.50s/it] 77%|███████▋  | 2903/3753 [28:28<59:19,  4.19s/it]   77%|███████▋  | 2904/3753 [28:32<1:00:36,  4.28s/it] 77%|███████▋  | 2905/3753 [28:36<56:31,  4.00s/it]   77%|███████▋  | 2906/3753 [28:40<56:05,  3.97s/it] 77%|███████▋  | 2907/3753 [28:43<55:17,  3.92s/it] 77%|███████▋  | 2908/3753 [28:48<57:24,  4.08s/it] 78%|███████▊  | 2909/3753 [28:52<58:22,  4.15s/it] 78%|███████▊  | 2910/3753 [28:56<55:51,  3.98s/it]                                                   {'loss': 0.3084, 'grad_norm': 36.56703567504883, 'learning_rate': 1.0245507446048649e-07, 'rewards/chosen': -3.8398609161376953, 'rewards/rejected': -8.766195297241211, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 4.926334381103516, 'logps/chosen': -541.6651611328125, 'logps/rejected': -1042.566162109375, 'logits/chosen': 0.09670375287532806, 'logits/rejected': 0.35613900423049927, 'epoch': 0.78}
 78%|███████▊  | 2910/3753 [28:56<55:51,  3.98s/it] 78%|███████▊  | 2911/3753 [29:00<55:28,  3.95s/it] 78%|███████▊  | 2912/3753 [29:03<53:10,  3.79s/it] 78%|███████▊  | 2913/3753 [29:07<53:03,  3.79s/it] 78%|███████▊  | 2914/3753 [29:12<56:51,  4.07s/it] 78%|███████▊  | 2915/3753 [29:15<53:56,  3.86s/it] 78%|███████▊  | 2916/3753 [29:22<1:06:03,  4.74s/it] 78%|███████▊  | 2917/3753 [29:26<1:04:15,  4.61s/it] 78%|███████▊  | 2918/3753 [29:30<1:01:35,  4.43s/it] 78%|███████▊  | 2919/3753 [29:35<1:03:30,  4.57s/it] 78%|███████▊  | 2920/3753 [29:39<59:12,  4.26s/it]                                                     {'loss': 0.271, 'grad_norm': 64.95650482177734, 'learning_rate': 1.0016400216972911e-07, 'rewards/chosen': -3.8146793842315674, 'rewards/rejected': -8.374151229858398, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.559471607208252, 'logps/chosen': -534.3651733398438, 'logps/rejected': -1003.83154296875, 'logits/chosen': 0.23607507348060608, 'logits/rejected': 0.4377050995826721, 'epoch': 0.78}
 78%|███████▊  | 2920/3753 [29:39<59:12,  4.26s/it] 78%|███████▊  | 2921/3753 [29:43<59:39,  4.30s/it] 78%|███████▊  | 2922/3753 [29:46<55:57,  4.04s/it] 78%|███████▊  | 2923/3753 [29:50<55:54,  4.04s/it] 78%|███████▊  | 2924/3753 [29:55<59:33,  4.31s/it] 78%|███████▊  | 2925/3753 [29:59<58:29,  4.24s/it] 78%|███████▊  | 2926/3753 [30:04<58:28,  4.24s/it] 78%|███████▊  | 2927/3753 [30:11<1:11:55,  5.22s/it] 78%|███████▊  | 2928/3753 [30:14<1:02:26,  4.54s/it] 78%|███████▊  | 2929/3753 [30:18<1:00:09,  4.38s/it] 78%|███████▊  | 2930/3753 [30:22<58:15,  4.25s/it]                                                     {'loss': 0.3221, 'grad_norm': 14.462474822998047, 'learning_rate': 9.78945515624914e-08, 'rewards/chosen': -4.3907670974731445, 'rewards/rejected': -10.354182243347168, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 5.963415145874023, 'logps/chosen': -592.1087646484375, 'logps/rejected': -1195.465087890625, 'logits/chosen': 0.2136184722185135, 'logits/rejected': 0.39969179034233093, 'epoch': 0.78}
 78%|███████▊  | 2930/3753 [30:22<58:15,  4.25s/it] 78%|███████▊  | 2931/3753 [30:26<57:00,  4.16s/it] 78%|███████▊  | 2932/3753 [30:30<55:53,  4.09s/it] 78%|███████▊  | 2933/3753 [30:34<55:12,  4.04s/it] 78%|███████▊  | 2934/3753 [30:39<57:51,  4.24s/it] 78%|███████▊  | 2935/3753 [30:42<56:02,  4.11s/it] 78%|███████▊  | 2936/3753 [30:47<56:05,  4.12s/it] 78%|███████▊  | 2937/3753 [30:51<56:20,  4.14s/it] 78%|███████▊  | 2938/3753 [30:54<53:13,  3.92s/it] 78%|███████▊  | 2939/3753 [30:58<52:03,  3.84s/it] 78%|███████▊  | 2940/3753 [31:02<53:34,  3.95s/it]                                                   {'loss': 0.4775, 'grad_norm': 186.30250549316406, 'learning_rate': 9.564691904498841e-08, 'rewards/chosen': -4.594313621520996, 'rewards/rejected': -9.829586029052734, 'rewards/accuracies': 0.875, 'rewards/margins': 5.235272407531738, 'logps/chosen': -629.482177734375, 'logps/rejected': -1148.130126953125, 'logits/chosen': 0.18377788364887238, 'logits/rejected': 0.40497246384620667, 'epoch': 0.78}
 78%|███████▊  | 2940/3753 [31:02<53:34,  3.95s/it] 78%|███████▊  | 2941/3753 [31:06<52:52,  3.91s/it] 78%|███████▊  | 2942/3753 [31:10<53:01,  3.92s/it] 78%|███████▊  | 2943/3753 [31:16<1:02:38,  4.64s/it] 78%|███████▊  | 2944/3753 [31:20<1:01:27,  4.56s/it] 78%|███████▊  | 2945/3753 [31:25<59:38,  4.43s/it]   78%|███████▊  | 2946/3753 [31:29<59:41,  4.44s/it] 79%|███████▊  | 2947/3753 [31:33<56:09,  4.18s/it] 79%|███████▊  | 2948/3753 [31:37<55:08,  4.11s/it] 79%|███████▊  | 2949/3753 [31:41<55:00,  4.11s/it] 79%|███████▊  | 2950/3753 [31:44<52:58,  3.96s/it]                                                   {'loss': 0.2454, 'grad_norm': 98.11419677734375, 'learning_rate': 9.342129913522166e-08, 'rewards/chosen': -3.967433452606201, 'rewards/rejected': -9.438913345336914, 'rewards/accuracies': 0.875, 'rewards/margins': 5.471479415893555, 'logps/chosen': -553.71484375, 'logps/rejected': -1107.6351318359375, 'logits/chosen': 0.1592443883419037, 'logits/rejected': 0.3807770013809204, 'epoch': 0.79}
 79%|███████▊  | 2950/3753 [31:44<52:58,  3.96s/it] 79%|███████▊  | 2951/3753 [31:48<51:42,  3.87s/it] 79%|███████▊  | 2952/3753 [31:52<52:51,  3.96s/it] 79%|███████▊  | 2953/3753 [31:56<52:17,  3.92s/it] 79%|███████▊  | 2954/3753 [32:00<52:54,  3.97s/it] 79%|███████▊  | 2955/3753 [32:03<48:53,  3.68s/it] 79%|███████▉  | 2956/3753 [32:08<52:24,  3.95s/it] 79%|███████▉  | 2957/3753 [32:11<50:49,  3.83s/it] 79%|███████▉  | 2958/3753 [32:17<57:23,  4.33s/it] 79%|███████▉  | 2959/3753 [32:24<1:07:20,  5.09s/it] 79%|███████▉  | 2960/3753 [32:28<1:04:24,  4.87s/it]                                                     {'loss': 0.2895, 'grad_norm': 69.37266540527344, 'learning_rate': 9.121788444614417e-08, 'rewards/chosen': -4.037266731262207, 'rewards/rejected': -9.081897735595703, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 5.044631004333496, 'logps/chosen': -570.202880859375, 'logps/rejected': -1076.819580078125, 'logits/chosen': 0.16809794306755066, 'logits/rejected': 0.3158898949623108, 'epoch': 0.79}
 79%|███████▉  | 2960/3753 [32:28<1:04:24,  4.87s/it] 79%|███████▉  | 2961/3753 [32:32<1:02:32,  4.74s/it] 79%|███████▉  | 2962/3753 [32:35<56:20,  4.27s/it]   79%|███████▉  | 2963/3753 [32:40<55:27,  4.21s/it] 79%|███████▉  | 2964/3753 [32:43<54:07,  4.12s/it] 79%|███████▉  | 2965/3753 [32:48<54:57,  4.19s/it] 79%|███████▉  | 2966/3753 [32:52<53:58,  4.12s/it] 79%|███████▉  | 2967/3753 [32:56<53:54,  4.11s/it] 79%|███████▉  | 2968/3753 [32:59<51:25,  3.93s/it] 79%|███████▉  | 2969/3753 [33:03<50:05,  3.83s/it] 79%|███████▉  | 2970/3753 [33:08<54:20,  4.16s/it]                                                   {'loss': 0.3709, 'grad_norm': 119.54861450195312, 'learning_rate': 8.903686566899146e-08, 'rewards/chosen': -4.373269557952881, 'rewards/rejected': -9.097977638244629, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 4.72470760345459, 'logps/chosen': -602.5257568359375, 'logps/rejected': -1085.02978515625, 'logits/chosen': 0.1944747120141983, 'logits/rejected': 0.3179579973220825, 'epoch': 0.79}
 79%|███████▉  | 2970/3753 [33:08<54:20,  4.16s/it] 79%|███████▉  | 2971/3753 [33:14<1:02:32,  4.80s/it] 79%|███████▉  | 2972/3753 [33:19<1:01:36,  4.73s/it] 79%|███████▉  | 2973/3753 [33:23<58:06,  4.47s/it]   79%|███████▉  | 2974/3753 [33:28<1:00:08,  4.63s/it] 79%|███████▉  | 2975/3753 [33:31<56:28,  4.35s/it]   79%|███████▉  | 2976/3753 [33:35<53:20,  4.12s/it] 79%|███████▉  | 2977/3753 [33:39<53:57,  4.17s/it] 79%|███████▉  | 2978/3753 [33:43<51:19,  3.97s/it] 79%|███████▉  | 2979/3753 [33:49<59:02,  4.58s/it] 79%|███████▉  | 2980/3753 [33:52<55:47,  4.33s/it]                                                   {'loss': 0.2815, 'grad_norm': 117.83771514892578, 'learning_rate': 8.68784315567779e-08, 'rewards/chosen': -4.0663604736328125, 'rewards/rejected': -8.546518325805664, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.48015832901001, 'logps/chosen': -583.2938842773438, 'logps/rejected': -1036.6932373046875, 'logits/chosen': 0.0990041121840477, 'logits/rejected': 0.31408196687698364, 'epoch': 0.79}
 79%|███████▉  | 2980/3753 [33:53<55:47,  4.33s/it] 79%|███████▉  | 2981/3753 [33:56<52:55,  4.11s/it] 79%|███████▉  | 2982/3753 [34:03<1:04:40,  5.03s/it] 79%|███████▉  | 2983/3753 [34:09<1:06:21,  5.17s/it] 80%|███████▉  | 2984/3753 [34:12<1:00:04,  4.69s/it] 80%|███████▉  | 2985/3753 [34:17<1:01:31,  4.81s/it] 80%|███████▉  | 2986/3753 [34:21<58:31,  4.58s/it]   80%|███████▉  | 2987/3753 [34:25<56:17,  4.41s/it] 80%|███████▉  | 2988/3753 [34:29<53:42,  4.21s/it] 80%|███████▉  | 2989/3753 [34:37<1:06:50,  5.25s/it] 80%|███████▉  | 2990/3753 [34:41<1:03:13,  4.97s/it]                                                     {'loss': 0.3081, 'grad_norm': 96.64921569824219, 'learning_rate': 8.474276890796212e-08, 'rewards/chosen': -3.559166669845581, 'rewards/rejected': -9.09321117401123, 'rewards/accuracies': 0.875, 'rewards/margins': 5.53404426574707, 'logps/chosen': -516.5452270507812, 'logps/rejected': -1072.2835693359375, 'logits/chosen': 0.11691750586032867, 'logits/rejected': 0.2981414198875427, 'epoch': 0.8}
 80%|███████▉  | 2990/3753 [34:41<1:03:13,  4.97s/it] 80%|███████▉  | 2991/3753 [34:46<1:01:16,  4.83s/it] 80%|███████▉  | 2992/3753 [34:49<53:57,  4.25s/it]   80%|███████▉  | 2993/3753 [34:53<54:11,  4.28s/it] 80%|███████▉  | 2994/3753 [34:57<54:57,  4.34s/it] 80%|███████▉  | 2995/3753 [35:01<51:23,  4.07s/it] 80%|███████▉  | 2996/3753 [35:05<50:24,  4.00s/it] 80%|███████▉  | 2997/3753 [35:12<1:04:22,  5.11s/it] 80%|███████▉  | 2998/3753 [35:16<1:00:05,  4.78s/it] 80%|███████▉  | 2999/3753 [35:20<55:29,  4.42s/it]   80%|███████▉  | 3000/3753 [35:24<52:51,  4.21s/it]                                                   {'loss': 0.2584, 'grad_norm': 37.344425201416016, 'learning_rate': 8.26300625502803e-08, 'rewards/chosen': -3.8763644695281982, 'rewards/rejected': -9.721064567565918, 'rewards/accuracies': 0.875, 'rewards/margins': 5.844700813293457, 'logps/chosen': -548.897705078125, 'logps/rejected': -1140.969482421875, 'logits/chosen': 0.1590178906917572, 'logits/rejected': 0.3372238278388977, 'epoch': 0.8}
 80%|███████▉  | 3000/3753 [35:24<52:51,  4.21s/it]wandb: WARNING URL not available in offline run
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 80%|███████▉  | 3001/3753 [36:24<4:22:17, 20.93s/it] 80%|███████▉  | 3002/3753 [36:28<3:18:10, 15.83s/it] 80%|████████  | 3003/3753 [36:34<2:42:19, 12.99s/it] 80%|████████  | 3004/3753 [36:37<2:06:02, 10.10s/it] 80%|████████  | 3005/3753 [36:42<1:46:26,  8.54s/it] 80%|████████  | 3006/3753 [36:51<1:48:09,  8.69s/it] 80%|████████  | 3007/3753 [36:56<1:31:58,  7.40s/it] 80%|████████  | 3008/3753 [36:59<1:18:16,  6.30s/it] 80%|████████  | 3009/3753 [37:04<1:10:56,  5.72s/it] 80%|████████  | 3010/3753 [37:08<1:03:57,  5.17s/it]                                                     {'loss': 0.2527, 'grad_norm': 53.26369857788086, 'learning_rate': 8.054049532475066e-08, 'rewards/chosen': -4.054270267486572, 'rewards/rejected': -8.95396900177002, 'rewards/accuracies': 0.90625, 'rewards/margins': 4.899698257446289, 'logps/chosen': -581.0012817382812, 'logps/rejected': -1070.3515625, 'logits/chosen': 0.08607937395572662, 'logits/rejected': 0.3101975619792938, 'epoch': 0.8}
 80%|████████  | 3010/3753 [37:08<1:03:57,  5.17s/it] 80%|████████  | 3011/3753 [37:12<59:38,  4.82s/it]   80%|████████  | 3012/3753 [37:17<1:00:23,  4.89s/it] 80%|████████  | 3013/3753 [37:20<55:52,  4.53s/it]   80%|████████  | 3014/3753 [37:25<54:36,  4.43s/it] 80%|████████  | 3015/3753 [37:28<52:42,  4.28s/it] 80%|████████  | 3016/3753 [37:32<50:31,  4.11s/it] 80%|████████  | 3017/3753 [37:36<50:02,  4.08s/it] 80%|████████  | 3018/3753 [37:40<48:05,  3.93s/it] 80%|████████  | 3019/3753 [37:43<46:39,  3.81s/it] 80%|████████  | 3020/3753 [37:47<46:27,  3.80s/it]                                                   {'loss': 0.3134, 'grad_norm': 42.72947692871094, 'learning_rate': 7.847424806984982e-08, 'rewards/chosen': -3.9409401416778564, 'rewards/rejected': -8.663891792297363, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.722951889038086, 'logps/chosen': -549.4256591796875, 'logps/rejected': -1021.8548583984375, 'logits/chosen': 0.2044840157032013, 'logits/rejected': 0.3692576587200165, 'epoch': 0.8}
 80%|████████  | 3020/3753 [37:47<46:27,  3.80s/it] 80%|████████  | 3021/3753 [37:54<59:21,  4.86s/it] 81%|████████  | 3022/3753 [37:59<58:20,  4.79s/it] 81%|████████  | 3023/3753 [38:03<54:36,  4.49s/it] 81%|████████  | 3024/3753 [38:06<51:26,  4.23s/it] 81%|████████  | 3025/3753 [38:12<54:46,  4.51s/it] 81%|████████  | 3026/3753 [38:16<55:36,  4.59s/it] 81%|████████  | 3027/3753 [38:20<53:07,  4.39s/it] 81%|████████  | 3028/3753 [38:24<50:29,  4.18s/it] 81%|████████  | 3029/3753 [38:28<50:25,  4.18s/it] 81%|████████  | 3030/3753 [38:32<48:25,  4.02s/it]                                                   {'loss': 0.2426, 'grad_norm': 44.90121078491211, 'learning_rate': 7.64314996058623e-08, 'rewards/chosen': -3.9477317333221436, 'rewards/rejected': -10.959182739257812, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.01145076751709, 'logps/chosen': -552.6063842773438, 'logps/rejected': -1263.2620849609375, 'logits/chosen': 0.27270522713661194, 'logits/rejected': 0.4272363781929016, 'epoch': 0.81}
 81%|████████  | 3030/3753 [38:32<48:25,  4.02s/it] 81%|████████  | 3031/3753 [38:35<46:52,  3.89s/it] 81%|████████  | 3032/3753 [38:39<46:35,  3.88s/it] 81%|████████  | 3033/3753 [38:43<45:51,  3.82s/it] 81%|████████  | 3034/3753 [38:46<44:31,  3.72s/it] 81%|████████  | 3035/3753 [38:51<46:22,  3.88s/it] 81%|████████  | 3036/3753 [38:55<47:23,  3.97s/it] 81%|████████  | 3037/3753 [38:59<47:14,  3.96s/it] 81%|████████  | 3038/3753 [39:03<48:20,  4.06s/it] 81%|████████  | 3039/3753 [39:08<49:40,  4.17s/it] 81%|████████  | 3040/3753 [39:11<47:33,  4.00s/it]                                                   {'loss': 0.3515, 'grad_norm': 96.825927734375, 'learning_rate': 7.441242671940491e-08, 'rewards/chosen': -3.736881971359253, 'rewards/rejected': -8.633210182189941, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.896328449249268, 'logps/chosen': -535.074951171875, 'logps/rejected': -1023.6613159179688, 'logits/chosen': 0.13290801644325256, 'logits/rejected': 0.36061152815818787, 'epoch': 0.81}
 81%|████████  | 3040/3753 [39:11<47:33,  4.00s/it] 81%|████████  | 3041/3753 [39:16<50:01,  4.22s/it] 81%|████████  | 3042/3753 [39:20<49:13,  4.15s/it] 81%|████████  | 3043/3753 [39:28<1:02:33,  5.29s/it] 81%|████████  | 3044/3753 [39:33<1:02:16,  5.27s/it] 81%|████████  | 3045/3753 [39:37<57:31,  4.88s/it]   81%|████████  | 3046/3753 [39:41<54:53,  4.66s/it] 81%|████████  | 3047/3753 [39:45<51:02,  4.34s/it] 81%|████████  | 3048/3753 [39:49<50:12,  4.27s/it] 81%|████████  | 3049/3753 [39:54<51:36,  4.40s/it] 81%|████████▏ | 3050/3753 [39:58<50:46,  4.33s/it]                                                   {'loss': 0.3049, 'grad_norm': 32.476566314697266, 'learning_rate': 7.241720414812677e-08, 'rewards/chosen': -4.21254825592041, 'rewards/rejected': -10.434225082397461, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 6.221675872802734, 'logps/chosen': -585.51416015625, 'logps/rejected': -1209.266357421875, 'logits/chosen': 0.23078349232673645, 'logits/rejected': 0.4129846692085266, 'epoch': 0.81}
 81%|████████▏ | 3050/3753 [39:58<50:46,  4.33s/it] 81%|████████▏ | 3051/3753 [40:01<48:13,  4.12s/it] 81%|████████▏ | 3052/3753 [40:06<48:45,  4.17s/it] 81%|████████▏ | 3053/3753 [40:09<45:19,  3.89s/it] 81%|████████▏ | 3054/3753 [40:13<46:08,  3.96s/it] 81%|████████▏ | 3055/3753 [40:16<43:34,  3.75s/it] 81%|████████▏ | 3056/3753 [40:21<46:12,  3.98s/it] 81%|████████▏ | 3057/3753 [40:25<46:06,  3.97s/it] 81%|████████▏ | 3058/3753 [40:29<47:26,  4.10s/it] 82%|████████▏ | 3059/3753 [40:33<45:10,  3.91s/it] 82%|████████▏ | 3060/3753 [40:37<47:31,  4.12s/it]                                                   {'loss': 0.2793, 'grad_norm': 18.50642204284668, 'learning_rate': 7.044600456558717e-08, 'rewards/chosen': -3.8336341381073, 'rewards/rejected': -8.690033912658691, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.8563995361328125, 'logps/chosen': -535.3153686523438, 'logps/rejected': -1029.0968017578125, 'logits/chosen': 0.17988568544387817, 'logits/rejected': 0.3852737843990326, 'epoch': 0.82}
 82%|████████▏ | 3060/3753 [40:37<47:31,  4.12s/it] 82%|████████▏ | 3061/3753 [40:42<51:36,  4.47s/it] 82%|████████▏ | 3062/3753 [40:47<52:06,  4.53s/it] 82%|████████▏ | 3063/3753 [40:51<50:08,  4.36s/it] 82%|████████▏ | 3064/3753 [40:57<54:30,  4.75s/it] 82%|████████▏ | 3065/3753 [41:01<51:56,  4.53s/it] 82%|████████▏ | 3066/3753 [41:05<49:24,  4.32s/it] 82%|████████▏ | 3067/3753 [41:08<45:39,  3.99s/it] 82%|████████▏ | 3068/3753 [41:12<44:54,  3.93s/it] 82%|████████▏ | 3069/3753 [41:16<44:41,  3.92s/it] 82%|████████▏ | 3070/3753 [41:19<44:06,  3.87s/it]                                                   {'loss': 0.288, 'grad_norm': 105.37576293945312, 'learning_rate': 6.849899856631178e-08, 'rewards/chosen': -4.2802605628967285, 'rewards/rejected': -9.262979507446289, 'rewards/accuracies': 0.925000011920929, 'rewards/margins': 4.982719421386719, 'logps/chosen': -586.8525390625, 'logps/rejected': -1085.7869873046875, 'logits/chosen': 0.2142498940229416, 'logits/rejected': 0.45343637466430664, 'epoch': 0.82}
 82%|████████▏ | 3070/3753 [41:19<44:06,  3.87s/it] 82%|████████▏ | 3071/3753 [41:24<46:16,  4.07s/it] 82%|████████▏ | 3072/3753 [41:28<47:01,  4.14s/it] 82%|████████▏ | 3073/3753 [41:33<48:49,  4.31s/it] 82%|████████▏ | 3074/3753 [41:37<46:40,  4.12s/it] 82%|████████▏ | 3075/3753 [41:40<45:56,  4.07s/it] 82%|████████▏ | 3076/3753 [41:44<44:17,  3.93s/it] 82%|████████▏ | 3077/3753 [41:48<42:41,  3.79s/it] 82%|████████▏ | 3078/3753 [41:52<46:21,  4.12s/it] 82%|████████▏ | 3079/3753 [41:56<46:02,  4.10s/it] 82%|████████▏ | 3080/3753 [42:01<47:54,  4.27s/it]                                                   {'loss': 0.305, 'grad_norm': 47.807281494140625, 'learning_rate': 6.65763546510287e-08, 'rewards/chosen': -5.194833278656006, 'rewards/rejected': -9.95792007446289, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 4.763085842132568, 'logps/chosen': -683.5345458984375, 'logps/rejected': -1160.0263671875, 'logits/chosen': 0.26412433385849, 'logits/rejected': 0.38280659914016724, 'epoch': 0.82}
 82%|████████▏ | 3080/3753 [42:01<47:54,  4.27s/it] 82%|████████▏ | 3081/3753 [42:04<43:49,  3.91s/it] 82%|████████▏ | 3082/3753 [42:08<43:32,  3.89s/it] 82%|████████▏ | 3083/3753 [42:13<45:37,  4.09s/it] 82%|████████▏ | 3084/3753 [42:17<46:08,  4.14s/it] 82%|████████▏ | 3085/3753 [42:20<43:55,  3.95s/it] 82%|████████▏ | 3086/3753 [42:24<42:10,  3.79s/it] 82%|████████▏ | 3087/3753 [42:28<42:43,  3.85s/it] 82%|████████▏ | 3088/3753 [42:32<43:46,  3.95s/it] 82%|████████▏ | 3089/3753 [42:36<44:23,  4.01s/it] 82%|████████▏ | 3090/3753 [42:40<43:40,  3.95s/it]                                                   {'loss': 0.3409, 'grad_norm': 55.27915954589844, 'learning_rate': 6.467823921208565e-08, 'rewards/chosen': -4.681888103485107, 'rewards/rejected': -9.943452835083008, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 5.261565208435059, 'logps/chosen': -625.058349609375, 'logps/rejected': -1157.176513671875, 'logits/chosen': 0.23111319541931152, 'logits/rejected': 0.38090071082115173, 'epoch': 0.82}
 82%|████████▏ | 3090/3753 [42:40<43:40,  3.95s/it] 82%|████████▏ | 3091/3753 [42:44<42:26,  3.85s/it] 82%|████████▏ | 3092/3753 [42:48<43:00,  3.90s/it] 82%|████████▏ | 3093/3753 [42:51<43:00,  3.91s/it] 82%|████████▏ | 3094/3753 [42:55<41:11,  3.75s/it] 82%|████████▏ | 3095/3753 [42:59<40:56,  3.73s/it] 82%|████████▏ | 3096/3753 [43:02<39:53,  3.64s/it] 83%|████████▎ | 3097/3753 [43:07<44:25,  4.06s/it] 83%|████████▎ | 3098/3753 [43:14<52:48,  4.84s/it] 83%|████████▎ | 3099/3753 [43:18<50:33,  4.64s/it] 83%|████████▎ | 3100/3753 [43:22<47:54,  4.40s/it]                                                   {'loss': 0.2405, 'grad_norm': 41.964969635009766, 'learning_rate': 6.280481651905015e-08, 'rewards/chosen': -4.30230712890625, 'rewards/rejected': -11.675561904907227, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 7.373255252838135, 'logps/chosen': -585.804931640625, 'logps/rejected': -1337.640380859375, 'logits/chosen': 0.23110227286815643, 'logits/rejected': 0.4091969430446625, 'epoch': 0.83}
 83%|████████▎ | 3100/3753 [43:22<47:54,  4.40s/it] 83%|████████▎ | 3101/3753 [43:29<56:46,  5.23s/it] 83%|████████▎ | 3102/3753 [43:33<51:39,  4.76s/it] 83%|████████▎ | 3103/3753 [43:37<49:56,  4.61s/it] 83%|████████▎ | 3104/3753 [43:41<48:09,  4.45s/it] 83%|████████▎ | 3105/3753 [43:45<47:41,  4.42s/it] 83%|████████▎ | 3106/3753 [43:49<46:26,  4.31s/it] 83%|████████▎ | 3107/3753 [43:54<46:54,  4.36s/it] 83%|████████▎ | 3108/3753 [43:58<46:12,  4.30s/it] 83%|████████▎ | 3109/3753 [44:01<43:31,  4.06s/it] 83%|████████▎ | 3110/3753 [44:05<41:15,  3.85s/it]                                                   {'loss': 0.2556, 'grad_norm': 76.10709381103516, 'learning_rate': 6.095624870449289e-08, 'rewards/chosen': -4.368686199188232, 'rewards/rejected': -9.265342712402344, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 4.8966569900512695, 'logps/chosen': -620.4478759765625, 'logps/rejected': -1096.887939453125, 'logits/chosen': 0.22211018204689026, 'logits/rejected': 0.4684656262397766, 'epoch': 0.83}
 83%|████████▎ | 3110/3753 [44:05<41:15,  3.85s/it] 83%|████████▎ | 3111/3753 [44:09<42:18,  3.95s/it] 83%|████████▎ | 3112/3753 [44:12<40:27,  3.79s/it] 83%|████████▎ | 3113/3753 [44:17<41:56,  3.93s/it] 83%|████████▎ | 3114/3753 [44:21<42:55,  4.03s/it] 83%|████████▎ | 3115/3753 [44:25<42:47,  4.02s/it] 83%|████████▎ | 3116/3753 [44:29<42:22,  3.99s/it] 83%|████████▎ | 3117/3753 [44:33<44:27,  4.19s/it] 83%|████████▎ | 3118/3753 [44:37<42:36,  4.03s/it] 83%|████████▎ | 3119/3753 [44:42<43:53,  4.15s/it] 83%|████████▎ | 3120/3753 [44:46<46:09,  4.38s/it]                                                   {'loss': 0.2973, 'grad_norm': 92.0125961303711, 'learning_rate': 5.9132695749956185e-08, 'rewards/chosen': -4.447348117828369, 'rewards/rejected': -10.100539207458496, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 5.653191089630127, 'logps/chosen': -598.6524658203125, 'logps/rejected': -1170.0848388671875, 'logits/chosen': 0.2460578978061676, 'logits/rejected': 0.389926552772522, 'epoch': 0.83}
 83%|████████▎ | 3120/3753 [44:47<46:09,  4.38s/it] 83%|████████▎ | 3121/3753 [44:50<45:03,  4.28s/it] 83%|████████▎ | 3122/3753 [44:55<46:23,  4.41s/it] 83%|████████▎ | 3123/3753 [44:59<43:25,  4.14s/it] 83%|████████▎ | 3124/3753 [45:03<44:25,  4.24s/it] 83%|████████▎ | 3125/3753 [45:07<41:34,  3.97s/it] 83%|████████▎ | 3126/3753 [45:10<40:49,  3.91s/it] 83%|████████▎ | 3127/3753 [45:14<40:50,  3.91s/it] 83%|████████▎ | 3128/3753 [45:18<41:13,  3.96s/it] 83%|████████▎ | 3129/3753 [45:22<39:48,  3.83s/it] 83%|████████▎ | 3130/3753 [45:26<40:00,  3.85s/it]                                                   {'loss': 0.3774, 'grad_norm': 122.38065338134766, 'learning_rate': 5.733431547210847e-08, 'rewards/chosen': -4.17434549331665, 'rewards/rejected': -8.721372604370117, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.547026634216309, 'logps/chosen': -573.626708984375, 'logps/rejected': -1031.9537353515625, 'logits/chosen': 0.26421576738357544, 'logits/rejected': 0.45048147439956665, 'epoch': 0.83}
 83%|████████▎ | 3130/3753 [45:26<40:00,  3.85s/it] 83%|████████▎ | 3131/3753 [45:30<39:48,  3.84s/it] 83%|████████▎ | 3132/3753 [45:33<39:58,  3.86s/it] 83%|████████▎ | 3133/3753 [45:37<38:59,  3.77s/it] 84%|████████▎ | 3134/3753 [45:41<39:56,  3.87s/it] 84%|████████▎ | 3135/3753 [45:45<40:31,  3.93s/it] 84%|████████▎ | 3136/3753 [45:49<39:38,  3.85s/it] 84%|████████▎ | 3137/3753 [45:53<39:35,  3.86s/it] 84%|████████▎ | 3138/3753 [45:57<42:01,  4.10s/it] 84%|████████▎ | 3139/3753 [46:01<40:19,  3.94s/it] 84%|████████▎ | 3140/3753 [46:05<41:20,  4.05s/it]                                                   {'loss': 0.2301, 'grad_norm': 20.910112380981445, 'learning_rate': 5.556126350908654e-08, 'rewards/chosen': -4.324463844299316, 'rewards/rejected': -9.741517066955566, 'rewards/accuracies': 0.9312499761581421, 'rewards/margins': 5.417052745819092, 'logps/chosen': -592.6682739257812, 'logps/rejected': -1138.108642578125, 'logits/chosen': 0.26540711522102356, 'logits/rejected': 0.43774908781051636, 'epoch': 0.84}
 84%|████████▎ | 3140/3753 [46:05<41:20,  4.05s/it] 84%|████████▎ | 3141/3753 [46:10<43:16,  4.24s/it] 84%|████████▎ | 3142/3753 [46:13<40:43,  4.00s/it] 84%|████████▎ | 3143/3753 [46:17<40:56,  4.03s/it] 84%|████████▍ | 3144/3753 [46:21<39:29,  3.89s/it] 84%|████████▍ | 3145/3753 [46:25<38:16,  3.78s/it] 84%|████████▍ | 3146/3753 [46:30<41:58,  4.15s/it] 84%|████████▍ | 3147/3753 [46:33<39:25,  3.90s/it] 84%|████████▍ | 3148/3753 [46:37<39:51,  3.95s/it] 84%|████████▍ | 3149/3753 [46:41<40:08,  3.99s/it] 84%|████████▍ | 3150/3753 [46:45<41:05,  4.09s/it]                                                   {'loss': 0.2311, 'grad_norm': 44.65666961669922, 'learning_rate': 5.3813693307026295e-08, 'rewards/chosen': -4.165610313415527, 'rewards/rejected': -9.310149192810059, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 5.144539833068848, 'logps/chosen': -574.237548828125, 'logps/rejected': -1097.4954833984375, 'logits/chosen': 0.2691401541233063, 'logits/rejected': 0.45647725462913513, 'epoch': 0.84}
 84%|████████▍ | 3150/3753 [46:45<41:05,  4.09s/it] 84%|████████▍ | 3151/3753 [46:50<41:34,  4.14s/it] 84%|████████▍ | 3152/3753 [46:53<40:15,  4.02s/it] 84%|████████▍ | 3153/3753 [46:57<39:21,  3.94s/it] 84%|████████▍ | 3154/3753 [47:00<36:58,  3.70s/it] 84%|████████▍ | 3155/3753 [47:04<37:25,  3.75s/it] 84%|████████▍ | 3156/3753 [47:08<36:36,  3.68s/it] 84%|████████▍ | 3157/3753 [47:11<36:34,  3.68s/it] 84%|████████▍ | 3158/3753 [47:15<37:14,  3.76s/it] 84%|████████▍ | 3159/3753 [47:19<36:20,  3.67s/it] 84%|████████▍ | 3160/3753 [47:24<42:20,  4.28s/it]                                                   {'loss': 0.3814, 'grad_norm': 423.08367919921875, 'learning_rate': 5.209175610678215e-08, 'rewards/chosen': -4.630654811859131, 'rewards/rejected': -9.116532325744629, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 4.485876560211182, 'logps/chosen': -627.85107421875, 'logps/rejected': -1079.8485107421875, 'logits/chosen': 0.1960332691669464, 'logits/rejected': 0.4933377206325531, 'epoch': 0.84}
 84%|████████▍ | 3160/3753 [47:25<42:20,  4.28s/it] 84%|████████▍ | 3161/3753 [47:28<40:51,  4.14s/it] 84%|████████▍ | 3162/3753 [47:32<40:34,  4.12s/it] 84%|████████▍ | 3163/3753 [47:37<40:46,  4.15s/it] 84%|████████▍ | 3164/3753 [47:41<41:15,  4.20s/it] 84%|████████▍ | 3165/3753 [47:44<38:40,  3.95s/it] 84%|████████▍ | 3166/3753 [47:48<39:08,  4.00s/it] 84%|████████▍ | 3167/3753 [47:52<39:15,  4.02s/it] 84%|████████▍ | 3168/3753 [47:56<37:29,  3.84s/it] 84%|████████▍ | 3169/3753 [47:59<36:46,  3.78s/it] 84%|████████▍ | 3170/3753 [48:03<36:03,  3.71s/it]                                                   {'loss': 0.3322, 'grad_norm': 64.932861328125, 'learning_rate': 5.039560093083896e-08, 'rewards/chosen': -4.494247913360596, 'rewards/rejected': -9.857389450073242, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 5.363142013549805, 'logps/chosen': -602.2888793945312, 'logps/rejected': -1143.597900390625, 'logits/chosen': 0.22539487481117249, 'logits/rejected': 0.42730712890625, 'epoch': 0.84}
 84%|████████▍ | 3170/3753 [48:03<36:03,  3.71s/it] 84%|████████▍ | 3171/3753 [48:07<37:56,  3.91s/it] 85%|████████▍ | 3172/3753 [48:12<39:35,  4.09s/it] 85%|████████▍ | 3173/3753 [48:15<37:31,  3.88s/it] 85%|████████▍ | 3174/3753 [48:19<36:52,  3.82s/it] 85%|████████▍ | 3175/3753 [48:22<35:15,  3.66s/it] 85%|████████▍ | 3176/3753 [48:26<36:35,  3.81s/it] 85%|████████▍ | 3177/3753 [48:29<33:19,  3.47s/it] 85%|████████▍ | 3178/3753 [48:33<33:49,  3.53s/it] 85%|████████▍ | 3179/3753 [48:40<43:48,  4.58s/it] 85%|████████▍ | 3180/3753 [48:45<45:19,  4.75s/it]                                                   {'loss': 0.3111, 'grad_norm': 17.578378677368164, 'learning_rate': 4.872537457041472e-08, 'rewards/chosen': -4.417900085449219, 'rewards/rejected': -10.88308048248291, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 6.465180397033691, 'logps/chosen': -591.4072265625, 'logps/rejected': -1236.1561279296875, 'logits/chosen': 0.22584481537342072, 'logits/rejected': 0.40332603454589844, 'epoch': 0.85}
 85%|████████▍ | 3180/3753 [48:45<45:19,  4.75s/it] 85%|████████▍ | 3181/3753 [48:49<43:46,  4.59s/it] 85%|████████▍ | 3182/3753 [48:53<41:58,  4.41s/it] 85%|████████▍ | 3183/3753 [48:57<41:07,  4.33s/it] 85%|████████▍ | 3184/3753 [49:01<39:37,  4.18s/it] 85%|████████▍ | 3185/3753 [49:08<46:23,  4.90s/it] 85%|████████▍ | 3186/3753 [49:12<44:01,  4.66s/it] 85%|████████▍ | 3187/3753 [49:16<42:33,  4.51s/it] 85%|████████▍ | 3188/3753 [49:21<44:23,  4.71s/it] 85%|████████▍ | 3189/3753 [49:25<41:41,  4.44s/it] 85%|████████▍ | 3190/3753 [49:29<40:01,  4.27s/it]                                                   {'loss': 0.3282, 'grad_norm': 22.716482162475586, 'learning_rate': 4.70812215727568e-08, 'rewards/chosen': -4.453763008117676, 'rewards/rejected': -8.994653701782227, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.540891170501709, 'logps/chosen': -624.5094604492188, 'logps/rejected': -1069.460693359375, 'logits/chosen': 0.18750575184822083, 'logits/rejected': 0.41609257459640503, 'epoch': 0.85}
 85%|████████▍ | 3190/3753 [49:29<40:01,  4.27s/it] 85%|████████▌ | 3191/3753 [49:32<37:38,  4.02s/it] 85%|████████▌ | 3192/3753 [49:36<37:32,  4.02s/it] 85%|████████▌ | 3193/3753 [49:40<36:23,  3.90s/it] 85%|████████▌ | 3194/3753 [49:44<37:08,  3.99s/it] 85%|████████▌ | 3195/3753 [49:48<35:43,  3.84s/it] 85%|████████▌ | 3196/3753 [49:51<34:59,  3.77s/it] 85%|████████▌ | 3197/3753 [49:55<35:03,  3.78s/it] 85%|████████▌ | 3198/3753 [49:59<36:26,  3.94s/it] 85%|████████▌ | 3199/3753 [50:03<36:44,  3.98s/it] 85%|████████▌ | 3200/3753 [50:07<35:47,  3.88s/it]                                                   {'loss': 0.3685, 'grad_norm': 64.30735778808594, 'learning_rate': 4.546328422863211e-08, 'rewards/chosen': -4.335949897766113, 'rewards/rejected': -8.924985885620117, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 4.589035987854004, 'logps/chosen': -587.2887573242188, 'logps/rejected': -1051.459228515625, 'logits/chosen': 0.1947326958179474, 'logits/rejected': 0.40951624512672424, 'epoch': 0.85}
 85%|████████▌ | 3200/3753 [50:07<35:47,  3.88s/it] 85%|████████▌ | 3201/3753 [50:10<34:29,  3.75s/it] 85%|████████▌ | 3202/3753 [50:14<34:50,  3.79s/it] 85%|████████▌ | 3203/3753 [50:18<35:17,  3.85s/it] 85%|████████▌ | 3204/3753 [50:22<35:09,  3.84s/it] 85%|████████▌ | 3205/3753 [50:30<45:03,  4.93s/it] 85%|████████▌ | 3206/3753 [50:34<42:41,  4.68s/it] 85%|████████▌ | 3207/3753 [50:38<40:16,  4.43s/it] 85%|████████▌ | 3208/3753 [50:42<39:17,  4.33s/it] 86%|████████▌ | 3209/3753 [50:46<38:45,  4.28s/it] 86%|████████▌ | 3210/3753 [50:50<39:16,  4.34s/it]                                                   {'loss': 0.2956, 'grad_norm': 32.62055969238281, 'learning_rate': 4.3871702560013234e-08, 'rewards/chosen': -4.019354343414307, 'rewards/rejected': -9.0529203414917, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 5.033566474914551, 'logps/chosen': -570.440185546875, 'logps/rejected': -1076.564697265625, 'logits/chosen': 0.1533184051513672, 'logits/rejected': 0.3926095962524414, 'epoch': 0.86}
 86%|████████▌ | 3210/3753 [50:50<39:16,  4.34s/it] 86%|████████▌ | 3211/3753 [50:55<39:36,  4.39s/it] 86%|████████▌ | 3212/3753 [51:01<45:31,  5.05s/it] 86%|████████▌ | 3213/3753 [51:05<42:52,  4.76s/it] 86%|████████▌ | 3214/3753 [51:09<39:48,  4.43s/it] 86%|████████▌ | 3215/3753 [51:16<46:20,  5.17s/it] 86%|████████▌ | 3216/3753 [51:22<47:55,  5.35s/it] 86%|████████▌ | 3217/3753 [51:28<49:12,  5.51s/it] 86%|████████▌ | 3218/3753 [51:32<45:52,  5.14s/it] 86%|████████▌ | 3219/3753 [51:36<42:36,  4.79s/it] 86%|████████▌ | 3220/3753 [51:39<38:29,  4.33s/it]                                                   {'loss': 0.4275, 'grad_norm': 184.37139892578125, 'learning_rate': 4.230661430796006e-08, 'rewards/chosen': -4.166487693786621, 'rewards/rejected': -9.903663635253906, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 5.737176418304443, 'logps/chosen': -585.3199462890625, 'logps/rejected': -1167.7012939453125, 'logits/chosen': 0.14550462365150452, 'logits/rejected': 0.3447025418281555, 'epoch': 0.86}
 86%|████████▌ | 3220/3753 [51:39<38:29,  4.33s/it] 86%|████████▌ | 3221/3753 [51:43<37:11,  4.19s/it] 86%|████████▌ | 3222/3753 [51:47<35:12,  3.98s/it] 86%|████████▌ | 3223/3753 [51:52<40:11,  4.55s/it] 86%|████████▌ | 3224/3753 [51:57<38:57,  4.42s/it] 86%|████████▌ | 3225/3753 [52:00<36:58,  4.20s/it] 86%|████████▌ | 3226/3753 [52:05<37:24,  4.26s/it] 86%|████████▌ | 3227/3753 [52:08<34:25,  3.93s/it] 86%|████████▌ | 3228/3753 [52:11<33:03,  3.78s/it] 86%|████████▌ | 3229/3753 [52:16<34:45,  3.98s/it] 86%|████████▌ | 3230/3753 [52:20<34:31,  3.96s/it]                                                   {'loss': 0.2959, 'grad_norm': 73.35552978515625, 'learning_rate': 4.0768154920699265e-08, 'rewards/chosen': -3.8137214183807373, 'rewards/rejected': -8.491771697998047, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.6780500411987305, 'logps/chosen': -536.5955810546875, 'logps/rejected': -1008.8560791015625, 'logits/chosen': 0.14653782546520233, 'logits/rejected': 0.3973630666732788, 'epoch': 0.86}
 86%|████████▌ | 3230/3753 [52:20<34:31,  3.96s/it] 86%|████████▌ | 3231/3753 [52:24<35:33,  4.09s/it] 86%|████████▌ | 3232/3753 [52:28<34:40,  3.99s/it] 86%|████████▌ | 3233/3753 [52:32<36:13,  4.18s/it] 86%|████████▌ | 3234/3753 [52:36<34:35,  4.00s/it] 86%|████████▌ | 3235/3753 [52:39<33:07,  3.84s/it] 86%|████████▌ | 3236/3753 [52:44<34:12,  3.97s/it] 86%|████████▋ | 3237/3753 [52:47<32:27,  3.77s/it] 86%|████████▋ | 3238/3753 [52:51<33:34,  3.91s/it] 86%|████████▋ | 3239/3753 [52:56<34:33,  4.03s/it] 86%|████████▋ | 3240/3753 [53:00<36:31,  4.27s/it]                                                   {'loss': 0.2647, 'grad_norm': 65.72175598144531, 'learning_rate': 3.925645754190203e-08, 'rewards/chosen': -4.401297569274902, 'rewards/rejected': -9.539243698120117, 'rewards/accuracies': 0.918749988079071, 'rewards/margins': 5.137948036193848, 'logps/chosen': -609.034423828125, 'logps/rejected': -1139.517578125, 'logits/chosen': 0.17086702585220337, 'logits/rejected': 0.2789406180381775, 'epoch': 0.86}
 86%|████████▋ | 3240/3753 [53:00<36:31,  4.27s/it] 86%|████████▋ | 3241/3753 [53:05<38:36,  4.53s/it] 86%|████████▋ | 3242/3753 [53:13<45:21,  5.33s/it] 86%|████████▋ | 3243/3753 [53:20<51:36,  6.07s/it] 86%|████████▋ | 3244/3753 [53:25<47:25,  5.59s/it] 86%|████████▋ | 3245/3753 [53:29<43:45,  5.17s/it] 86%|████████▋ | 3246/3753 [53:33<40:53,  4.84s/it] 87%|████████▋ | 3247/3753 [53:37<38:03,  4.51s/it] 87%|████████▋ | 3248/3753 [53:41<37:29,  4.45s/it] 87%|████████▋ | 3249/3753 [53:45<36:43,  4.37s/it] 87%|████████▋ | 3250/3753 [53:50<36:54,  4.40s/it]                                                   {'loss': 0.1537, 'grad_norm': 29.393558502197266, 'learning_rate': 3.777165299916175e-08, 'rewards/chosen': -4.130393028259277, 'rewards/rejected': -12.355450630187988, 'rewards/accuracies': 0.9624999761581421, 'rewards/margins': 8.225057601928711, 'logps/chosen': -570.2947387695312, 'logps/rejected': -1403.540771484375, 'logits/chosen': 0.23533912003040314, 'logits/rejected': 0.4480903148651123, 'epoch': 0.87}
 87%|████████▋ | 3250/3753 [53:50<36:54,  4.40s/it] 87%|████████▋ | 3251/3753 [53:55<39:23,  4.71s/it] 87%|████████▋ | 3252/3753 [53:59<36:41,  4.39s/it] 87%|████████▋ | 3253/3753 [54:03<36:45,  4.41s/it] 87%|████████▋ | 3254/3753 [54:07<34:47,  4.18s/it] 87%|████████▋ | 3255/3753 [54:11<34:03,  4.10s/it] 87%|████████▋ | 3256/3753 [54:16<35:49,  4.33s/it] 87%|████████▋ | 3257/3753 [54:19<33:55,  4.10s/it] 87%|████████▋ | 3258/3753 [54:24<33:44,  4.09s/it] 87%|████████▋ | 3259/3753 [54:28<33:53,  4.12s/it] 87%|████████▋ | 3260/3753 [54:32<34:45,  4.23s/it]                                                   {'loss': 0.4022, 'grad_norm': 53.649105072021484, 'learning_rate': 3.6313869792671205e-08, 'rewards/chosen': -4.389103889465332, 'rewards/rejected': -8.938919067382812, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.549813747406006, 'logps/chosen': -593.4869384765625, 'logps/rejected': -1062.354248046875, 'logits/chosen': 0.20897245407104492, 'logits/rejected': 0.4128318727016449, 'epoch': 0.87}
 87%|████████▋ | 3260/3753 [54:32<34:45,  4.23s/it] 87%|████████▋ | 3261/3753 [54:36<33:44,  4.11s/it] 87%|████████▋ | 3262/3753 [54:40<34:21,  4.20s/it] 87%|████████▋ | 3263/3753 [54:45<35:34,  4.36s/it] 87%|████████▋ | 3264/3753 [54:50<36:12,  4.44s/it] 87%|████████▋ | 3265/3753 [54:54<34:58,  4.30s/it] 87%|████████▋ | 3266/3753 [54:58<34:38,  4.27s/it] 87%|████████▋ | 3267/3753 [55:03<36:46,  4.54s/it] 87%|████████▋ | 3268/3753 [55:07<36:14,  4.48s/it] 87%|████████▋ | 3269/3753 [55:12<35:08,  4.36s/it] 87%|████████▋ | 3270/3753 [55:15<33:06,  4.11s/it]                                                   {'loss': 0.2576, 'grad_norm': 34.82014083862305, 'learning_rate': 3.488323408410218e-08, 'rewards/chosen': -3.867870807647705, 'rewards/rejected': -9.263673782348633, 'rewards/accuracies': 0.875, 'rewards/margins': 5.395804405212402, 'logps/chosen': -558.7026977539062, 'logps/rejected': -1125.9385986328125, 'logits/chosen': 0.17752249538898468, 'logits/rejected': 0.3373888432979584, 'epoch': 0.87}
 87%|████████▋ | 3270/3753 [55:15<33:06,  4.11s/it] 87%|████████▋ | 3271/3753 [55:20<34:02,  4.24s/it] 87%|████████▋ | 3272/3753 [55:24<33:24,  4.17s/it] 87%|████████▋ | 3273/3753 [55:32<42:59,  5.37s/it] 87%|████████▋ | 3274/3753 [55:36<40:01,  5.01s/it] 87%|████████▋ | 3275/3753 [55:40<37:38,  4.73s/it] 87%|████████▋ | 3276/3753 [55:44<35:10,  4.43s/it] 87%|████████▋ | 3277/3753 [55:48<33:57,  4.28s/it] 87%|████████▋ | 3278/3753 [55:52<32:44,  4.13s/it] 87%|████████▋ | 3279/3753 [55:56<32:54,  4.17s/it] 87%|████████▋ | 3280/3753 [56:00<33:33,  4.26s/it]                                                   {'loss': 0.274, 'grad_norm': 81.83012390136719, 'learning_rate': 3.347986968568659e-08, 'rewards/chosen': -3.7328484058380127, 'rewards/rejected': -8.841043472290039, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 5.108195781707764, 'logps/chosen': -539.0723876953125, 'logps/rejected': -1052.9534912109375, 'logits/chosen': 0.15234436094760895, 'logits/rejected': 0.3973923921585083, 'epoch': 0.87}
 87%|████████▋ | 3280/3753 [56:00<33:33,  4.26s/it] 87%|████████▋ | 3281/3753 [56:04<32:49,  4.17s/it] 87%|████████▋ | 3282/3753 [56:08<31:59,  4.07s/it] 87%|████████▋ | 3283/3753 [56:12<31:48,  4.06s/it] 88%|████████▊ | 3284/3753 [56:19<39:03,  5.00s/it] 88%|████████▊ | 3285/3753 [56:24<38:13,  4.90s/it] 88%|████████▊ | 3286/3753 [56:28<36:09,  4.65s/it] 88%|████████▊ | 3287/3753 [56:32<34:38,  4.46s/it] 88%|████████▊ | 3288/3753 [56:38<37:06,  4.79s/it] 88%|████████▊ | 3289/3753 [56:44<41:37,  5.38s/it] 88%|████████▊ | 3290/3753 [56:48<38:03,  4.93s/it]                                                   {'loss': 0.3177, 'grad_norm': 43.57828903198242, 'learning_rate': 3.21038980495016e-08, 'rewards/chosen': -4.577427864074707, 'rewards/rejected': -11.138275146484375, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 6.560847282409668, 'logps/chosen': -616.0267333984375, 'logps/rejected': -1271.798583984375, 'logits/chosen': 0.1748749017715454, 'logits/rejected': 0.4040384888648987, 'epoch': 0.88}
 88%|████████▊ | 3290/3753 [56:48<38:03,  4.93s/it] 88%|████████▊ | 3291/3753 [56:52<36:14,  4.71s/it] 88%|████████▊ | 3292/3753 [56:56<33:53,  4.41s/it] 88%|████████▊ | 3293/3753 [57:00<32:46,  4.28s/it] 88%|████████▊ | 3294/3753 [57:05<33:50,  4.42s/it] 88%|████████▊ | 3295/3753 [57:10<36:18,  4.76s/it] 88%|████████▊ | 3296/3753 [57:14<34:13,  4.49s/it] 88%|████████▊ | 3297/3753 [57:18<32:58,  4.34s/it] 88%|████████▊ | 3298/3753 [57:27<42:34,  5.61s/it] 88%|████████▊ | 3299/3753 [57:31<40:03,  5.29s/it] 88%|████████▊ | 3300/3753 [57:36<37:32,  4.97s/it]                                                   {'loss': 0.3592, 'grad_norm': 18.27130699157715, 'learning_rate': 3.0755438256958714e-08, 'rewards/chosen': -4.0807390213012695, 'rewards/rejected': -9.185641288757324, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 5.104902744293213, 'logps/chosen': -569.1153564453125, 'logps/rejected': -1082.306884765625, 'logits/chosen': 0.23699907958507538, 'logits/rejected': 0.41860803961753845, 'epoch': 0.88}
 88%|████████▊ | 3300/3753 [57:36<37:32,  4.97s/it] 88%|████████▊ | 3301/3753 [57:39<34:53,  4.63s/it] 88%|████████▊ | 3302/3753 [57:43<32:43,  4.35s/it] 88%|████████▊ | 3303/3753 [57:47<31:02,  4.14s/it] 88%|████████▊ | 3304/3753 [57:51<31:59,  4.27s/it] 88%|████████▊ | 3305/3753 [57:55<30:32,  4.09s/it] 88%|████████▊ | 3306/3753 [58:01<34:14,  4.60s/it] 88%|████████▊ | 3307/3753 [58:04<31:18,  4.21s/it] 88%|████████▊ | 3308/3753 [58:09<31:57,  4.31s/it] 88%|████████▊ | 3309/3753 [58:13<31:43,  4.29s/it] 88%|████████▊ | 3310/3753 [58:17<32:14,  4.37s/it]                                                   {'loss': 0.3444, 'grad_norm': 45.71970748901367, 'learning_rate': 2.9434607008497847e-08, 'rewards/chosen': -4.03808069229126, 'rewards/rejected': -8.482260704040527, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 4.444180488586426, 'logps/chosen': -574.7522583007812, 'logps/rejected': -1022.13232421875, 'logits/chosen': 0.1770753413438797, 'logits/rejected': 0.37921035289764404, 'epoch': 0.88}
 88%|████████▊ | 3310/3753 [58:18<32:14,  4.37s/it] 88%|████████▊ | 3311/3753 [58:22<33:42,  4.57s/it] 88%|████████▊ | 3312/3753 [58:27<32:41,  4.45s/it] 88%|████████▊ | 3313/3753 [58:31<32:39,  4.45s/it] 88%|████████▊ | 3314/3753 [58:35<31:49,  4.35s/it] 88%|████████▊ | 3315/3753 [58:40<33:28,  4.58s/it] 88%|████████▊ | 3316/3753 [58:44<31:14,  4.29s/it] 88%|████████▊ | 3317/3753 [58:47<29:17,  4.03s/it] 88%|████████▊ | 3318/3753 [58:52<30:51,  4.26s/it] 88%|████████▊ | 3319/3753 [58:56<30:14,  4.18s/it] 88%|████████▊ | 3320/3753 [59:00<29:39,  4.11s/it]                                                   {'loss': 0.2848, 'grad_norm': 37.603328704833984, 'learning_rate': 2.814151861348788e-08, 'rewards/chosen': -4.670327186584473, 'rewards/rejected': -9.392184257507324, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 4.721856117248535, 'logps/chosen': -643.3468017578125, 'logps/rejected': -1121.3809814453125, 'logits/chosen': 0.2064155638217926, 'logits/rejected': 0.4827544689178467, 'epoch': 0.88}
 88%|████████▊ | 3320/3753 [59:00<29:39,  4.11s/it] 88%|████████▊ | 3321/3753 [59:04<28:47,  4.00s/it] 89%|████████▊ | 3322/3753 [59:09<30:24,  4.23s/it] 89%|████████▊ | 3323/3753 [59:13<30:42,  4.28s/it] 89%|████████▊ | 3324/3753 [59:18<32:07,  4.49s/it] 89%|████████▊ | 3325/3753 [59:23<32:38,  4.57s/it] 89%|████████▊ | 3326/3753 [59:27<31:45,  4.46s/it] 89%|████████▊ | 3327/3753 [59:31<30:59,  4.37s/it] 89%|████████▊ | 3328/3753 [59:36<31:05,  4.39s/it] 89%|████████▊ | 3329/3753 [59:39<28:36,  4.05s/it] 89%|████████▊ | 3330/3753 [59:42<27:06,  3.85s/it]                                                   {'loss': 0.4525, 'grad_norm': 40.649200439453125, 'learning_rate': 2.6876284980333874e-08, 'rewards/chosen': -4.441287040710449, 'rewards/rejected': -9.864246368408203, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 5.422959804534912, 'logps/chosen': -611.5955200195312, 'logps/rejected': -1160.256103515625, 'logits/chosen': 0.11783695220947266, 'logits/rejected': 0.341644823551178, 'epoch': 0.89}
 89%|████████▊ | 3330/3753 [59:42<27:06,  3.85s/it] 89%|████████▉ | 3331/3753 [59:46<26:40,  3.79s/it] 89%|████████▉ | 3332/3753 [59:50<26:20,  3.75s/it] 89%|████████▉ | 3333/3753 [59:52<24:34,  3.51s/it] 89%|████████▉ | 3334/3753 [1:00:01<34:35,  4.95s/it] 89%|████████▉ | 3335/3753 [1:00:05<32:16,  4.63s/it] 89%|████████▉ | 3336/3753 [1:00:09<30:38,  4.41s/it] 89%|████████▉ | 3337/3753 [1:00:13<29:44,  4.29s/it] 89%|████████▉ | 3338/3753 [1:00:16<28:48,  4.16s/it] 89%|████████▉ | 3339/3753 [1:00:20<27:13,  3.95s/it] 89%|████████▉ | 3340/3753 [1:00:23<25:53,  3.76s/it]                                                     {'loss': 0.3674, 'grad_norm': 80.9441146850586, 'learning_rate': 2.563901560679218e-08, 'rewards/chosen': -3.866288423538208, 'rewards/rejected': -9.556941032409668, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 5.690653324127197, 'logps/chosen': -544.6990966796875, 'logps/rejected': -1113.4378662109375, 'logits/chosen': 0.1579527109861374, 'logits/rejected': 0.45921021699905396, 'epoch': 0.89}
 89%|████████▉ | 3340/3753 [1:00:23<25:53,  3.76s/it] 89%|████████▉ | 3341/3753 [1:00:27<25:55,  3.78s/it] 89%|████████▉ | 3342/3753 [1:00:30<25:10,  3.68s/it] 89%|████████▉ | 3343/3753 [1:00:35<26:39,  3.90s/it] 89%|████████▉ | 3344/3753 [1:00:38<25:45,  3.78s/it] 89%|████████▉ | 3345/3753 [1:00:42<25:57,  3.82s/it] 89%|████████▉ | 3346/3753 [1:00:46<25:02,  3.69s/it] 89%|████████▉ | 3347/3753 [1:00:49<25:00,  3.70s/it] 89%|████████▉ | 3348/3753 [1:00:57<33:00,  4.89s/it] 89%|████████▉ | 3349/3753 [1:01:01<30:43,  4.56s/it] 89%|████████▉ | 3350/3753 [1:01:04<28:15,  4.21s/it]                                                     {'loss': 0.2932, 'grad_norm': 50.5410270690918, 'learning_rate': 2.4429817570493762e-08, 'rewards/chosen': -3.9646506309509277, 'rewards/rejected': -8.548020362854004, 'rewards/accuracies': 0.90625, 'rewards/margins': 4.583369255065918, 'logps/chosen': -547.8365478515625, 'logps/rejected': -1012.5216674804688, 'logits/chosen': 0.16324594616889954, 'logits/rejected': 0.4050360321998596, 'epoch': 0.89}
 89%|████████▉ | 3350/3753 [1:01:04<28:15,  4.21s/it] 89%|████████▉ | 3351/3753 [1:01:08<27:11,  4.06s/it] 89%|████████▉ | 3352/3753 [1:01:12<27:17,  4.08s/it] 89%|████████▉ | 3353/3753 [1:01:17<28:54,  4.34s/it] 89%|████████▉ | 3354/3753 [1:01:22<29:35,  4.45s/it] 89%|████████▉ | 3355/3753 [1:01:26<28:21,  4.28s/it] 89%|████████▉ | 3356/3753 [1:01:29<26:41,  4.03s/it] 89%|████████▉ | 3357/3753 [1:01:34<27:24,  4.15s/it] 89%|████████▉ | 3358/3753 [1:01:39<29:13,  4.44s/it] 90%|████████▉ | 3359/3753 [1:01:46<34:16,  5.22s/it] 90%|████████▉ | 3360/3753 [1:01:54<39:35,  6.05s/it]                                                     {'loss': 0.2798, 'grad_norm': 16.906766891479492, 'learning_rate': 2.3248795519677923e-08, 'rewards/chosen': -3.4850306510925293, 'rewards/rejected': -9.659067153930664, 'rewards/accuracies': 0.875, 'rewards/margins': 6.174036979675293, 'logps/chosen': -523.6001586914062, 'logps/rejected': -1157.683837890625, 'logits/chosen': 0.11742069572210312, 'logits/rejected': 0.35044971108436584, 'epoch': 0.9}
 90%|████████▉ | 3360/3753 [1:01:54<39:35,  6.05s/it] 90%|████████▉ | 3361/3753 [1:01:57<35:13,  5.39s/it] 90%|████████▉ | 3362/3753 [1:02:05<39:32,  6.07s/it] 90%|████████▉ | 3363/3753 [1:02:09<35:26,  5.45s/it] 90%|████████▉ | 3364/3753 [1:02:13<32:19,  4.99s/it] 90%|████████▉ | 3365/3753 [1:02:17<30:59,  4.79s/it] 90%|████████▉ | 3366/3753 [1:02:22<30:09,  4.68s/it] 90%|████████▉ | 3367/3753 [1:02:25<28:07,  4.37s/it] 90%|████████▉ | 3368/3753 [1:02:29<26:57,  4.20s/it] 90%|████████▉ | 3369/3753 [1:02:33<25:17,  3.95s/it] 90%|████████▉ | 3370/3753 [1:02:40<32:04,  5.02s/it]                                                     {'loss': 0.2678, 'grad_norm': 56.29634094238281, 'learning_rate': 2.2096051664135185e-08, 'rewards/chosen': -4.778468132019043, 'rewards/rejected': -9.713472366333008, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.935003757476807, 'logps/chosen': -644.8765869140625, 'logps/rejected': -1144.58935546875, 'logits/chosen': 0.1893640160560608, 'logits/rejected': 0.3744935095310211, 'epoch': 0.9}
 90%|████████▉ | 3370/3753 [1:02:40<32:04,  5.02s/it] 90%|████████▉ | 3371/3753 [1:02:45<30:47,  4.84s/it] 90%|████████▉ | 3372/3753 [1:02:48<28:08,  4.43s/it] 90%|████████▉ | 3373/3753 [1:02:51<25:47,  4.07s/it] 90%|████████▉ | 3374/3753 [1:02:56<27:04,  4.29s/it] 90%|████████▉ | 3375/3753 [1:03:00<26:19,  4.18s/it] 90%|████████▉ | 3376/3753 [1:03:03<24:13,  3.86s/it] 90%|████████▉ | 3377/3753 [1:03:08<25:12,  4.02s/it] 90%|█████████ | 3378/3753 [1:03:12<26:21,  4.22s/it] 90%|█████████ | 3379/3753 [1:03:16<24:52,  3.99s/it] 90%|█████████ | 3380/3753 [1:03:21<26:36,  4.28s/it]                                                     {'loss': 0.3443, 'grad_norm': 132.3107452392578, 'learning_rate': 2.0971685766361923e-08, 'rewards/chosen': -3.970196485519409, 'rewards/rejected': -8.98786449432373, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 5.017667293548584, 'logps/chosen': -558.0989379882812, 'logps/rejected': -1067.50439453125, 'logits/chosen': 0.1335253119468689, 'logits/rejected': 0.3338391184806824, 'epoch': 0.9}
 90%|█████████ | 3380/3753 [1:03:21<26:36,  4.28s/it] 90%|█████████ | 3381/3753 [1:03:24<25:32,  4.12s/it] 90%|█████████ | 3382/3753 [1:03:29<26:01,  4.21s/it] 90%|█████████ | 3383/3753 [1:03:33<26:05,  4.23s/it] 90%|█████████ | 3384/3753 [1:03:37<25:05,  4.08s/it] 90%|█████████ | 3385/3753 [1:03:42<26:32,  4.33s/it] 90%|█████████ | 3386/3753 [1:03:46<26:30,  4.33s/it] 90%|█████████ | 3387/3753 [1:03:50<25:07,  4.12s/it] 90%|█████████ | 3388/3753 [1:03:55<26:37,  4.38s/it] 90%|█████████ | 3389/3753 [1:03:59<26:00,  4.29s/it] 90%|█████████ | 3390/3753 [1:04:02<24:16,  4.01s/it]                                                     {'loss': 0.3386, 'grad_norm': 117.51514434814453, 'learning_rate': 1.98757951329264e-08, 'rewards/chosen': -3.8777167797088623, 'rewards/rejected': -8.317421913146973, 'rewards/accuracies': 0.875, 'rewards/margins': 4.439704895019531, 'logps/chosen': -527.1928100585938, 'logps/rejected': -969.7867431640625, 'logits/chosen': 0.22027108073234558, 'logits/rejected': 0.3252202868461609, 'epoch': 0.9}
 90%|█████████ | 3390/3753 [1:04:02<24:16,  4.01s/it] 90%|█████████ | 3391/3753 [1:04:05<23:02,  3.82s/it] 90%|█████████ | 3392/3753 [1:04:10<23:33,  3.92s/it] 90%|█████████ | 3393/3753 [1:04:13<22:39,  3.78s/it] 90%|█████████ | 3394/3753 [1:04:17<22:23,  3.74s/it] 90%|█████████ | 3395/3753 [1:04:21<23:02,  3.86s/it] 90%|█████████ | 3396/3753 [1:04:24<22:04,  3.71s/it] 91%|█████████ | 3397/3753 [1:04:33<30:32,  5.15s/it] 91%|█████████ | 3398/3753 [1:04:38<29:53,  5.05s/it] 91%|█████████ | 3399/3753 [1:04:42<28:22,  4.81s/it] 91%|█████████ | 3400/3753 [1:04:46<27:20,  4.65s/it]                                                     {'loss': 0.7498, 'grad_norm': 59.79396057128906, 'learning_rate': 1.8808474606047876e-08, 'rewards/chosen': -5.124491214752197, 'rewards/rejected': -9.46886157989502, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 4.344369888305664, 'logps/chosen': -675.8546752929688, 'logps/rejected': -1110.2335205078125, 'logits/chosen': 0.1809910088777542, 'logits/rejected': 0.3880787789821625, 'epoch': 0.91}
 91%|█████████ | 3400/3753 [1:04:46<27:20,  4.65s/it] 91%|█████████ | 3401/3753 [1:04:50<25:43,  4.38s/it] 91%|█████████ | 3402/3753 [1:04:53<24:01,  4.11s/it] 91%|█████████ | 3403/3753 [1:04:59<26:32,  4.55s/it] 91%|█████████ | 3404/3753 [1:05:02<24:49,  4.27s/it] 91%|█████████ | 3405/3753 [1:05:06<23:53,  4.12s/it] 91%|█████████ | 3406/3753 [1:05:14<30:04,  5.20s/it] 91%|█████████ | 3407/3753 [1:05:18<28:06,  4.87s/it] 91%|█████████ | 3408/3753 [1:05:23<27:54,  4.85s/it] 91%|█████████ | 3409/3753 [1:05:27<26:26,  4.61s/it] 91%|█████████ | 3410/3753 [1:05:30<24:16,  4.24s/it]                                                     {'loss': 0.3386, 'grad_norm': 79.89204406738281, 'learning_rate': 1.7769816555388188e-08, 'rewards/chosen': -3.950899600982666, 'rewards/rejected': -9.547593116760254, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 5.5966925621032715, 'logps/chosen': -547.0555419921875, 'logps/rejected': -1104.04443359375, 'logits/chosen': 0.1811269372701645, 'logits/rejected': 0.3834996223449707, 'epoch': 0.91}
 91%|█████████ | 3410/3753 [1:05:30<24:16,  4.24s/it] 91%|█████████ | 3411/3753 [1:05:34<24:02,  4.22s/it] 91%|█████████ | 3412/3753 [1:05:39<24:02,  4.23s/it] 91%|█████████ | 3413/3753 [1:05:43<24:10,  4.27s/it] 91%|█████████ | 3414/3753 [1:05:47<24:07,  4.27s/it] 91%|█████████ | 3415/3753 [1:05:52<24:49,  4.41s/it] 91%|█████████ | 3416/3753 [1:05:56<24:04,  4.29s/it] 91%|█████████ | 3417/3753 [1:06:00<23:26,  4.19s/it] 91%|█████████ | 3418/3753 [1:06:05<24:49,  4.45s/it] 91%|█████████ | 3419/3753 [1:06:09<24:02,  4.32s/it] 91%|█████████ | 3420/3753 [1:06:14<24:26,  4.40s/it]                                                     {'loss': 0.3246, 'grad_norm': 63.06911087036133, 'learning_rate': 1.675991087005796e-08, 'rewards/chosen': -4.005829334259033, 'rewards/rejected': -8.608060836791992, 'rewards/accuracies': 0.875, 'rewards/margins': 4.602231979370117, 'logps/chosen': -568.2282104492188, 'logps/rejected': -1031.4580078125, 'logits/chosen': 0.17153236269950867, 'logits/rejected': 0.41169625520706177, 'epoch': 0.91}
 91%|█████████ | 3420/3753 [1:06:14<24:26,  4.40s/it] 91%|█████████ | 3421/3753 [1:06:18<23:56,  4.33s/it] 91%|█████████ | 3422/3753 [1:06:22<23:21,  4.23s/it] 91%|█████████ | 3423/3753 [1:06:25<22:12,  4.04s/it] 91%|█████████ | 3424/3753 [1:06:29<22:00,  4.01s/it] 91%|█████████▏| 3425/3753 [1:06:33<20:54,  3.82s/it] 91%|█████████▏| 3426/3753 [1:06:36<19:58,  3.66s/it] 91%|█████████▏| 3427/3753 [1:06:40<20:30,  3.78s/it] 91%|█████████▏| 3428/3753 [1:06:45<21:39,  4.00s/it] 91%|█████████▏| 3429/3753 [1:06:49<22:11,  4.11s/it] 91%|█████████▏| 3430/3753 [1:06:57<27:48,  5.17s/it]                                                     {'loss': 0.2532, 'grad_norm': 68.0706558227539, 'learning_rate': 1.5778844950837283e-08, 'rewards/chosen': -4.273534774780273, 'rewards/rejected': -10.146661758422852, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 5.87312650680542, 'logps/chosen': -597.3717651367188, 'logps/rejected': -1181.923095703125, 'logits/chosen': 0.19849379360675812, 'logits/rejected': 0.31947875022888184, 'epoch': 0.91}
 91%|█████████▏| 3430/3753 [1:06:57<27:48,  5.17s/it] 91%|█████████▏| 3431/3753 [1:07:01<25:54,  4.83s/it] 91%|█████████▏| 3432/3753 [1:07:04<23:41,  4.43s/it] 91%|█████████▏| 3433/3753 [1:07:08<22:05,  4.14s/it] 92%|█████████▏| 3434/3753 [1:07:12<22:01,  4.14s/it] 92%|█████████▏| 3435/3753 [1:07:16<21:18,  4.02s/it] 92%|█████████▏| 3436/3753 [1:07:21<23:21,  4.42s/it] 92%|█████████▏| 3437/3753 [1:07:25<22:25,  4.26s/it] 92%|█████████▏| 3438/3753 [1:07:29<21:35,  4.11s/it] 92%|█████████▏| 3439/3753 [1:07:33<21:41,  4.14s/it] 92%|█████████▏| 3440/3753 [1:07:36<20:33,  3.94s/it]                                                     {'loss': 0.276, 'grad_norm': 25.352487564086914, 'learning_rate': 1.4826703702611848e-08, 'rewards/chosen': -3.889680862426758, 'rewards/rejected': -9.027125358581543, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 5.137444496154785, 'logps/chosen': -552.3822021484375, 'logps/rejected': -1068.188232421875, 'logits/chosen': 0.14312568306922913, 'logits/rejected': 0.34737420082092285, 'epoch': 0.92}
 92%|█████████▏| 3440/3753 [1:07:36<20:33,  3.94s/it] 92%|█████████▏| 3441/3753 [1:07:39<19:24,  3.73s/it] 92%|█████████▏| 3442/3753 [1:07:45<21:58,  4.24s/it] 92%|█████████▏| 3443/3753 [1:07:49<21:44,  4.21s/it] 92%|█████████▏| 3444/3753 [1:07:54<22:57,  4.46s/it] 92%|█████████▏| 3445/3753 [1:07:58<21:49,  4.25s/it] 92%|█████████▏| 3446/3753 [1:08:02<20:55,  4.09s/it] 92%|█████████▏| 3447/3753 [1:08:05<19:43,  3.87s/it] 92%|█████████▏| 3448/3753 [1:08:09<20:09,  3.97s/it] 92%|█████████▏| 3449/3753 [1:08:13<20:08,  3.98s/it] 92%|█████████▏| 3450/3753 [1:08:17<20:27,  4.05s/it]                                                     {'loss': 0.3739, 'grad_norm': 16.510927200317383, 'learning_rate': 1.3903569527024788e-08, 'rewards/chosen': -4.085700035095215, 'rewards/rejected': -8.409065246582031, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.323365211486816, 'logps/chosen': -581.9879760742188, 'logps/rejected': -1014.3582153320312, 'logits/chosen': 0.14512307941913605, 'logits/rejected': 0.351153701543808, 'epoch': 0.92}
 92%|█████████▏| 3450/3753 [1:08:17<20:27,  4.05s/it] 92%|█████████▏| 3451/3753 [1:08:21<20:27,  4.06s/it] 92%|█████████▏| 3452/3753 [1:08:25<19:39,  3.92s/it] 92%|█████████▏| 3453/3753 [1:08:29<19:49,  3.96s/it] 92%|█████████▏| 3454/3753 [1:08:32<18:38,  3.74s/it] 92%|█████████▏| 3455/3753 [1:08:36<17:50,  3.59s/it] 92%|█████████▏| 3456/3753 [1:08:39<17:53,  3.61s/it] 92%|█████████▏| 3457/3753 [1:08:47<24:31,  4.97s/it] 92%|█████████▏| 3458/3753 [1:08:51<22:27,  4.57s/it] 92%|█████████▏| 3459/3753 [1:08:55<21:13,  4.33s/it] 92%|█████████▏| 3460/3753 [1:08:58<19:18,  3.95s/it]                                                     {'loss': 0.2991, 'grad_norm': 52.860111236572266, 'learning_rate': 1.3009522315345355e-08, 'rewards/chosen': -3.321143627166748, 'rewards/rejected': -7.256095886230469, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.9349524974823, 'logps/chosen': -472.891357421875, 'logps/rejected': -872.2115478515625, 'logits/chosen': 0.19910213351249695, 'logits/rejected': 0.3743080198764801, 'epoch': 0.92}
 92%|█████████▏| 3460/3753 [1:08:58<19:18,  3.95s/it] 92%|█████████▏| 3461/3753 [1:09:02<19:43,  4.05s/it] 92%|█████████▏| 3462/3753 [1:09:06<19:28,  4.02s/it] 92%|█████████▏| 3463/3753 [1:09:10<18:49,  3.89s/it] 92%|█████████▏| 3464/3753 [1:09:13<18:35,  3.86s/it] 92%|█████████▏| 3465/3753 [1:09:17<18:46,  3.91s/it] 92%|█████████▏| 3466/3753 [1:09:21<18:48,  3.93s/it] 92%|█████████▏| 3467/3753 [1:09:26<20:03,  4.21s/it] 92%|█████████▏| 3468/3753 [1:09:30<19:20,  4.07s/it] 92%|█████████▏| 3469/3753 [1:09:34<18:36,  3.93s/it] 92%|█████████▏| 3470/3753 [1:09:37<17:41,  3.75s/it]                                                     {'loss': 0.2481, 'grad_norm': 54.407283782958984, 'learning_rate': 1.2144639441555021e-08, 'rewards/chosen': -3.4347541332244873, 'rewards/rejected': -8.262008666992188, 'rewards/accuracies': 0.893750011920929, 'rewards/margins': 4.827254295349121, 'logps/chosen': -498.690673828125, 'logps/rejected': -987.20703125, 'logits/chosen': 0.1835971176624298, 'logits/rejected': 0.3900461792945862, 'epoch': 0.92}
 92%|█████████▏| 3470/3753 [1:09:37<17:41,  3.75s/it] 92%|█████████▏| 3471/3753 [1:09:42<18:59,  4.04s/it] 93%|█████████▎| 3472/3753 [1:09:46<19:11,  4.10s/it] 93%|█████████▎| 3473/3753 [1:09:51<21:00,  4.50s/it] 93%|█████████▎| 3474/3753 [1:09:57<21:49,  4.69s/it] 93%|█████████▎| 3475/3753 [1:10:00<20:11,  4.36s/it] 93%|█████████▎| 3476/3753 [1:10:04<19:35,  4.24s/it] 93%|█████████▎| 3477/3753 [1:10:08<18:32,  4.03s/it] 93%|█████████▎| 3478/3753 [1:10:11<18:02,  3.94s/it] 93%|█████████▎| 3479/3753 [1:10:15<18:16,  4.00s/it] 93%|█████████▎| 3480/3753 [1:10:19<18:04,  3.97s/it]                                                     {'loss': 0.3441, 'grad_norm': 25.554054260253906, 'learning_rate': 1.130899575565119e-08, 'rewards/chosen': -4.035505294799805, 'rewards/rejected': -8.36884880065918, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 4.333342552185059, 'logps/chosen': -572.1141967773438, 'logps/rejected': -1003.5066528320312, 'logits/chosen': 0.16425630450248718, 'logits/rejected': 0.3712875545024872, 'epoch': 0.93}
 93%|█████████▎| 3480/3753 [1:10:19<18:04,  3.97s/it] 93%|█████████▎| 3481/3753 [1:10:23<17:06,  3.77s/it] 93%|█████████▎| 3482/3753 [1:10:26<16:25,  3.64s/it] 93%|█████████▎| 3483/3753 [1:10:30<16:48,  3.74s/it] 93%|█████████▎| 3484/3753 [1:10:34<16:30,  3.68s/it] 93%|█████████▎| 3485/3753 [1:10:38<17:03,  3.82s/it] 93%|█████████▎| 3486/3753 [1:10:47<24:09,  5.43s/it] 93%|█████████▎| 3487/3753 [1:10:51<21:52,  4.93s/it] 93%|█████████▎| 3488/3753 [1:10:54<20:18,  4.60s/it] 93%|█████████▎| 3489/3753 [1:10:58<18:38,  4.24s/it] 93%|█████████▎| 3490/3753 [1:11:02<17:55,  4.09s/it]                                                     {'loss': 0.2703, 'grad_norm': 38.97655487060547, 'learning_rate': 1.0502663577169373e-08, 'rewards/chosen': -3.5806527137756348, 'rewards/rejected': -8.862619400024414, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.281966209411621, 'logps/chosen': -504.6258850097656, 'logps/rejected': -1041.906494140625, 'logits/chosen': 0.13979966938495636, 'logits/rejected': 0.3094642162322998, 'epoch': 0.93}
 93%|█████████▎| 3490/3753 [1:11:02<17:55,  4.09s/it] 93%|█████████▎| 3491/3753 [1:11:06<18:05,  4.14s/it] 93%|█████████▎| 3492/3753 [1:11:11<18:49,  4.33s/it] 93%|█████████▎| 3493/3753 [1:11:14<17:25,  4.02s/it] 93%|█████████▎| 3494/3753 [1:11:18<17:17,  4.01s/it] 93%|█████████▎| 3495/3753 [1:11:21<16:16,  3.79s/it] 93%|█████████▎| 3496/3753 [1:11:24<15:24,  3.60s/it] 93%|█████████▎| 3497/3753 [1:11:28<16:03,  3.77s/it] 93%|█████████▎| 3498/3753 [1:11:33<16:54,  3.98s/it] 93%|█████████▎| 3499/3753 [1:11:36<16:06,  3.80s/it] 93%|█████████▎| 3500/3753 [1:11:45<22:27,  5.33s/it]                                                     {'loss': 0.3066, 'grad_norm': 58.00688552856445, 'learning_rate': 9.72571268892436e-09, 'rewards/chosen': -3.706697940826416, 'rewards/rejected': -9.57136058807373, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 5.8646626472473145, 'logps/chosen': -532.7041625976562, 'logps/rejected': -1123.837646484375, 'logits/chosen': 0.1240583062171936, 'logits/rejected': 0.3210778832435608, 'epoch': 0.93}
 93%|█████████▎| 3500/3753 [1:11:45<22:27,  5.33s/it]wandb: WARNING URL not available in offline run
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 93%|█████████▎| 3501/3753 [1:12:47<1:33:33, 22.28s/it] 93%|█████████▎| 3502/3753 [1:12:51<1:10:31, 16.86s/it] 93%|█████████▎| 3503/3753 [1:12:55<54:13, 13.01s/it]   93%|█████████▎| 3504/3753 [1:12:59<41:48, 10.08s/it] 93%|█████████▎| 3505/3753 [1:13:03<34:19,  8.30s/it] 93%|█████████▎| 3506/3753 [1:13:07<28:56,  7.03s/it] 93%|█████████▎| 3507/3753 [1:13:10<24:19,  5.93s/it] 93%|█████████▎| 3508/3753 [1:13:14<21:22,  5.23s/it] 93%|█████████▎| 3509/3753 [1:13:18<19:45,  4.86s/it] 94%|█████████▎| 3510/3753 [1:13:22<18:33,  4.58s/it]                                                     {'loss': 0.282, 'grad_norm': 126.85444641113281, 'learning_rate': 8.978210330971009e-09, 'rewards/chosen': -3.6152889728546143, 'rewards/rejected': -7.827846527099609, 'rewards/accuracies': 0.875, 'rewards/margins': 4.212557792663574, 'logps/chosen': -524.9070434570312, 'logps/rejected': -944.7222900390625, 'logits/chosen': 0.16211870312690735, 'logits/rejected': 0.33085957169532776, 'epoch': 0.94}
 94%|█████████▎| 3510/3753 [1:13:22<18:33,  4.58s/it] 94%|█████████▎| 3511/3753 [1:13:26<18:48,  4.67s/it] 94%|█████████▎| 3512/3753 [1:13:30<17:42,  4.41s/it] 94%|█████████▎| 3513/3753 [1:13:34<16:54,  4.23s/it] 94%|█████████▎| 3514/3753 [1:13:38<16:00,  4.02s/it] 94%|█████████▎| 3515/3753 [1:13:42<16:50,  4.25s/it] 94%|█████████▎| 3516/3753 [1:13:46<15:54,  4.03s/it] 94%|█████████▎| 3517/3753 [1:13:51<16:38,  4.23s/it] 94%|█████████▎| 3518/3753 [1:13:55<16:12,  4.14s/it] 94%|█████████▍| 3519/3753 [1:14:02<20:01,  5.14s/it] 94%|█████████▍| 3520/3753 [1:14:09<22:18,  5.75s/it]                                                     {'loss': 0.1446, 'grad_norm': 12.975669860839844, 'learning_rate': 8.260221194785267e-09, 'rewards/chosen': -4.438237190246582, 'rewards/rejected': -11.271034240722656, 'rewards/accuracies': 0.949999988079071, 'rewards/margins': 6.832796573638916, 'logps/chosen': -613.8104248046875, 'logps/rejected': -1300.5799560546875, 'logits/chosen': 0.19748851656913757, 'logits/rejected': 0.42144185304641724, 'epoch': 0.94}
 94%|█████████▍| 3520/3753 [1:14:09<22:18,  5.75s/it] 94%|█████████▍| 3521/3753 [1:14:14<20:46,  5.37s/it] 94%|█████████▍| 3522/3753 [1:14:18<19:01,  4.94s/it] 94%|█████████▍| 3523/3753 [1:14:22<18:19,  4.78s/it] 94%|█████████▍| 3524/3753 [1:14:26<17:11,  4.50s/it] 94%|█████████▍| 3525/3753 [1:14:31<17:25,  4.59s/it] 94%|█████████▍| 3526/3753 [1:14:34<16:01,  4.23s/it] 94%|█████████▍| 3527/3753 [1:14:38<15:54,  4.23s/it] 94%|█████████▍| 3528/3753 [1:14:46<19:59,  5.33s/it] 94%|█████████▍| 3529/3753 [1:14:51<19:21,  5.18s/it] 94%|█████████▍| 3530/3753 [1:14:55<17:49,  4.80s/it]                                                     {'loss': 0.3148, 'grad_norm': 118.08897399902344, 'learning_rate': 7.571807417665133e-09, 'rewards/chosen': -4.350841522216797, 'rewards/rejected': -9.31895923614502, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.968117713928223, 'logps/chosen': -616.120849609375, 'logps/rejected': -1115.111083984375, 'logits/chosen': 0.1766214668750763, 'logits/rejected': 0.4049226641654968, 'epoch': 0.94}
 94%|█████████▍| 3530/3753 [1:14:55<17:49,  4.80s/it] 94%|█████████▍| 3531/3753 [1:15:02<20:27,  5.53s/it] 94%|█████████▍| 3532/3753 [1:15:06<18:53,  5.13s/it] 94%|█████████▍| 3533/3753 [1:15:10<17:11,  4.69s/it] 94%|█████████▍| 3534/3753 [1:15:16<18:08,  4.97s/it] 94%|█████████▍| 3535/3753 [1:15:19<16:38,  4.58s/it] 94%|█████████▍| 3536/3753 [1:15:29<21:40,  5.99s/it] 94%|█████████▍| 3537/3753 [1:15:34<20:57,  5.82s/it] 94%|█████████▍| 3538/3753 [1:15:38<19:05,  5.33s/it] 94%|█████████▍| 3539/3753 [1:15:42<17:12,  4.83s/it] 94%|█████████▍| 3540/3753 [1:15:47<17:45,  5.00s/it]                                                     {'loss': 0.2655, 'grad_norm': 25.364774703979492, 'learning_rate': 6.913028577353486e-09, 'rewards/chosen': -4.044951915740967, 'rewards/rejected': -10.304230690002441, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 6.25927734375, 'logps/chosen': -568.1276245117188, 'logps/rejected': -1205.1214599609375, 'logits/chosen': 0.22125034034252167, 'logits/rejected': 0.4189957082271576, 'epoch': 0.94}
 94%|█████████▍| 3540/3753 [1:15:47<17:45,  5.00s/it] 94%|█████████▍| 3541/3753 [1:15:52<17:00,  4.82s/it] 94%|█████████▍| 3542/3753 [1:15:56<16:20,  4.65s/it] 94%|█████████▍| 3543/3753 [1:16:01<16:11,  4.63s/it] 94%|█████████▍| 3544/3753 [1:16:04<15:06,  4.34s/it] 94%|█████████▍| 3545/3753 [1:16:08<14:06,  4.07s/it] 94%|█████████▍| 3546/3753 [1:16:12<14:06,  4.09s/it] 95%|█████████▍| 3547/3753 [1:16:16<14:20,  4.18s/it] 95%|█████████▍| 3548/3753 [1:16:19<13:03,  3.82s/it] 95%|█████████▍| 3549/3753 [1:16:23<13:20,  3.92s/it] 95%|█████████▍| 3550/3753 [1:16:28<14:19,  4.23s/it]                                                     {'loss': 0.229, 'grad_norm': 18.523727416992188, 'learning_rate': 6.283941686881689e-09, 'rewards/chosen': -3.384131908416748, 'rewards/rejected': -8.380645751953125, 'rewards/accuracies': 0.9125000238418579, 'rewards/margins': 4.996513366699219, 'logps/chosen': -500.49639892578125, 'logps/rejected': -1008.4202880859375, 'logits/chosen': 0.13780739903450012, 'logits/rejected': 0.394286572933197, 'epoch': 0.95}
 95%|█████████▍| 3550/3753 [1:16:28<14:19,  4.23s/it] 95%|█████████▍| 3551/3753 [1:16:32<13:21,  3.97s/it] 95%|█████████▍| 3552/3753 [1:16:36<13:24,  4.00s/it] 95%|█████████▍| 3553/3753 [1:16:39<12:51,  3.86s/it] 95%|█████████▍| 3554/3753 [1:16:43<13:02,  3.93s/it] 95%|█████████▍| 3555/3753 [1:16:48<13:32,  4.10s/it] 95%|█████████▍| 3556/3753 [1:16:52<13:22,  4.07s/it] 95%|█████████▍| 3557/3753 [1:16:56<13:27,  4.12s/it] 95%|█████████▍| 3558/3753 [1:17:00<13:40,  4.21s/it] 95%|█████████▍| 3559/3753 [1:17:05<14:12,  4.40s/it] 95%|█████████▍| 3560/3753 [1:17:09<13:26,  4.18s/it]                                                     {'loss': 0.3665, 'grad_norm': 36.60404586791992, 'learning_rate': 5.684601189635735e-09, 'rewards/chosen': -3.2960517406463623, 'rewards/rejected': -7.2927751541137695, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 3.9967236518859863, 'logps/chosen': -493.5126037597656, 'logps/rejected': -891.0618896484375, 'logits/chosen': 0.13125328719615936, 'logits/rejected': 0.33493685722351074, 'epoch': 0.95}
 95%|█████████▍| 3560/3753 [1:17:09<13:26,  4.18s/it] 95%|█████████▍| 3561/3753 [1:17:13<13:20,  4.17s/it] 95%|█████████▍| 3562/3753 [1:17:17<12:47,  4.02s/it] 95%|█████████▍| 3563/3753 [1:17:20<12:19,  3.89s/it] 95%|█████████▍| 3564/3753 [1:17:24<12:05,  3.84s/it] 95%|█████████▍| 3565/3753 [1:17:28<12:01,  3.84s/it] 95%|█████████▌| 3566/3753 [1:17:31<11:42,  3.76s/it] 95%|█████████▌| 3567/3753 [1:17:35<11:33,  3.73s/it] 95%|█████████▌| 3568/3753 [1:17:38<10:43,  3.48s/it] 95%|█████████▌| 3569/3753 [1:17:42<10:52,  3.55s/it] 95%|█████████▌| 3570/3753 [1:17:46<11:00,  3.61s/it]                                                     {'loss': 0.2503, 'grad_norm': 28.37752914428711, 'learning_rate': 5.115058954644275e-09, 'rewards/chosen': -3.4223015308380127, 'rewards/rejected': -7.890920162200928, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 4.468618392944336, 'logps/chosen': -492.2059020996094, 'logps/rejected': -943.1483154296875, 'logits/chosen': 0.12762950360774994, 'logits/rejected': 0.32888108491897583, 'epoch': 0.95}
 95%|█████████▌| 3570/3753 [1:17:46<11:00,  3.61s/it] 95%|█████████▌| 3571/3753 [1:17:49<11:17,  3.72s/it] 95%|█████████▌| 3572/3753 [1:17:56<13:42,  4.54s/it] 95%|█████████▌| 3573/3753 [1:18:01<14:19,  4.78s/it] 95%|█████████▌| 3574/3753 [1:18:04<12:47,  4.29s/it] 95%|█████████▌| 3575/3753 [1:18:08<12:19,  4.16s/it] 95%|█████████▌| 3576/3753 [1:18:12<11:40,  3.96s/it] 95%|█████████▌| 3577/3753 [1:18:15<11:18,  3.86s/it] 95%|█████████▌| 3578/3753 [1:18:19<10:56,  3.75s/it] 95%|█████████▌| 3579/3753 [1:18:24<11:47,  4.07s/it] 95%|█████████▌| 3580/3753 [1:18:29<12:32,  4.35s/it]                                                     {'loss': 0.2872, 'grad_norm': 87.22820281982422, 'learning_rate': 4.575364272089993e-09, 'rewards/chosen': -3.7750587463378906, 'rewards/rejected': -8.921700477600098, 'rewards/accuracies': 0.875, 'rewards/margins': 5.146641731262207, 'logps/chosen': -536.6219482421875, 'logps/rejected': -1051.1629638671875, 'logits/chosen': 0.12145115435123444, 'logits/rejected': 0.369416207075119, 'epoch': 0.95}
 95%|█████████▌| 3580/3753 [1:18:29<12:32,  4.35s/it] 95%|█████████▌| 3581/3753 [1:18:33<12:05,  4.22s/it] 95%|█████████▌| 3582/3753 [1:18:37<12:19,  4.33s/it] 95%|█████████▌| 3583/3753 [1:18:42<12:58,  4.58s/it] 95%|█████████▌| 3584/3753 [1:18:47<12:31,  4.45s/it] 96%|█████████▌| 3585/3753 [1:18:51<12:08,  4.34s/it] 96%|█████████▌| 3586/3753 [1:18:55<11:58,  4.30s/it] 96%|█████████▌| 3587/3753 [1:18:58<11:12,  4.05s/it] 96%|█████████▌| 3588/3753 [1:19:02<11:15,  4.10s/it] 96%|█████████▌| 3589/3753 [1:19:06<10:33,  3.86s/it] 96%|█████████▌| 3590/3753 [1:19:11<11:24,  4.20s/it]                                                     {'loss': 0.3764, 'grad_norm': 121.1998519897461, 'learning_rate': 4.065563849043646e-09, 'rewards/chosen': -3.978431224822998, 'rewards/rejected': -8.744473457336426, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 4.766042232513428, 'logps/chosen': -556.263427734375, 'logps/rejected': -1034.1004638671875, 'logits/chosen': 0.17326536774635315, 'logits/rejected': 0.3766303062438965, 'epoch': 0.96}
 96%|█████████▌| 3590/3753 [1:19:11<11:24,  4.20s/it] 96%|█████████▌| 3591/3753 [1:19:15<11:44,  4.35s/it] 96%|█████████▌| 3592/3753 [1:19:19<11:01,  4.11s/it] 96%|█████████▌| 3593/3753 [1:19:23<10:45,  4.03s/it] 96%|█████████▌| 3594/3753 [1:19:27<10:36,  4.00s/it] 96%|█████████▌| 3595/3753 [1:19:32<11:08,  4.23s/it] 96%|█████████▌| 3596/3753 [1:19:35<10:41,  4.09s/it] 96%|█████████▌| 3597/3753 [1:19:39<10:16,  3.95s/it] 96%|█████████▌| 3598/3753 [1:19:43<10:25,  4.04s/it] 96%|█████████▌| 3599/3753 [1:19:47<10:17,  4.01s/it] 96%|█████████▌| 3600/3753 [1:19:51<10:25,  4.09s/it]                                                     {'loss': 0.2967, 'grad_norm': 159.71832275390625, 'learning_rate': 3.5857018054218367e-09, 'rewards/chosen': -3.866422176361084, 'rewards/rejected': -8.717073440551758, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 4.850651741027832, 'logps/chosen': -541.7730712890625, 'logps/rejected': -1034.6800537109375, 'logits/chosen': 0.18079957365989685, 'logits/rejected': 0.35929909348487854, 'epoch': 0.96}
 96%|█████████▌| 3600/3753 [1:19:51<10:25,  4.09s/it] 96%|█████████▌| 3601/3753 [1:19:55<10:13,  4.03s/it] 96%|█████████▌| 3602/3753 [1:19:59<10:11,  4.05s/it] 96%|█████████▌| 3603/3753 [1:20:03<09:54,  3.97s/it] 96%|█████████▌| 3604/3753 [1:20:07<09:28,  3.82s/it] 96%|█████████▌| 3605/3753 [1:20:15<12:32,  5.09s/it] 96%|█████████▌| 3606/3753 [1:20:19<11:36,  4.74s/it] 96%|█████████▌| 3607/3753 [1:20:22<10:49,  4.45s/it] 96%|█████████▌| 3608/3753 [1:20:26<10:02,  4.16s/it] 96%|█████████▌| 3609/3753 [1:20:34<12:38,  5.27s/it] 96%|█████████▌| 3610/3753 [1:20:38<11:39,  4.89s/it]                                                     {'loss': 0.2858, 'grad_norm': 144.17880249023438, 'learning_rate': 3.1358196701688875e-09, 'rewards/chosen': -3.8461921215057373, 'rewards/rejected': -9.069305419921875, 'rewards/accuracies': 0.862500011920929, 'rewards/margins': 5.223113536834717, 'logps/chosen': -556.1610107421875, 'logps/rejected': -1078.5068359375, 'logits/chosen': 0.16265031695365906, 'logits/rejected': 0.4277564585208893, 'epoch': 0.96}
 96%|█████████▌| 3610/3753 [1:20:38<11:39,  4.89s/it] 96%|█████████▌| 3611/3753 [1:20:44<12:34,  5.31s/it] 96%|█████████▌| 3612/3753 [1:20:49<12:06,  5.15s/it] 96%|█████████▋| 3613/3753 [1:20:53<11:08,  4.78s/it] 96%|█████████▋| 3614/3753 [1:20:57<10:34,  4.57s/it] 96%|█████████▋| 3615/3753 [1:21:01<10:00,  4.35s/it] 96%|█████████▋| 3616/3753 [1:21:04<09:25,  4.13s/it] 96%|█████████▋| 3617/3753 [1:21:07<08:45,  3.86s/it] 96%|█████████▋| 3618/3753 [1:21:12<09:22,  4.17s/it] 96%|█████████▋| 3619/3753 [1:21:16<09:05,  4.07s/it] 96%|█████████▋| 3620/3753 [1:21:21<09:21,  4.22s/it]                                                     {'loss': 0.2269, 'grad_norm': 30.382871627807617, 'learning_rate': 2.7159563776627257e-09, 'rewards/chosen': -3.924783229827881, 'rewards/rejected': -8.748922348022461, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 4.824139595031738, 'logps/chosen': -553.9978637695312, 'logps/rejected': -1044.40087890625, 'logits/chosen': 0.17633004486560822, 'logits/rejected': 0.3417696952819824, 'epoch': 0.96}
 96%|█████████▋| 3620/3753 [1:21:21<09:21,  4.22s/it] 96%|█████████▋| 3621/3753 [1:21:25<09:15,  4.21s/it] 97%|█████████▋| 3622/3753 [1:21:28<08:41,  3.98s/it] 97%|█████████▋| 3623/3753 [1:21:32<08:35,  3.97s/it] 97%|█████████▋| 3624/3753 [1:21:36<08:26,  3.93s/it] 97%|█████████▋| 3625/3753 [1:21:40<08:28,  3.97s/it] 97%|█████████▋| 3626/3753 [1:21:44<08:08,  3.85s/it] 97%|█████████▋| 3627/3753 [1:21:50<09:27,  4.50s/it] 97%|█████████▋| 3628/3753 [1:21:53<08:50,  4.24s/it] 97%|█████████▋| 3629/3753 [1:21:57<08:19,  4.03s/it] 97%|█████████▋| 3630/3753 [1:22:01<08:21,  4.08s/it]                                                     {'loss': 0.3889, 'grad_norm': 124.44745635986328, 'learning_rate': 2.32614826434529e-09, 'rewards/chosen': -4.354320526123047, 'rewards/rejected': -8.50212287902832, 'rewards/accuracies': 0.8187500238418579, 'rewards/margins': 4.147802352905273, 'logps/chosen': -612.5106201171875, 'logps/rejected': -1026.8837890625, 'logits/chosen': 0.13439571857452393, 'logits/rejected': 0.3323500156402588, 'epoch': 0.97}
 97%|█████████▋| 3630/3753 [1:22:01<08:21,  4.08s/it] 97%|█████████▋| 3631/3753 [1:22:05<07:49,  3.85s/it] 97%|█████████▋| 3632/3753 [1:22:12<09:58,  4.95s/it] 97%|█████████▋| 3633/3753 [1:22:16<09:24,  4.70s/it] 97%|█████████▋| 3634/3753 [1:22:20<08:37,  4.35s/it] 97%|█████████▋| 3635/3753 [1:22:24<08:21,  4.25s/it] 97%|█████████▋| 3636/3753 [1:22:28<08:28,  4.34s/it] 97%|█████████▋| 3637/3753 [1:22:32<07:49,  4.05s/it] 97%|█████████▋| 3638/3753 [1:22:35<07:35,  3.96s/it] 97%|█████████▋| 3639/3753 [1:22:40<07:44,  4.07s/it] 97%|█████████▋| 3640/3753 [1:22:43<07:17,  3.88s/it]                                                     {'loss': 0.2727, 'grad_norm': 107.58827209472656, 'learning_rate': 1.966429065577885e-09, 'rewards/chosen': -3.8980345726013184, 'rewards/rejected': -9.691245079040527, 'rewards/accuracies': 0.856249988079071, 'rewards/margins': 5.793210029602051, 'logps/chosen': -553.2503662109375, 'logps/rejected': -1133.424560546875, 'logits/chosen': 0.14219695329666138, 'logits/rejected': 0.38885900378227234, 'epoch': 0.97}
 97%|█████████▋| 3640/3753 [1:22:43<07:17,  3.88s/it] 97%|█████████▋| 3641/3753 [1:22:48<08:00,  4.29s/it] 97%|█████████▋| 3642/3753 [1:22:52<07:35,  4.10s/it] 97%|█████████▋| 3643/3753 [1:22:56<07:40,  4.19s/it] 97%|█████████▋| 3644/3753 [1:23:01<07:33,  4.16s/it] 97%|█████████▋| 3645/3753 [1:23:04<07:11,  3.99s/it] 97%|█████████▋| 3646/3753 [1:23:08<07:19,  4.10s/it] 97%|█████████▋| 3647/3753 [1:23:12<06:51,  3.88s/it] 97%|█████████▋| 3648/3753 [1:23:19<08:42,  4.98s/it] 97%|█████████▋| 3649/3753 [1:23:24<08:32,  4.93s/it] 97%|█████████▋| 3650/3753 [1:23:28<07:50,  4.56s/it]                                                     {'loss': 0.2996, 'grad_norm': 45.70123291015625, 'learning_rate': 1.6368299127216379e-09, 'rewards/chosen': -3.74713397026062, 'rewards/rejected': -8.052915573120117, 'rewards/accuracies': 0.887499988079071, 'rewards/margins': 4.305782318115234, 'logps/chosen': -517.7825927734375, 'logps/rejected': -957.72607421875, 'logits/chosen': 0.24440081417560577, 'logits/rejected': 0.41102084517478943, 'epoch': 0.97}
 97%|█████████▋| 3650/3753 [1:23:28<07:50,  4.56s/it] 97%|█████████▋| 3651/3753 [1:23:34<08:21,  4.92s/it] 97%|█████████▋| 3652/3753 [1:23:37<07:32,  4.48s/it] 97%|█████████▋| 3653/3753 [1:23:41<07:13,  4.33s/it] 97%|█████████▋| 3654/3753 [1:23:46<07:12,  4.37s/it] 97%|█████████▋| 3655/3753 [1:23:50<06:57,  4.26s/it] 97%|█████████▋| 3656/3753 [1:23:55<07:21,  4.55s/it] 97%|█████████▋| 3657/3753 [1:23:59<06:58,  4.36s/it] 97%|█████████▋| 3658/3753 [1:24:02<06:35,  4.17s/it] 97%|█████████▋| 3659/3753 [1:24:08<07:05,  4.52s/it] 98%|█████████▊| 3660/3753 [1:24:11<06:32,  4.22s/it]                                                     {'loss': 0.221, 'grad_norm': 60.76638412475586, 'learning_rate': 1.3373793304432945e-09, 'rewards/chosen': -4.721997261047363, 'rewards/rejected': -9.886812210083008, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 5.1648149490356445, 'logps/chosen': -646.8169555664062, 'logps/rejected': -1165.301513671875, 'logits/chosen': 0.19090795516967773, 'logits/rejected': 0.3563595414161682, 'epoch': 0.98}
 98%|█████████▊| 3660/3753 [1:24:11<06:32,  4.22s/it] 98%|█████████▊| 3661/3753 [1:24:16<06:38,  4.33s/it] 98%|█████████▊| 3662/3753 [1:24:20<06:20,  4.18s/it] 98%|█████████▊| 3663/3753 [1:24:29<08:30,  5.67s/it] 98%|█████████▊| 3664/3753 [1:24:33<07:34,  5.11s/it] 98%|█████████▊| 3665/3753 [1:24:36<06:31,  4.45s/it] 98%|█████████▊| 3666/3753 [1:24:40<06:14,  4.30s/it] 98%|█████████▊| 3667/3753 [1:24:43<05:44,  4.00s/it] 98%|█████████▊| 3668/3753 [1:24:47<05:53,  4.16s/it] 98%|█████████▊| 3669/3753 [1:24:54<06:58,  4.98s/it] 98%|█████████▊| 3670/3753 [1:24:58<06:24,  4.63s/it]                                                     {'loss': 0.2903, 'grad_norm': 178.33872985839844, 'learning_rate': 1.0681032342465035e-09, 'rewards/chosen': -4.286362648010254, 'rewards/rejected': -10.127049446105957, 'rewards/accuracies': 0.875, 'rewards/margins': 5.840686321258545, 'logps/chosen': -578.9589233398438, 'logps/rejected': -1169.04248046875, 'logits/chosen': 0.19732330739498138, 'logits/rejected': 0.3686937093734741, 'epoch': 0.98}
 98%|█████████▊| 3670/3753 [1:24:58<06:24,  4.63s/it] 98%|█████████▊| 3671/3753 [1:25:01<05:47,  4.24s/it] 98%|█████████▊| 3672/3753 [1:25:08<06:47,  5.03s/it] 98%|█████████▊| 3673/3753 [1:25:12<06:21,  4.77s/it] 98%|█████████▊| 3674/3753 [1:25:16<05:41,  4.32s/it] 98%|█████████▊| 3675/3753 [1:25:20<05:34,  4.29s/it] 98%|█████████▊| 3676/3753 [1:25:24<05:20,  4.17s/it] 98%|█████████▊| 3677/3753 [1:25:28<05:11,  4.10s/it] 98%|█████████▊| 3678/3753 [1:25:32<05:05,  4.08s/it] 98%|█████████▊| 3679/3753 [1:25:36<05:01,  4.07s/it] 98%|█████████▊| 3680/3753 [1:25:40<04:56,  4.06s/it]                                                     {'loss': 0.2691, 'grad_norm': 38.33289337158203, 'learning_rate': 8.290249282290995e-10, 'rewards/chosen': -4.417083740234375, 'rewards/rejected': -9.925569534301758, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.508484840393066, 'logps/chosen': -610.7021484375, 'logps/rejected': -1169.48193359375, 'logits/chosen': 0.20147088170051575, 'logits/rejected': 0.4222013056278229, 'epoch': 0.98}
 98%|█████████▊| 3680/3753 [1:25:40<04:56,  4.06s/it] 98%|█████████▊| 3681/3753 [1:25:44<04:57,  4.13s/it] 98%|█████████▊| 3682/3753 [1:25:48<04:47,  4.04s/it] 98%|█████████▊| 3683/3753 [1:25:54<05:27,  4.68s/it] 98%|█████████▊| 3684/3753 [1:25:58<05:04,  4.42s/it] 98%|█████████▊| 3685/3753 [1:26:02<04:51,  4.29s/it] 98%|█████████▊| 3686/3753 [1:26:06<04:35,  4.11s/it] 98%|█████████▊| 3687/3753 [1:26:10<04:37,  4.21s/it] 98%|█████████▊| 3688/3753 [1:26:15<04:41,  4.33s/it] 98%|█████████▊| 3689/3753 [1:26:19<04:42,  4.41s/it] 98%|█████████▊| 3690/3753 [1:26:22<04:10,  3.97s/it]                                                     {'loss': 0.2879, 'grad_norm': 67.39092254638672, 'learning_rate': 6.201651030661892e-10, 'rewards/chosen': -3.833101272583008, 'rewards/rejected': -8.04983901977539, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 4.216738224029541, 'logps/chosen': -540.8297119140625, 'logps/rejected': -965.9461059570312, 'logits/chosen': 0.19292113184928894, 'logits/rejected': 0.40009474754333496, 'epoch': 0.98}
 98%|█████████▊| 3690/3753 [1:26:22<04:10,  3.97s/it] 98%|█████████▊| 3691/3753 [1:26:27<04:23,  4.25s/it] 98%|█████████▊| 3692/3753 [1:26:31<04:17,  4.23s/it] 98%|█████████▊| 3693/3753 [1:26:35<04:03,  4.06s/it] 98%|█████████▊| 3694/3753 [1:26:40<04:11,  4.26s/it] 98%|█████████▊| 3695/3753 [1:26:43<03:55,  4.06s/it] 98%|█████████▊| 3696/3753 [1:26:47<03:50,  4.04s/it] 99%|█████████▊| 3697/3753 [1:26:51<03:40,  3.93s/it] 99%|█████████▊| 3698/3753 [1:26:54<03:21,  3.66s/it] 99%|█████████▊| 3699/3753 [1:26:58<03:24,  3.78s/it] 99%|█████████▊| 3700/3753 [1:27:01<03:11,  3.60s/it]                                                     {'loss': 0.346, 'grad_norm': 133.325439453125, 'learning_rate': 4.41541834219622e-10, 'rewards/chosen': -3.511735439300537, 'rewards/rejected': -7.992352485656738, 'rewards/accuracies': 0.8374999761581421, 'rewards/margins': 4.480616569519043, 'logps/chosen': -505.5868225097656, 'logps/rejected': -958.2672119140625, 'logits/chosen': 0.07295414060354233, 'logits/rejected': 0.26416343450546265, 'epoch': 0.99}
 99%|█████████▊| 3700/3753 [1:27:01<03:11,  3.60s/it] 99%|█████████▊| 3701/3753 [1:27:06<03:19,  3.83s/it] 99%|█████████▊| 3702/3753 [1:27:10<03:16,  3.86s/it] 99%|█████████▊| 3703/3753 [1:27:14<03:16,  3.94s/it] 99%|█████████▊| 3704/3753 [1:27:18<03:13,  3.96s/it] 99%|█████████▊| 3705/3753 [1:27:22<03:10,  3.97s/it] 99%|█████████▊| 3706/3753 [1:27:26<03:07,  3.98s/it] 99%|█████████▉| 3707/3753 [1:27:29<02:57,  3.86s/it] 99%|█████████▉| 3708/3753 [1:27:34<03:05,  4.13s/it] 99%|█████████▉| 3709/3753 [1:27:40<03:26,  4.69s/it] 99%|█████████▉| 3710/3753 [1:27:45<03:27,  4.82s/it]                                                     {'loss': 0.3628, 'grad_norm': 37.10325241088867, 'learning_rate': 2.931705803735751e-10, 'rewards/chosen': -3.5383429527282715, 'rewards/rejected': -7.520556449890137, 'rewards/accuracies': 0.824999988079071, 'rewards/margins': 3.982213258743286, 'logps/chosen': -512.4487915039062, 'logps/rejected': -926.1826171875, 'logits/chosen': 0.14447511732578278, 'logits/rejected': 0.31640562415122986, 'epoch': 0.99}
 99%|█████████▉| 3710/3753 [1:27:45<03:27,  4.82s/it] 99%|█████████▉| 3711/3753 [1:27:49<03:07,  4.45s/it] 99%|█████████▉| 3712/3753 [1:27:53<02:59,  4.37s/it] 99%|█████████▉| 3713/3753 [1:27:57<02:50,  4.26s/it] 99%|█████████▉| 3714/3753 [1:28:02<02:56,  4.53s/it] 99%|█████████▉| 3715/3753 [1:28:06<02:44,  4.34s/it] 99%|█████████▉| 3716/3753 [1:28:10<02:35,  4.21s/it] 99%|█████████▉| 3717/3753 [1:28:13<02:21,  3.94s/it] 99%|█████████▉| 3718/3753 [1:28:17<02:16,  3.91s/it] 99%|█████████▉| 3719/3753 [1:28:21<02:13,  3.94s/it] 99%|█████████▉| 3720/3753 [1:28:28<02:37,  4.77s/it]                                                     {'loss': 0.2922, 'grad_norm': 159.02149963378906, 'learning_rate': 1.7506418209671803e-10, 'rewards/chosen': -3.8605799674987793, 'rewards/rejected': -9.31291389465332, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 5.452332496643066, 'logps/chosen': -543.2626953125, 'logps/rejected': -1091.2548828125, 'logits/chosen': 0.22364163398742676, 'logits/rejected': 0.39302128553390503, 'epoch': 0.99}
 99%|█████████▉| 3720/3753 [1:28:28<02:37,  4.77s/it] 99%|█████████▉| 3721/3753 [1:28:31<02:21,  4.42s/it] 99%|█████████▉| 3722/3753 [1:28:36<02:14,  4.34s/it] 99%|█████████▉| 3723/3753 [1:28:39<02:06,  4.21s/it] 99%|█████████▉| 3724/3753 [1:28:43<01:59,  4.11s/it] 99%|█████████▉| 3725/3753 [1:28:49<02:09,  4.62s/it] 99%|█████████▉| 3726/3753 [1:28:53<02:02,  4.55s/it] 99%|█████████▉| 3727/3753 [1:28:57<01:50,  4.25s/it] 99%|█████████▉| 3728/3753 [1:29:01<01:45,  4.22s/it] 99%|█████████▉| 3729/3753 [1:29:05<01:39,  4.16s/it] 99%|█████████▉| 3730/3753 [1:29:09<01:30,  3.93s/it]                                                     {'loss': 0.2407, 'grad_norm': 62.09672546386719, 'learning_rate': 8.72328607310735e-11, 'rewards/chosen': -3.862718105316162, 'rewards/rejected': -8.25365924835205, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 4.3909406661987305, 'logps/chosen': -553.1676025390625, 'logps/rejected': -1002.3092651367188, 'logits/chosen': 0.10279394686222076, 'logits/rejected': 0.25823506712913513, 'epoch': 0.99}
 99%|█████████▉| 3730/3753 [1:29:09<01:30,  3.93s/it] 99%|█████████▉| 3731/3753 [1:29:12<01:26,  3.92s/it] 99%|█████████▉| 3732/3753 [1:29:20<01:42,  4.90s/it] 99%|█████████▉| 3733/3753 [1:29:24<01:34,  4.72s/it] 99%|█████████▉| 3734/3753 [1:29:27<01:19,  4.19s/it]100%|█████████▉| 3735/3753 [1:29:31<01:15,  4.19s/it]100%|█████████▉| 3736/3753 [1:29:36<01:12,  4.28s/it]100%|█████████▉| 3737/3753 [1:29:40<01:06,  4.16s/it]100%|█████████▉| 3738/3753 [1:29:44<01:01,  4.12s/it]100%|█████████▉| 3739/3753 [1:29:47<00:56,  4.02s/it]100%|█████████▉| 3740/3753 [1:29:52<00:53,  4.15s/it]                                                     {'loss': 0.2545, 'grad_norm': 91.78945922851562, 'learning_rate': 2.968421750718653e-11, 'rewards/chosen': -3.878183364868164, 'rewards/rejected': -9.746116638183594, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.86793327331543, 'logps/chosen': -543.3421630859375, 'logps/rejected': -1133.0625, 'logits/chosen': 0.22555632889270782, 'logits/rejected': 0.43562421202659607, 'epoch': 1.0}
100%|█████████▉| 3740/3753 [1:29:52<00:53,  4.15s/it]100%|█████████▉| 3741/3753 [1:29:55<00:47,  3.95s/it]100%|█████████▉| 3742/3753 [1:30:00<00:46,  4.19s/it]100%|█████████▉| 3743/3753 [1:30:04<00:41,  4.13s/it]100%|█████████▉| 3744/3753 [1:30:08<00:37,  4.20s/it]100%|█████████▉| 3745/3753 [1:30:12<00:33,  4.14s/it]100%|█████████▉| 3746/3753 [1:30:16<00:28,  4.13s/it]100%|█████████▉| 3747/3753 [1:30:20<00:22,  3.80s/it]100%|█████████▉| 3748/3753 [1:30:23<00:18,  3.80s/it]100%|█████████▉| 3749/3753 [1:30:27<00:15,  3.84s/it]100%|█████████▉| 3750/3753 [1:30:35<00:15,  5.11s/it]                                                     {'loss': 0.4335, 'grad_norm': 51.39006805419922, 'learning_rate': 2.4232328864948193e-12, 'rewards/chosen': -4.47114372253418, 'rewards/rejected': -9.314947128295898, 'rewards/accuracies': 0.831250011920929, 'rewards/margins': 4.843804359436035, 'logps/chosen': -608.0093994140625, 'logps/rejected': -1090.45068359375, 'logits/chosen': 0.20796164870262146, 'logits/rejected': 0.40695667266845703, 'epoch': 1.0}
100%|█████████▉| 3750/3753 [1:30:35<00:15,  5.11s/it]100%|█████████▉| 3751/3753 [1:30:39<00:09,  4.68s/it]100%|█████████▉| 3752/3753 [1:30:43<00:04,  4.55s/it]100%|██████████| 3753/3753 [1:30:45<00:00,  3.72s/it]wandb: WARNING URL not available in offline run
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
                                                     {'train_runtime': 5503.7592, 'train_samples_per_second': 10.909, 'train_steps_per_second': 0.682, 'train_loss': 0.10442831711295189, 'epoch': 1.0}
100%|██████████| 3753/3753 [1:31:43<00:00,  3.72s/it]100%|██████████| 3753/3753 [1:31:43<00:00,  1.47s/it]
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /wandb/offline-run-20251028_202244-c4npz5zb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20251028_202244-c4npz5zb/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /wandb/offline-run-20251028_202244-qzf68761[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20251028_202244-qzf68761/logs[0m
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /wandb/offline-run-20251028_202244-k5oc4fr1[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20251028_202244-k5oc4fr1/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /wandb/offline-run-20251028_202244-6vk82zds[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20251028_202244-6vk82zds/logs[0m
[rank0]:[W1028 21:54:52.645147998 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
