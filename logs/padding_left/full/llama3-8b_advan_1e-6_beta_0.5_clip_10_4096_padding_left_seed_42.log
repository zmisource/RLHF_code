nohup: ignoring input
[W1202 10:54:07.998017083 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 42
设置随机种子为: 42
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 42
设置随机种子为: 42
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.62it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.49it/s]
加载作为参考的SFT模型 (Reference Model)...
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.80it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 98.25it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.62it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.73it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.81it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.52it/s]
[W1202 10:54:12.467382582 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1202 10:54:12.480607810 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1202 10:54:12.481129451 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1202 10:54:13.489928970 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...初始化 CustomSymPOTrainer...

初始化 CustomSymPOTrainer.../rlhf_code/code/implement_final_v3.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)

/rlhf_code/code/implement_final_v3.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
/rlhf_code/code/implement_final_v3.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /wandb/offline-run-20251202_105422-1tkr22we
  0%|          | 0/3753 [00:00<?, ?it/s]--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -44.5
Sample 0 - pi_logp_chosen:  -44.146331787109375
Difference: 0.353668212890625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -100.5
Sample 0 - pi_logp_chosen:  -100.34402465820312
Difference: 0.155975341796875
---------------------------------
Sample 0 - ref_logp_chosen: -112.0
Sample 0 - pi_logp_chosen:  -111.70196533203125
Difference: 0.29803466796875
---------------------------------
Sample 0 - ref_logp_chosen: -234.0
Sample 0 - pi_logp_chosen:  -233.57894897460938
Difference: 0.421051025390625
---------------------------------
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -65.5
Sample 0 - pi_logp_chosen:  -65.91077423095703
Difference: -0.41077423095703125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -209.0Sample 0 - ref_logp_chosen: -246.0

Sample 0 - pi_logp_chosen:  -246.4385986328125
Difference: -0.4385986328125
---------------------------------
Sample 0 - pi_logp_chosen:  -208.26136779785156
Difference: 0.7386322021484375
---------------------------------
Sample 0 - ref_logp_chosen: -380.0
Sample 0 - pi_logp_chosen:  -381.313720703125
Difference: -1.313720703125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -70.0
Sample 0 - pi_logp_chosen:  -70.18619537353516
Difference: -0.18619537353515625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -167.0
Sample 0 - pi_logp_chosen:  -167.149169921875
Difference: -0.149169921875
---------------------------------
Sample 0 - ref_logp_chosen: -350.0
Sample 0 - pi_logp_chosen:  -349.3069152832031
Difference: 0.693084716796875
---------------------------------
Sample 0 - ref_logp_chosen: -452.0
Sample 0 - pi_logp_chosen:  -453.64239501953125
Difference: -1.64239501953125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -81.5
Sample 0 - pi_logp_chosen:  -81.75975036621094
Difference: -0.2597503662109375
---------------------------------
Sample 0 - ref_logp_chosen: -98.5
Sample 0 - pi_logp_chosen:  -98.78225708007812
Difference: -0.282257080078125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -251.0
Sample 0 - pi_logp_chosen:  -249.6898956298828
Difference: 1.3101043701171875
---------------------------------
Sample 0 - ref_logp_chosen: -242.0
Sample 0 - pi_logp_chosen:  -241.97824096679688
Difference: 0.021759033203125
---------------------------------
  0%|          | 1/3753 [00:04<4:55:13,  4.72s/it]{'loss': -0.1159, 'grad_norm': 1902.8248291015625, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 2.1782100200653076, 'weight_chosen': 0.2668696641921997, 'weight_rejected': 0.4339325726032257, 'kl_term_chosen': 0.6550521850585938, 'kl_term_rejected': 0.389251708984375, 'epoch': 0.0002664890073284477}
                                                  {'loss': -0.1159, 'grad_norm': 1902.8248291015625, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 2.1782100200653076, 'weight_chosen': 0.2668696641921997, 'weight_rejected': 0.4339325726032257, 'kl_term_chosen': 0.6550521850585938, 'kl_term_rejected': 0.389251708984375, 'epoch': 0.0}
  0%|          | 1/3753 [00:04<4:55:13,  4.72s/it]  0%|          | 2/3753 [00:10<5:17:55,  5.09s/it]  0%|          | 3/3753 [00:14<5:06:14,  4.90s/it]  0%|          | 4/3753 [00:18<4:42:07,  4.52s/it]  0%|          | 5/3753 [00:22<4:35:44,  4.41s/it]  0%|          | 6/3753 [00:28<4:57:22,  4.76s/it]  0%|          | 7/3753 [00:32<4:44:53,  4.56s/it]  0%|          | 8/3753 [00:36<4:42:51,  4.53s/it]  0%|          | 9/3753 [00:40<4:24:33,  4.24s/it]  0%|          | 10/3753 [00:44<4:15:50,  4.10s/it]{'loss': -0.1159, 'grad_norm': 1843.7535400390625, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 1.178917407989502, 'mean_ratio_rejected': 0.5126004219055176, 'weight_chosen': 0.16278672218322754, 'weight_rejected': 0.08219262957572937, 'kl_term_chosen': 0.08229827880859375, 'kl_term_rejected': -0.33412933349609375, 'epoch': 0.002664890073284477}
                                                   {'loss': -0.1159, 'grad_norm': 1843.7535400390625, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 1.178917407989502, 'mean_ratio_rejected': 0.5126004219055176, 'weight_chosen': 0.16278672218322754, 'weight_rejected': 0.08219262957572937, 'kl_term_chosen': 0.08229827880859375, 'kl_term_rejected': -0.33412933349609375, 'epoch': 0.0}
  0%|          | 10/3753 [00:44<4:15:50,  4.10s/it]  0%|          | 11/3753 [00:48<4:22:53,  4.22s/it]  0%|          | 12/3753 [00:53<4:36:58,  4.44s/it]  0%|          | 13/3753 [00:58<4:34:13,  4.40s/it]  0%|          | 14/3753 [01:02<4:27:28,  4.29s/it]  0%|          | 15/3753 [01:05<4:17:03,  4.13s/it]  0%|          | 16/3753 [01:09<4:13:03,  4.06s/it]  0%|          | 17/3753 [01:13<4:08:18,  3.99s/it]  0%|          | 18/3753 [01:18<4:24:30,  4.25s/it]  1%|          | 19/3753 [01:21<4:07:47,  3.98s/it]  1%|          | 20/3753 [01:25<4:05:44,  3.95s/it]{'loss': 0.0472, 'grad_norm': 2142.10888671875, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 1.1432563066482544, 'mean_ratio_rejected': 1.5094813108444214, 'weight_chosen': 0.6656515002250671, 'weight_rejected': 0.5025372505187988, 'kl_term_chosen': 0.0669403076171875, 'kl_term_rejected': 0.20588302612304688, 'epoch': 0.005329780146568954}
                                                   {'loss': 0.0472, 'grad_norm': 2142.10888671875, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 1.1432563066482544, 'mean_ratio_rejected': 1.5094813108444214, 'weight_chosen': 0.6656515002250671, 'weight_rejected': 0.5025372505187988, 'kl_term_chosen': 0.0669403076171875, 'kl_term_rejected': 0.20588302612304688, 'epoch': 0.01}
  1%|          | 20/3753 [01:25<4:05:44,  3.95s/it]  1%|          | 21/3753 [01:29<4:08:31,  4.00s/it]  1%|          | 22/3753 [01:37<5:14:14,  5.05s/it]  1%|          | 23/3753 [01:42<5:13:41,  5.05s/it]  1%|          | 24/3753 [01:45<4:40:34,  4.51s/it]  1%|          | 25/3753 [01:49<4:34:44,  4.42s/it]  1%|          | 26/3753 [01:52<4:08:32,  4.00s/it]  1%|          | 27/3753 [01:56<4:08:31,  4.00s/it]  1%|          | 28/3753 [02:00<4:06:24,  3.97s/it]  1%|          | 29/3753 [02:04<4:03:28,  3.92s/it]  1%|          | 30/3753 [02:08<4:07:51,  3.99s/it]{'loss': -0.0739, 'grad_norm': 2600.516357421875, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 1.3610988855361938, 'mean_ratio_rejected': 1.092306137084961, 'weight_chosen': 0.4738050103187561, 'weight_rejected': 0.6429271101951599, 'kl_term_chosen': 0.1541461944580078, 'kl_term_rejected': 0.04414558410644531, 'epoch': 0.007994670219853431}
                                                   {'loss': -0.0739, 'grad_norm': 2600.516357421875, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 1.3610988855361938, 'mean_ratio_rejected': 1.092306137084961, 'weight_chosen': 0.4738050103187561, 'weight_rejected': 0.6429271101951599, 'kl_term_chosen': 0.1541461944580078, 'kl_term_rejected': 0.04414558410644531, 'epoch': 0.01}
  1%|          | 30/3753 [02:08<4:07:51,  3.99s/it]  1%|          | 31/3753 [02:13<4:30:55,  4.37s/it]  1%|          | 32/3753 [02:17<4:16:50,  4.14s/it]  1%|          | 33/3753 [02:21<4:06:50,  3.98s/it]  1%|          | 34/3753 [02:27<4:56:53,  4.79s/it]  1%|          | 35/3753 [02:33<5:11:48,  5.03s/it]  1%|          | 36/3753 [02:39<5:32:53,  5.37s/it]  1%|          | 37/3753 [02:45<5:39:26,  5.48s/it]  1%|          | 38/3753 [02:49<5:17:32,  5.13s/it]  1%|          | 39/3753 [02:57<6:13:10,  6.03s/it]  1%|          | 40/3753 [03:01<5:38:44,  5.47s/it]{'loss': 0.2211, 'grad_norm': 4174.72509765625, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 1.3986217975616455, 'mean_ratio_rejected': 1.2340251207351685, 'weight_chosen': 0.5900506973266602, 'weight_rejected': 0.23279331624507904, 'kl_term_chosen': 0.16774368286132812, 'kl_term_rejected': 0.10514068603515625, 'epoch': 0.010659560293137908}
                                                   {'loss': 0.2211, 'grad_norm': 4174.72509765625, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 1.3986217975616455, 'mean_ratio_rejected': 1.2340251207351685, 'weight_chosen': 0.5900506973266602, 'weight_rejected': 0.23279331624507904, 'kl_term_chosen': 0.16774368286132812, 'kl_term_rejected': 0.10514068603515625, 'epoch': 0.01}
  1%|          | 40/3753 [03:02<5:38:44,  5.47s/it]  1%|          | 41/3753 [03:08<5:59:48,  5.82s/it]  1%|          | 42/3753 [03:11<5:07:50,  4.98s/it]  1%|          | 43/3753 [03:16<5:01:56,  4.88s/it]  1%|          | 44/3753 [03:20<4:46:45,  4.64s/it]  1%|          | 45/3753 [03:25<4:52:54,  4.74s/it]  1%|          | 46/3753 [03:30<4:57:14,  4.81s/it]  1%|▏         | 47/3753 [03:33<4:22:26,  4.25s/it]  1%|▏         | 48/3753 [03:37<4:18:28,  4.19s/it]  1%|▏         | 49/3753 [03:41<4:22:03,  4.25s/it]  1%|▏         | 50/3753 [03:45<4:15:24,  4.14s/it]{'loss': 0.2649, 'grad_norm': 1794.249267578125, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 1.077202558517456, 'mean_ratio_rejected': 1.551041603088379, 'weight_chosen': 0.8262078762054443, 'weight_rejected': 0.9045706987380981, 'kl_term_chosen': 0.03718376159667969, 'kl_term_rejected': 0.21946334838867188, 'epoch': 0.013324450366422385}
                                                   {'loss': 0.2649, 'grad_norm': 1794.249267578125, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 1.077202558517456, 'mean_ratio_rejected': 1.551041603088379, 'weight_chosen': 0.8262078762054443, 'weight_rejected': 0.9045706987380981, 'kl_term_chosen': 0.03718376159667969, 'kl_term_rejected': 0.21946334838867188, 'epoch': 0.01}
  1%|▏         | 50/3753 [03:45<4:15:24,  4.14s/it]  1%|▏         | 51/3753 [03:49<4:15:13,  4.14s/it]  1%|▏         | 52/3753 [03:54<4:25:11,  4.30s/it]  1%|▏         | 53/3753 [04:00<4:53:30,  4.76s/it]  1%|▏         | 54/3753 [04:03<4:29:39,  4.37s/it]  1%|▏         | 55/3753 [04:11<5:34:57,  5.43s/it]  1%|▏         | 56/3753 [04:19<6:19:08,  6.15s/it]  2%|▏         | 57/3753 [04:24<5:52:27,  5.72s/it]  2%|▏         | 58/3753 [04:27<5:10:20,  5.04s/it]  2%|▏         | 59/3753 [04:35<5:56:49,  5.80s/it]  2%|▏         | 60/3753 [04:38<5:07:42,  5.00s/it]{'loss': 0.2104, 'grad_norm': 2085.209228515625, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 0.6837954521179199, 'mean_ratio_rejected': 0.9249616861343384, 'weight_chosen': 0.2202628254890442, 'weight_rejected': 0.898209273815155, 'kl_term_chosen': -0.1900482177734375, 'kl_term_rejected': -0.03900146484375, 'epoch': 0.015989340439706862}
                                                   {'loss': 0.2104, 'grad_norm': 2085.209228515625, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 0.6837954521179199, 'mean_ratio_rejected': 0.9249616861343384, 'weight_chosen': 0.2202628254890442, 'weight_rejected': 0.898209273815155, 'kl_term_chosen': -0.1900482177734375, 'kl_term_rejected': -0.03900146484375, 'epoch': 0.02}
  2%|▏         | 60/3753 [04:38<5:07:42,  5.00s/it]  2%|▏         | 61/3753 [04:43<5:16:53,  5.15s/it]  2%|▏         | 62/3753 [04:48<5:01:29,  4.90s/it]  2%|▏         | 63/3753 [04:52<4:52:54,  4.76s/it]  2%|▏         | 64/3753 [04:57<5:02:11,  4.92s/it]  2%|▏         | 65/3753 [05:01<4:43:20,  4.61s/it]  2%|▏         | 66/3753 [05:06<4:46:32,  4.66s/it]  2%|▏         | 67/3753 [05:11<4:48:31,  4.70s/it]  2%|▏         | 68/3753 [05:14<4:30:33,  4.41s/it]  2%|▏         | 69/3753 [05:19<4:33:13,  4.45s/it]  2%|▏         | 70/3753 [05:23<4:19:02,  4.22s/it]{'loss': 0.0406, 'grad_norm': 2153.125, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.1325606107711792, 'weight_chosen': -0.49932438135147095, 'weight_rejected': 0.10692146420478821, 'kl_term_chosen': 1.462554931640625, 'kl_term_rejected': 0.0622406005859375, 'epoch': 0.018654230512991338}
                                                   {'loss': 0.0406, 'grad_norm': 2153.125, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.1325606107711792, 'weight_chosen': -0.49932438135147095, 'weight_rejected': 0.10692146420478821, 'kl_term_chosen': 1.462554931640625, 'kl_term_rejected': 0.0622406005859375, 'epoch': 0.02}
  2%|▏         | 70/3753 [05:23<4:19:02,  4.22s/it]  2%|▏         | 71/3753 [05:27<4:28:05,  4.37s/it]  2%|▏         | 72/3753 [05:32<4:32:38,  4.44s/it]  2%|▏         | 73/3753 [05:36<4:20:56,  4.25s/it]  2%|▏         | 74/3753 [05:40<4:11:19,  4.10s/it]  2%|▏         | 75/3753 [05:43<4:02:52,  3.96s/it]  2%|▏         | 76/3753 [05:49<4:34:48,  4.48s/it]  2%|▏         | 77/3753 [05:52<4:08:25,  4.05s/it]  2%|▏         | 78/3753 [05:57<4:30:35,  4.42s/it]  2%|▏         | 79/3753 [06:02<4:28:22,  4.38s/it]  2%|▏         | 80/3753 [06:06<4:38:33,  4.55s/it]{'loss': 0.2257, 'grad_norm': 3878.9189453125, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 1.6206235885620117, 'mean_ratio_rejected': 2.3976128101348877, 'weight_chosen': 0.6870033144950867, 'weight_rejected': 0.539541482925415, 'kl_term_chosen': 0.24140548706054688, 'kl_term_rejected': 0.4372367858886719, 'epoch': 0.021319120586275817}
                                                   {'loss': 0.2257, 'grad_norm': 3878.9189453125, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 1.6206235885620117, 'mean_ratio_rejected': 2.3976128101348877, 'weight_chosen': 0.6870033144950867, 'weight_rejected': 0.539541482925415, 'kl_term_chosen': 0.24140548706054688, 'kl_term_rejected': 0.4372367858886719, 'epoch': 0.02}
  2%|▏         | 80/3753 [06:07<4:38:33,  4.55s/it]  2%|▏         | 81/3753 [06:11<4:42:05,  4.61s/it]  2%|▏         | 82/3753 [06:15<4:27:22,  4.37s/it]  2%|▏         | 83/3753 [06:22<5:12:59,  5.12s/it]  2%|▏         | 84/3753 [06:27<5:06:23,  5.01s/it]  2%|▏         | 85/3753 [06:30<4:38:31,  4.56s/it]  2%|▏         | 86/3753 [06:34<4:16:43,  4.20s/it]  2%|▏         | 87/3753 [06:40<5:06:31,  5.02s/it]  2%|▏         | 88/3753 [06:44<4:43:56,  4.65s/it]  2%|▏         | 89/3753 [06:49<4:41:49,  4.61s/it]  2%|▏         | 90/3753 [06:53<4:31:30,  4.45s/it]{'loss': 0.2078, 'grad_norm': 7244.94189453125, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 4.466396808624268, 'mean_ratio_rejected': 0.7522639632225037, 'weight_chosen': 0.04094266891479492, 'weight_rejected': 0.007694825530052185, 'kl_term_chosen': 0.748291015625, 'kl_term_rejected': -0.142333984375, 'epoch': 0.023984010659560292}
                                                   {'loss': 0.2078, 'grad_norm': 7244.94189453125, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 4.466396808624268, 'mean_ratio_rejected': 0.7522639632225037, 'weight_chosen': 0.04094266891479492, 'weight_rejected': 0.007694825530052185, 'kl_term_chosen': 0.748291015625, 'kl_term_rejected': -0.142333984375, 'epoch': 0.02}
  2%|▏         | 90/3753 [06:53<4:31:30,  4.45s/it]  2%|▏         | 91/3753 [06:56<4:10:31,  4.10s/it]  2%|▏         | 92/3753 [07:00<4:07:36,  4.06s/it]  2%|▏         | 93/3753 [07:06<4:35:11,  4.51s/it]  3%|▎         | 94/3753 [07:10<4:22:45,  4.31s/it]  3%|▎         | 95/3753 [07:16<5:06:35,  5.03s/it]  3%|▎         | 96/3753 [07:20<4:48:08,  4.73s/it]  3%|▎         | 97/3753 [07:24<4:39:06,  4.58s/it]  3%|▎         | 98/3753 [07:30<5:01:06,  4.94s/it]  3%|▎         | 99/3753 [07:34<4:33:44,  4.49s/it]  3%|▎         | 100/3753 [07:38<4:21:15,  4.29s/it]{'loss': 0.1362, 'grad_norm': 1799.130126953125, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 0.4052760899066925, 'mean_ratio_rejected': 1.038527250289917, 'weight_chosen': 1.0795445442199707, 'weight_rejected': 0.16305068135261536, 'kl_term_chosen': -0.45159339904785156, 'kl_term_rejected': 0.018901824951171875, 'epoch': 0.02664890073284477}
                                                    {'loss': 0.1362, 'grad_norm': 1799.130126953125, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 0.4052760899066925, 'mean_ratio_rejected': 1.038527250289917, 'weight_chosen': 1.0795445442199707, 'weight_rejected': 0.16305068135261536, 'kl_term_chosen': -0.45159339904785156, 'kl_term_rejected': 0.018901824951171875, 'epoch': 0.03}
  3%|▎         | 100/3753 [07:38<4:21:15,  4.29s/it]  3%|▎         | 101/3753 [07:42<4:24:40,  4.35s/it]  3%|▎         | 102/3753 [07:46<4:20:35,  4.28s/it]  3%|▎         | 103/3753 [07:50<4:10:12,  4.11s/it]  3%|▎         | 104/3753 [07:56<4:38:12,  4.57s/it]  3%|▎         | 105/3753 [08:00<4:32:38,  4.48s/it]  3%|▎         | 106/3753 [08:05<4:48:12,  4.74s/it]  3%|▎         | 107/3753 [08:10<4:46:06,  4.71s/it]  3%|▎         | 108/3753 [08:14<4:33:12,  4.50s/it]  3%|▎         | 109/3753 [08:18<4:22:45,  4.33s/it]  3%|▎         | 110/3753 [08:22<4:15:28,  4.21s/it]{'loss': 0.2817, 'grad_norm': 1570.6650390625, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 3.2285075187683105, 'mean_ratio_rejected': 1.3929033279418945, 'weight_chosen': 0.3276665210723877, 'weight_rejected': 0.2071574628353119, 'kl_term_chosen': 0.5860099792480469, 'kl_term_rejected': 0.1656951904296875, 'epoch': 0.029313790806129246}
                                                    {'loss': 0.2817, 'grad_norm': 1570.6650390625, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 3.2285075187683105, 'mean_ratio_rejected': 1.3929033279418945, 'weight_chosen': 0.3276665210723877, 'weight_rejected': 0.2071574628353119, 'kl_term_chosen': 0.5860099792480469, 'kl_term_rejected': 0.1656951904296875, 'epoch': 0.03}
  3%|▎         | 110/3753 [08:22<4:15:28,  4.21s/it]  3%|▎         | 111/3753 [08:27<4:44:31,  4.69s/it]  3%|▎         | 112/3753 [08:31<4:25:30,  4.38s/it]  3%|▎         | 113/3753 [08:34<4:06:05,  4.06s/it]  3%|▎         | 114/3753 [08:38<3:57:03,  3.91s/it]  3%|▎         | 115/3753 [08:42<3:55:20,  3.88s/it]  3%|▎         | 116/3753 [08:46<4:10:18,  4.13s/it]  3%|▎         | 117/3753 [08:51<4:08:56,  4.11s/it]  3%|▎         | 118/3753 [08:55<4:13:24,  4.18s/it]  3%|▎         | 119/3753 [09:03<5:21:21,  5.31s/it]  3%|▎         | 120/3753 [09:07<5:05:36,  5.05s/it]{'loss': 0.2127, 'grad_norm': 1571.6334228515625, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 0.6963730454444885, 'mean_ratio_rejected': 0.3440202474594116, 'weight_chosen': 1.0174894332885742, 'weight_rejected': -0.038501590490341187, 'kl_term_chosen': -0.18093490600585938, 'kl_term_rejected': -0.5335273742675781, 'epoch': 0.031978680879413725}
                                                    {'loss': 0.2127, 'grad_norm': 1571.6334228515625, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 0.6963730454444885, 'mean_ratio_rejected': 0.3440202474594116, 'weight_chosen': 1.0174894332885742, 'weight_rejected': -0.038501590490341187, 'kl_term_chosen': -0.18093490600585938, 'kl_term_rejected': -0.5335273742675781, 'epoch': 0.03}
  3%|▎         | 120/3753 [09:07<5:05:36,  5.05s/it]  3%|▎         | 121/3753 [09:12<4:51:29,  4.82s/it]  3%|▎         | 122/3753 [09:16<4:49:15,  4.78s/it]  3%|▎         | 123/3753 [09:20<4:39:05,  4.61s/it]  3%|▎         | 124/3753 [09:24<4:24:09,  4.37s/it]  3%|▎         | 125/3753 [09:29<4:30:36,  4.48s/it]  3%|▎         | 126/3753 [09:34<4:38:55,  4.61s/it]  3%|▎         | 127/3753 [09:38<4:20:52,  4.32s/it]  3%|▎         | 128/3753 [09:42<4:28:26,  4.44s/it]  3%|▎         | 129/3753 [09:48<4:50:08,  4.80s/it]  3%|▎         | 130/3753 [09:52<4:45:23,  4.73s/it]{'loss': 0.457, 'grad_norm': 4221.52734375, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 2.911755323410034, 'mean_ratio_rejected': 0.6484648585319519, 'weight_chosen': -0.23690813779830933, 'weight_rejected': -0.10686793178319931, 'kl_term_chosen': 0.5343780517578125, 'kl_term_rejected': -0.21657371520996094, 'epoch': 0.034643570952698204}
                                                    {'loss': 0.457, 'grad_norm': 4221.52734375, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 2.911755323410034, 'mean_ratio_rejected': 0.6484648585319519, 'weight_chosen': -0.23690813779830933, 'weight_rejected': -0.10686793178319931, 'kl_term_chosen': 0.5343780517578125, 'kl_term_rejected': -0.21657371520996094, 'epoch': 0.03}
  3%|▎         | 130/3753 [09:53<4:45:23,  4.73s/it]  3%|▎         | 131/3753 [09:56<4:30:41,  4.48s/it]  4%|▎         | 132/3753 [10:00<4:08:51,  4.12s/it]  4%|▎         | 133/3753 [10:04<4:19:43,  4.30s/it]  4%|▎         | 134/3753 [10:09<4:22:38,  4.35s/it]  4%|▎         | 135/3753 [10:13<4:11:13,  4.17s/it]  4%|▎         | 136/3753 [10:16<3:59:43,  3.98s/it]  4%|▎         | 137/3753 [10:20<3:55:08,  3.90s/it]  4%|▎         | 138/3753 [10:24<4:06:12,  4.09s/it]  4%|▎         | 139/3753 [10:28<4:03:31,  4.04s/it]  4%|▎         | 140/3753 [10:33<4:18:05,  4.29s/it]{'loss': 0.1169, 'grad_norm': 1997.98876953125, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 3.275273323059082, 'mean_ratio_rejected': 1.549208402633667, 'weight_chosen': 0.266463041305542, 'weight_rejected': 0.3659365773200989, 'kl_term_chosen': 0.59320068359375, 'kl_term_rejected': 0.2188720703125, 'epoch': 0.037308461025982675}
                                                    {'loss': 0.1169, 'grad_norm': 1997.98876953125, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 3.275273323059082, 'mean_ratio_rejected': 1.549208402633667, 'weight_chosen': 0.266463041305542, 'weight_rejected': 0.3659365773200989, 'kl_term_chosen': 0.59320068359375, 'kl_term_rejected': 0.2188720703125, 'epoch': 0.04}
  4%|▎         | 140/3753 [10:33<4:18:05,  4.29s/it]  4%|▍         | 141/3753 [10:37<4:09:57,  4.15s/it]  4%|▍         | 142/3753 [10:44<4:53:22,  4.87s/it]  4%|▍         | 143/3753 [10:48<4:39:23,  4.64s/it]  4%|▍         | 144/3753 [10:54<5:01:25,  5.01s/it]  4%|▍         | 145/3753 [11:01<5:47:07,  5.77s/it]  4%|▍         | 146/3753 [11:06<5:35:18,  5.58s/it]  4%|▍         | 147/3753 [11:13<5:59:34,  5.98s/it]  4%|▍         | 148/3753 [11:18<5:43:20,  5.71s/it]  4%|▍         | 149/3753 [11:22<5:12:15,  5.20s/it]  4%|▍         | 150/3753 [11:29<5:40:58,  5.68s/it]{'loss': 0.5383, 'grad_norm': 1772.25439453125, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 0.19183434545993805, 'mean_ratio_rejected': 0.4709559679031372, 'weight_chosen': 1.1610212326049805, 'weight_rejected': 0.21381163597106934, 'kl_term_chosen': -0.8255615234375, 'kl_term_rejected': -0.376495361328125, 'epoch': 0.039973351099267154}
                                                    {'loss': 0.5383, 'grad_norm': 1772.25439453125, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 0.19183434545993805, 'mean_ratio_rejected': 0.4709559679031372, 'weight_chosen': 1.1610212326049805, 'weight_rejected': 0.21381163597106934, 'kl_term_chosen': -0.8255615234375, 'kl_term_rejected': -0.376495361328125, 'epoch': 0.04}
  4%|▍         | 150/3753 [11:29<5:40:58,  5.68s/it]  4%|▍         | 151/3753 [11:34<5:33:31,  5.56s/it]  4%|▍         | 152/3753 [11:38<5:03:29,  5.06s/it]  4%|▍         | 153/3753 [11:43<4:59:35,  4.99s/it]  4%|▍         | 154/3753 [11:47<4:47:39,  4.80s/it]  4%|▍         | 155/3753 [11:52<4:40:14,  4.67s/it]  4%|▍         | 156/3753 [11:56<4:34:31,  4.58s/it]  4%|▍         | 157/3753 [12:00<4:20:14,  4.34s/it]  4%|▍         | 158/3753 [12:05<4:27:35,  4.47s/it]  4%|▍         | 159/3753 [12:09<4:20:05,  4.34s/it]  4%|▍         | 160/3753 [12:13<4:25:10,  4.43s/it]{'loss': 0.2231, 'grad_norm': 2851.899169921875, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 1.4384024143218994, 'mean_ratio_rejected': 1.631901741027832, 'weight_chosen': 0.49826276302337646, 'weight_rejected': 0.5820765495300293, 'kl_term_chosen': 0.18176651000976562, 'kl_term_rejected': 0.244873046875, 'epoch': 0.04263824117255163}
                                                    {'loss': 0.2231, 'grad_norm': 2851.899169921875, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 1.4384024143218994, 'mean_ratio_rejected': 1.631901741027832, 'weight_chosen': 0.49826276302337646, 'weight_rejected': 0.5820765495300293, 'kl_term_chosen': 0.18176651000976562, 'kl_term_rejected': 0.244873046875, 'epoch': 0.04}
  4%|▍         | 160/3753 [12:13<4:25:10,  4.43s/it]  4%|▍         | 161/3753 [12:17<4:18:03,  4.31s/it]  4%|▍         | 162/3753 [12:22<4:15:32,  4.27s/it]  4%|▍         | 163/3753 [12:25<3:59:35,  4.00s/it]  4%|▍         | 164/3753 [12:32<4:48:56,  4.83s/it]  4%|▍         | 165/3753 [12:38<5:22:04,  5.39s/it]  4%|▍         | 166/3753 [12:42<4:50:10,  4.85s/it]  4%|▍         | 167/3753 [12:47<4:54:17,  4.92s/it]  4%|▍         | 168/3753 [12:52<5:00:18,  5.03s/it]  5%|▍         | 169/3753 [12:56<4:32:25,  4.56s/it]  5%|▍         | 170/3753 [12:59<4:09:57,  4.19s/it]{'loss': 0.4914, 'grad_norm': 1654.6746826171875, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 1.0540531873703003, 'mean_ratio_rejected': 2.277942657470703, 'weight_chosen': 0.8460259437561035, 'weight_rejected': 0.5473259091377258, 'kl_term_chosen': 0.0263214111328125, 'kl_term_rejected': 0.4116363525390625, 'epoch': 0.04530313124583611}
                                                    {'loss': 0.4914, 'grad_norm': 1654.6746826171875, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 1.0540531873703003, 'mean_ratio_rejected': 2.277942657470703, 'weight_chosen': 0.8460259437561035, 'weight_rejected': 0.5473259091377258, 'kl_term_chosen': 0.0263214111328125, 'kl_term_rejected': 0.4116363525390625, 'epoch': 0.05}
  5%|▍         | 170/3753 [12:59<4:09:57,  4.19s/it]  5%|▍         | 171/3753 [13:04<4:16:10,  4.29s/it]  5%|▍         | 172/3753 [13:12<5:34:41,  5.61s/it]  5%|▍         | 173/3753 [13:16<5:00:29,  5.04s/it]  5%|▍         | 174/3753 [13:20<4:48:05,  4.83s/it]  5%|▍         | 175/3753 [13:25<4:40:58,  4.71s/it]  5%|▍         | 176/3753 [13:28<4:21:34,  4.39s/it]  5%|▍         | 177/3753 [13:33<4:24:46,  4.44s/it]  5%|▍         | 178/3753 [13:38<4:32:44,  4.58s/it]  5%|▍         | 179/3753 [13:41<4:14:26,  4.27s/it]  5%|▍         | 180/3753 [13:46<4:14:22,  4.27s/it]{'loss': 0.3985, 'grad_norm': 3603.126953125, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 6.812728404998779, 'mean_ratio_rejected': 1.7451740503311157, 'weight_chosen': -0.024049878120422363, 'weight_rejected': 0.37111490964889526, 'kl_term_chosen': 0.9593963623046875, 'kl_term_rejected': 0.2784271240234375, 'epoch': 0.047968021319120584}
                                                    {'loss': 0.3985, 'grad_norm': 3603.126953125, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 6.812728404998779, 'mean_ratio_rejected': 1.7451740503311157, 'weight_chosen': -0.024049878120422363, 'weight_rejected': 0.37111490964889526, 'kl_term_chosen': 0.9593963623046875, 'kl_term_rejected': 0.2784271240234375, 'epoch': 0.05}
  5%|▍         | 180/3753 [13:46<4:14:22,  4.27s/it]  5%|▍         | 181/3753 [13:50<4:19:18,  4.36s/it]  5%|▍         | 182/3753 [13:57<5:06:14,  5.15s/it]  5%|▍         | 183/3753 [14:02<4:59:17,  5.03s/it]  5%|▍         | 184/3753 [14:08<5:07:24,  5.17s/it]  5%|▍         | 185/3753 [14:12<5:02:13,  5.08s/it]  5%|▍         | 186/3753 [14:16<4:43:31,  4.77s/it]  5%|▍         | 187/3753 [14:20<4:28:53,  4.52s/it]  5%|▌         | 188/3753 [14:25<4:23:24,  4.43s/it]  5%|▌         | 189/3753 [14:32<5:10:27,  5.23s/it]  5%|▌         | 190/3753 [14:36<4:54:00,  4.95s/it]{'loss': 0.5956, 'grad_norm': 4894.9921875, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 0.3723408579826355, 'mean_ratio_rejected': 0.18926410377025604, 'weight_chosen': 1.374769926071167, 'weight_rejected': -0.7472068667411804, 'kl_term_chosen': -0.4939727783203125, 'kl_term_rejected': -0.832305908203125, 'epoch': 0.05063291139240506}
                                                    {'loss': 0.5956, 'grad_norm': 4894.9921875, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 0.3723408579826355, 'mean_ratio_rejected': 0.18926410377025604, 'weight_chosen': 1.374769926071167, 'weight_rejected': -0.7472068667411804, 'kl_term_chosen': -0.4939727783203125, 'kl_term_rejected': -0.832305908203125, 'epoch': 0.05}
  5%|▌         | 190/3753 [14:36<4:54:00,  4.95s/it]  5%|▌         | 191/3753 [14:40<4:31:17,  4.57s/it]  5%|▌         | 192/3753 [14:47<5:21:37,  5.42s/it]  5%|▌         | 193/3753 [14:52<5:03:20,  5.11s/it]  5%|▌         | 194/3753 [14:57<5:05:26,  5.15s/it]  5%|▌         | 195/3753 [15:01<4:47:23,  4.85s/it]  5%|▌         | 196/3753 [15:04<4:23:14,  4.44s/it]  5%|▌         | 197/3753 [15:13<5:40:11,  5.74s/it]  5%|▌         | 198/3753 [15:17<5:07:14,  5.19s/it]  5%|▌         | 199/3753 [15:23<5:14:58,  5.32s/it]  5%|▌         | 200/3753 [15:27<4:56:26,  5.01s/it]{'loss': 1.0362, 'grad_norm': 4880.0556640625, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.6259177327156067, 'weight_chosen': -0.780788779258728, 'weight_rejected': -0.17844504117965698, 'kl_term_chosen': 1.7241363525390625, 'kl_term_rejected': -0.2342681884765625, 'epoch': 0.05329780146568954}
                                                    {'loss': 1.0362, 'grad_norm': 4880.0556640625, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.6259177327156067, 'weight_chosen': -0.780788779258728, 'weight_rejected': -0.17844504117965698, 'kl_term_chosen': 1.7241363525390625, 'kl_term_rejected': -0.2342681884765625, 'epoch': 0.05}
  5%|▌         | 200/3753 [15:27<4:56:26,  5.01s/it]  5%|▌         | 201/3753 [15:33<5:23:12,  5.46s/it]  5%|▌         | 202/3753 [15:37<4:57:11,  5.02s/it]  5%|▌         | 203/3753 [15:42<4:55:21,  4.99s/it]  5%|▌         | 204/3753 [15:46<4:31:11,  4.58s/it]  5%|▌         | 205/3753 [15:50<4:24:28,  4.47s/it]  5%|▌         | 206/3753 [15:56<4:55:50,  5.00s/it]  6%|▌         | 207/3753 [16:01<4:40:08,  4.74s/it]  6%|▌         | 208/3753 [16:06<4:48:22,  4.88s/it]  6%|▌         | 209/3753 [16:11<4:47:23,  4.87s/it]  6%|▌         | 210/3753 [16:15<4:42:53,  4.79s/it]{'loss': 1.1398, 'grad_norm': 2351.09375, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 1.0522050857543945, 'mean_ratio_rejected': 3.029594898223877, 'weight_chosen': 0.793292760848999, 'weight_rejected': 0.7072566151618958, 'kl_term_chosen': 0.02544403076171875, 'kl_term_rejected': 0.5542144775390625, 'epoch': 0.05596269153897402}
                                                    {'loss': 1.1398, 'grad_norm': 2351.09375, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 1.0522050857543945, 'mean_ratio_rejected': 3.029594898223877, 'weight_chosen': 0.793292760848999, 'weight_rejected': 0.7072566151618958, 'kl_term_chosen': 0.02544403076171875, 'kl_term_rejected': 0.5542144775390625, 'epoch': 0.06}
  6%|▌         | 210/3753 [16:15<4:42:53,  4.79s/it]  6%|▌         | 211/3753 [16:21<4:55:13,  5.00s/it]  6%|▌         | 212/3753 [16:24<4:26:48,  4.52s/it]  6%|▌         | 213/3753 [16:29<4:27:55,  4.54s/it]  6%|▌         | 214/3753 [16:34<4:47:23,  4.87s/it]  6%|▌         | 215/3753 [16:38<4:32:28,  4.62s/it]  6%|▌         | 216/3753 [16:43<4:30:38,  4.59s/it]  6%|▌         | 217/3753 [16:47<4:17:17,  4.37s/it]  6%|▌         | 218/3753 [16:51<4:20:07,  4.42s/it]  6%|▌         | 219/3753 [16:55<4:07:45,  4.21s/it]  6%|▌         | 220/3753 [16:59<3:59:36,  4.07s/it]{'loss': 0.514, 'grad_norm': 6897.18505859375, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 3.1574506759643555, 'mean_ratio_rejected': 1.3310863971710205, 'weight_chosen': 0.10684430599212646, 'weight_rejected': 0.26302337646484375, 'kl_term_chosen': 0.5748825073242188, 'kl_term_rejected': 0.14299774169921875, 'epoch': 0.05862758161225849}
                                                    {'loss': 0.514, 'grad_norm': 6897.18505859375, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 3.1574506759643555, 'mean_ratio_rejected': 1.3310863971710205, 'weight_chosen': 0.10684430599212646, 'weight_rejected': 0.26302337646484375, 'kl_term_chosen': 0.5748825073242188, 'kl_term_rejected': 0.14299774169921875, 'epoch': 0.06}
  6%|▌         | 220/3753 [16:59<3:59:36,  4.07s/it]  6%|▌         | 221/3753 [17:02<3:52:45,  3.95s/it]  6%|▌         | 222/3753 [17:07<4:01:32,  4.10s/it]  6%|▌         | 223/3753 [17:10<3:50:05,  3.91s/it]  6%|▌         | 224/3753 [17:14<3:50:23,  3.92s/it]  6%|▌         | 225/3753 [17:18<3:55:10,  4.00s/it]  6%|▌         | 226/3753 [17:22<3:53:10,  3.97s/it]  6%|▌         | 227/3753 [17:28<4:15:20,  4.34s/it]  6%|▌         | 228/3753 [17:31<4:03:28,  4.14s/it]  6%|▌         | 229/3753 [17:36<4:13:32,  4.32s/it]  6%|▌         | 230/3753 [17:42<4:51:27,  4.96s/it]{'loss': 0.7837, 'grad_norm': 2817.213623046875, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 3.06783390045166, 'mean_ratio_rejected': 0.4859946668148041, 'weight_chosen': 0.3767249584197998, 'weight_rejected': -0.2117435187101364, 'kl_term_chosen': 0.56048583984375, 'kl_term_rejected': -0.36077880859375, 'epoch': 0.06129247168554297}
                                                    {'loss': 0.7837, 'grad_norm': 2817.213623046875, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 3.06783390045166, 'mean_ratio_rejected': 0.4859946668148041, 'weight_chosen': 0.3767249584197998, 'weight_rejected': -0.2117435187101364, 'kl_term_chosen': 0.56048583984375, 'kl_term_rejected': -0.36077880859375, 'epoch': 0.06}
  6%|▌         | 230/3753 [17:43<4:51:27,  4.96s/it]  6%|▌         | 231/3753 [17:48<5:04:05,  5.18s/it]  6%|▌         | 232/3753 [17:52<4:49:03,  4.93s/it]  6%|▌         | 233/3753 [17:57<4:47:50,  4.91s/it]  6%|▌         | 234/3753 [18:03<4:54:16,  5.02s/it]  6%|▋         | 235/3753 [18:11<5:56:53,  6.09s/it]  6%|▋         | 236/3753 [18:15<5:24:16,  5.53s/it]  6%|▋         | 237/3753 [18:19<4:47:52,  4.91s/it]  6%|▋         | 238/3753 [18:24<4:43:16,  4.84s/it]  6%|▋         | 239/3753 [18:28<4:44:23,  4.86s/it]  6%|▋         | 240/3753 [18:33<4:37:34,  4.74s/it]{'loss': 2.3727, 'grad_norm': 10713.8759765625, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 0.9335685968399048, 'mean_ratio_rejected': 0.2281985878944397, 'weight_chosen': 0.8655134439468384, 'weight_rejected': -0.5609586834907532, 'kl_term_chosen': -0.03437042236328125, 'kl_term_rejected': -0.73876953125, 'epoch': 0.06395736175882745}
                                                    {'loss': 2.3727, 'grad_norm': 10713.8759765625, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 0.9335685968399048, 'mean_ratio_rejected': 0.2281985878944397, 'weight_chosen': 0.8655134439468384, 'weight_rejected': -0.5609586834907532, 'kl_term_chosen': -0.03437042236328125, 'kl_term_rejected': -0.73876953125, 'epoch': 0.06}
  6%|▋         | 240/3753 [18:33<4:37:34,  4.74s/it]  6%|▋         | 241/3753 [18:37<4:25:32,  4.54s/it]  6%|▋         | 242/3753 [18:41<4:18:40,  4.42s/it]  6%|▋         | 243/3753 [18:46<4:22:22,  4.49s/it]  7%|▋         | 244/3753 [18:52<4:47:26,  4.92s/it]  7%|▋         | 245/3753 [18:56<4:42:40,  4.83s/it]  7%|▋         | 246/3753 [19:00<4:20:43,  4.46s/it]  7%|▋         | 247/3753 [19:07<5:06:20,  5.24s/it]  7%|▋         | 248/3753 [19:12<5:00:52,  5.15s/it]  7%|▋         | 249/3753 [19:17<5:06:00,  5.24s/it]  7%|▋         | 250/3753 [19:23<5:04:20,  5.21s/it]{'loss': 0.6642, 'grad_norm': 5365.89404296875, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 8.017195701599121, 'mean_ratio_rejected': 0.8782251477241516, 'weight_chosen': -0.14600491523742676, 'weight_rejected': 0.08312104642391205, 'kl_term_chosen': 1.0407943725585938, 'kl_term_rejected': -0.0649261474609375, 'epoch': 0.06662225183211193}
                                                    {'loss': 0.6642, 'grad_norm': 5365.89404296875, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 8.017195701599121, 'mean_ratio_rejected': 0.8782251477241516, 'weight_chosen': -0.14600491523742676, 'weight_rejected': 0.08312104642391205, 'kl_term_chosen': 1.0407943725585938, 'kl_term_rejected': -0.0649261474609375, 'epoch': 0.07}
  7%|▋         | 250/3753 [19:23<5:04:20,  5.21s/it]  7%|▋         | 251/3753 [19:29<5:30:32,  5.66s/it]  7%|▋         | 252/3753 [19:34<5:19:57,  5.48s/it]  7%|▋         | 253/3753 [19:39<5:05:46,  5.24s/it]  7%|▋         | 254/3753 [19:43<4:38:07,  4.77s/it]  7%|▋         | 255/3753 [19:47<4:23:00,  4.51s/it]  7%|▋         | 256/3753 [19:50<4:07:01,  4.24s/it]  7%|▋         | 257/3753 [19:55<4:11:33,  4.32s/it]  7%|▋         | 258/3753 [19:59<4:03:34,  4.18s/it]  7%|▋         | 259/3753 [20:02<3:51:58,  3.98s/it]  7%|▋         | 260/3753 [20:07<4:05:42,  4.22s/it]{'loss': 0.3704, 'grad_norm': 1771.590087890625, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 1.3112999200820923, 'mean_ratio_rejected': 1.2960525751113892, 'weight_chosen': 0.7516950964927673, 'weight_rejected': 0.26352906227111816, 'kl_term_chosen': 0.13550949096679688, 'kl_term_rejected': 0.12966156005859375, 'epoch': 0.06928714190539641}
                                                    {'loss': 0.3704, 'grad_norm': 1771.590087890625, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 1.3112999200820923, 'mean_ratio_rejected': 1.2960525751113892, 'weight_chosen': 0.7516950964927673, 'weight_rejected': 0.26352906227111816, 'kl_term_chosen': 0.13550949096679688, 'kl_term_rejected': 0.12966156005859375, 'epoch': 0.07}
  7%|▋         | 260/3753 [20:07<4:05:42,  4.22s/it]  7%|▋         | 261/3753 [20:11<4:11:36,  4.32s/it]  7%|▋         | 262/3753 [20:16<4:15:50,  4.40s/it]  7%|▋         | 263/3753 [20:21<4:18:33,  4.45s/it]  7%|▋         | 264/3753 [20:24<4:09:44,  4.29s/it]  7%|▋         | 265/3753 [20:29<4:04:59,  4.21s/it]  7%|▋         | 266/3753 [20:32<4:00:34,  4.14s/it]  7%|▋         | 267/3753 [20:36<3:57:29,  4.09s/it]  7%|▋         | 268/3753 [20:41<4:12:00,  4.34s/it]  7%|▋         | 269/3753 [20:45<3:53:41,  4.02s/it]  7%|▋         | 270/3753 [20:49<4:02:03,  4.17s/it]{'loss': 0.8306, 'grad_norm': 4814.802734375, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 7.499921798706055, 'mean_ratio_rejected': 1.1965512037277222, 'weight_chosen': -0.031869351863861084, 'weight_rejected': 0.14005231857299805, 'kl_term_chosen': 1.0074462890625, 'kl_term_rejected': 0.0897216796875, 'epoch': 0.07195203197868089}
                                                    {'loss': 0.8306, 'grad_norm': 4814.802734375, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 7.499921798706055, 'mean_ratio_rejected': 1.1965512037277222, 'weight_chosen': -0.031869351863861084, 'weight_rejected': 0.14005231857299805, 'kl_term_chosen': 1.0074462890625, 'kl_term_rejected': 0.0897216796875, 'epoch': 0.07}
  7%|▋         | 270/3753 [20:49<4:02:03,  4.17s/it]  7%|▋         | 271/3753 [20:54<4:11:31,  4.33s/it]  7%|▋         | 272/3753 [20:58<4:10:40,  4.32s/it]  7%|▋         | 273/3753 [21:02<4:00:10,  4.14s/it]  7%|▋         | 274/3753 [21:06<3:53:05,  4.02s/it]  7%|▋         | 275/3753 [21:10<3:52:58,  4.02s/it]  7%|▋         | 276/3753 [21:13<3:45:18,  3.89s/it]  7%|▋         | 277/3753 [21:19<4:11:57,  4.35s/it]  7%|▋         | 278/3753 [21:22<3:53:38,  4.03s/it]  7%|▋         | 279/3753 [21:27<4:04:36,  4.22s/it]  7%|▋         | 280/3753 [21:31<4:13:50,  4.39s/it]{'loss': 1.5805, 'grad_norm': 2307.11962890625, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.18422789871692657, 'mean_ratio_rejected': 0.12440447509288788, 'weight_chosen': 1.7762491703033447, 'weight_rejected': -0.96947181224823, 'kl_term_chosen': -0.8457908630371094, 'kl_term_rejected': -1.0421085357666016, 'epoch': 0.07461692205196535}
                                                    {'loss': 1.5805, 'grad_norm': 2307.11962890625, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.18422789871692657, 'mean_ratio_rejected': 0.12440447509288788, 'weight_chosen': 1.7762491703033447, 'weight_rejected': -0.96947181224823, 'kl_term_chosen': -0.8457908630371094, 'kl_term_rejected': -1.0421085357666016, 'epoch': 0.07}
  7%|▋         | 280/3753 [21:31<4:13:50,  4.39s/it]  7%|▋         | 281/3753 [21:36<4:09:12,  4.31s/it]  8%|▊         | 282/3753 [21:42<4:38:42,  4.82s/it]  8%|▊         | 283/3753 [21:46<4:33:21,  4.73s/it]  8%|▊         | 284/3753 [21:50<4:24:54,  4.58s/it]  8%|▊         | 285/3753 [21:58<5:13:26,  5.42s/it]  8%|▊         | 286/3753 [22:01<4:44:25,  4.92s/it]  8%|▊         | 287/3753 [22:05<4:29:18,  4.66s/it]  8%|▊         | 288/3753 [22:14<5:40:49,  5.90s/it]  8%|▊         | 289/3753 [22:19<5:20:31,  5.55s/it]  8%|▊         | 290/3753 [22:28<6:14:53,  6.50s/it]{'loss': 1.1701, 'grad_norm': 1387.431884765625, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 1.2453559637069702, 'mean_ratio_rejected': 0.3817993402481079, 'weight_chosen': 0.6437559723854065, 'weight_rejected': -0.27196037769317627, 'kl_term_chosen': 0.109710693359375, 'kl_term_rejected': -0.4814300537109375, 'epoch': 0.07728181212524983}
                                                    {'loss': 1.1701, 'grad_norm': 1387.431884765625, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 1.2453559637069702, 'mean_ratio_rejected': 0.3817993402481079, 'weight_chosen': 0.6437559723854065, 'weight_rejected': -0.27196037769317627, 'kl_term_chosen': 0.109710693359375, 'kl_term_rejected': -0.4814300537109375, 'epoch': 0.08}
  8%|▊         | 290/3753 [22:28<6:14:53,  6.50s/it]  8%|▊         | 291/3753 [22:31<5:26:20,  5.66s/it]  8%|▊         | 292/3753 [22:37<5:29:44,  5.72s/it]  8%|▊         | 293/3753 [22:41<4:53:56,  5.10s/it]  8%|▊         | 294/3753 [22:45<4:39:30,  4.85s/it]  8%|▊         | 295/3753 [22:50<4:39:04,  4.84s/it]  8%|▊         | 296/3753 [22:54<4:23:34,  4.57s/it]  8%|▊         | 297/3753 [22:58<4:21:36,  4.54s/it]  8%|▊         | 298/3753 [23:04<4:43:57,  4.93s/it]  8%|▊         | 299/3753 [23:09<4:32:43,  4.74s/it]  8%|▊         | 300/3753 [23:13<4:26:19,  4.63s/it]{'loss': 1.2423, 'grad_norm': 1466.2017822265625, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 0.8478477001190186, 'mean_ratio_rejected': 0.28585851192474365, 'weight_chosen': 1.006669044494629, 'weight_rejected': -0.5735101699829102, 'kl_term_chosen': -0.08252716064453125, 'kl_term_rejected': -0.626129150390625, 'epoch': 0.07994670219853431}
                                                    {'loss': 1.2423, 'grad_norm': 1466.2017822265625, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 0.8478477001190186, 'mean_ratio_rejected': 0.28585851192474365, 'weight_chosen': 1.006669044494629, 'weight_rejected': -0.5735101699829102, 'kl_term_chosen': -0.08252716064453125, 'kl_term_rejected': -0.626129150390625, 'epoch': 0.08}
  8%|▊         | 300/3753 [23:13<4:26:19,  4.63s/it]  8%|▊         | 301/3753 [23:17<4:20:57,  4.54s/it]  8%|▊         | 302/3753 [23:22<4:27:30,  4.65s/it]  8%|▊         | 303/3753 [23:27<4:28:44,  4.67s/it]  8%|▊         | 304/3753 [23:30<4:03:13,  4.23s/it]  8%|▊         | 305/3753 [23:34<4:00:50,  4.19s/it]  8%|▊         | 306/3753 [23:38<3:54:33,  4.08s/it]  8%|▊         | 307/3753 [23:43<4:06:18,  4.29s/it]  8%|▊         | 308/3753 [23:48<4:30:45,  4.72s/it]  8%|▊         | 309/3753 [23:53<4:27:08,  4.65s/it]  8%|▊         | 310/3753 [23:57<4:18:01,  4.50s/it]{'loss': 1.5605, 'grad_norm': 2148.407958984375, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 0.7682607769966125, 'mean_ratio_rejected': 0.2195117026567459, 'weight_chosen': 0.7954819798469543, 'weight_rejected': -0.5300183892250061, 'kl_term_chosen': -0.13181304931640625, 'kl_term_rejected': -0.7581748962402344, 'epoch': 0.08261159227181879}
                                                    {'loss': 1.5605, 'grad_norm': 2148.407958984375, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 0.7682607769966125, 'mean_ratio_rejected': 0.2195117026567459, 'weight_chosen': 0.7954819798469543, 'weight_rejected': -0.5300183892250061, 'kl_term_chosen': -0.13181304931640625, 'kl_term_rejected': -0.7581748962402344, 'epoch': 0.08}
  8%|▊         | 310/3753 [23:57<4:18:01,  4.50s/it]  8%|▊         | 311/3753 [24:01<4:14:33,  4.44s/it]  8%|▊         | 312/3753 [24:06<4:08:49,  4.34s/it]  8%|▊         | 313/3753 [24:10<4:07:33,  4.32s/it]  8%|▊         | 314/3753 [24:17<4:52:27,  5.10s/it]  8%|▊         | 315/3753 [24:20<4:27:19,  4.67s/it]  8%|▊         | 316/3753 [24:24<4:13:00,  4.42s/it]  8%|▊         | 317/3753 [24:28<4:07:19,  4.32s/it]  8%|▊         | 318/3753 [24:33<4:12:34,  4.41s/it]  8%|▊         | 319/3753 [24:37<4:08:14,  4.34s/it]  9%|▊         | 320/3753 [24:42<4:14:18,  4.44s/it]{'loss': 1.2802, 'grad_norm': 1206.613037109375, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 0.37623587250709534, 'mean_ratio_rejected': 0.4037160873413086, 'weight_chosen': 1.4259803295135498, 'weight_rejected': -0.41267600655555725, 'kl_term_chosen': -0.48876953125, 'kl_term_rejected': -0.453521728515625, 'epoch': 0.08527648234510327}
                                                    {'loss': 1.2802, 'grad_norm': 1206.613037109375, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 0.37623587250709534, 'mean_ratio_rejected': 0.4037160873413086, 'weight_chosen': 1.4259803295135498, 'weight_rejected': -0.41267600655555725, 'kl_term_chosen': -0.48876953125, 'kl_term_rejected': -0.453521728515625, 'epoch': 0.09}
  9%|▊         | 320/3753 [24:42<4:14:18,  4.44s/it]  9%|▊         | 321/3753 [24:46<4:15:34,  4.47s/it]  9%|▊         | 322/3753 [24:50<4:07:11,  4.32s/it]  9%|▊         | 323/3753 [24:54<3:53:34,  4.09s/it]  9%|▊         | 324/3753 [25:01<4:45:08,  4.99s/it]  9%|▊         | 325/3753 [25:05<4:33:42,  4.79s/it]  9%|▊         | 326/3753 [25:09<4:13:07,  4.43s/it]  9%|▊         | 327/3753 [25:13<4:08:38,  4.35s/it]  9%|▊         | 328/3753 [25:17<4:02:34,  4.25s/it]  9%|▉         | 329/3753 [25:22<4:07:18,  4.33s/it]  9%|▉         | 330/3753 [25:27<4:17:56,  4.52s/it]{'loss': 4.8324, 'grad_norm': 1458.2685546875, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 0.6641948819160461, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.0661280155181885, 'weight_rejected': -2.11440372467041, 'kl_term_chosen': -0.20458984375, 'kl_term_rejected': -2.33575439453125, 'epoch': 0.08794137241838774}
                                                    {'loss': 4.8324, 'grad_norm': 1458.2685546875, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 0.6641948819160461, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.0661280155181885, 'weight_rejected': -2.11440372467041, 'kl_term_chosen': -0.20458984375, 'kl_term_rejected': -2.33575439453125, 'epoch': 0.09}
  9%|▉         | 330/3753 [25:27<4:17:56,  4.52s/it]  9%|▉         | 331/3753 [25:30<4:08:37,  4.36s/it]  9%|▉         | 332/3753 [25:35<4:02:28,  4.25s/it]  9%|▉         | 333/3753 [25:39<4:06:20,  4.32s/it]  9%|▉         | 334/3753 [25:47<5:10:44,  5.45s/it]  9%|▉         | 335/3753 [25:52<4:58:37,  5.24s/it]  9%|▉         | 336/3753 [25:55<4:26:22,  4.68s/it]  9%|▉         | 337/3753 [26:00<4:26:49,  4.69s/it]  9%|▉         | 338/3753 [26:03<4:07:59,  4.36s/it]  9%|▉         | 339/3753 [26:07<3:54:49,  4.13s/it]  9%|▉         | 340/3753 [26:12<4:00:00,  4.22s/it]{'loss': 4.1003, 'grad_norm': 2383.4638671875, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.553586483001709, 'weight_rejected': -3.628957748413086, 'kl_term_chosen': -2.3099441528320312, 'kl_term_rejected': -4.411620140075684, 'epoch': 0.09060626249167222}
                                                    {'loss': 4.1003, 'grad_norm': 2383.4638671875, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.553586483001709, 'weight_rejected': -3.628957748413086, 'kl_term_chosen': -2.3099441528320312, 'kl_term_rejected': -4.411620140075684, 'epoch': 0.09}
  9%|▉         | 340/3753 [26:12<4:00:00,  4.22s/it]  9%|▉         | 341/3753 [26:15<3:51:00,  4.06s/it]  9%|▉         | 342/3753 [26:19<3:48:08,  4.01s/it]  9%|▉         | 343/3753 [26:24<4:00:40,  4.23s/it]  9%|▉         | 344/3753 [26:28<3:53:42,  4.11s/it]  9%|▉         | 345/3753 [26:33<4:20:30,  4.59s/it]  9%|▉         | 346/3753 [26:37<4:11:08,  4.42s/it]  9%|▉         | 347/3753 [26:42<4:12:27,  4.45s/it]  9%|▉         | 348/3753 [26:47<4:26:50,  4.70s/it]  9%|▉         | 349/3753 [26:51<4:09:24,  4.40s/it]  9%|▉         | 350/3753 [26:56<4:14:58,  4.50s/it]{'loss': 1.2064, 'grad_norm': 912.8613891601562, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.3911848068237305, 'weight_rejected': -2.9715847969055176, 'kl_term_chosen': -2.5567779541015625, 'kl_term_rejected': -3.1902542114257812, 'epoch': 0.09327115256495669}
                                                    {'loss': 1.2064, 'grad_norm': 912.8613891601562, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.3911848068237305, 'weight_rejected': -2.9715847969055176, 'kl_term_chosen': -2.5567779541015625, 'kl_term_rejected': -3.1902542114257812, 'epoch': 0.09}
  9%|▉         | 350/3753 [26:56<4:14:58,  4.50s/it]  9%|▉         | 351/3753 [27:00<4:05:06,  4.32s/it]  9%|▉         | 352/3753 [27:03<3:46:55,  4.00s/it]  9%|▉         | 353/3753 [27:07<3:48:55,  4.04s/it]  9%|▉         | 354/3753 [27:11<3:56:10,  4.17s/it]  9%|▉         | 355/3753 [27:17<4:23:03,  4.64s/it]  9%|▉         | 356/3753 [27:22<4:24:14,  4.67s/it] 10%|▉         | 357/3753 [27:26<4:15:53,  4.52s/it] 10%|▉         | 358/3753 [27:31<4:19:42,  4.59s/it] 10%|▉         | 359/3753 [27:35<4:12:17,  4.46s/it] 10%|▉         | 360/3753 [27:39<4:00:04,  4.25s/it]{'loss': 7.9642, 'grad_norm': 3572.636962890625, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 0.10695615410804749, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.661985158920288, 'weight_rejected': -1.563350796699524, 'kl_term_chosen': -1.1176681518554688, 'kl_term_rejected': -1.7300262451171875, 'epoch': 0.09593604263824117}
                                                    {'loss': 7.9642, 'grad_norm': 3572.636962890625, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 0.10695615410804749, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.661985158920288, 'weight_rejected': -1.563350796699524, 'kl_term_chosen': -1.1176681518554688, 'kl_term_rejected': -1.7300262451171875, 'epoch': 0.1}
 10%|▉         | 360/3753 [27:39<4:00:04,  4.25s/it] 10%|▉         | 361/3753 [27:43<4:08:25,  4.39s/it] 10%|▉         | 362/3753 [27:48<4:05:49,  4.35s/it] 10%|▉         | 363/3753 [27:52<4:01:28,  4.27s/it] 10%|▉         | 364/3753 [27:56<4:04:33,  4.33s/it] 10%|▉         | 365/3753 [28:00<3:48:07,  4.04s/it] 10%|▉         | 366/3753 [28:03<3:35:50,  3.82s/it] 10%|▉         | 367/3753 [28:07<3:44:24,  3.98s/it] 10%|▉         | 368/3753 [28:12<4:02:51,  4.30s/it] 10%|▉         | 369/3753 [28:17<4:05:27,  4.35s/it] 10%|▉         | 370/3753 [28:21<4:02:01,  4.29s/it]{'loss': 0.9962, 'grad_norm': 2907.6171875, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.9256393909454346, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.9029456973075867, 'weight_rejected': -1.850682258605957, 'kl_term_chosen': -0.03863525390625, 'kl_term_rejected': -2.0562973022460938, 'epoch': 0.09860093271152565}
                                                    {'loss': 0.9962, 'grad_norm': 2907.6171875, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.9256393909454346, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.9029456973075867, 'weight_rejected': -1.850682258605957, 'kl_term_chosen': -0.03863525390625, 'kl_term_rejected': -2.0562973022460938, 'epoch': 0.1}
 10%|▉         | 370/3753 [28:21<4:02:01,  4.29s/it] 10%|▉         | 371/3753 [28:25<3:50:47,  4.09s/it] 10%|▉         | 372/3753 [28:29<3:58:17,  4.23s/it] 10%|▉         | 373/3753 [28:33<3:56:58,  4.21s/it] 10%|▉         | 374/3753 [28:41<4:48:42,  5.13s/it] 10%|▉         | 375/3753 [28:46<4:55:54,  5.26s/it] 10%|█         | 376/3753 [28:55<5:59:04,  6.38s/it] 10%|█         | 377/3753 [29:02<6:01:21,  6.42s/it] 10%|█         | 378/3753 [29:05<5:16:57,  5.63s/it] 10%|█         | 379/3753 [29:09<4:44:17,  5.06s/it] 10%|█         | 380/3753 [29:14<4:38:13,  4.95s/it]{'loss': 9.3513, 'grad_norm': 463.3969421386719, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.8429601192474365, 'weight_rejected': -2.4885385036468506, 'kl_term_chosen': -1.882598876953125, 'kl_term_rejected': -2.514495849609375, 'epoch': 0.10126582278481013}
                                                    {'loss': 9.3513, 'grad_norm': 463.3969421386719, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.8429601192474365, 'weight_rejected': -2.4885385036468506, 'kl_term_chosen': -1.882598876953125, 'kl_term_rejected': -2.514495849609375, 'epoch': 0.1}
 10%|█         | 380/3753 [29:14<4:38:13,  4.95s/it] 10%|█         | 381/3753 [29:18<4:23:26,  4.69s/it] 10%|█         | 382/3753 [29:23<4:22:05,  4.67s/it] 10%|█         | 383/3753 [29:26<4:10:07,  4.45s/it] 10%|█         | 384/3753 [29:32<4:24:30,  4.71s/it] 10%|█         | 385/3753 [29:42<5:52:25,  6.28s/it] 10%|█         | 386/3753 [29:45<5:07:52,  5.49s/it] 10%|█         | 387/3753 [29:50<4:49:27,  5.16s/it] 10%|█         | 388/3753 [29:54<4:39:04,  4.98s/it] 10%|█         | 389/3753 [29:59<4:34:53,  4.90s/it] 10%|█         | 390/3753 [30:05<4:52:15,  5.21s/it]{'loss': 7.2001, 'grad_norm': 4369.0546875, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.24516431987285614, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.341748595237732, 'weight_rejected': -0.5145071744918823, 'kl_term_chosen': -0.7029132843017578, 'kl_term_rejected': -1.3309135437011719, 'epoch': 0.1039307128580946}
                                                    {'loss': 7.2001, 'grad_norm': 4369.0546875, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.24516431987285614, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.341748595237732, 'weight_rejected': -0.5145071744918823, 'kl_term_chosen': -0.7029132843017578, 'kl_term_rejected': -1.3309135437011719, 'epoch': 0.1}
 10%|█         | 390/3753 [30:05<4:52:15,  5.21s/it] 10%|█         | 391/3753 [30:09<4:37:55,  4.96s/it] 10%|█         | 392/3753 [30:13<4:18:20,  4.61s/it] 10%|█         | 393/3753 [30:18<4:21:09,  4.66s/it] 10%|█         | 394/3753 [30:22<4:12:43,  4.51s/it] 11%|█         | 395/3753 [30:27<4:18:50,  4.62s/it] 11%|█         | 396/3753 [30:36<5:25:51,  5.82s/it] 11%|█         | 397/3753 [30:39<4:45:40,  5.11s/it] 11%|█         | 398/3753 [30:45<4:57:47,  5.33s/it] 11%|█         | 399/3753 [30:50<4:55:41,  5.29s/it] 11%|█         | 400/3753 [30:54<4:35:55,  4.94s/it]{'loss': 3.3623, 'grad_norm': 669.1321411132812, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.2483937740325928, 'weight_rejected': -3.926478385925293, 'kl_term_chosen': -2.553262710571289, 'kl_term_rejected': -4.177391052246094, 'epoch': 0.10659560293137908}
                                                    {'loss': 3.3623, 'grad_norm': 669.1321411132812, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.2483937740325928, 'weight_rejected': -3.926478385925293, 'kl_term_chosen': -2.553262710571289, 'kl_term_rejected': -4.177391052246094, 'epoch': 0.11}
 11%|█         | 400/3753 [30:54<4:35:55,  4.94s/it] 11%|█         | 401/3753 [30:58<4:20:22,  4.66s/it] 11%|█         | 402/3753 [31:03<4:21:55,  4.69s/it] 11%|█         | 403/3753 [31:06<3:57:15,  4.25s/it] 11%|█         | 404/3753 [31:10<3:56:21,  4.23s/it] 11%|█         | 405/3753 [31:16<4:14:28,  4.56s/it] 11%|█         | 406/3753 [31:20<4:10:27,  4.49s/it] 11%|█         | 407/3753 [31:24<3:59:16,  4.29s/it] 11%|█         | 408/3753 [31:29<4:09:04,  4.47s/it] 11%|█         | 409/3753 [31:33<4:03:00,  4.36s/it] 11%|█         | 410/3753 [31:37<4:06:51,  4.43s/it]{'loss': 9.2625, 'grad_norm': 505.5042724609375, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.526644229888916, 'weight_rejected': -10.123590469360352, 'kl_term_chosen': -4.879737854003906, 'kl_term_rejected': -10.411357879638672, 'epoch': 0.10926049300466356}
                                                    {'loss': 9.2625, 'grad_norm': 505.5042724609375, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.526644229888916, 'weight_rejected': -10.123590469360352, 'kl_term_chosen': -4.879737854003906, 'kl_term_rejected': -10.411357879638672, 'epoch': 0.11}
 11%|█         | 410/3753 [31:38<4:06:51,  4.43s/it] 11%|█         | 411/3753 [31:43<4:18:07,  4.63s/it] 11%|█         | 412/3753 [31:46<4:05:57,  4.42s/it] 11%|█         | 413/3753 [31:52<4:23:33,  4.73s/it] 11%|█         | 414/3753 [31:57<4:24:49,  4.76s/it] 11%|█         | 415/3753 [32:01<4:14:37,  4.58s/it] 11%|█         | 416/3753 [32:05<4:12:40,  4.54s/it] 11%|█         | 417/3753 [32:09<4:03:39,  4.38s/it] 11%|█         | 418/3753 [32:13<3:56:13,  4.25s/it] 11%|█         | 419/3753 [32:17<3:51:09,  4.16s/it] 11%|█         | 420/3753 [32:21<3:46:17,  4.07s/it]{'loss': 1.616, 'grad_norm': 1118.1632080078125, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.9403257369995117, 'weight_rejected': -3.706899404525757, 'kl_term_chosen': -2.288970947265625, 'kl_term_rejected': -3.9796981811523438, 'epoch': 0.11192538307794804}
                                                    {'loss': 1.616, 'grad_norm': 1118.1632080078125, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.9403257369995117, 'weight_rejected': -3.706899404525757, 'kl_term_chosen': -2.288970947265625, 'kl_term_rejected': -3.9796981811523438, 'epoch': 0.11}
 11%|█         | 420/3753 [32:21<3:46:17,  4.07s/it] 11%|█         | 421/3753 [32:26<3:52:49,  4.19s/it] 11%|█         | 422/3753 [32:30<3:54:56,  4.23s/it] 11%|█▏        | 423/3753 [32:34<3:45:54,  4.07s/it] 11%|█▏        | 424/3753 [32:37<3:29:25,  3.77s/it] 11%|█▏        | 425/3753 [32:41<3:36:49,  3.91s/it] 11%|█▏        | 426/3753 [32:46<3:47:50,  4.11s/it] 11%|█▏        | 427/3753 [32:50<3:53:21,  4.21s/it] 11%|█▏        | 428/3753 [32:54<3:58:22,  4.30s/it] 11%|█▏        | 429/3753 [32:59<3:53:50,  4.22s/it] 11%|█▏        | 430/3753 [33:04<4:06:58,  4.46s/it]{'loss': 9.6453, 'grad_norm': 2130.24560546875, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.728489398956299, 'weight_rejected': -2.745349884033203, 'kl_term_chosen': -5.1648712158203125, 'kl_term_rejected': -3.0166015625, 'epoch': 0.1145902731512325}
                                                    {'loss': 9.6453, 'grad_norm': 2130.24560546875, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.728489398956299, 'weight_rejected': -2.745349884033203, 'kl_term_chosen': -5.1648712158203125, 'kl_term_rejected': -3.0166015625, 'epoch': 0.11}
 11%|█▏        | 430/3753 [33:04<4:06:58,  4.46s/it] 11%|█▏        | 431/3753 [33:07<3:53:33,  4.22s/it] 12%|█▏        | 432/3753 [33:16<5:06:25,  5.54s/it] 12%|█▏        | 433/3753 [33:20<4:43:19,  5.12s/it] 12%|█▏        | 434/3753 [33:24<4:20:58,  4.72s/it] 12%|█▏        | 435/3753 [33:28<4:05:19,  4.44s/it] 12%|█▏        | 436/3753 [33:32<4:03:43,  4.41s/it] 12%|█▏        | 437/3753 [33:36<4:00:17,  4.35s/it] 12%|█▏        | 438/3753 [33:41<4:16:15,  4.64s/it] 12%|█▏        | 439/3753 [33:46<4:08:51,  4.51s/it] 12%|█▏        | 440/3753 [33:50<4:00:13,  4.35s/it]{'loss': 7.3493, 'grad_norm': 199.0166778564453, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 8.600093841552734, 'weight_rejected': -14.509907722473145, 'kl_term_chosen': -7.64544677734375, 'kl_term_rejected': -14.55804443359375, 'epoch': 0.11725516322451698}
                                                    {'loss': 7.3493, 'grad_norm': 199.0166778564453, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 8.600093841552734, 'weight_rejected': -14.509907722473145, 'kl_term_chosen': -7.64544677734375, 'kl_term_rejected': -14.55804443359375, 'epoch': 0.12}
 12%|█▏        | 440/3753 [33:50<4:00:13,  4.35s/it] 12%|█▏        | 441/3753 [33:56<4:26:54,  4.84s/it] 12%|█▏        | 442/3753 [34:00<4:23:05,  4.77s/it] 12%|█▏        | 443/3753 [34:03<3:59:31,  4.34s/it] 12%|█▏        | 444/3753 [34:09<4:11:52,  4.57s/it] 12%|█▏        | 445/3753 [34:12<3:54:13,  4.25s/it] 12%|█▏        | 446/3753 [34:17<3:59:11,  4.34s/it] 12%|█▏        | 447/3753 [34:21<3:59:38,  4.35s/it] 12%|█▏        | 448/3753 [34:24<3:41:17,  4.02s/it] 12%|█▏        | 449/3753 [34:30<4:06:50,  4.48s/it] 12%|█▏        | 450/3753 [34:34<4:02:42,  4.41s/it]{'loss': 6.1504, 'grad_norm': 7224.98828125, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.220980644226074, 'weight_chosen': -0.9735423922538757, 'weight_rejected': 1.1665637493133545, 'kl_term_chosen': 1.866851806640625, 'kl_term_rejected': 1.1107406616210938, 'epoch': 0.11992005329780146}
                                                    {'loss': 6.1504, 'grad_norm': 7224.98828125, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.220980644226074, 'weight_chosen': -0.9735423922538757, 'weight_rejected': 1.1665637493133545, 'kl_term_chosen': 1.866851806640625, 'kl_term_rejected': 1.1107406616210938, 'epoch': 0.12}
 12%|█▏        | 450/3753 [34:34<4:02:42,  4.41s/it] 12%|█▏        | 451/3753 [34:38<3:59:00,  4.34s/it] 12%|█▏        | 452/3753 [34:43<4:11:47,  4.58s/it] 12%|█▏        | 453/3753 [34:47<3:53:49,  4.25s/it] 12%|█▏        | 454/3753 [34:53<4:17:03,  4.68s/it] 12%|█▏        | 455/3753 [34:57<4:13:51,  4.62s/it] 12%|█▏        | 456/3753 [35:03<4:37:42,  5.05s/it] 12%|█▏        | 457/3753 [35:07<4:21:43,  4.76s/it] 12%|█▏        | 458/3753 [35:11<4:06:30,  4.49s/it] 12%|█▏        | 459/3753 [35:15<4:02:13,  4.41s/it] 12%|█▏        | 460/3753 [35:21<4:25:16,  4.83s/it]{'loss': 7.9124, 'grad_norm': 5778.82666015625, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.200371265411377, 'weight_rejected': -5.091531753540039, 'kl_term_chosen': -3.281890869140625, 'kl_term_rejected': -5.132377624511719, 'epoch': 0.12258494337108594}
                                                    {'loss': 7.9124, 'grad_norm': 5778.82666015625, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.200371265411377, 'weight_rejected': -5.091531753540039, 'kl_term_chosen': -3.281890869140625, 'kl_term_rejected': -5.132377624511719, 'epoch': 0.12}
 12%|█▏        | 460/3753 [35:21<4:25:16,  4.83s/it] 12%|█▏        | 461/3753 [35:25<4:04:01,  4.45s/it] 12%|█▏        | 462/3753 [35:27<3:37:15,  3.96s/it] 12%|█▏        | 463/3753 [35:32<3:42:55,  4.07s/it] 12%|█▏        | 464/3753 [35:36<3:44:49,  4.10s/it] 12%|█▏        | 465/3753 [35:40<3:44:07,  4.09s/it] 12%|█▏        | 466/3753 [35:44<3:50:48,  4.21s/it] 12%|█▏        | 467/3753 [35:49<3:50:59,  4.22s/it] 12%|█▏        | 468/3753 [35:56<4:49:06,  5.28s/it] 12%|█▏        | 469/3753 [36:02<4:52:16,  5.34s/it] 13%|█▎        | 470/3753 [36:08<5:01:39,  5.51s/it]{'loss': -0.5811, 'grad_norm': 1082.07861328125, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.8634517192840576, 'weight_rejected': -19.336265563964844, 'kl_term_chosen': -2.91845703125, 'kl_term_rejected': -19.41778564453125, 'epoch': 0.1252498334443704}
                                                    {'loss': -0.5811, 'grad_norm': 1082.07861328125, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.8634517192840576, 'weight_rejected': -19.336265563964844, 'kl_term_chosen': -2.91845703125, 'kl_term_rejected': -19.41778564453125, 'epoch': 0.13}
 13%|█▎        | 470/3753 [36:08<5:01:39,  5.51s/it] 13%|█▎        | 471/3753 [36:14<5:03:47,  5.55s/it] 13%|█▎        | 472/3753 [36:17<4:33:32,  5.00s/it] 13%|█▎        | 473/3753 [36:20<3:58:04,  4.35s/it] 13%|█▎        | 474/3753 [36:25<3:59:58,  4.39s/it] 13%|█▎        | 475/3753 [36:29<4:02:40,  4.44s/it] 13%|█▎        | 476/3753 [36:33<3:54:33,  4.29s/it] 13%|█▎        | 477/3753 [36:37<3:56:23,  4.33s/it] 13%|█▎        | 478/3753 [36:42<3:51:19,  4.24s/it] 13%|█▎        | 479/3753 [36:47<4:16:54,  4.71s/it] 13%|█▎        | 480/3753 [36:52<4:16:21,  4.70s/it]{'loss': 30.68, 'grad_norm': 4978.37548828125, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 8.053962707519531, 'weight_rejected': -3.3575291633605957, 'kl_term_chosen': -7.477420806884766, 'kl_term_rejected': -3.595458984375, 'epoch': 0.1279147235176549}
                                                    {'loss': 30.68, 'grad_norm': 4978.37548828125, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 8.053962707519531, 'weight_rejected': -3.3575291633605957, 'kl_term_chosen': -7.477420806884766, 'kl_term_rejected': -3.595458984375, 'epoch': 0.13}
 13%|█▎        | 480/3753 [36:52<4:16:21,  4.70s/it] 13%|█▎        | 481/3753 [36:57<4:20:33,  4.78s/it] 13%|█▎        | 482/3753 [37:01<4:03:35,  4.47s/it] 13%|█▎        | 483/3753 [37:05<3:56:22,  4.34s/it] 13%|█▎        | 484/3753 [37:09<3:48:26,  4.19s/it] 13%|█▎        | 485/3753 [37:12<3:39:03,  4.02s/it] 13%|█▎        | 486/3753 [37:17<3:57:04,  4.35s/it] 13%|█▎        | 487/3753 [37:22<4:06:41,  4.53s/it] 13%|█▎        | 488/3753 [37:26<3:55:33,  4.33s/it] 13%|█▎        | 489/3753 [37:31<4:02:36,  4.46s/it] 13%|█▎        | 490/3753 [37:36<4:16:34,  4.72s/it]{'loss': 78.7964, 'grad_norm': 722.2296142578125, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.3771274089813232, 'weight_rejected': -1.3086628913879395, 'kl_term_chosen': 3.3213043212890625, 'kl_term_rejected': -1.3628616333007812, 'epoch': 0.13057961359093936}
                                                    {'loss': 78.7964, 'grad_norm': 722.2296142578125, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.3771274089813232, 'weight_rejected': -1.3086628913879395, 'kl_term_chosen': 3.3213043212890625, 'kl_term_rejected': -1.3628616333007812, 'epoch': 0.13}
 13%|█▎        | 490/3753 [37:36<4:16:34,  4.72s/it] 13%|█▎        | 491/3753 [37:41<4:19:22,  4.77s/it] 13%|█▎        | 492/3753 [37:45<4:03:07,  4.47s/it] 13%|█▎        | 493/3753 [37:55<5:29:36,  6.07s/it] 13%|█▎        | 494/3753 [37:59<4:55:26,  5.44s/it] 13%|█▎        | 495/3753 [38:02<4:21:13,  4.81s/it] 13%|█▎        | 496/3753 [38:07<4:22:09,  4.83s/it] 13%|█▎        | 497/3753 [38:11<4:02:46,  4.47s/it] 13%|█▎        | 498/3753 [38:19<5:01:17,  5.55s/it] 13%|█▎        | 499/3753 [38:25<5:11:37,  5.75s/it] 13%|█▎        | 500/3753 [38:29<4:53:16,  5.41s/it]{'loss': 67.7873, 'grad_norm': 173.16281127929688, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.392306327819824, 'weight_rejected': -7.000905990600586, 'kl_term_chosen': -4.749874114990234, 'kl_term_rejected': -7.223606109619141, 'epoch': 0.13324450366422386}
                                                    {'loss': 67.7873, 'grad_norm': 173.16281127929688, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.392306327819824, 'weight_rejected': -7.000905990600586, 'kl_term_chosen': -4.749874114990234, 'kl_term_rejected': -7.223606109619141, 'epoch': 0.13}
 13%|█▎        | 500/3753 [38:30<4:53:16,  5.41s/it] 13%|█▎        | 501/3753 [38:34<4:34:03,  5.06s/it] 13%|█▎        | 502/3753 [38:42<5:20:42,  5.92s/it] 13%|█▎        | 503/3753 [38:46<4:53:44,  5.42s/it] 13%|█▎        | 504/3753 [38:50<4:32:59,  5.04s/it] 13%|█▎        | 505/3753 [38:54<4:09:41,  4.61s/it] 13%|█▎        | 506/3753 [38:57<3:55:34,  4.35s/it] 14%|█▎        | 507/3753 [39:02<4:04:29,  4.52s/it] 14%|█▎        | 508/3753 [39:07<4:15:11,  4.72s/it] 14%|█▎        | 509/3753 [39:11<4:03:06,  4.50s/it] 14%|█▎        | 510/3753 [39:16<4:09:45,  4.62s/it]{'loss': 41.8329, 'grad_norm': 55.37486267089844, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.018465995788574, 'weight_rejected': -4.9383955001831055, 'kl_term_chosen': -5.0624847412109375, 'kl_term_rejected': -4.97198486328125, 'epoch': 0.13590939373750832}
                                                    {'loss': 41.8329, 'grad_norm': 55.37486267089844, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.018465995788574, 'weight_rejected': -4.9383955001831055, 'kl_term_chosen': -5.0624847412109375, 'kl_term_rejected': -4.97198486328125, 'epoch': 0.14}
 14%|█▎        | 510/3753 [39:16<4:09:45,  4.62s/it] 14%|█▎        | 511/3753 [39:21<4:05:02,  4.53s/it] 14%|█▎        | 512/3753 [39:24<3:51:24,  4.28s/it] 14%|█▎        | 513/3753 [39:32<4:42:04,  5.22s/it] 14%|█▎        | 514/3753 [39:37<4:37:29,  5.14s/it] 14%|█▎        | 515/3753 [39:42<4:37:55,  5.15s/it] 14%|█▎        | 516/3753 [39:46<4:24:59,  4.91s/it] 14%|█▍        | 517/3753 [39:50<4:03:22,  4.51s/it] 14%|█▍        | 518/3753 [39:54<3:53:30,  4.33s/it] 14%|█▍        | 519/3753 [39:59<4:02:04,  4.49s/it] 14%|█▍        | 520/3753 [40:04<4:16:24,  4.76s/it]{'loss': 40.4835, 'grad_norm': 546.625732421875, 'learning_rate': 9.955821687527552e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.1604301929473877, 'weight_rejected': -1.8864679336547852, 'kl_term_chosen': 4.083469390869141, 'kl_term_rejected': -1.9390869140625, 'epoch': 0.13857428381079281}
                                                    {'loss': 40.4835, 'grad_norm': 546.625732421875, 'learning_rate': 9.955821687527552e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.1604301929473877, 'weight_rejected': -1.8864679336547852, 'kl_term_chosen': 4.083469390869141, 'kl_term_rejected': -1.9390869140625, 'epoch': 0.14}
 14%|█▍        | 520/3753 [40:04<4:16:24,  4.76s/it] 14%|█▍        | 521/3753 [40:08<4:10:25,  4.65s/it] 14%|█▍        | 522/3753 [40:13<4:06:59,  4.59s/it] 14%|█▍        | 523/3753 [40:19<4:27:38,  4.97s/it] 14%|█▍        | 524/3753 [40:23<4:20:42,  4.84s/it] 14%|█▍        | 525/3753 [40:27<4:06:25,  4.58s/it] 14%|█▍        | 526/3753 [40:31<3:51:48,  4.31s/it] 14%|█▍        | 527/3753 [40:35<3:41:04,  4.11s/it] 14%|█▍        | 528/3753 [40:39<3:48:22,  4.25s/it] 14%|█▍        | 529/3753 [40:42<3:34:20,  3.99s/it] 14%|█▍        | 530/3753 [40:47<3:37:04,  4.04s/it]{'loss': 49.2372, 'grad_norm': 572.5455932617188, 'learning_rate': 9.94943765952491e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 13.88299560546875, 'weight_rejected': -14.252951622009277, 'kl_term_chosen': -13.447093963623047, 'kl_term_rejected': -14.585803985595703, 'epoch': 0.14123917388407728}
                                                    {'loss': 49.2372, 'grad_norm': 572.5455932617188, 'learning_rate': 9.94943765952491e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 13.88299560546875, 'weight_rejected': -14.252951622009277, 'kl_term_chosen': -13.447093963623047, 'kl_term_rejected': -14.585803985595703, 'epoch': 0.14}
 14%|█▍        | 530/3753 [40:47<3:37:04,  4.04s/it] 14%|█▍        | 531/3753 [40:50<3:29:15,  3.90s/it] 14%|█▍        | 532/3753 [40:55<3:41:41,  4.13s/it] 14%|█▍        | 533/3753 [41:00<3:54:24,  4.37s/it] 14%|█▍        | 534/3753 [41:03<3:40:04,  4.10s/it] 14%|█▍        | 535/3753 [41:08<3:44:36,  4.19s/it] 14%|█▍        | 536/3753 [41:12<3:50:24,  4.30s/it] 14%|█▍        | 537/3753 [41:17<4:00:16,  4.48s/it] 14%|█▍        | 538/3753 [41:21<3:43:14,  4.17s/it] 14%|█▍        | 539/3753 [41:24<3:31:58,  3.96s/it] 14%|█▍        | 540/3753 [41:27<3:19:59,  3.73s/it]{'loss': 42.5984, 'grad_norm': 2986.28369140625, 'learning_rate': 9.942625289827702e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -5.137181282043457, 'weight_rejected': -2.4231584072113037, 'kl_term_chosen': 6.065589904785156, 'kl_term_rejected': -2.5465240478515625, 'epoch': 0.14390406395736177}
                                                    {'loss': 42.5984, 'grad_norm': 2986.28369140625, 'learning_rate': 9.942625289827702e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -5.137181282043457, 'weight_rejected': -2.4231584072113037, 'kl_term_chosen': 6.065589904785156, 'kl_term_rejected': -2.5465240478515625, 'epoch': 0.14}
 14%|█▍        | 540/3753 [41:27<3:19:59,  3.73s/it] 14%|█▍        | 541/3753 [41:31<3:17:41,  3.69s/it] 14%|█▍        | 542/3753 [41:35<3:23:46,  3.81s/it] 14%|█▍        | 543/3753 [41:38<3:17:35,  3.69s/it] 14%|█▍        | 544/3753 [41:43<3:30:05,  3.93s/it] 15%|█▍        | 545/3753 [41:47<3:29:00,  3.91s/it] 15%|█▍        | 546/3753 [41:50<3:21:23,  3.77s/it] 15%|█▍        | 547/3753 [41:55<3:37:39,  4.07s/it] 15%|█▍        | 548/3753 [42:02<4:32:51,  5.11s/it] 15%|█▍        | 549/3753 [42:06<4:14:30,  4.77s/it] 15%|█▍        | 550/3753 [42:11<4:19:16,  4.86s/it]{'loss': 50.3375, 'grad_norm': 2923.91064453125, 'learning_rate': 9.935385168002298e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.5590152740478516, 'weight_rejected': 4.349310874938965, 'kl_term_chosen': 3.49530029296875, 'kl_term_rejected': 4.2734527587890625, 'epoch': 0.14656895403064624}
                                                    {'loss': 50.3375, 'grad_norm': 2923.91064453125, 'learning_rate': 9.935385168002298e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.5590152740478516, 'weight_rejected': 4.349310874938965, 'kl_term_chosen': 3.49530029296875, 'kl_term_rejected': 4.2734527587890625, 'epoch': 0.15}
 15%|█▍        | 550/3753 [42:12<4:19:16,  4.86s/it] 15%|█▍        | 551/3753 [42:16<4:12:38,  4.73s/it] 15%|█▍        | 552/3753 [42:19<3:49:34,  4.30s/it] 15%|█▍        | 553/3753 [42:23<3:43:15,  4.19s/it] 15%|█▍        | 554/3753 [42:28<3:51:44,  4.35s/it] 15%|█▍        | 555/3753 [42:32<3:49:44,  4.31s/it] 15%|█▍        | 556/3753 [42:36<3:48:51,  4.30s/it] 15%|█▍        | 557/3753 [42:42<4:09:04,  4.68s/it] 15%|█▍        | 558/3753 [42:46<4:03:01,  4.56s/it] 15%|█▍        | 559/3753 [42:50<3:54:34,  4.41s/it] 15%|█▍        | 560/3753 [42:54<3:49:59,  4.32s/it]{'loss': 21.3139, 'grad_norm': 975.690673828125, 'learning_rate': 9.927717920634233e-07, 'mean_ratio_chosen': 1.4020299911499023, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.7093536853790283, 'weight_rejected': -1.9509135484695435, 'kl_term_chosen': 0.1689605712890625, 'kl_term_rejected': -2.1380462646484375, 'epoch': 0.1492338441039307}
                                                    {'loss': 21.3139, 'grad_norm': 975.690673828125, 'learning_rate': 9.927717920634233e-07, 'mean_ratio_chosen': 1.4020299911499023, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.7093536853790283, 'weight_rejected': -1.9509135484695435, 'kl_term_chosen': 0.1689605712890625, 'kl_term_rejected': -2.1380462646484375, 'epoch': 0.15}
 15%|█▍        | 560/3753 [42:54<3:49:59,  4.32s/it] 15%|█▍        | 561/3753 [42:58<3:41:30,  4.16s/it] 15%|█▍        | 562/3753 [43:03<3:58:39,  4.49s/it] 15%|█▌        | 563/3753 [43:08<3:53:02,  4.38s/it] 15%|█▌        | 564/3753 [43:12<3:47:11,  4.27s/it] 15%|█▌        | 565/3753 [43:17<3:57:47,  4.48s/it] 15%|█▌        | 566/3753 [43:21<3:58:05,  4.48s/it] 15%|█▌        | 567/3753 [43:26<4:05:23,  4.62s/it] 15%|█▌        | 568/3753 [43:34<4:54:38,  5.55s/it] 15%|█▌        | 569/3753 [43:38<4:32:25,  5.13s/it] 15%|█▌        | 570/3753 [43:41<4:04:45,  4.61s/it]{'loss': 36.9273, 'grad_norm': 3021.098388671875, 'learning_rate': 9.919624211273986e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.0580596923828125, 'weight_rejected': 6.6561808586120605, 'kl_term_chosen': 5.02874755859375, 'kl_term_rejected': 6.601982116699219, 'epoch': 0.1518987341772152}
                                                    {'loss': 36.9273, 'grad_norm': 3021.098388671875, 'learning_rate': 9.919624211273986e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.0580596923828125, 'weight_rejected': 6.6561808586120605, 'kl_term_chosen': 5.02874755859375, 'kl_term_rejected': 6.601982116699219, 'epoch': 0.15}
 15%|█▌        | 570/3753 [43:41<4:04:45,  4.61s/it] 15%|█▌        | 571/3753 [43:47<4:20:19,  4.91s/it] 15%|█▌        | 572/3753 [43:50<3:54:44,  4.43s/it] 15%|█▌        | 573/3753 [43:54<3:43:40,  4.22s/it] 15%|█▌        | 574/3753 [43:58<3:39:11,  4.14s/it] 15%|█▌        | 575/3753 [44:06<4:38:15,  5.25s/it] 15%|█▌        | 576/3753 [44:10<4:24:42,  5.00s/it] 15%|█▌        | 577/3753 [44:15<4:24:01,  4.99s/it] 15%|█▌        | 578/3753 [44:20<4:15:56,  4.84s/it] 15%|█▌        | 579/3753 [44:23<3:49:43,  4.34s/it] 15%|█▌        | 580/3753 [44:27<3:50:07,  4.35s/it]{'loss': 42.6874, 'grad_norm': 1253.4521484375, 'learning_rate': 9.911104740379551e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 10.376151084899902, 'weight_rejected': -8.97374439239502, 'kl_term_chosen': -10.26644515991211, 'kl_term_rejected': -9.823715209960938, 'epoch': 0.15456362425049966}
                                                    {'loss': 42.6874, 'grad_norm': 1253.4521484375, 'learning_rate': 9.911104740379551e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 10.376151084899902, 'weight_rejected': -8.97374439239502, 'kl_term_chosen': -10.26644515991211, 'kl_term_rejected': -9.823715209960938, 'epoch': 0.15}
 15%|█▌        | 580/3753 [44:27<3:50:07,  4.35s/it] 15%|█▌        | 581/3753 [44:31<3:41:46,  4.20s/it] 16%|█▌        | 582/3753 [44:36<3:51:34,  4.38s/it] 16%|█▌        | 583/3753 [44:40<3:42:49,  4.22s/it] 16%|█▌        | 584/3753 [44:43<3:26:39,  3.91s/it] 16%|█▌        | 585/3753 [44:47<3:27:57,  3.94s/it] 16%|█▌        | 586/3753 [44:50<3:24:04,  3.87s/it] 16%|█▌        | 587/3753 [44:55<3:36:50,  4.11s/it] 16%|█▌        | 588/3753 [45:00<3:46:38,  4.30s/it] 16%|█▌        | 589/3753 [45:05<4:06:10,  4.67s/it] 16%|█▌        | 590/3753 [45:09<3:47:28,  4.31s/it]{'loss': 25.9974, 'grad_norm': 103.80155181884766, 'learning_rate': 9.902160245255826e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.651763439178467, 'weight_rejected': 4.912185192108154, 'kl_term_chosen': 8.525840759277344, 'kl_term_rejected': 4.786262512207031, 'epoch': 0.15722851432378415}
                                                    {'loss': 25.9974, 'grad_norm': 103.80155181884766, 'learning_rate': 9.902160245255826e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.651763439178467, 'weight_rejected': 4.912185192108154, 'kl_term_chosen': 8.525840759277344, 'kl_term_rejected': 4.786262512207031, 'epoch': 0.16}
 16%|█▌        | 590/3753 [45:09<3:47:28,  4.31s/it] 16%|█▌        | 591/3753 [45:13<3:46:36,  4.30s/it] 16%|█▌        | 592/3753 [45:17<3:38:29,  4.15s/it] 16%|█▌        | 593/3753 [45:23<4:02:07,  4.60s/it] 16%|█▌        | 594/3753 [45:27<3:54:47,  4.46s/it] 16%|█▌        | 595/3753 [45:30<3:38:34,  4.15s/it] 16%|█▌        | 596/3753 [45:34<3:35:45,  4.10s/it] 16%|█▌        | 597/3753 [45:38<3:29:57,  3.99s/it] 16%|█▌        | 598/3753 [45:42<3:35:06,  4.09s/it] 16%|█▌        | 599/3753 [45:47<3:48:53,  4.35s/it] 16%|█▌        | 600/3753 [45:52<3:59:30,  4.56s/it]{'loss': 41.7871, 'grad_norm': 2090.014892578125, 'learning_rate': 9.892791499990784e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.3219974040985107, 'weight_rejected': -5.919051170349121, 'kl_term_chosen': 2.2835311889648438, 'kl_term_rejected': -6.004150390625, 'epoch': 0.15989340439706862}
                                                    {'loss': 41.7871, 'grad_norm': 2090.014892578125, 'learning_rate': 9.892791499990784e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.3219974040985107, 'weight_rejected': -5.919051170349121, 'kl_term_chosen': 2.2835311889648438, 'kl_term_rejected': -6.004150390625, 'epoch': 0.16}
 16%|█▌        | 600/3753 [45:52<3:59:30,  4.56s/it] 16%|█▌        | 601/3753 [45:57<4:06:20,  4.69s/it] 16%|█▌        | 602/3753 [46:01<3:58:53,  4.55s/it] 16%|█▌        | 603/3753 [46:06<4:02:07,  4.61s/it] 16%|█▌        | 604/3753 [46:10<3:55:06,  4.48s/it] 16%|█▌        | 605/3753 [46:14<3:49:13,  4.37s/it] 16%|█▌        | 606/3753 [46:19<3:47:10,  4.33s/it] 16%|█▌        | 607/3753 [46:22<3:30:03,  4.01s/it] 16%|█▌        | 608/3753 [46:26<3:32:15,  4.05s/it] 16%|█▌        | 609/3753 [46:31<3:41:34,  4.23s/it] 16%|█▋        | 610/3753 [46:34<3:31:16,  4.03s/it]{'loss': 38.0805, 'grad_norm': 1958.15869140625, 'learning_rate': 9.882999315388504e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.9993745684623718, 'weight_chosen': -4.404117584228516, 'weight_rejected': 0.14002344012260437, 'kl_term_chosen': 5.241737365722656, 'kl_term_rejected': -0.00031280517578125, 'epoch': 0.1625582944703531}
                                                    {'loss': 38.0805, 'grad_norm': 1958.15869140625, 'learning_rate': 9.882999315388504e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.9993745684623718, 'weight_chosen': -4.404117584228516, 'weight_rejected': 0.14002344012260437, 'kl_term_chosen': 5.241737365722656, 'kl_term_rejected': -0.00031280517578125, 'epoch': 0.16}
 16%|█▋        | 610/3753 [46:34<3:31:16,  4.03s/it] 16%|█▋        | 611/3753 [46:37<3:16:21,  3.75s/it] 16%|█▋        | 612/3753 [46:46<4:33:03,  5.22s/it] 16%|█▋        | 613/3753 [46:50<4:05:20,  4.69s/it] 16%|█▋        | 614/3753 [46:55<4:16:24,  4.90s/it] 16%|█▋        | 615/3753 [46:59<4:08:18,  4.75s/it] 16%|█▋        | 616/3753 [47:04<4:09:50,  4.78s/it] 16%|█▋        | 617/3753 [47:08<3:53:37,  4.47s/it] 16%|█▋        | 618/3753 [47:11<3:36:00,  4.13s/it] 16%|█▋        | 619/3753 [47:14<3:17:35,  3.78s/it] 17%|█▋        | 620/3753 [47:20<3:52:19,  4.45s/it]{'loss': 48.9888, 'grad_norm': 927.1771850585938, 'learning_rate': 9.872784538898985e-07, 'mean_ratio_chosen': 5.56524658203125, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.5175661444664001, 'weight_rejected': -7.2370991706848145, 'kl_term_chosen': 0.8582706451416016, 'kl_term_rejected': -7.7000579833984375, 'epoch': 0.16522318454363757}
                                                    {'loss': 48.9888, 'grad_norm': 927.1771850585938, 'learning_rate': 9.872784538898985e-07, 'mean_ratio_chosen': 5.56524658203125, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.5175661444664001, 'weight_rejected': -7.2370991706848145, 'kl_term_chosen': 0.8582706451416016, 'kl_term_rejected': -7.7000579833984375, 'epoch': 0.17}
 17%|█▋        | 620/3753 [47:20<3:52:19,  4.45s/it] 17%|█▋        | 621/3753 [47:28<4:42:48,  5.42s/it] 17%|█▋        | 622/3753 [47:31<4:13:07,  4.85s/it] 17%|█▋        | 623/3753 [47:35<3:55:38,  4.52s/it] 17%|█▋        | 624/3753 [47:39<3:50:22,  4.42s/it] 17%|█▋        | 625/3753 [47:43<3:42:07,  4.26s/it] 17%|█▋        | 626/3753 [47:47<3:40:14,  4.23s/it] 17%|█▋        | 627/3753 [47:54<4:13:27,  4.86s/it] 17%|█▋        | 628/3753 [47:58<4:06:41,  4.74s/it] 17%|█▋        | 629/3753 [48:03<4:08:31,  4.77s/it] 17%|█▋        | 630/3753 [48:07<4:02:42,  4.66s/it]{'loss': 23.3031, 'grad_norm': 191.3323974609375, 'learning_rate': 9.86214805454481e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 7.7170820236206055, 'weight_rejected': -4.309195518493652, 'kl_term_chosen': -7.6073760986328125, 'kl_term_rejected': -4.449531555175781, 'epoch': 0.16788807461692204}
                                                    {'loss': 23.3031, 'grad_norm': 191.3323974609375, 'learning_rate': 9.86214805454481e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 7.7170820236206055, 'weight_rejected': -4.309195518493652, 'kl_term_chosen': -7.6073760986328125, 'kl_term_rejected': -4.449531555175781, 'epoch': 0.17}
 17%|█▋        | 630/3753 [48:08<4:02:42,  4.66s/it] 17%|█▋        | 631/3753 [48:12<4:02:47,  4.67s/it] 17%|█▋        | 632/3753 [48:17<3:58:16,  4.58s/it] 17%|█▋        | 633/3753 [48:22<4:18:09,  4.96s/it] 17%|█▋        | 634/3753 [48:27<4:10:10,  4.81s/it] 17%|█▋        | 635/3753 [48:30<3:50:26,  4.43s/it] 17%|█▋        | 636/3753 [48:35<3:47:58,  4.39s/it] 17%|█▋        | 637/3753 [48:39<3:40:01,  4.24s/it] 17%|█▋        | 638/3753 [48:42<3:33:18,  4.11s/it] 17%|█▋        | 639/3753 [48:51<4:50:57,  5.61s/it] 17%|█▋        | 640/3753 [48:56<4:27:16,  5.15s/it]{'loss': 0.648, 'grad_norm': 380.644287109375, 'learning_rate': 9.851090782844644e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.2052463293075562, 'weight_rejected': -7.091618061065674, 'kl_term_chosen': 2.1485939025878906, 'kl_term_rejected': -7.1685791015625, 'epoch': 0.17055296469020653}
                                                    {'loss': 0.648, 'grad_norm': 380.644287109375, 'learning_rate': 9.851090782844644e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.2052463293075562, 'weight_rejected': -7.091618061065674, 'kl_term_chosen': 2.1485939025878906, 'kl_term_rejected': -7.1685791015625, 'epoch': 0.17}
 17%|█▋        | 640/3753 [48:56<4:27:16,  5.15s/it] 17%|█▋        | 641/3753 [49:03<5:02:03,  5.82s/it] 17%|█▋        | 642/3753 [49:11<5:36:27,  6.49s/it] 17%|█▋        | 643/3753 [49:15<5:03:14,  5.85s/it] 17%|█▋        | 644/3753 [49:20<4:41:47,  5.44s/it] 17%|█▋        | 645/3753 [49:24<4:27:28,  5.16s/it] 17%|█▋        | 646/3753 [49:28<4:03:57,  4.71s/it] 17%|█▋        | 647/3753 [49:32<3:57:02,  4.58s/it] 17%|█▋        | 648/3753 [49:36<3:36:42,  4.19s/it] 17%|█▋        | 649/3753 [49:40<3:40:16,  4.26s/it] 17%|█▋        | 650/3753 [49:44<3:31:22,  4.09s/it]{'loss': -2.0444, 'grad_norm': 0.0, 'learning_rate': 9.839613680733559e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 10.389054298400879, 'weight_rejected': -10.404770851135254, 'kl_term_chosen': -9.635587692260742, 'kl_term_rejected': -10.744598388671875, 'epoch': 0.173217854763491}
                                                    {'loss': -2.0444, 'grad_norm': 0.0, 'learning_rate': 9.839613680733559e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 10.389054298400879, 'weight_rejected': -10.404770851135254, 'kl_term_chosen': -9.635587692260742, 'kl_term_rejected': -10.744598388671875, 'epoch': 0.17}
 17%|█▋        | 650/3753 [49:44<3:31:22,  4.09s/it] 17%|█▋        | 651/3753 [49:52<4:42:43,  5.47s/it] 17%|█▋        | 652/3753 [49:58<4:46:41,  5.55s/it] 17%|█▋        | 653/3753 [50:03<4:38:13,  5.38s/it] 17%|█▋        | 654/3753 [50:12<5:39:31,  6.57s/it] 17%|█▋        | 655/3753 [50:16<4:58:03,  5.77s/it] 17%|█▋        | 656/3753 [50:20<4:30:40,  5.24s/it] 18%|█▊        | 657/3753 [50:24<4:07:17,  4.79s/it] 18%|█▊        | 658/3753 [50:30<4:32:03,  5.27s/it] 18%|█▊        | 659/3753 [50:34<4:01:52,  4.69s/it] 18%|█▊        | 660/3753 [50:39<4:04:53,  4.75s/it]{'loss': -3.8897, 'grad_norm': 0.0, 'learning_rate': 9.827717741480229e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 22.985795974731445, 'weight_rejected': -21.51313591003418, 'kl_term_chosen': -22.939071655273438, 'kl_term_rejected': -21.942325592041016, 'epoch': 0.1758827448367755}
                                                    {'loss': -3.8897, 'grad_norm': 0.0, 'learning_rate': 9.827717741480229e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 22.985795974731445, 'weight_rejected': -21.51313591003418, 'kl_term_chosen': -22.939071655273438, 'kl_term_rejected': -21.942325592041016, 'epoch': 0.18}
 18%|█▊        | 660/3753 [50:39<4:04:53,  4.75s/it] 18%|█▊        | 661/3753 [50:42<3:49:47,  4.46s/it] 18%|█▊        | 662/3753 [50:50<4:40:35,  5.45s/it] 18%|█▊        | 663/3753 [50:53<4:01:02,  4.68s/it] 18%|█▊        | 664/3753 [50:57<3:51:16,  4.49s/it] 18%|█▊        | 665/3753 [51:04<4:23:48,  5.13s/it] 18%|█▊        | 666/3753 [51:09<4:19:24,  5.04s/it] 18%|█▊        | 667/3753 [51:12<3:56:32,  4.60s/it] 18%|█▊        | 668/3753 [51:16<3:43:25,  4.35s/it] 18%|█▊        | 669/3753 [51:21<3:48:15,  4.44s/it] 18%|█▊        | 670/3753 [51:25<3:51:56,  4.51s/it]{'loss': -4.5675, 'grad_norm': 0.0, 'learning_rate': 9.815403994600958e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 13.412226676940918, 'weight_rejected': -21.07260513305664, 'kl_term_chosen': -12.483818054199219, 'kl_term_rejected': -21.149566650390625, 'epoch': 0.17854763491005995}
                                                    {'loss': -4.5675, 'grad_norm': 0.0, 'learning_rate': 9.815403994600958e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 13.412226676940918, 'weight_rejected': -21.07260513305664, 'kl_term_chosen': -12.483818054199219, 'kl_term_rejected': -21.149566650390625, 'epoch': 0.18}
 18%|█▊        | 670/3753 [51:25<3:51:56,  4.51s/it] 18%|█▊        | 671/3753 [51:29<3:44:50,  4.38s/it] 18%|█▊        | 672/3753 [51:40<5:22:55,  6.29s/it] 18%|█▊        | 673/3753 [51:44<4:42:46,  5.51s/it] 18%|█▊        | 674/3753 [51:51<5:12:03,  6.08s/it] 18%|█▊        | 675/3753 [51:55<4:41:56,  5.50s/it] 18%|█▊        | 676/3753 [52:00<4:23:24,  5.14s/it] 18%|█▊        | 677/3753 [52:05<4:23:08,  5.13s/it] 18%|█▊        | 678/3753 [52:09<4:07:03,  4.82s/it] 18%|█▊        | 679/3753 [52:18<5:17:11,  6.19s/it] 18%|█▊        | 680/3753 [52:23<4:47:21,  5.61s/it]{'loss': -4.3489, 'grad_norm': 0.0, 'learning_rate': 9.80267350577059e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 25.84527587890625, 'weight_rejected': -23.534921646118164, 'kl_term_chosen': -25.12274932861328, 'kl_term_rejected': -23.803863525390625, 'epoch': 0.18121252498334445}
                                                    {'loss': -4.3489, 'grad_norm': 0.0, 'learning_rate': 9.80267350577059e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 25.84527587890625, 'weight_rejected': -23.534921646118164, 'kl_term_chosen': -25.12274932861328, 'kl_term_rejected': -23.803863525390625, 'epoch': 0.18}
 18%|█▊        | 680/3753 [52:23<4:47:21,  5.61s/it] 18%|█▊        | 681/3753 [52:27<4:35:53,  5.39s/it] 18%|█▊        | 682/3753 [52:36<5:18:02,  6.21s/it] 18%|█▊        | 683/3753 [52:40<4:48:44,  5.64s/it] 18%|█▊        | 684/3753 [52:44<4:23:00,  5.14s/it] 18%|█▊        | 685/3753 [52:49<4:19:09,  5.07s/it] 18%|█▊        | 686/3753 [52:53<4:04:34,  4.78s/it] 18%|█▊        | 687/3753 [52:57<3:48:17,  4.47s/it] 18%|█▊        | 688/3753 [53:03<4:25:47,  5.20s/it] 18%|█▊        | 689/3753 [53:08<4:10:38,  4.91s/it] 18%|█▊        | 690/3753 [53:14<4:27:41,  5.24s/it]{'loss': -4.7051, 'grad_norm': 0.0, 'learning_rate': 9.78952737673028e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 16.24959945678711, 'weight_rejected': -15.904667854309082, 'kl_term_chosen': -15.480518341064453, 'kl_term_rejected': -15.98162841796875, 'epoch': 0.1838774150566289}
                                                    {'loss': -4.7051, 'grad_norm': 0.0, 'learning_rate': 9.78952737673028e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 16.24959945678711, 'weight_rejected': -15.904667854309082, 'kl_term_chosen': -15.480518341064453, 'kl_term_rejected': -15.98162841796875, 'epoch': 0.18}
 18%|█▊        | 690/3753 [53:14<4:27:41,  5.24s/it] 18%|█▊        | 691/3753 [53:18<4:12:04,  4.94s/it] 18%|█▊        | 692/3753 [53:21<3:44:57,  4.41s/it] 18%|█▊        | 693/3753 [53:28<4:17:42,  5.05s/it] 18%|█▊        | 694/3753 [53:35<4:45:00,  5.59s/it] 19%|█▊        | 695/3753 [53:39<4:28:50,  5.27s/it] 19%|█▊        | 696/3753 [53:43<4:11:23,  4.93s/it] 19%|█▊        | 697/3753 [53:47<3:52:57,  4.57s/it] 19%|█▊        | 698/3753 [53:52<3:58:10,  4.68s/it] 19%|█▊        | 699/3753 [53:57<4:01:37,  4.75s/it] 19%|█▊        | 700/3753 [54:01<3:52:13,  4.56s/it]{'loss': -4.6005, 'grad_norm': 0.0, 'learning_rate': 9.775966745192144e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 20.950260162353516, 'weight_rejected': -19.13887596130371, 'kl_term_chosen': -19.99561309814453, 'kl_term_rejected': -19.31328582763672, 'epoch': 0.18654230512991338}
                                                    {'loss': -4.6005, 'grad_norm': 0.0, 'learning_rate': 9.775966745192144e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 20.950260162353516, 'weight_rejected': -19.13887596130371, 'kl_term_chosen': -19.99561309814453, 'kl_term_rejected': -19.31328582763672, 'epoch': 0.19}
 19%|█▊        | 700/3753 [54:01<3:52:13,  4.56s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 19%|█▊        | 701/3753 [54:55<16:32:45, 19.52s/it] 19%|█▊        | 702/3753 [54:59<12:26:48, 14.69s/it] 19%|█▊        | 703/3753 [55:03<9:41:33, 11.44s/it]  19%|█▉        | 704/3753 [55:07<8:00:30,  9.46s/it] 19%|█▉        | 705/3753 [55:13<6:54:34,  8.16s/it] 19%|█▉        | 706/3753 [55:18<6:10:57,  7.30s/it] 19%|█▉        | 707/3753 [55:22<5:23:21,  6.37s/it] 19%|█▉        | 708/3753 [55:26<4:52:54,  5.77s/it] 19%|█▉        | 709/3753 [55:31<4:40:28,  5.53s/it] 19%|█▉        | 710/3753 [55:35<4:07:43,  4.88s/it]{'loss': -4.554, 'grad_norm': 0.0, 'learning_rate': 9.761992784740795e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 13.56354808807373, 'weight_rejected': -11.920360565185547, 'kl_term_chosen': -13.394691467285156, 'kl_term_rejected': -11.959999084472656, 'epoch': 0.18920719520319787}
                                                    {'loss': -4.554, 'grad_norm': 0.0, 'learning_rate': 9.761992784740795e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 13.56354808807373, 'weight_rejected': -11.920360565185547, 'kl_term_chosen': -13.394691467285156, 'kl_term_rejected': -11.959999084472656, 'epoch': 0.19}
 19%|█▉        | 710/3753 [55:35<4:07:43,  4.88s/it] 19%|█▉        | 711/3753 [55:38<3:48:18,  4.50s/it] 19%|█▉        | 712/3753 [55:44<4:06:39,  4.87s/it] 19%|█▉        | 713/3753 [55:48<3:59:26,  4.73s/it] 19%|█▉        | 714/3753 [55:53<3:49:06,  4.52s/it] 19%|█▉        | 715/3753 [55:59<4:18:49,  5.11s/it] 19%|█▉        | 716/3753 [56:04<4:18:16,  5.10s/it] 19%|█▉        | 717/3753 [56:10<4:24:10,  5.22s/it] 19%|█▉        | 718/3753 [56:15<4:22:35,  5.19s/it] 19%|█▉        | 719/3753 [56:18<4:01:05,  4.77s/it] 19%|█▉        | 720/3753 [56:22<3:46:52,  4.49s/it]{'loss': -4.4999, 'grad_norm': 0.0, 'learning_rate': 9.747606704731785e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 38.43206787109375, 'weight_rejected': -23.850297927856445, 'kl_term_chosen': -37.579132080078125, 'kl_term_rejected': -24.095382690429688, 'epoch': 0.19187208527648233}
                                                    {'loss': -4.4999, 'grad_norm': 0.0, 'learning_rate': 9.747606704731785e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 38.43206787109375, 'weight_rejected': -23.850297927856445, 'kl_term_chosen': -37.579132080078125, 'kl_term_rejected': -24.095382690429688, 'epoch': 0.19}
 19%|█▉        | 720/3753 [56:22<3:46:52,  4.49s/it] 19%|█▉        | 721/3753 [56:26<3:28:53,  4.13s/it] 19%|█▉        | 722/3753 [56:32<4:03:35,  4.82s/it] 19%|█▉        | 723/3753 [56:37<4:11:45,  4.99s/it] 19%|█▉        | 724/3753 [56:42<4:08:20,  4.92s/it] 19%|█▉        | 725/3753 [56:47<4:10:12,  4.96s/it] 19%|█▉        | 726/3753 [56:50<3:34:24,  4.25s/it] 19%|█▉        | 727/3753 [56:54<3:36:46,  4.30s/it] 19%|█▉        | 728/3753 [56:59<3:48:04,  4.52s/it]W1202 11:51:24.977000 4871 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
W1202 11:51:24.983000 4871 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 4954 closing signal SIGTERM
W1202 11:51:24.984000 4871 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 4955 closing signal SIGTERM
W1202 11:51:24.985000 4871 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 4956 closing signal SIGTERM
W1202 11:51:24.985000 4871 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 4957 closing signal SIGTERM
Traceback (most recent call last):
  File "/root/miniconda3/envs/advan/bin/accelerate", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/launch.py", line 1222, in launch_command
    multi_gpu_launcher(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/launch.py", line 853, in multi_gpu_launcher
    distrib_run.run(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py", line 138, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 715, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 879, in _invoke_run
    time.sleep(monitor_interval)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 4871 got signal: 15
