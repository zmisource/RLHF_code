nohup: ignoring input
[W1215 10:57:04.389439565 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
⚙️  Running in WANDB offline mode⚙️  Running in WANDB offline mode

⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 90.54it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 89.19it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 89.52it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 84.45it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 91.46it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 89.91it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 91.32it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 87.44it/s]
[W1215 10:57:10.892027557 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1215 10:57:10.899480565 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1215 10:57:10.903778380 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1215 10:57:10.905742892 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
/rlhf_code/code/implement_final_v3_no_kl_term2.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
开始分布式训练...开始分布式训练...开始分布式训练...开始分布式训练...



The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /wandb/offline-run-20251215_105722-mx755dwf
  0%|          | 0/3753 [00:00<?, ?it/s]--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -44.5
Sample 0 - pi_logp_chosen:  -44.146331787109375
--- Sanity Check at Step 0 ---
Difference: 0.353668212890625
---------------------------------
Sample 0 - ref_logp_chosen: -100.5
Sample 0 - pi_logp_chosen:  -100.34402465820312
Difference: 0.155975341796875
---------------------------------
Sample 0 - ref_logp_chosen: -112.0
Sample 0 - pi_logp_chosen:  -111.70196533203125
Difference: 0.29803466796875
---------------------------------
Sample 0 - ref_logp_chosen: -234.0
Sample 0 - pi_logp_chosen:  -233.57894897460938
Difference: 0.421051025390625
---------------------------------
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -65.5
Sample 0 - pi_logp_chosen:  -65.91077423095703
Difference: -0.41077423095703125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -209.0Sample 0 - ref_logp_chosen: -246.0

Sample 0 - pi_logp_chosen:  -246.4385986328125
Sample 0 - pi_logp_chosen:  -208.26136779785156Difference: -0.4385986328125
---------------------------------

Difference: 0.7386322021484375
---------------------------------
Sample 0 - ref_logp_chosen: -380.0
Sample 0 - pi_logp_chosen:  -381.313720703125
Difference: -1.313720703125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -70.0
Sample 0 - pi_logp_chosen:  -70.18619537353516
Difference: -0.18619537353515625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -167.0
Sample 0 - pi_logp_chosen:  -167.149169921875
Difference: -0.149169921875
---------------------------------
Sample 0 - ref_logp_chosen: -350.0
Sample 0 - pi_logp_chosen:  -349.3069152832031
Difference: 0.693084716796875
---------------------------------
Sample 0 - ref_logp_chosen: -452.0
Sample 0 - pi_logp_chosen:  -453.64239501953125
Difference: -1.64239501953125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -81.5
Sample 0 - pi_logp_chosen:  -81.75975036621094
Difference: -0.2597503662109375
---------------------------------
Sample 0 - ref_logp_chosen: -98.5
Sample 0 - pi_logp_chosen:  -98.78225708007812
Difference: -0.282257080078125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -251.0
Sample 0 - pi_logp_chosen:  -249.6898956298828
Difference: 1.3101043701171875
---------------------------------
Sample 0 - ref_logp_chosen: -242.0
Sample 0 - pi_logp_chosen:  -241.97824096679688
Difference: 0.021759033203125
---------------------------------
  0%|          | 1/3753 [00:04<4:56:54,  4.75s/it]{'loss': 0.2825, 'grad_norm': 1742.768798828125, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 2.1782100200653076, 'weight_chosen': -0.1649991273880005, 'weight_rejected': 0.4904192090034485, 'kl_term_chosen': 0.6550521850585938, 'epoch': 0.0002664890073284477}
                                                  {'loss': 0.2825, 'grad_norm': 1742.768798828125, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 2.1782100200653076, 'weight_chosen': -0.1649991273880005, 'weight_rejected': 0.4904192090034485, 'kl_term_chosen': 0.6550521850585938, 'epoch': 0.0}
  0%|          | 1/3753 [00:04<4:56:54,  4.75s/it]  0%|          | 2/3753 [00:10<5:18:52,  5.10s/it]  0%|          | 3/3753 [00:14<5:06:57,  4.91s/it]  0%|          | 4/3753 [00:18<4:43:01,  4.53s/it]  0%|          | 5/3753 [00:22<4:37:09,  4.44s/it]  0%|          | 6/3753 [00:28<4:58:02,  4.77s/it]  0%|          | 7/3753 [00:32<4:44:56,  4.56s/it]  0%|          | 8/3753 [00:37<4:43:05,  4.54s/it]  0%|          | 9/3753 [00:40<4:25:06,  4.25s/it]  0%|          | 10/3753 [00:44<4:19:33,  4.16s/it]{'loss': 0.2688, 'grad_norm': 2044.0826416015625, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 0.8308273553848267, 'mean_ratio_rejected': 0.5775645971298218, 'weight_chosen': 0.5862889885902405, 'weight_rejected': 0.49340879917144775, 'kl_term_chosen': -0.0926666259765625, 'epoch': 0.002664890073284477}
                                                   {'loss': 0.2688, 'grad_norm': 2044.0826416015625, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 0.8308273553848267, 'mean_ratio_rejected': 0.5775645971298218, 'weight_chosen': 0.5862889885902405, 'weight_rejected': 0.49340879917144775, 'kl_term_chosen': -0.0926666259765625, 'epoch': 0.0}
  0%|          | 10/3753 [00:44<4:19:33,  4.16s/it]  0%|          | 11/3753 [00:49<4:25:38,  4.26s/it]  0%|          | 12/3753 [00:54<4:38:01,  4.46s/it]  0%|          | 13/3753 [00:58<4:34:57,  4.41s/it]  0%|          | 14/3753 [01:02<4:27:59,  4.30s/it]  0%|          | 15/3753 [01:06<4:17:09,  4.13s/it]  0%|          | 16/3753 [01:10<4:15:23,  4.10s/it]  0%|          | 17/3753 [01:13<4:08:44,  3.99s/it]  0%|          | 18/3753 [01:18<4:25:19,  4.26s/it]  1%|          | 19/3753 [01:22<4:08:09,  3.99s/it]  1%|          | 20/3753 [01:25<4:05:48,  3.95s/it]{'loss': 0.3642, 'grad_norm': 2524.141845703125, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 0.8199647665023804, 'mean_ratio_rejected': 1.0182422399520874, 'weight_chosen': 0.5967140793800354, 'weight_rejected': 0.4972687363624573, 'kl_term_chosen': -0.09924697875976562, 'epoch': 0.005329780146568954}
                                                   {'loss': 0.3642, 'grad_norm': 2524.141845703125, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 0.8199647665023804, 'mean_ratio_rejected': 1.0182422399520874, 'weight_chosen': 0.5967140793800354, 'weight_rejected': 0.4972687363624573, 'kl_term_chosen': -0.09924697875976562, 'epoch': 0.01}
  1%|          | 20/3753 [01:26<4:05:48,  3.95s/it]  1%|          | 21/3753 [01:30<4:10:19,  4.02s/it]  1%|          | 22/3753 [01:37<5:17:31,  5.11s/it]  1%|          | 23/3753 [01:42<5:15:14,  5.07s/it]  1%|          | 24/3753 [01:46<4:42:04,  4.54s/it]  1%|          | 25/3753 [01:50<4:35:39,  4.44s/it]  1%|          | 26/3753 [01:53<4:10:34,  4.03s/it]  1%|          | 27/3753 [01:57<4:11:57,  4.06s/it]  1%|          | 28/3753 [02:01<4:09:14,  4.01s/it]  1%|          | 29/3753 [02:05<4:05:52,  3.96s/it]  1%|          | 30/3753 [02:09<4:09:34,  4.02s/it]{'loss': 0.084, 'grad_norm': 1044.1171875, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 0.6715014576911926, 'mean_ratio_rejected': 0.740013837814331, 'weight_chosen': 0.6952744722366333, 'weight_rejected': 0.49697884917259216, 'kl_term_chosen': -0.19911956787109375, 'epoch': 0.007994670219853431}
                                                   {'loss': 0.084, 'grad_norm': 1044.1171875, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 0.6715014576911926, 'mean_ratio_rejected': 0.740013837814331, 'weight_chosen': 0.6952744722366333, 'weight_rejected': 0.49697884917259216, 'kl_term_chosen': -0.19911956787109375, 'epoch': 0.01}
  1%|          | 30/3753 [02:09<4:09:34,  4.02s/it]  1%|          | 31/3753 [02:14<4:32:20,  4.39s/it]  1%|          | 32/3753 [02:18<4:19:41,  4.19s/it]  1%|          | 33/3753 [02:21<4:08:47,  4.01s/it]  1%|          | 34/3753 [02:28<4:59:04,  4.83s/it]  1%|          | 35/3753 [02:34<5:12:42,  5.05s/it]  1%|          | 36/3753 [02:40<5:33:25,  5.38s/it]  1%|          | 37/3753 [02:46<5:39:36,  5.48s/it]  1%|          | 38/3753 [02:50<5:19:26,  5.16s/it]  1%|          | 39/3753 [02:58<6:16:25,  6.08s/it]  1%|          | 40/3753 [03:03<5:42:11,  5.53s/it]{'loss': -0.0165, 'grad_norm': 970.0148315429688, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 0.6942086815834045, 'mean_ratio_rejected': 0.5275301337242126, 'weight_chosen': 0.6798668503761292, 'weight_rejected': 0.4971313774585724, 'kl_term_chosen': -0.18249130249023438, 'epoch': 0.010659560293137908}
                                                   {'loss': -0.0165, 'grad_norm': 970.0148315429688, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 0.6942086815834045, 'mean_ratio_rejected': 0.5275301337242126, 'weight_chosen': 0.6798668503761292, 'weight_rejected': 0.4971313774585724, 'kl_term_chosen': -0.18249130249023438, 'epoch': 0.01}
  1%|          | 40/3753 [03:03<5:42:11,  5.53s/it]  1%|          | 41/3753 [03:09<6:02:17,  5.86s/it]  1%|          | 42/3753 [03:12<5:09:43,  5.01s/it]  1%|          | 43/3753 [03:17<5:05:14,  4.94s/it]  1%|          | 44/3753 [03:21<4:51:48,  4.72s/it]  1%|          | 45/3753 [03:26<4:55:00,  4.77s/it]  1%|          | 46/3753 [03:31<4:58:30,  4.83s/it]  1%|▏         | 47/3753 [03:34<4:22:59,  4.26s/it]  1%|▏         | 48/3753 [03:38<4:18:40,  4.19s/it]  1%|▏         | 49/3753 [03:43<4:26:10,  4.31s/it]  1%|▏         | 50/3753 [03:46<4:18:30,  4.19s/it]{'loss': -0.0177, 'grad_norm': 712.5924682617188, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 0.7177934646606445, 'mean_ratio_rejected': 1.043793797492981, 'weight_chosen': 0.6633453369140625, 'weight_rejected': 0.498779296875, 'kl_term_chosen': -0.1657867431640625, 'epoch': 0.013324450366422385}
                                                   {'loss': -0.0177, 'grad_norm': 712.5924682617188, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 0.7177934646606445, 'mean_ratio_rejected': 1.043793797492981, 'weight_chosen': 0.6633453369140625, 'weight_rejected': 0.498779296875, 'kl_term_chosen': -0.1657867431640625, 'epoch': 0.01}
  1%|▏         | 50/3753 [03:47<4:18:30,  4.19s/it]  1%|▏         | 51/3753 [03:51<4:17:22,  4.17s/it]  1%|▏         | 52/3753 [03:55<4:26:53,  4.33s/it]  1%|▏         | 53/3753 [04:01<4:55:21,  4.79s/it]  1%|▏         | 54/3753 [04:05<4:31:18,  4.40s/it]  1%|▏         | 55/3753 [04:13<5:40:12,  5.52s/it]  1%|▏         | 56/3753 [04:21<6:23:53,  6.23s/it]  2%|▏         | 57/3753 [04:26<5:59:18,  5.83s/it]  2%|▏         | 58/3753 [04:29<5:15:22,  5.12s/it]  2%|▏         | 59/3753 [04:37<5:59:59,  5.85s/it]  2%|▏         | 60/3753 [04:40<5:10:11,  5.04s/it]{'loss': 0.0271, 'grad_norm': 783.38330078125, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 1.0256609916687012, 'mean_ratio_rejected': 1.1953010559082031, 'weight_chosen': 0.4865989685058594, 'weight_rejected': 0.4970703423023224, 'kl_term_chosen': 0.012668609619140625, 'epoch': 0.015989340439706862}
                                                   {'loss': 0.0271, 'grad_norm': 783.38330078125, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 1.0256609916687012, 'mean_ratio_rejected': 1.1953010559082031, 'weight_chosen': 0.4865989685058594, 'weight_rejected': 0.4970703423023224, 'kl_term_chosen': 0.012668609619140625, 'epoch': 0.02}
  2%|▏         | 60/3753 [04:40<5:10:11,  5.04s/it]  2%|▏         | 61/3753 [04:46<5:24:28,  5.27s/it]  2%|▏         | 62/3753 [04:50<5:06:35,  4.98s/it]  2%|▏         | 63/3753 [04:54<4:57:30,  4.84s/it]  2%|▏         | 64/3753 [05:00<5:05:27,  4.97s/it]  2%|▏         | 65/3753 [05:04<4:45:56,  4.65s/it]  2%|▏         | 66/3753 [05:09<4:55:20,  4.81s/it]  2%|▏         | 67/3753 [05:13<4:52:26,  4.76s/it]  2%|▏         | 68/3753 [05:17<4:32:46,  4.44s/it]  2%|▏         | 69/3753 [05:22<4:35:05,  4.48s/it]  2%|▏         | 70/3753 [05:25<4:20:48,  4.25s/it]{'loss': 0.0024, 'grad_norm': 934.402587890625, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 1.5817899703979492, 'mean_ratio_rejected': 0.2471371442079544, 'weight_chosen': 0.2673645615577698, 'weight_rejected': 0.4969483017921448, 'kl_term_chosen': 0.229278564453125, 'epoch': 0.018654230512991338}
                                                   {'loss': 0.0024, 'grad_norm': 934.402587890625, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 1.5817899703979492, 'mean_ratio_rejected': 0.2471371442079544, 'weight_chosen': 0.2673645615577698, 'weight_rejected': 0.4969483017921448, 'kl_term_chosen': 0.229278564453125, 'epoch': 0.02}
  2%|▏         | 70/3753 [05:25<4:20:48,  4.25s/it]  2%|▏         | 71/3753 [05:30<4:33:18,  4.45s/it]  2%|▏         | 72/3753 [05:35<4:39:16,  4.55s/it]  2%|▏         | 73/3753 [05:39<4:27:34,  4.36s/it]  2%|▏         | 74/3753 [05:43<4:16:11,  4.18s/it]  2%|▏         | 75/3753 [05:46<4:06:05,  4.01s/it]  2%|▏         | 76/3753 [05:52<4:37:25,  4.53s/it]  2%|▏         | 77/3753 [05:55<4:15:36,  4.17s/it]  2%|▏         | 78/3753 [06:01<4:33:27,  4.46s/it]  2%|▏         | 79/3753 [06:05<4:30:35,  4.42s/it]  2%|▏         | 80/3753 [06:10<4:41:10,  4.59s/it]{'loss': 0.0199, 'grad_norm': 1306.4617919921875, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 1.1170796155929565, 'mean_ratio_rejected': 1.7295200824737549, 'weight_chosen': 0.4415283799171448, 'weight_rejected': 0.4974670708179474, 'kl_term_chosen': 0.05535888671875, 'epoch': 0.021319120586275817}
                                                   {'loss': 0.0199, 'grad_norm': 1306.4617919921875, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 1.1170796155929565, 'mean_ratio_rejected': 1.7295200824737549, 'weight_chosen': 0.4415283799171448, 'weight_rejected': 0.4974670708179474, 'kl_term_chosen': 0.05535888671875, 'epoch': 0.02}
  2%|▏         | 80/3753 [06:10<4:41:10,  4.59s/it]  2%|▏         | 81/3753 [06:15<4:44:06,  4.64s/it]  2%|▏         | 82/3753 [06:18<4:28:58,  4.40s/it]  2%|▏         | 83/3753 [06:25<5:17:33,  5.19s/it]  2%|▏         | 84/3753 [06:30<5:11:03,  5.09s/it]  2%|▏         | 85/3753 [06:34<4:43:50,  4.64s/it]  2%|▏         | 86/3753 [06:37<4:20:36,  4.26s/it]  2%|▏         | 87/3753 [06:44<5:09:03,  5.06s/it]  2%|▏         | 88/3753 [06:48<4:45:37,  4.68s/it]  2%|▏         | 89/3753 [06:53<4:45:18,  4.67s/it]  2%|▏         | 90/3753 [06:57<4:33:45,  4.48s/it]{'loss': 0.0007, 'grad_norm': 1050.046142578125, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 3.322387218475342, 'mean_ratio_rejected': 0.12409970164299011, 'weight_chosen': -0.10510236024856567, 'weight_rejected': 0.49713143706321716, 'kl_term_chosen': 0.600341796875, 'epoch': 0.023984010659560292}
                                                   {'loss': 0.0007, 'grad_norm': 1050.046142578125, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 3.322387218475342, 'mean_ratio_rejected': 0.12409970164299011, 'weight_chosen': -0.10510236024856567, 'weight_rejected': 0.49713143706321716, 'kl_term_chosen': 0.600341796875, 'epoch': 0.02}
  2%|▏         | 90/3753 [06:57<4:33:45,  4.48s/it]  2%|▏         | 91/3753 [07:00<4:12:15,  4.13s/it]  2%|▏         | 92/3753 [07:04<4:09:01,  4.08s/it]  2%|▏         | 93/3753 [07:09<4:33:17,  4.48s/it]  3%|▎         | 94/3753 [07:14<4:27:14,  4.38s/it]  3%|▎         | 95/3753 [07:20<5:06:52,  5.03s/it]  3%|▎         | 96/3753 [07:24<4:48:10,  4.73s/it]  3%|▎         | 97/3753 [07:28<4:39:39,  4.59s/it]  3%|▎         | 98/3753 [07:34<5:01:46,  4.95s/it]  3%|▎         | 99/3753 [07:38<4:34:04,  4.50s/it]  3%|▎         | 100/3753 [07:42<4:27:44,  4.40s/it]{'loss': -0.007, 'grad_norm': 725.0858764648438, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 0.5272525548934937, 'mean_ratio_rejected': 0.5623375177383423, 'weight_chosen': 0.8151247501373291, 'weight_rejected': 0.49652114510536194, 'kl_term_chosen': -0.320037841796875, 'epoch': 0.02664890073284477}
                                                    {'loss': -0.007, 'grad_norm': 725.0858764648438, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 0.5272525548934937, 'mean_ratio_rejected': 0.5623375177383423, 'weight_chosen': 0.8151247501373291, 'weight_rejected': 0.49652114510536194, 'kl_term_chosen': -0.320037841796875, 'epoch': 0.03}
  3%|▎         | 100/3753 [07:42<4:27:44,  4.40s/it]  3%|▎         | 101/3753 [07:46<4:29:09,  4.42s/it]  3%|▎         | 102/3753 [07:50<4:24:07,  4.34s/it]  3%|▎         | 103/3753 [07:54<4:13:30,  4.17s/it]  3%|▎         | 104/3753 [08:00<4:41:02,  4.62s/it]  3%|▎         | 105/3753 [08:04<4:37:03,  4.56s/it]  3%|▎         | 106/3753 [08:10<4:53:44,  4.83s/it]  3%|▎         | 107/3753 [08:14<4:49:52,  4.77s/it]  3%|▎         | 108/3753 [08:18<4:35:58,  4.54s/it]  3%|▎         | 109/3753 [08:22<4:25:08,  4.37s/it]  3%|▎         | 110/3753 [08:26<4:17:23,  4.24s/it]{'loss': 0.0211, 'grad_norm': 730.62841796875, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 1.3562839031219482, 'mean_ratio_rejected': 0.37153497338294983, 'weight_chosen': 0.3466796875, 'weight_rejected': 0.499267578125, 'kl_term_chosen': 0.152374267578125, 'epoch': 0.029313790806129246}
                                                    {'loss': 0.0211, 'grad_norm': 730.62841796875, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 1.3562839031219482, 'mean_ratio_rejected': 0.37153497338294983, 'weight_chosen': 0.3466796875, 'weight_rejected': 0.499267578125, 'kl_term_chosen': 0.152374267578125, 'epoch': 0.03}
  3%|▎         | 110/3753 [08:26<4:17:23,  4.24s/it]  3%|▎         | 111/3753 [08:32<4:49:04,  4.76s/it]  3%|▎         | 112/3753 [08:36<4:30:55,  4.46s/it]  3%|▎         | 113/3753 [08:39<4:10:29,  4.13s/it]  3%|▎         | 114/3753 [08:43<4:00:22,  3.96s/it]  3%|▎         | 115/3753 [08:47<3:57:08,  3.91s/it]  3%|▎         | 116/3753 [08:52<4:14:56,  4.21s/it]  3%|▎         | 117/3753 [08:56<4:13:39,  4.19s/it]  3%|▎         | 118/3753 [09:00<4:16:54,  4.24s/it]  3%|▎         | 119/3753 [09:08<5:24:01,  5.35s/it]  3%|▎         | 120/3753 [09:13<5:07:29,  5.08s/it]{'loss': 0.0624, 'grad_norm': 1257.7886962890625, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 1.1010915040969849, 'mean_ratio_rejected': 0.20982898771762848, 'weight_chosen': 0.4476224184036255, 'weight_rejected': 0.49591079354286194, 'kl_term_chosen': 0.04815101623535156, 'epoch': 0.031978680879413725}
                                                    {'loss': 0.0624, 'grad_norm': 1257.7886962890625, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 1.1010915040969849, 'mean_ratio_rejected': 0.20982898771762848, 'weight_chosen': 0.4476224184036255, 'weight_rejected': 0.49591079354286194, 'kl_term_chosen': 0.04815101623535156, 'epoch': 0.03}
  3%|▎         | 120/3753 [09:13<5:07:29,  5.08s/it]  3%|▎         | 121/3753 [09:17<4:52:40,  4.84s/it]  3%|▎         | 122/3753 [09:22<4:54:04,  4.86s/it]  3%|▎         | 123/3753 [09:26<4:43:03,  4.68s/it]  3%|▎         | 124/3753 [09:30<4:26:46,  4.41s/it]  3%|▎         | 125/3753 [09:35<4:32:45,  4.51s/it]  3%|▎         | 126/3753 [09:39<4:40:10,  4.63s/it]  3%|▎         | 127/3753 [09:43<4:22:13,  4.34s/it]  3%|▎         | 128/3753 [09:48<4:35:30,  4.56s/it]  3%|▎         | 129/3753 [09:54<4:56:58,  4.92s/it]  3%|▎         | 130/3753 [09:58<4:50:42,  4.81s/it]{'loss': 0.054, 'grad_norm': 1046.9578857421875, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 2.9921982288360596, 'mean_ratio_rejected': 0.29129648208618164, 'weight_chosen': -0.05428999662399292, 'weight_rejected': 0.4922495186328888, 'kl_term_chosen': 0.548004150390625, 'epoch': 0.034643570952698204}
                                                    {'loss': 0.054, 'grad_norm': 1046.9578857421875, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 2.9921982288360596, 'mean_ratio_rejected': 0.29129648208618164, 'weight_chosen': -0.05428999662399292, 'weight_rejected': 0.4922495186328888, 'kl_term_chosen': 0.548004150390625, 'epoch': 0.03}
  3%|▎         | 130/3753 [09:59<4:50:42,  4.81s/it]  3%|▎         | 131/3753 [10:02<4:34:40,  4.55s/it]  4%|▎         | 132/3753 [10:06<4:12:18,  4.18s/it]  4%|▎         | 133/3753 [10:11<4:23:15,  4.36s/it]  4%|▎         | 134/3753 [10:15<4:27:02,  4.43s/it]  4%|▎         | 135/3753 [10:19<4:14:58,  4.23s/it]  4%|▎         | 136/3753 [10:22<4:02:28,  4.02s/it]  4%|▎         | 137/3753 [10:26<3:56:59,  3.93s/it]  4%|▎         | 138/3753 [10:31<4:11:58,  4.18s/it]  4%|▎         | 139/3753 [10:35<4:05:36,  4.08s/it]  4%|▎         | 140/3753 [10:40<4:24:16,  4.39s/it]{'loss': 0.0368, 'grad_norm': 938.5759887695312, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 0.6509706377983093, 'mean_ratio_rejected': 0.8504260182380676, 'weight_chosen': 0.7133636474609375, 'weight_rejected': 0.49884033203125, 'kl_term_chosen': -0.2146453857421875, 'epoch': 0.037308461025982675}
                                                    {'loss': 0.0368, 'grad_norm': 938.5759887695312, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 0.6509706377983093, 'mean_ratio_rejected': 0.8504260182380676, 'weight_chosen': 0.7133636474609375, 'weight_rejected': 0.49884033203125, 'kl_term_chosen': -0.2146453857421875, 'epoch': 0.04}
  4%|▎         | 140/3753 [10:40<4:24:16,  4.39s/it]  4%|▍         | 141/3753 [10:44<4:14:33,  4.23s/it]  4%|▍         | 142/3753 [10:50<4:56:44,  4.93s/it]  4%|▍         | 143/3753 [10:54<4:41:29,  4.68s/it]  4%|▍         | 144/3753 [11:00<5:07:01,  5.10s/it]  4%|▍         | 145/3753 [11:08<5:46:01,  5.75s/it]  4%|▍         | 146/3753 [11:13<5:37:19,  5.61s/it]  4%|▍         | 147/3753 [11:20<6:01:39,  6.02s/it]  4%|▍         | 148/3753 [11:25<5:44:44,  5.74s/it]  4%|▍         | 149/3753 [11:29<5:12:14,  5.20s/it]  4%|▍         | 150/3753 [11:36<5:45:53,  5.76s/it]{'loss': 0.1496, 'grad_norm': 725.3217163085938, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 0.2067430317401886, 'mean_ratio_rejected': 0.12918709218502045, 'weight_chosen': 1.2845993041992188, 'weight_rejected': 0.4977417290210724, 'kl_term_chosen': -0.7881393432617188, 'epoch': 0.039973351099267154}
                                                    {'loss': 0.1496, 'grad_norm': 725.3217163085938, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 0.2067430317401886, 'mean_ratio_rejected': 0.12918709218502045, 'weight_chosen': 1.2845993041992188, 'weight_rejected': 0.4977417290210724, 'kl_term_chosen': -0.7881393432617188, 'epoch': 0.04}
  4%|▍         | 150/3753 [11:36<5:45:53,  5.76s/it]  4%|▍         | 151/3753 [11:41<5:38:37,  5.64s/it]  4%|▍         | 152/3753 [11:45<5:07:18,  5.12s/it]  4%|▍         | 153/3753 [11:50<5:02:59,  5.05s/it]  4%|▍         | 154/3753 [11:55<4:50:09,  4.84s/it]  4%|▍         | 155/3753 [11:59<4:43:43,  4.73s/it]  4%|▍         | 156/3753 [12:04<4:39:45,  4.67s/it]  4%|▍         | 157/3753 [12:07<4:23:50,  4.40s/it]  4%|▍         | 158/3753 [12:12<4:29:11,  4.49s/it]  4%|▍         | 159/3753 [12:16<4:21:00,  4.36s/it]  4%|▍         | 160/3753 [12:21<4:25:04,  4.43s/it]{'loss': 0.2, 'grad_norm': 1869.4287109375, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 0.31507712602615356, 'mean_ratio_rejected': 0.5668257474899292, 'weight_chosen': 1.0755767822265625, 'weight_rejected': 0.4984588623046875, 'kl_term_chosen': -0.5774688720703125, 'epoch': 0.04263824117255163}
                                                    {'loss': 0.2, 'grad_norm': 1869.4287109375, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 0.31507712602615356, 'mean_ratio_rejected': 0.5668257474899292, 'weight_chosen': 1.0755767822265625, 'weight_rejected': 0.4984588623046875, 'kl_term_chosen': -0.5774688720703125, 'epoch': 0.04}
  4%|▍         | 160/3753 [12:21<4:25:04,  4.43s/it]  4%|▍         | 161/3753 [12:25<4:19:17,  4.33s/it]  4%|▍         | 162/3753 [12:29<4:19:27,  4.34s/it]  4%|▍         | 163/3753 [12:33<4:02:26,  4.05s/it]  4%|▍         | 164/3753 [12:39<4:50:59,  4.86s/it]  4%|▍         | 165/3753 [12:46<5:23:55,  5.42s/it]  4%|▍         | 166/3753 [12:50<4:53:43,  4.91s/it]  4%|▍         | 167/3753 [12:55<4:56:52,  4.97s/it]  4%|▍         | 168/3753 [13:00<5:02:13,  5.06s/it]  5%|▍         | 169/3753 [13:04<4:33:27,  4.58s/it]  5%|▍         | 170/3753 [13:07<4:10:15,  4.19s/it]{'loss': 0.34, 'grad_norm': 2253.114990234375, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 1.0017104148864746, 'mean_ratio_rejected': 1.7799203395843506, 'weight_chosen': 0.49646008014678955, 'weight_rejected': 0.4950563609600067, 'kl_term_chosen': 0.0008544921875, 'epoch': 0.04530313124583611}
                                                    {'loss': 0.34, 'grad_norm': 2253.114990234375, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 1.0017104148864746, 'mean_ratio_rejected': 1.7799203395843506, 'weight_chosen': 0.49646008014678955, 'weight_rejected': 0.4950563609600067, 'kl_term_chosen': 0.0008544921875, 'epoch': 0.05}
  5%|▍         | 170/3753 [13:07<4:10:15,  4.19s/it]  5%|▍         | 171/3753 [13:11<4:16:16,  4.29s/it]  5%|▍         | 172/3753 [13:20<5:37:54,  5.66s/it]  5%|▍         | 173/3753 [13:24<5:02:46,  5.07s/it]  5%|▍         | 174/3753 [13:28<4:51:01,  4.88s/it]  5%|▍         | 175/3753 [13:33<4:43:07,  4.75s/it]  5%|▍         | 176/3753 [13:36<4:23:30,  4.42s/it]  5%|▍         | 177/3753 [13:41<4:25:56,  4.46s/it]  5%|▍         | 178/3753 [13:46<4:36:57,  4.65s/it]  5%|▍         | 179/3753 [13:50<4:19:10,  4.35s/it]  5%|▍         | 180/3753 [13:54<4:17:59,  4.33s/it]{'loss': 0.5131, 'grad_norm': 6760.00927734375, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 5.280881404876709, 'mean_ratio_rejected': 5.660892486572266, 'weight_chosen': -0.3367459177970886, 'weight_rejected': 0.49401894211769104, 'kl_term_chosen': 0.8320465087890625, 'epoch': 0.047968021319120584}
                                                    {'loss': 0.5131, 'grad_norm': 6760.00927734375, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 5.280881404876709, 'mean_ratio_rejected': 5.660892486572266, 'weight_chosen': -0.3367459177970886, 'weight_rejected': 0.49401894211769104, 'kl_term_chosen': 0.8320465087890625, 'epoch': 0.05}
  5%|▍         | 180/3753 [13:54<4:17:59,  4.33s/it]  5%|▍         | 181/3753 [13:59<4:21:51,  4.40s/it]  5%|▍         | 182/3753 [14:06<5:10:58,  5.22s/it]  5%|▍         | 183/3753 [14:10<4:58:50,  5.02s/it]  5%|▍         | 184/3753 [14:16<5:07:31,  5.17s/it]  5%|▍         | 185/3753 [14:21<5:03:20,  5.10s/it]  5%|▍         | 186/3753 [14:25<4:44:20,  4.78s/it]  5%|▍         | 187/3753 [14:29<4:29:42,  4.54s/it]  5%|▌         | 188/3753 [14:33<4:26:13,  4.48s/it]  5%|▌         | 189/3753 [14:40<5:11:09,  5.24s/it]  5%|▌         | 190/3753 [14:44<4:55:42,  4.98s/it]{'loss': 0.1578, 'grad_norm': 837.2716064453125, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 0.13668006658554077, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.490539789199829, 'weight_rejected': 0.4950563907623291, 'kl_term_chosen': -0.99505615234375, 'epoch': 0.05063291139240506}
                                                    {'loss': 0.1578, 'grad_norm': 837.2716064453125, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 0.13668006658554077, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.490539789199829, 'weight_rejected': 0.4950563907623291, 'kl_term_chosen': -0.99505615234375, 'epoch': 0.05}
  5%|▌         | 190/3753 [14:45<4:55:42,  4.98s/it]  5%|▌         | 191/3753 [14:48<4:32:14,  4.59s/it]  5%|▌         | 192/3753 [14:56<5:22:47,  5.44s/it]  5%|▌         | 193/3753 [15:00<5:03:15,  5.11s/it]  5%|▌         | 194/3753 [15:05<5:06:06,  5.16s/it]  5%|▌         | 195/3753 [15:09<4:49:45,  4.89s/it]  5%|▌         | 196/3753 [15:13<4:26:21,  4.49s/it]  5%|▌         | 197/3753 [15:21<5:36:07,  5.67s/it]  5%|▌         | 198/3753 [15:25<5:05:14,  5.15s/it]  5%|▌         | 199/3753 [15:31<5:15:54,  5.33s/it]  5%|▌         | 200/3753 [15:35<4:57:55,  5.03s/it]{'loss': 0.1938, 'grad_norm': 1195.8465576171875, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 3.1028125286102295, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.06847381591796875, 'weight_rejected': 0.49896240234375, 'kl_term_chosen': 0.5661544799804688, 'epoch': 0.05329780146568954}
                                                    {'loss': 0.1938, 'grad_norm': 1195.8465576171875, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 3.1028125286102295, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.06847381591796875, 'weight_rejected': 0.49896240234375, 'kl_term_chosen': 0.5661544799804688, 'epoch': 0.05}
  5%|▌         | 200/3753 [15:36<4:57:55,  5.03s/it]  5%|▌         | 201/3753 [15:42<5:25:25,  5.50s/it]  5%|▌         | 202/3753 [15:46<5:00:06,  5.07s/it]  5%|▌         | 203/3753 [15:51<4:58:59,  5.05s/it]  5%|▌         | 204/3753 [15:55<4:33:39,  4.63s/it]  5%|▌         | 205/3753 [15:59<4:28:08,  4.53s/it]  5%|▌         | 206/3753 [16:05<5:00:30,  5.08s/it]  6%|▌         | 207/3753 [16:10<4:44:30,  4.81s/it]  6%|▌         | 208/3753 [16:15<4:50:06,  4.91s/it]  6%|▌         | 209/3753 [16:20<4:48:31,  4.88s/it]  6%|▌         | 210/3753 [16:24<4:42:51,  4.79s/it]{'loss': 0.199, 'grad_norm': 479.6103515625, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 0.29745909571647644, 'mean_ratio_rejected': 1.2931092977523804, 'weight_chosen': 1.1049575805664062, 'weight_rejected': 0.498992919921875, 'kl_term_chosen': -0.6062393188476562, 'epoch': 0.05596269153897402}
                                                    {'loss': 0.199, 'grad_norm': 479.6103515625, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 0.29745909571647644, 'mean_ratio_rejected': 1.2931092977523804, 'weight_chosen': 1.1049575805664062, 'weight_rejected': 0.498992919921875, 'kl_term_chosen': -0.6062393188476562, 'epoch': 0.06}
  6%|▌         | 210/3753 [16:24<4:42:51,  4.79s/it]  6%|▌         | 211/3753 [16:30<4:58:31,  5.06s/it]  6%|▌         | 212/3753 [16:33<4:29:05,  4.56s/it]  6%|▌         | 213/3753 [16:38<4:31:12,  4.60s/it]  6%|▌         | 214/3753 [16:44<4:49:49,  4.91s/it]  6%|▌         | 215/3753 [16:48<4:34:24,  4.65s/it]  6%|▌         | 216/3753 [16:52<4:32:08,  4.62s/it]  6%|▌         | 217/3753 [16:56<4:18:53,  4.39s/it]  6%|▌         | 218/3753 [17:01<4:21:02,  4.43s/it]  6%|▌         | 219/3753 [17:04<4:10:17,  4.25s/it]  6%|▌         | 220/3753 [17:08<4:01:36,  4.10s/it]{'loss': 0.101, 'grad_norm': 696.8262939453125, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 0.5414387583732605, 'mean_ratio_rejected': 0.5969040989875793, 'weight_chosen': 0.8043213486671448, 'weight_rejected': 0.4969483017921448, 'kl_term_chosen': -0.3067626953125, 'epoch': 0.05862758161225849}
                                                    {'loss': 0.101, 'grad_norm': 696.8262939453125, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 0.5414387583732605, 'mean_ratio_rejected': 0.5969040989875793, 'weight_chosen': 0.8043213486671448, 'weight_rejected': 0.4969483017921448, 'kl_term_chosen': -0.3067626953125, 'epoch': 0.06}
  6%|▌         | 220/3753 [17:08<4:01:36,  4.10s/it]  6%|▌         | 221/3753 [17:12<3:54:16,  3.98s/it]  6%|▌         | 222/3753 [17:16<4:03:30,  4.14s/it]  6%|▌         | 223/3753 [17:20<3:52:51,  3.96s/it]  6%|▌         | 224/3753 [17:24<3:55:18,  4.00s/it]  6%|▌         | 225/3753 [17:28<3:58:23,  4.05s/it]  6%|▌         | 226/3753 [17:32<3:54:14,  3.98s/it]  6%|▌         | 227/3753 [17:37<4:19:10,  4.41s/it]  6%|▌         | 228/3753 [17:41<4:05:32,  4.18s/it]  6%|▌         | 229/3753 [17:46<4:14:53,  4.34s/it]  6%|▌         | 230/3753 [17:52<4:53:51,  5.00s/it]{'loss': 0.0718, 'grad_norm': 814.2748413085938, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 0.5291061401367188, 'mean_ratio_rejected': 0.28879594802856445, 'weight_chosen': 0.8165130615234375, 'weight_rejected': 0.4981079399585724, 'kl_term_chosen': -0.3182830810546875, 'epoch': 0.06129247168554297}
                                                    {'loss': 0.0718, 'grad_norm': 814.2748413085938, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 0.5291061401367188, 'mean_ratio_rejected': 0.28879594802856445, 'weight_chosen': 0.8165130615234375, 'weight_rejected': 0.4981079399585724, 'kl_term_chosen': -0.3182830810546875, 'epoch': 0.06}
  6%|▌         | 230/3753 [17:52<4:53:51,  5.00s/it]  6%|▌         | 231/3753 [17:58<5:05:32,  5.21s/it]  6%|▌         | 232/3753 [18:02<4:48:50,  4.92s/it]  6%|▌         | 233/3753 [18:07<4:49:52,  4.94s/it]  6%|▌         | 234/3753 [18:13<4:57:13,  5.07s/it]  6%|▋         | 235/3753 [18:21<5:57:58,  6.11s/it]  6%|▋         | 236/3753 [18:25<5:26:01,  5.56s/it]  6%|▋         | 237/3753 [18:29<4:49:07,  4.93s/it]  6%|▋         | 238/3753 [18:34<4:44:27,  4.86s/it]  6%|▋         | 239/3753 [18:39<4:46:19,  4.89s/it]  6%|▋         | 240/3753 [18:43<4:38:47,  4.76s/it]{'loss': 0.4479, 'grad_norm': 840.4769897460938, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 0.4379221796989441, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.9067234396934509, 'weight_rejected': 0.49423256516456604, 'kl_term_chosen': -0.4128570556640625, 'epoch': 0.06395736175882745}
                                                    {'loss': 0.4479, 'grad_norm': 840.4769897460938, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 0.4379221796989441, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.9067234396934509, 'weight_rejected': 0.49423256516456604, 'kl_term_chosen': -0.4128570556640625, 'epoch': 0.06}
  6%|▋         | 240/3753 [18:43<4:38:47,  4.76s/it]  6%|▋         | 241/3753 [18:47<4:28:15,  4.58s/it]  6%|▋         | 242/3753 [18:51<4:20:40,  4.45s/it]  6%|▋         | 243/3753 [18:56<4:23:06,  4.50s/it]  7%|▋         | 244/3753 [19:02<4:48:25,  4.93s/it]  7%|▋         | 245/3753 [19:07<4:44:45,  4.87s/it]  7%|▋         | 246/3753 [19:10<4:22:27,  4.49s/it]  7%|▋         | 247/3753 [19:17<5:05:28,  5.23s/it]  7%|▋         | 248/3753 [19:22<4:59:21,  5.12s/it]  7%|▋         | 249/3753 [19:27<5:04:24,  5.21s/it]  7%|▋         | 250/3753 [19:33<5:02:34,  5.18s/it]{'loss': 0.2218, 'grad_norm': 539.5325927734375, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 0.8978177905082703, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.5439932942390442, 'weight_rejected': 0.4912892282009125, 'kl_term_chosen': -0.05389404296875, 'epoch': 0.06662225183211193}
                                                    {'loss': 0.2218, 'grad_norm': 539.5325927734375, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 0.8978177905082703, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.5439932942390442, 'weight_rejected': 0.4912892282009125, 'kl_term_chosen': -0.05389404296875, 'epoch': 0.07}
  7%|▋         | 250/3753 [19:33<5:02:34,  5.18s/it]  7%|▋         | 251/3753 [19:39<5:28:57,  5.64s/it]  7%|▋         | 252/3753 [19:44<5:21:44,  5.51s/it]  7%|▋         | 253/3753 [19:49<5:06:55,  5.26s/it]  7%|▋         | 254/3753 [19:53<4:36:24,  4.74s/it]  7%|▋         | 255/3753 [19:57<4:26:20,  4.57s/it]  7%|▋         | 256/3753 [20:00<4:09:37,  4.28s/it]  7%|▋         | 257/3753 [20:05<4:15:29,  4.38s/it]  7%|▋         | 258/3753 [20:09<4:10:18,  4.30s/it]  7%|▋         | 259/3753 [20:13<3:56:46,  4.07s/it]  7%|▋         | 260/3753 [20:17<4:08:08,  4.26s/it]{'loss': 0.5714, 'grad_norm': 702.2933959960938, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 0.3975631594657898, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.9598579406738281, 'weight_rejected': 0.4989013671875, 'kl_term_chosen': -0.4612007141113281, 'epoch': 0.06928714190539641}
                                                    {'loss': 0.5714, 'grad_norm': 702.2933959960938, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 0.3975631594657898, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.9598579406738281, 'weight_rejected': 0.4989013671875, 'kl_term_chosen': -0.4612007141113281, 'epoch': 0.07}
  7%|▋         | 260/3753 [20:17<4:08:08,  4.26s/it]  7%|▋         | 261/3753 [20:22<4:13:39,  4.36s/it]  7%|▋         | 262/3753 [20:26<4:16:01,  4.40s/it]  7%|▋         | 263/3753 [20:31<4:18:36,  4.45s/it]  7%|▋         | 264/3753 [20:35<4:13:15,  4.36s/it]  7%|▋         | 265/3753 [20:39<4:10:04,  4.30s/it]  7%|▋         | 266/3753 [20:43<4:00:01,  4.13s/it]  7%|▋         | 267/3753 [20:47<3:58:58,  4.11s/it]  7%|▋         | 268/3753 [20:52<4:12:54,  4.35s/it]  7%|▋         | 269/3753 [20:55<3:54:22,  4.04s/it]  7%|▋         | 270/3753 [21:00<4:04:47,  4.22s/it]{'loss': 0.2976, 'grad_norm': 750.8389282226562, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 0.40397489070892334, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.9513702392578125, 'weight_rejected': 0.498779296875, 'kl_term_chosen': -0.4532012939453125, 'epoch': 0.07195203197868089}
                                                    {'loss': 0.2976, 'grad_norm': 750.8389282226562, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 0.40397489070892334, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.9513702392578125, 'weight_rejected': 0.498779296875, 'kl_term_chosen': -0.4532012939453125, 'epoch': 0.07}
  7%|▋         | 270/3753 [21:00<4:04:47,  4.22s/it]  7%|▋         | 271/3753 [21:05<4:11:55,  4.34s/it]  7%|▋         | 272/3753 [21:09<4:10:48,  4.32s/it]  7%|▋         | 273/3753 [21:13<4:01:18,  4.16s/it]  7%|▋         | 274/3753 [21:16<3:54:41,  4.05s/it]  7%|▋         | 275/3753 [21:21<3:56:41,  4.08s/it]  7%|▋         | 276/3753 [21:24<3:48:12,  3.94s/it]  7%|▋         | 277/3753 [21:30<4:11:34,  4.34s/it]  7%|▋         | 278/3753 [21:33<3:53:32,  4.03s/it]  7%|▋         | 279/3753 [21:38<4:05:39,  4.24s/it]  7%|▋         | 280/3753 [21:42<4:14:13,  4.39s/it]{'loss': 0.3787, 'grad_norm': 377.41656494140625, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.6644020080566406, 'weight_rejected': 0.4975586235523224, 'kl_term_chosen': -2.1680641174316406, 'epoch': 0.07461692205196535}
                                                    {'loss': 0.3787, 'grad_norm': 377.41656494140625, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.6644020080566406, 'weight_rejected': 0.4975586235523224, 'kl_term_chosen': -2.1680641174316406, 'epoch': 0.07}
  7%|▋         | 280/3753 [21:42<4:14:13,  4.39s/it]  7%|▋         | 281/3753 [21:46<4:09:25,  4.31s/it]  8%|▊         | 282/3753 [21:52<4:38:23,  4.81s/it]  8%|▊         | 283/3753 [21:57<4:29:39,  4.66s/it]  8%|▊         | 284/3753 [22:01<4:23:48,  4.56s/it]  8%|▊         | 285/3753 [22:08<5:12:20,  5.40s/it]  8%|▊         | 286/3753 [22:12<4:44:40,  4.93s/it]  8%|▊         | 287/3753 [22:16<4:31:48,  4.71s/it]  8%|▊         | 288/3753 [22:25<5:42:35,  5.93s/it]  8%|▊         | 289/3753 [22:30<5:21:22,  5.57s/it]  8%|▊         | 290/3753 [22:39<6:16:35,  6.52s/it]{'loss': 1.0884, 'grad_norm': 1848.49365234375, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 1.2169899940490723, 'mean_ratio_rejected': 0.45877742767333984, 'weight_chosen': 0.4005889892578125, 'weight_rejected': 0.498779296875, 'kl_term_chosen': 0.0981903076171875, 'epoch': 0.07728181212524983}
                                                    {'loss': 1.0884, 'grad_norm': 1848.49365234375, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 1.2169899940490723, 'mean_ratio_rejected': 0.45877742767333984, 'weight_chosen': 0.4005889892578125, 'weight_rejected': 0.498779296875, 'kl_term_chosen': 0.0981903076171875, 'epoch': 0.08}
  8%|▊         | 290/3753 [22:39<6:16:35,  6.52s/it]  8%|▊         | 291/3753 [22:42<5:27:35,  5.68s/it]  8%|▊         | 292/3753 [22:48<5:33:46,  5.79s/it]  8%|▊         | 293/3753 [22:52<4:58:43,  5.18s/it]  8%|▊         | 294/3753 [22:56<4:40:44,  4.87s/it]  8%|▊         | 295/3753 [23:01<4:39:17,  4.85s/it]  8%|▊         | 296/3753 [23:05<4:24:18,  4.59s/it]  8%|▊         | 297/3753 [23:10<4:21:39,  4.54s/it]  8%|▊         | 298/3753 [23:16<4:46:12,  4.97s/it]  8%|▊         | 299/3753 [23:20<4:36:45,  4.81s/it]  8%|▊         | 300/3753 [23:24<4:26:30,  4.63s/it]{'loss': 0.4167, 'grad_norm': 4057.875244140625, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 3.6455893516540527, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.15029895305633545, 'weight_rejected': 0.49621590971946716, 'kl_term_chosen': 0.646759033203125, 'epoch': 0.07994670219853431}
                                                    {'loss': 0.4167, 'grad_norm': 4057.875244140625, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 3.6455893516540527, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.15029895305633545, 'weight_rejected': 0.49621590971946716, 'kl_term_chosen': 0.646759033203125, 'epoch': 0.08}
  8%|▊         | 300/3753 [23:24<4:26:30,  4.63s/it]  8%|▊         | 301/3753 [23:29<4:22:46,  4.57s/it]  8%|▊         | 302/3753 [23:34<4:28:44,  4.67s/it]  8%|▊         | 303/3753 [23:38<4:32:01,  4.73s/it]  8%|▊         | 304/3753 [23:42<4:08:52,  4.33s/it]  8%|▊         | 305/3753 [23:46<4:01:51,  4.21s/it]  8%|▊         | 306/3753 [23:50<3:55:08,  4.09s/it]  8%|▊         | 307/3753 [23:54<4:08:32,  4.33s/it]  8%|▊         | 308/3753 [24:00<4:33:50,  4.77s/it]  8%|▊         | 309/3753 [24:05<4:29:12,  4.69s/it]  8%|▊         | 310/3753 [24:09<4:21:42,  4.56s/it]{'loss': 0.4554, 'grad_norm': 478.6475524902344, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 0.5129446983337402, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.8298874497413635, 'weight_rejected': 0.4979553520679474, 'kl_term_chosen': -0.33379364013671875, 'epoch': 0.08261159227181879}
                                                    {'loss': 0.4554, 'grad_norm': 478.6475524902344, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 0.5129446983337402, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.8298874497413635, 'weight_rejected': 0.4979553520679474, 'kl_term_chosen': -0.33379364013671875, 'epoch': 0.08}
  8%|▊         | 310/3753 [24:09<4:21:42,  4.56s/it]  8%|▊         | 311/3753 [24:13<4:17:22,  4.49s/it]  8%|▊         | 312/3753 [24:17<4:11:06,  4.38s/it]  8%|▊         | 313/3753 [24:22<4:09:12,  4.35s/it]  8%|▊         | 314/3753 [24:29<4:59:40,  5.23s/it]  8%|▊         | 315/3753 [24:33<4:34:45,  4.80s/it]  8%|▊         | 316/3753 [24:37<4:17:59,  4.50s/it]  8%|▊         | 317/3753 [24:40<4:07:40,  4.33s/it]  8%|▊         | 318/3753 [24:45<4:13:40,  4.43s/it]  8%|▊         | 319/3753 [24:49<4:09:09,  4.35s/it]  9%|▊         | 320/3753 [24:54<4:15:50,  4.47s/it]{'loss': 0.6569, 'grad_norm': 347.4790344238281, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.002411127090454, 'weight_rejected': 0.49731454253196716, 'kl_term_chosen': -2.507965087890625, 'epoch': 0.08527648234510327}
                                                    {'loss': 0.6569, 'grad_norm': 347.4790344238281, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.002411127090454, 'weight_rejected': 0.49731454253196716, 'kl_term_chosen': -2.507965087890625, 'epoch': 0.09}
  9%|▊         | 320/3753 [24:54<4:15:50,  4.47s/it]  9%|▊         | 321/3753 [24:59<4:20:53,  4.56s/it]  9%|▊         | 322/3753 [25:03<4:08:19,  4.34s/it]  9%|▊         | 323/3753 [25:06<3:51:03,  4.04s/it]  9%|▊         | 324/3753 [25:13<4:46:13,  5.01s/it]  9%|▊         | 325/3753 [25:18<4:36:12,  4.83s/it]  9%|▊         | 326/3753 [25:21<4:14:56,  4.46s/it]  9%|▊         | 327/3753 [25:26<4:12:47,  4.43s/it]  9%|▊         | 328/3753 [25:29<4:02:12,  4.24s/it]  9%|▉         | 329/3753 [25:34<4:08:14,  4.35s/it]  9%|▉         | 330/3753 [25:39<4:17:08,  4.51s/it]{'loss': 1.6923, 'grad_norm': 3878.4970703125, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.7536760568618774, 'weight_chosen': -1.0536631345748901, 'weight_rejected': 0.4951179325580597, 'kl_term_chosen': 1.5423736572265625, 'epoch': 0.08794137241838774}
                                                    {'loss': 1.6923, 'grad_norm': 3878.4970703125, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.7536760568618774, 'weight_chosen': -1.0536631345748901, 'weight_rejected': 0.4951179325580597, 'kl_term_chosen': 1.5423736572265625, 'epoch': 0.09}
  9%|▉         | 330/3753 [25:39<4:17:08,  4.51s/it]  9%|▉         | 331/3753 [25:43<4:11:58,  4.42s/it]  9%|▉         | 332/3753 [25:47<4:04:48,  4.29s/it]  9%|▉         | 333/3753 [25:51<4:05:09,  4.30s/it]  9%|▉         | 334/3753 [26:00<5:10:01,  5.44s/it]  9%|▉         | 335/3753 [26:04<4:57:26,  5.22s/it]  9%|▉         | 336/3753 [26:08<4:25:44,  4.67s/it]  9%|▉         | 337/3753 [26:13<4:31:48,  4.77s/it]  9%|▉         | 338/3753 [26:16<4:08:24,  4.36s/it]  9%|▉         | 339/3753 [26:20<3:52:33,  4.09s/it]  9%|▉         | 340/3753 [26:24<3:58:36,  4.19s/it]{'loss': 0.3406, 'grad_norm': 63.16622543334961, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.912883758544922, 'weight_rejected': 0.499786376953125, 'kl_term_chosen': -3.412975311279297, 'epoch': 0.09060626249167222}
                                                    {'loss': 0.3406, 'grad_norm': 63.16622543334961, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.912883758544922, 'weight_rejected': 0.499786376953125, 'kl_term_chosen': -3.412975311279297, 'epoch': 0.09}
  9%|▉         | 340/3753 [26:24<3:58:36,  4.19s/it]  9%|▉         | 341/3753 [26:28<3:49:31,  4.04s/it]  9%|▉         | 342/3753 [26:32<3:46:57,  3.99s/it]  9%|▉         | 343/3753 [26:37<4:05:16,  4.32s/it]  9%|▉         | 344/3753 [26:40<3:56:50,  4.17s/it]  9%|▉         | 345/3753 [26:46<4:22:33,  4.62s/it]  9%|▉         | 346/3753 [26:50<4:12:37,  4.45s/it]  9%|▉         | 347/3753 [26:55<4:13:11,  4.46s/it]  9%|▉         | 348/3753 [27:00<4:28:39,  4.73s/it]  9%|▉         | 349/3753 [27:04<4:15:17,  4.50s/it]  9%|▉         | 350/3753 [27:09<4:18:04,  4.55s/it]{'loss': 1.8934, 'grad_norm': 1082.99853515625, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.2824859619140625, 'weight_rejected': 0.49615490436553955, 'kl_term_chosen': -2.7862701416015625, 'epoch': 0.09327115256495669}
                                                    {'loss': 1.8934, 'grad_norm': 1082.99853515625, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.2824859619140625, 'weight_rejected': 0.49615490436553955, 'kl_term_chosen': -2.7862701416015625, 'epoch': 0.09}
  9%|▉         | 350/3753 [27:09<4:18:04,  4.55s/it]  9%|▉         | 351/3753 [27:13<4:07:14,  4.36s/it]  9%|▉         | 352/3753 [27:16<3:48:21,  4.03s/it]  9%|▉         | 353/3753 [27:20<3:49:52,  4.06s/it]  9%|▉         | 354/3753 [27:25<4:03:01,  4.29s/it]  9%|▉         | 355/3753 [27:31<4:29:50,  4.76s/it]  9%|▉         | 356/3753 [27:35<4:22:41,  4.64s/it] 10%|▉         | 357/3753 [27:39<4:14:18,  4.49s/it] 10%|▉         | 358/3753 [27:44<4:13:49,  4.49s/it] 10%|▉         | 359/3753 [27:48<4:13:17,  4.48s/it] 10%|▉         | 360/3753 [27:52<4:00:05,  4.25s/it]{'loss': -0.5177, 'grad_norm': 0.0, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 8.588044166564941, 'weight_rejected': 0.4884971082210541, 'kl_term_chosen': -8.09515380859375, 'epoch': 0.09593604263824117}
                                                    {'loss': -0.5177, 'grad_norm': 0.0, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 8.588044166564941, 'weight_rejected': 0.4884971082210541, 'kl_term_chosen': -8.09515380859375, 'epoch': 0.1}
 10%|▉         | 360/3753 [27:52<4:00:05,  4.25s/it] 10%|▉         | 361/3753 [27:56<4:07:23,  4.38s/it] 10%|▉         | 362/3753 [28:01<4:05:25,  4.34s/it] 10%|▉         | 363/3753 [28:05<4:01:12,  4.27s/it] 10%|▉         | 364/3753 [28:09<4:04:24,  4.33s/it] 10%|▉         | 365/3753 [28:13<3:55:05,  4.16s/it] 10%|▉         | 366/3753 [28:16<3:40:40,  3.91s/it] 10%|▉         | 367/3753 [28:21<3:45:18,  3.99s/it] 10%|▉         | 368/3753 [28:25<3:58:42,  4.23s/it] 10%|▉         | 369/3753 [28:30<4:02:19,  4.30s/it] 10%|▉         | 370/3753 [28:34<4:01:43,  4.29s/it]{'loss': -1.0088, 'grad_norm': 0.0, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 9.328941345214844, 'weight_rejected': 0.4978332817554474, 'kl_term_chosen': -8.830589294433594, 'epoch': 0.09860093271152565}
                                                    {'loss': -1.0088, 'grad_norm': 0.0, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 9.328941345214844, 'weight_rejected': 0.4978332817554474, 'kl_term_chosen': -8.830589294433594, 'epoch': 0.1}
 10%|▉         | 370/3753 [28:34<4:01:43,  4.29s/it] 10%|▉         | 371/3753 [28:38<3:54:51,  4.17s/it] 10%|▉         | 372/3753 [28:42<4:00:52,  4.27s/it] 10%|▉         | 373/3753 [28:46<3:56:40,  4.20s/it] 10%|▉         | 374/3753 [28:54<4:46:09,  5.08s/it] 10%|▉         | 375/3753 [28:59<4:52:46,  5.20s/it] 10%|█         | 376/3753 [29:08<6:00:10,  6.40s/it] 10%|█         | 377/3753 [29:15<6:00:03,  6.40s/it] 10%|█         | 378/3753 [29:19<5:17:16,  5.64s/it] 10%|█         | 379/3753 [29:22<4:44:41,  5.06s/it] 10%|█         | 380/3753 [29:27<4:38:38,  4.96s/it]{'loss': -1.0725, 'grad_norm': 0.0, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 10.87103271484375, 'weight_rejected': 0.4982910454273224, 'kl_term_chosen': -10.37359619140625, 'epoch': 0.10126582278481013}
                                                    {'loss': -1.0725, 'grad_norm': 0.0, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 10.87103271484375, 'weight_rejected': 0.4982910454273224, 'kl_term_chosen': -10.37359619140625, 'epoch': 0.1}
 10%|█         | 380/3753 [29:27<4:38:38,  4.96s/it] 10%|█         | 381/3753 [29:31<4:23:24,  4.69s/it] 10%|█         | 382/3753 [29:36<4:26:16,  4.74s/it] 10%|█         | 383/3753 [29:40<4:10:13,  4.46s/it] 10%|█         | 384/3753 [29:45<4:25:37,  4.73s/it] 10%|█         | 385/3753 [29:55<5:52:48,  6.29s/it] 10%|█         | 386/3753 [29:59<5:10:05,  5.53s/it] 10%|█         | 387/3753 [30:03<4:52:43,  5.22s/it] 10%|█         | 388/3753 [30:08<4:40:34,  5.00s/it] 10%|█         | 389/3753 [30:12<4:34:45,  4.90s/it] 10%|█         | 390/3753 [30:18<4:51:06,  5.19s/it]{'loss': -1.1258, 'grad_norm': 0.0, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.041954040527344, 'weight_rejected': 0.4991455078125, 'kl_term_chosen': -10.543540954589844, 'epoch': 0.1039307128580946}
                                                    {'loss': -1.1258, 'grad_norm': 0.0, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.041954040527344, 'weight_rejected': 0.4991455078125, 'kl_term_chosen': -10.543540954589844, 'epoch': 0.1}
 10%|█         | 390/3753 [30:18<4:51:06,  5.19s/it] 10%|█         | 391/3753 [30:23<4:37:03,  4.94s/it] 10%|█         | 392/3753 [30:27<4:23:16,  4.70s/it] 10%|█         | 393/3753 [30:31<4:23:01,  4.70s/it] 10%|█         | 394/3753 [30:36<4:13:42,  4.53s/it] 11%|█         | 395/3753 [30:40<4:18:50,  4.63s/it] 11%|█         | 396/3753 [30:49<5:25:00,  5.81s/it] 11%|█         | 397/3753 [30:52<4:44:45,  5.09s/it] 11%|█         | 398/3753 [30:58<5:00:44,  5.38s/it] 11%|█         | 399/3753 [31:04<4:57:11,  5.32s/it] 11%|█         | 400/3753 [31:08<4:36:30,  4.95s/it]{'loss': -1.1176, 'grad_norm': 0.0, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.892876625061035, 'weight_rejected': 0.4958804249763489, 'kl_term_chosen': -11.400810241699219, 'epoch': 0.10659560293137908}
                                                    {'loss': -1.1176, 'grad_norm': 0.0, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.892876625061035, 'weight_rejected': 0.4958804249763489, 'kl_term_chosen': -11.400810241699219, 'epoch': 0.11}
 11%|█         | 400/3753 [31:08<4:36:30,  4.95s/it] 11%|█         | 401/3753 [31:12<4:20:42,  4.67s/it] 11%|█         | 402/3753 [31:16<4:21:42,  4.69s/it] 11%|█         | 403/3753 [31:20<4:04:40,  4.38s/it] 11%|█         | 404/3753 [31:24<4:01:22,  4.32s/it] 11%|█         | 405/3753 [31:29<4:13:24,  4.54s/it] 11%|█         | 406/3753 [31:34<4:11:28,  4.51s/it] 11%|█         | 407/3753 [31:38<4:00:25,  4.31s/it] 11%|█         | 408/3753 [31:43<4:09:22,  4.47s/it] 11%|█         | 409/3753 [31:47<4:09:55,  4.48s/it] 11%|█         | 410/3753 [31:51<4:09:04,  4.47s/it]{'loss': -1.0932, 'grad_norm': 0.0, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.417465209960938, 'weight_rejected': 0.4988250732421875, 'kl_term_chosen': -10.920486450195312, 'epoch': 0.10926049300466356}
                                                    {'loss': -1.0932, 'grad_norm': 0.0, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.417465209960938, 'weight_rejected': 0.4988250732421875, 'kl_term_chosen': -10.920486450195312, 'epoch': 0.11}
 11%|█         | 410/3753 [31:52<4:09:04,  4.47s/it] 11%|█         | 411/3753 [31:57<4:18:17,  4.64s/it] 11%|█         | 412/3753 [32:00<4:05:58,  4.42s/it] 11%|█         | 413/3753 [32:06<4:23:31,  4.73s/it] 11%|█         | 414/3753 [32:11<4:24:52,  4.76s/it] 11%|█         | 415/3753 [32:15<4:20:46,  4.69s/it] 11%|█         | 416/3753 [32:19<4:13:24,  4.56s/it] 11%|█         | 417/3753 [32:24<4:04:54,  4.40s/it] 11%|█         | 418/3753 [32:27<3:57:02,  4.26s/it] 11%|█         | 419/3753 [32:31<3:51:44,  4.17s/it] 11%|█         | 420/3753 [32:36<3:55:07,  4.23s/it]{'loss': -1.1091, 'grad_norm': 0.0, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.300640106201172, 'weight_rejected': 0.49591076374053955, 'kl_term_chosen': -10.804790496826172, 'epoch': 0.11192538307794804}
                                                    {'loss': -1.1091, 'grad_norm': 0.0, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.300640106201172, 'weight_rejected': 0.49591076374053955, 'kl_term_chosen': -10.804790496826172, 'epoch': 0.11}
 11%|█         | 420/3753 [32:36<3:55:07,  4.23s/it] 11%|█         | 421/3753 [32:40<3:57:16,  4.27s/it] 11%|█         | 422/3753 [32:44<3:55:50,  4.25s/it] 11%|█▏        | 423/3753 [32:48<3:46:17,  4.08s/it] 11%|█▏        | 424/3753 [32:51<3:29:45,  3.78s/it] 11%|█▏        | 425/3753 [32:55<3:36:43,  3.91s/it] 11%|█▏        | 426/3753 [33:00<3:51:05,  4.17s/it] 11%|█▏        | 427/3753 [33:05<3:55:38,  4.25s/it] 11%|█▏        | 428/3753 [33:09<4:01:10,  4.35s/it] 11%|█▏        | 429/3753 [33:13<3:55:49,  4.26s/it] 11%|█▏        | 430/3753 [33:18<4:05:35,  4.43s/it]{'loss': -1.0993, 'grad_norm': 0.0, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 15.781585693359375, 'weight_rejected': 0.4974976181983948, 'kl_term_chosen': -15.284576416015625, 'epoch': 0.1145902731512325}
                                                    {'loss': -1.0993, 'grad_norm': 0.0, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 15.781585693359375, 'weight_rejected': 0.4974976181983948, 'kl_term_chosen': -15.284576416015625, 'epoch': 0.11}
 11%|█▏        | 430/3753 [33:18<4:05:35,  4.43s/it] 11%|█▏        | 431/3753 [33:22<3:54:46,  4.24s/it] 12%|█▏        | 432/3753 [33:31<5:11:11,  5.62s/it] 12%|█▏        | 433/3753 [33:35<4:47:01,  5.19s/it] 12%|█▏        | 434/3753 [33:39<4:23:29,  4.76s/it] 12%|█▏        | 435/3753 [33:42<4:06:56,  4.47s/it] 12%|█▏        | 436/3753 [33:47<4:04:50,  4.43s/it] 12%|█▏        | 437/3753 [33:51<4:08:16,  4.49s/it] 12%|█▏        | 438/3753 [33:56<4:18:50,  4.68s/it] 12%|█▏        | 439/3753 [34:01<4:10:34,  4.54s/it] 12%|█▏        | 440/3753 [34:05<4:01:31,  4.37s/it]{'loss': -1.1121, 'grad_norm': 0.0, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 13.706329345703125, 'weight_rejected': 0.498779296875, 'kl_term_chosen': -13.209381103515625, 'epoch': 0.11725516322451698}
                                                    {'loss': -1.1121, 'grad_norm': 0.0, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 13.706329345703125, 'weight_rejected': 0.498779296875, 'kl_term_chosen': -13.209381103515625, 'epoch': 0.12}
 12%|█▏        | 440/3753 [34:05<4:01:31,  4.37s/it] 12%|█▏        | 441/3753 [34:11<4:28:20,  4.86s/it] 12%|█▏        | 442/3753 [34:15<4:26:44,  4.83s/it] 12%|█▏        | 443/3753 [34:19<4:03:04,  4.41s/it] 12%|█▏        | 444/3753 [34:24<4:16:18,  4.65s/it] 12%|█▏        | 445/3753 [34:28<3:57:41,  4.31s/it] 12%|█▏        | 446/3753 [34:32<4:01:22,  4.38s/it] 12%|█▏        | 447/3753 [34:36<4:00:49,  4.37s/it] 12%|█▏        | 448/3753 [34:40<3:44:14,  4.07s/it] 12%|█▏        | 449/3753 [34:45<4:09:54,  4.54s/it] 12%|█▏        | 450/3753 [34:50<4:05:39,  4.46s/it]{'loss': -1.1128, 'grad_norm': 0.0, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 15.1123046875, 'weight_rejected': 0.498779296875, 'kl_term_chosen': -14.613525390625, 'epoch': 0.11992005329780146}
                                                    {'loss': -1.1128, 'grad_norm': 0.0, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 15.1123046875, 'weight_rejected': 0.498779296875, 'kl_term_chosen': -14.613525390625, 'epoch': 0.12}
 12%|█▏        | 450/3753 [34:50<4:05:39,  4.46s/it] 12%|█▏        | 451/3753 [34:54<4:01:12,  4.38s/it] 12%|█▏        | 452/3753 [34:59<4:13:27,  4.61s/it] 12%|█▏        | 453/3753 [35:03<3:55:02,  4.27s/it] 12%|█▏        | 454/3753 [35:08<4:18:18,  4.70s/it] 12%|█▏        | 455/3753 [35:13<4:17:51,  4.69s/it] 12%|█▏        | 456/3753 [35:19<4:38:42,  5.07s/it] 12%|█▏        | 457/3753 [35:23<4:22:31,  4.78s/it] 12%|█▏        | 458/3753 [35:27<4:06:55,  4.50s/it] 12%|█▏        | 459/3753 [35:31<4:04:14,  4.45s/it] 12%|█▏        | 460/3753 [35:37<4:23:04,  4.79s/it]{'loss': -1.1331, 'grad_norm': 0.0, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 12.391464233398438, 'weight_rejected': 0.4938969016075134, 'kl_term_chosen': -11.897262573242188, 'epoch': 0.12258494337108594}
                                                    {'loss': -1.1331, 'grad_norm': 0.0, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 12.391464233398438, 'weight_rejected': 0.4938969016075134, 'kl_term_chosen': -11.897262573242188, 'epoch': 0.12}
 12%|█▏        | 460/3753 [35:37<4:23:04,  4.79s/it] 12%|█▏        | 461/3753 [35:41<4:09:12,  4.54s/it] 12%|█▏        | 462/3753 [35:44<3:41:53,  4.05s/it] 12%|█▏        | 463/3753 [35:48<3:46:03,  4.12s/it] 12%|█▏        | 464/3753 [35:52<3:46:39,  4.13s/it] 12%|█▏        | 465/3753 [35:56<3:48:26,  4.17s/it] 12%|█▏        | 466/3753 [36:01<3:54:51,  4.29s/it] 12%|█▏        | 467/3753 [36:05<3:53:28,  4.26s/it] 12%|█▏        | 468/3753 [36:13<4:50:38,  5.31s/it] 12%|█▏        | 469/3753 [36:18<4:52:26,  5.34s/it] 13%|█▎        | 470/3753 [36:24<5:06:47,  5.61s/it]{'loss': -1.11, 'grad_norm': 0.0, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.63934326171875, 'weight_rejected': 0.4973755180835724, 'kl_term_chosen': -11.1422119140625, 'epoch': 0.1252498334443704}
                                                    {'loss': -1.11, 'grad_norm': 0.0, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.63934326171875, 'weight_rejected': 0.4973755180835724, 'kl_term_chosen': -11.1422119140625, 'epoch': 0.13}
 13%|█▎        | 470/3753 [36:25<5:06:47,  5.61s/it] 13%|█▎        | 471/3753 [36:30<5:09:11,  5.65s/it] 13%|█▎        | 472/3753 [36:34<4:37:06,  5.07s/it] 13%|█▎        | 473/3753 [36:37<4:01:40,  4.42s/it] 13%|█▎        | 474/3753 [36:41<4:02:23,  4.44s/it] 13%|█▎        | 475/3753 [36:46<4:04:19,  4.47s/it] 13%|█▎        | 476/3753 [36:50<3:56:32,  4.33s/it] 13%|█▎        | 477/3753 [36:54<3:59:46,  4.39s/it] 13%|█▎        | 478/3753 [36:59<3:55:39,  4.32s/it] 13%|█▎        | 479/3753 [37:04<4:19:55,  4.76s/it] 13%|█▎        | 480/3753 [37:09<4:18:21,  4.74s/it]{'loss': -1.1063, 'grad_norm': 0.0, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 13.686005592346191, 'weight_rejected': 0.49275296926498413, 'kl_term_chosen': -13.193099975585938, 'epoch': 0.1279147235176549}
                                                    {'loss': -1.1063, 'grad_norm': 0.0, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 13.686005592346191, 'weight_rejected': 0.49275296926498413, 'kl_term_chosen': -13.193099975585938, 'epoch': 0.13}
 13%|█▎        | 480/3753 [37:09<4:18:21,  4.74s/it] 13%|█▎        | 481/3753 [37:14<4:21:33,  4.80s/it] 13%|█▎        | 482/3753 [37:18<4:12:52,  4.64s/it] 13%|█▎        | 483/3753 [37:22<4:03:53,  4.48s/it] 13%|█▎        | 484/3753 [37:26<3:53:32,  4.29s/it] 13%|█▎        | 485/3753 [37:30<3:42:29,  4.08s/it] 13%|█▎        | 486/3753 [37:35<3:59:39,  4.40s/it] 13%|█▎        | 487/3753 [37:40<4:05:49,  4.52s/it] 13%|█▎        | 488/3753 [37:44<3:57:42,  4.37s/it] 13%|█▎        | 489/3753 [37:49<4:04:02,  4.49s/it] 13%|█▎        | 490/3753 [37:54<4:17:31,  4.74s/it]{'loss': -1.105, 'grad_norm': 0.0, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 9.050857543945312, 'weight_rejected': 0.4978637993335724, 'kl_term_chosen': -8.553298950195312, 'epoch': 0.13057961359093936}
                                                    {'loss': -1.105, 'grad_norm': 0.0, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 9.050857543945312, 'weight_rejected': 0.4978637993335724, 'kl_term_chosen': -8.553298950195312, 'epoch': 0.13}
 13%|█▎        | 490/3753 [37:54<4:17:31,  4.74s/it] 13%|█▎        | 491/3753 [37:59<4:20:05,  4.78s/it] 13%|█▎        | 492/3753 [38:03<4:05:07,  4.51s/it] 13%|█▎        | 493/3753 [38:12<5:31:59,  6.11s/it] 13%|█▎        | 494/3753 [38:16<4:58:07,  5.49s/it] 13%|█▎        | 495/3753 [38:20<4:22:56,  4.84s/it] 13%|█▎        | 496/3753 [38:25<4:23:03,  4.85s/it] 13%|█▎        | 497/3753 [38:28<4:03:10,  4.48s/it] 13%|█▎        | 498/3753 [38:36<5:03:12,  5.59s/it] 13%|█▎        | 499/3753 [38:43<5:15:02,  5.81s/it] 13%|█▎        | 500/3753 [38:47<4:55:04,  5.44s/it]{'loss': -1.1443, 'grad_norm': 0.0, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.352368354797363, 'weight_rejected': 0.49597203731536865, 'kl_term_chosen': -10.860851287841797, 'epoch': 0.13324450366422386}
                                                    {'loss': -1.1443, 'grad_norm': 0.0, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.352368354797363, 'weight_rejected': 0.49597203731536865, 'kl_term_chosen': -10.860851287841797, 'epoch': 0.13}
 13%|█▎        | 500/3753 [38:47<4:55:04,  5.44s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 13%|█▎        | 501/3753 [39:49<20:07:10, 22.27s/it] 13%|█▎        | 502/3753 [39:57<16:12:30, 17.95s/it] 13%|█▎        | 503/3753 [40:01<12:33:13, 13.91s/it] 13%|█▎        | 504/3753 [40:05<9:49:40, 10.89s/it] 