nohup: ignoring input
[W1208 11:21:36.816348141 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.74it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.24it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.59it/s]
加载作为参考的SFT模型 (Reference Model)...
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.18it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.04it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 98.08it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 98.39it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 98.81it/s]
[W1208 11:21:41.440554896 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1208 11:21:41.445860272 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1208 11:21:41.459820695 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1208 11:21:41.461848537 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...初始化 CustomSymPOTrainer...

/rlhf_code/code/implement_final_v3_no_kl_term2.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
/rlhf_code/code/implement_final_v3_no_kl_term2.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /wandb/offline-run-20251208_112153-zyo90t72
  0%|          | 0/3753 [00:00<?, ?it/s]--- Sanity Check at Step 0 ------ Sanity Check at Step 0 ---

--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -44.5
Sample 0 - pi_logp_chosen:  -44.146331787109375
Difference: 0.353668212890625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -100.5
Sample 0 - pi_logp_chosen:  -100.34402465820312
Difference: 0.155975341796875
---------------------------------
Sample 0 - ref_logp_chosen: -112.0
Sample 0 - pi_logp_chosen:  -111.70196533203125
Difference: 0.29803466796875
---------------------------------
Sample 0 - ref_logp_chosen: -234.0
Sample 0 - pi_logp_chosen:  -233.57894897460938
Difference: 0.421051025390625
---------------------------------
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -65.5
Sample 0 - pi_logp_chosen:  -65.91077423095703
Difference: -0.41077423095703125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -246.0
Sample 0 - pi_logp_chosen:  -246.4385986328125
Sample 0 - ref_logp_chosen: -209.0Difference: -0.4385986328125
---------------------------------

Sample 0 - pi_logp_chosen:  -208.26136779785156
Difference: 0.7386322021484375
---------------------------------
Sample 0 - ref_logp_chosen: -380.0
Sample 0 - pi_logp_chosen:  -381.313720703125
Difference: -1.313720703125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -70.0
Sample 0 - pi_logp_chosen:  -70.18619537353516
Difference: -0.18619537353515625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -167.0
Sample 0 - pi_logp_chosen:  -167.149169921875
Difference: -0.149169921875
---------------------------------
Sample 0 - ref_logp_chosen: -350.0
Sample 0 - pi_logp_chosen:  -349.3069152832031
Difference: 0.693084716796875
---------------------------------
Sample 0 - ref_logp_chosen: -452.0
Sample 0 - pi_logp_chosen:  -453.64239501953125
Difference: -1.64239501953125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -81.5
Sample 0 - pi_logp_chosen:  -81.75975036621094
Difference: -0.2597503662109375
---------------------------------
Sample 0 - ref_logp_chosen: -98.5
Sample 0 - pi_logp_chosen:  -98.78225708007812
Difference: -0.282257080078125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -251.0
Sample 0 - pi_logp_chosen:  -249.6898956298828
Difference: 1.3101043701171875
---------------------------------
Sample 0 - ref_logp_chosen: -242.0
Sample 0 - pi_logp_chosen:  -241.97824096679688
Difference: 0.021759033203125
---------------------------------
  0%|          | 1/3753 [00:04<4:56:43,  4.75s/it]{'loss': -0.3531, 'grad_norm': 1997.89306640625, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 2.1782100200653076, 'weight_chosen': 0.2668696641921997, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 0.6550521850585938, 'epoch': 0.0002664890073284477}
                                                  {'loss': -0.3531, 'grad_norm': 1997.89306640625, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 2.1782100200653076, 'weight_chosen': 0.2668696641921997, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 0.6550521850585938, 'epoch': 0.0}
  0%|          | 1/3753 [00:04<4:56:43,  4.75s/it]  0%|          | 2/3753 [00:10<5:18:14,  5.09s/it]  0%|          | 3/3753 [00:14<5:06:31,  4.90s/it]  0%|          | 4/3753 [00:18<4:42:29,  4.52s/it]  0%|          | 5/3753 [00:22<4:33:51,  4.38s/it]  0%|          | 6/3753 [00:28<4:57:44,  4.77s/it]  0%|          | 7/3753 [00:32<4:45:06,  4.57s/it]  0%|          | 8/3753 [00:36<4:42:28,  4.53s/it]  0%|          | 9/3753 [00:40<4:24:18,  4.24s/it]  0%|          | 10/3753 [00:44<4:15:50,  4.10s/it]{'loss': -0.3954, 'grad_norm': 2006.7216796875, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 0.5947267413139343, 'mean_ratio_rejected': 0.6369590759277344, 'weight_chosen': 0.5049116611480713, 'weight_rejected': 0.4163219630718231, 'kl_term_chosen': -0.25982666015625, 'epoch': 0.002664890073284477}
                                                   {'loss': -0.3954, 'grad_norm': 2006.7216796875, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 0.5947267413139343, 'mean_ratio_rejected': 0.6369590759277344, 'weight_chosen': 0.5049116611480713, 'weight_rejected': 0.4163219630718231, 'kl_term_chosen': -0.25982666015625, 'epoch': 0.0}
  0%|          | 10/3753 [00:44<4:15:50,  4.10s/it]  0%|          | 11/3753 [00:48<4:23:17,  4.22s/it]  0%|          | 12/3753 [00:53<4:36:34,  4.44s/it]  0%|          | 13/3753 [00:58<4:33:45,  4.39s/it]  0%|          | 14/3753 [01:02<4:27:04,  4.29s/it]  0%|          | 15/3753 [01:05<4:16:42,  4.12s/it]  0%|          | 16/3753 [01:09<4:13:57,  4.08s/it]  0%|          | 17/3753 [01:13<4:07:30,  3.97s/it]  0%|          | 18/3753 [01:18<4:23:30,  4.23s/it]  1%|          | 19/3753 [01:21<4:06:42,  3.96s/it]  1%|          | 20/3753 [01:25<4:04:48,  3.93s/it]{'loss': -0.3298, 'grad_norm': 1963.0616455078125, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 1.4117546081542969, 'mean_ratio_rejected': 1.3886643648147583, 'weight_chosen': 0.5601751208305359, 'weight_rejected': 0.29665425419807434, 'kl_term_chosen': 0.17241668701171875, 'epoch': 0.005329780146568954}
                                                   {'loss': -0.3298, 'grad_norm': 1963.0616455078125, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 1.4117546081542969, 'mean_ratio_rejected': 1.3886643648147583, 'weight_chosen': 0.5601751208305359, 'weight_rejected': 0.29665425419807434, 'kl_term_chosen': 0.17241668701171875, 'epoch': 0.01}
  1%|          | 20/3753 [01:25<4:04:48,  3.93s/it]  1%|          | 21/3753 [01:29<4:08:51,  4.00s/it]  1%|          | 22/3753 [01:37<5:14:19,  5.05s/it]  1%|          | 23/3753 [01:42<5:14:14,  5.05s/it]  1%|          | 24/3753 [01:45<4:41:15,  4.53s/it]  1%|          | 25/3753 [01:49<4:35:32,  4.43s/it]  1%|          | 26/3753 [01:52<4:09:25,  4.02s/it]  1%|          | 27/3753 [01:56<4:09:34,  4.02s/it]  1%|          | 28/3753 [02:00<4:07:26,  3.99s/it]  1%|          | 29/3753 [02:04<4:04:19,  3.94s/it]  1%|          | 30/3753 [02:08<4:08:24,  4.00s/it]{'loss': -0.1285, 'grad_norm': 1484.73486328125, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 1.1703097820281982, 'mean_ratio_rejected': 2.19925856590271, 'weight_chosen': 0.549316942691803, 'weight_rejected': 0.5987815260887146, 'kl_term_chosen': 0.07863426208496094, 'epoch': 0.007994670219853431}
                                                   {'loss': -0.1285, 'grad_norm': 1484.73486328125, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 1.1703097820281982, 'mean_ratio_rejected': 2.19925856590271, 'weight_chosen': 0.549316942691803, 'weight_rejected': 0.5987815260887146, 'kl_term_chosen': 0.07863426208496094, 'epoch': 0.01}
  1%|          | 30/3753 [02:08<4:08:24,  4.00s/it]  1%|          | 31/3753 [02:14<4:31:28,  4.38s/it]  1%|          | 32/3753 [02:17<4:17:54,  4.16s/it]  1%|          | 33/3753 [02:21<4:08:52,  4.01s/it]  1%|          | 34/3753 [02:28<4:58:02,  4.81s/it]  1%|          | 35/3753 [02:33<5:13:47,  5.06s/it]  1%|          | 36/3753 [02:39<5:34:25,  5.40s/it]  1%|          | 37/3753 [02:45<5:40:03,  5.49s/it]  1%|          | 38/3753 [02:49<5:18:04,  5.14s/it]  1%|          | 39/3753 [02:58<6:18:36,  6.12s/it]  1%|          | 40/3753 [03:02<5:40:19,  5.50s/it]{'loss': 1.0508, 'grad_norm': 3193.06298828125, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 1.9969477653503418, 'mean_ratio_rejected': 5.446228981018066, 'weight_chosen': 0.4119844436645508, 'weight_rejected': 0.1276526302099228, 'kl_term_chosen': 0.3458099365234375, 'epoch': 0.010659560293137908}
                                                   {'loss': 1.0508, 'grad_norm': 3193.06298828125, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 1.9969477653503418, 'mean_ratio_rejected': 5.446228981018066, 'weight_chosen': 0.4119844436645508, 'weight_rejected': 0.1276526302099228, 'kl_term_chosen': 0.3458099365234375, 'epoch': 0.01}
  1%|          | 40/3753 [03:02<5:40:19,  5.50s/it]  1%|          | 41/3753 [03:08<5:59:39,  5.81s/it]  1%|          | 42/3753 [03:11<5:07:37,  4.97s/it]  1%|          | 43/3753 [03:16<5:03:35,  4.91s/it]  1%|          | 44/3753 [03:20<4:47:07,  4.64s/it]  1%|          | 45/3753 [03:25<4:54:44,  4.77s/it]  1%|          | 46/3753 [03:30<5:00:56,  4.87s/it]  1%|▏         | 47/3753 [03:33<4:24:52,  4.29s/it]  1%|▏         | 48/3753 [03:37<4:20:11,  4.21s/it]  1%|▏         | 49/3753 [03:42<4:24:04,  4.28s/it]  1%|▏         | 50/3753 [03:46<4:16:34,  4.16s/it]{'loss': 0.2862, 'grad_norm': 1382.9444580078125, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 1.192172646522522, 'mean_ratio_rejected': 1.6294385194778442, 'weight_chosen': 0.7755029201507568, 'weight_rejected': 0.6851073503494263, 'kl_term_chosen': 0.08788871765136719, 'epoch': 0.013324450366422385}
                                                   {'loss': 0.2862, 'grad_norm': 1382.9444580078125, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 1.192172646522522, 'mean_ratio_rejected': 1.6294385194778442, 'weight_chosen': 0.7755029201507568, 'weight_rejected': 0.6851073503494263, 'kl_term_chosen': 0.08788871765136719, 'epoch': 0.01}
  1%|▏         | 50/3753 [03:46<4:16:34,  4.16s/it]  1%|▏         | 51/3753 [03:50<4:16:03,  4.15s/it]  1%|▏         | 52/3753 [03:54<4:25:58,  4.31s/it]  1%|▏         | 53/3753 [04:00<4:54:12,  4.77s/it]  1%|▏         | 54/3753 [04:04<4:30:12,  4.38s/it]  1%|▏         | 55/3753 [04:12<5:40:07,  5.52s/it]  1%|▏         | 56/3753 [04:20<6:22:20,  6.21s/it]  2%|▏         | 57/3753 [04:24<5:54:52,  5.76s/it]  2%|▏         | 58/3753 [04:28<5:12:25,  5.07s/it]  2%|▏         | 59/3753 [04:35<5:57:57,  5.81s/it]  2%|▏         | 60/3753 [04:39<5:08:33,  5.01s/it]{'loss': 0.4035, 'grad_norm': 1396.69091796875, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 0.818293035030365, 'mean_ratio_rejected': 0.9475686550140381, 'weight_chosen': 0.130482017993927, 'weight_rejected': 0.937210738658905, 'kl_term_chosen': -0.10026741027832031, 'epoch': 0.015989340439706862}
                                                   {'loss': 0.4035, 'grad_norm': 1396.69091796875, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 0.818293035030365, 'mean_ratio_rejected': 0.9475686550140381, 'weight_chosen': 0.130482017993927, 'weight_rejected': 0.937210738658905, 'kl_term_chosen': -0.10026741027832031, 'epoch': 0.02}
  2%|▏         | 60/3753 [04:39<5:08:33,  5.01s/it]  2%|▏         | 61/3753 [04:44<5:17:59,  5.17s/it]  2%|▏         | 62/3753 [04:48<5:01:58,  4.91s/it]  2%|▏         | 63/3753 [04:53<4:52:32,  4.76s/it]  2%|▏         | 64/3753 [04:58<5:00:56,  4.89s/it]  2%|▏         | 65/3753 [05:02<4:42:42,  4.60s/it]  2%|▏         | 66/3753 [05:07<4:47:15,  4.67s/it]  2%|▏         | 67/3753 [05:12<4:48:03,  4.69s/it]  2%|▏         | 68/3753 [05:15<4:29:57,  4.40s/it]  2%|▏         | 69/3753 [05:20<4:33:15,  4.45s/it]  2%|▏         | 70/3753 [05:24<4:19:21,  4.23s/it]{'loss': 0.8357, 'grad_norm': 2310.505126953125, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.4378793239593506, 'weight_chosen': -0.796901285648346, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 1.7601318359375, 'epoch': 0.018654230512991338}
                                                   {'loss': 0.8357, 'grad_norm': 2310.505126953125, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.4378793239593506, 'weight_chosen': -0.796901285648346, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 1.7601318359375, 'epoch': 0.02}
  2%|▏         | 70/3753 [05:24<4:19:21,  4.23s/it]  2%|▏         | 71/3753 [05:28<4:29:22,  4.39s/it]  2%|▏         | 72/3753 [05:33<4:34:32,  4.47s/it]  2%|▏         | 73/3753 [05:37<4:21:17,  4.26s/it]  2%|▏         | 74/3753 [05:40<4:11:21,  4.10s/it]  2%|▏         | 75/3753 [05:44<4:02:50,  3.96s/it]  2%|▏         | 76/3753 [05:50<4:35:07,  4.49s/it]  2%|▏         | 77/3753 [05:53<4:08:40,  4.06s/it]  2%|▏         | 78/3753 [05:58<4:30:01,  4.41s/it]  2%|▏         | 79/3753 [06:02<4:28:15,  4.38s/it]  2%|▏         | 80/3753 [06:07<4:37:59,  4.54s/it]{'loss': 0.4952, 'grad_norm': 1522.900390625, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 2.830946922302246, 'mean_ratio_rejected': 4.367029190063477, 'weight_chosen': 0.40810316801071167, 'weight_rejected': 0.10230471193790436, 'kl_term_chosen': 0.5203056335449219, 'epoch': 0.021319120586275817}
                                                   {'loss': 0.4952, 'grad_norm': 1522.900390625, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 2.830946922302246, 'mean_ratio_rejected': 4.367029190063477, 'weight_chosen': 0.40810316801071167, 'weight_rejected': 0.10230471193790436, 'kl_term_chosen': 0.5203056335449219, 'epoch': 0.02}
  2%|▏         | 80/3753 [06:07<4:37:59,  4.54s/it]  2%|▏         | 81/3753 [06:12<4:41:38,  4.60s/it]  2%|▏         | 82/3753 [06:16<4:26:45,  4.36s/it]  2%|▏         | 83/3753 [06:23<5:10:59,  5.08s/it]  2%|▏         | 84/3753 [06:28<5:11:31,  5.09s/it]  2%|▏         | 85/3753 [06:31<4:42:52,  4.63s/it]  2%|▏         | 86/3753 [06:35<4:19:51,  4.25s/it]  2%|▏         | 87/3753 [06:42<5:09:48,  5.07s/it]  2%|▏         | 88/3753 [06:45<4:46:03,  4.68s/it]  2%|▏         | 89/3753 [06:50<4:41:27,  4.61s/it]  2%|▏         | 90/3753 [06:54<4:32:07,  4.46s/it]{'loss': 1.1059, 'grad_norm': 1593.4107666015625, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 6.525994777679443, 'weight_chosen': -0.9207272529602051, 'weight_rejected': 0.15002880990505219, 'kl_term_chosen': 1.7099609375, 'epoch': 0.023984010659560292}
                                                   {'loss': 1.1059, 'grad_norm': 1593.4107666015625, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 6.525994777679443, 'weight_chosen': -0.9207272529602051, 'weight_rejected': 0.15002880990505219, 'kl_term_chosen': 1.7099609375, 'epoch': 0.02}
  2%|▏         | 90/3753 [06:54<4:32:07,  4.46s/it]  2%|▏         | 91/3753 [06:57<4:10:53,  4.11s/it]  2%|▏         | 92/3753 [07:01<4:08:00,  4.06s/it]  2%|▏         | 93/3753 [07:07<4:34:48,  4.51s/it]  3%|▎         | 94/3753 [07:11<4:20:56,  4.28s/it]  3%|▎         | 95/3753 [07:17<5:06:01,  5.02s/it]  3%|▎         | 96/3753 [07:21<4:47:46,  4.72s/it]  3%|▎         | 97/3753 [07:26<4:39:01,  4.58s/it]  3%|▎         | 98/3753 [07:31<5:00:51,  4.94s/it]  3%|▎         | 99/3753 [07:35<4:33:25,  4.49s/it]  3%|▎         | 100/3753 [07:39<4:20:07,  4.27s/it]{'loss': 0.7167, 'grad_norm': 1197.3619384765625, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 0.5660889148712158, 'mean_ratio_rejected': 0.761387050151825, 'weight_chosen': 0.9124532341957092, 'weight_rejected': 0.14414885640144348, 'kl_term_chosen': -0.2845020294189453, 'epoch': 0.02664890073284477}
                                                    {'loss': 0.7167, 'grad_norm': 1197.3619384765625, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 0.5660889148712158, 'mean_ratio_rejected': 0.761387050151825, 'weight_chosen': 0.9124532341957092, 'weight_rejected': 0.14414885640144348, 'kl_term_chosen': -0.2845020294189453, 'epoch': 0.03}
  3%|▎         | 100/3753 [07:39<4:20:07,  4.27s/it]  3%|▎         | 101/3753 [07:43<4:24:52,  4.35s/it]  3%|▎         | 102/3753 [07:47<4:20:54,  4.29s/it]  3%|▎         | 103/3753 [07:51<4:10:50,  4.12s/it]  3%|▎         | 104/3753 [07:57<4:38:09,  4.57s/it]  3%|▎         | 105/3753 [08:01<4:28:14,  4.41s/it]  3%|▎         | 106/3753 [08:06<4:48:44,  4.75s/it]  3%|▎         | 107/3753 [08:11<4:46:30,  4.71s/it]  3%|▎         | 108/3753 [08:15<4:33:38,  4.50s/it]  3%|▎         | 109/3753 [08:19<4:23:29,  4.34s/it]  3%|▎         | 110/3753 [08:23<4:15:59,  4.22s/it]{'loss': 0.5909, 'grad_norm': 4133.8349609375, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 4.27534818649292, 'weight_chosen': -0.4226806163787842, 'weight_rejected': 0.04146226868033409, 'kl_term_chosen': 1.3363571166992188, 'epoch': 0.029313790806129246}
                                                    {'loss': 0.5909, 'grad_norm': 4133.8349609375, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 4.27534818649292, 'weight_chosen': -0.4226806163787842, 'weight_rejected': 0.04146226868033409, 'kl_term_chosen': 1.3363571166992188, 'epoch': 0.03}
  3%|▎         | 110/3753 [08:23<4:15:59,  4.22s/it]  3%|▎         | 111/3753 [08:28<4:41:42,  4.64s/it]  3%|▎         | 112/3753 [08:32<4:23:34,  4.34s/it]  3%|▎         | 113/3753 [08:35<4:04:38,  4.03s/it]  3%|▎         | 114/3753 [08:39<3:55:57,  3.89s/it]  3%|▎         | 115/3753 [08:43<3:54:12,  3.86s/it]  3%|▎         | 116/3753 [08:47<4:08:35,  4.10s/it]  3%|▎         | 117/3753 [08:51<4:07:43,  4.09s/it]  3%|▎         | 118/3753 [08:56<4:12:21,  4.17s/it]  3%|▎         | 119/3753 [09:04<5:21:54,  5.31s/it]  3%|▎         | 120/3753 [09:08<5:05:53,  5.05s/it]{'loss': 0.7078, 'grad_norm': 2378.52001953125, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 0.9767046570777893, 'mean_ratio_rejected': 0.17831340432167053, 'weight_chosen': 0.8483400344848633, 'weight_rejected': 0.49502578377723694, 'kl_term_chosen': -0.011785507202148438, 'epoch': 0.031978680879413725}
                                                    {'loss': 0.7078, 'grad_norm': 2378.52001953125, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 0.9767046570777893, 'mean_ratio_rejected': 0.17831340432167053, 'weight_chosen': 0.8483400344848633, 'weight_rejected': 0.49502578377723694, 'kl_term_chosen': -0.011785507202148438, 'epoch': 0.03}
  3%|▎         | 120/3753 [09:08<5:05:53,  5.05s/it]  3%|▎         | 121/3753 [09:12<4:51:50,  4.82s/it]  3%|▎         | 122/3753 [09:17<4:48:24,  4.77s/it]  3%|▎         | 123/3753 [09:21<4:38:24,  4.60s/it]  3%|▎         | 124/3753 [09:25<4:23:26,  4.36s/it]  3%|▎         | 125/3753 [09:30<4:31:20,  4.49s/it]  3%|▎         | 126/3753 [09:35<4:39:09,  4.62s/it]  3%|▎         | 127/3753 [09:38<4:20:44,  4.31s/it]  3%|▎         | 128/3753 [09:43<4:27:28,  4.43s/it]  3%|▎         | 129/3753 [09:49<4:50:42,  4.81s/it]  3%|▎         | 130/3753 [09:53<4:45:18,  4.72s/it]{'loss': 1.2164, 'grad_norm': 1297.6805419921875, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.4230940341949463, 'weight_chosen': -1.0002291202545166, 'weight_rejected': 0.10970578342676163, 'kl_term_chosen': 1.297698974609375, 'epoch': 0.034643570952698204}
                                                    {'loss': 1.2164, 'grad_norm': 1297.6805419921875, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.4230940341949463, 'weight_chosen': -1.0002291202545166, 'weight_rejected': 0.10970578342676163, 'kl_term_chosen': 1.297698974609375, 'epoch': 0.03}
  3%|▎         | 130/3753 [09:53<4:45:18,  4.72s/it]  3%|▎         | 131/3753 [09:57<4:30:28,  4.48s/it]  4%|▎         | 132/3753 [10:00<4:09:05,  4.13s/it]  4%|▎         | 133/3753 [10:05<4:18:48,  4.29s/it]  4%|▎         | 134/3753 [10:10<4:22:12,  4.35s/it]  4%|▎         | 135/3753 [10:13<4:10:56,  4.16s/it]  4%|▎         | 136/3753 [10:17<3:59:29,  3.97s/it]  4%|▎         | 137/3753 [10:21<3:54:45,  3.90s/it]  4%|▎         | 138/3753 [10:25<4:05:20,  4.07s/it]  4%|▎         | 139/3753 [10:29<4:01:42,  4.01s/it]  4%|▎         | 140/3753 [10:34<4:18:38,  4.30s/it]{'loss': 1.1758, 'grad_norm': 2036.4005126953125, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 8.891441345214844, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.2328808307647705, 'weight_rejected': 0.14706450700759888, 'kl_term_chosen': 1.0925445556640625, 'epoch': 0.037308461025982675}
                                                    {'loss': 1.1758, 'grad_norm': 2036.4005126953125, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 8.891441345214844, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.2328808307647705, 'weight_rejected': 0.14706450700759888, 'kl_term_chosen': 1.0925445556640625, 'epoch': 0.04}
  4%|▎         | 140/3753 [10:34<4:18:38,  4.30s/it]  4%|▍         | 141/3753 [10:38<4:10:03,  4.15s/it]  4%|▍         | 142/3753 [10:44<4:52:54,  4.87s/it]  4%|▍         | 143/3753 [10:48<4:38:50,  4.63s/it]  4%|▍         | 144/3753 [10:54<4:59:18,  4.98s/it]  4%|▍         | 145/3753 [11:01<5:37:50,  5.62s/it]  4%|▍         | 146/3753 [11:07<5:31:58,  5.52s/it]  4%|▍         | 147/3753 [11:13<5:57:03,  5.94s/it]  4%|▍         | 148/3753 [11:19<5:40:21,  5.66s/it]  4%|▍         | 149/3753 [11:22<5:09:21,  5.15s/it]  4%|▍         | 150/3753 [11:29<5:41:21,  5.68s/it]{'loss': 1.4508, 'grad_norm': 1635.668701171875, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 0.6077906489372253, 'mean_ratio_rejected': 0.40995481610298157, 'weight_chosen': 0.5844221115112305, 'weight_rejected': 0.5903069972991943, 'kl_term_chosen': -0.24896240234375, 'epoch': 0.039973351099267154}
                                                    {'loss': 1.4508, 'grad_norm': 1635.668701171875, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 0.6077906489372253, 'mean_ratio_rejected': 0.40995481610298157, 'weight_chosen': 0.5844221115112305, 'weight_rejected': 0.5903069972991943, 'kl_term_chosen': -0.24896240234375, 'epoch': 0.04}
  4%|▍         | 150/3753 [11:30<5:41:21,  5.68s/it]  4%|▍         | 151/3753 [11:35<5:34:18,  5.57s/it]  4%|▍         | 152/3753 [11:39<5:04:04,  5.07s/it]  4%|▍         | 153/3753 [11:43<5:00:20,  5.01s/it]  4%|▍         | 154/3753 [11:48<4:49:29,  4.83s/it]  4%|▍         | 155/3753 [11:52<4:41:50,  4.70s/it]  4%|▍         | 156/3753 [11:57<4:35:11,  4.59s/it]  4%|▍         | 157/3753 [12:00<4:20:49,  4.35s/it]  4%|▍         | 158/3753 [12:05<4:27:13,  4.46s/it]  4%|▍         | 159/3753 [12:09<4:19:30,  4.33s/it]  4%|▍         | 160/3753 [12:14<4:23:24,  4.40s/it]{'loss': 1.0558, 'grad_norm': 1282.056396484375, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 0.5123423337936401, 'mean_ratio_rejected': 2.7511634826660156, 'weight_chosen': 1.014410376548767, 'weight_rejected': 0.3372035324573517, 'kl_term_chosen': -0.334381103515625, 'epoch': 0.04263824117255163}
                                                    {'loss': 1.0558, 'grad_norm': 1282.056396484375, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 0.5123423337936401, 'mean_ratio_rejected': 2.7511634826660156, 'weight_chosen': 1.014410376548767, 'weight_rejected': 0.3372035324573517, 'kl_term_chosen': -0.334381103515625, 'epoch': 0.04}
  4%|▍         | 160/3753 [12:14<4:23:24,  4.40s/it]  4%|▍         | 161/3753 [12:18<4:15:40,  4.27s/it]  4%|▍         | 162/3753 [12:22<4:14:07,  4.25s/it]  4%|▍         | 163/3753 [12:25<3:58:27,  3.99s/it]  4%|▍         | 164/3753 [12:32<4:44:15,  4.75s/it]  4%|▍         | 165/3753 [12:38<5:18:31,  5.33s/it]  4%|▍         | 166/3753 [12:42<4:48:23,  4.82s/it]  4%|▍         | 167/3753 [12:47<4:49:01,  4.84s/it]  4%|▍         | 168/3753 [12:52<4:55:43,  4.95s/it]  5%|▍         | 169/3753 [12:56<4:28:44,  4.50s/it]  5%|▍         | 170/3753 [12:59<4:06:45,  4.13s/it]{'loss': 1.4005, 'grad_norm': 1361.6160888671875, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 2.273948907852173, 'mean_ratio_rejected': 4.47506046295166, 'weight_chosen': 0.46158838272094727, 'weight_rejected': 0.13568955659866333, 'kl_term_chosen': 0.41075897216796875, 'epoch': 0.04530313124583611}
                                                    {'loss': 1.4005, 'grad_norm': 1361.6160888671875, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 2.273948907852173, 'mean_ratio_rejected': 4.47506046295166, 'weight_chosen': 0.46158838272094727, 'weight_rejected': 0.13568955659866333, 'kl_term_chosen': 0.41075897216796875, 'epoch': 0.05}
  5%|▍         | 170/3753 [12:59<4:06:45,  4.13s/it]  5%|▍         | 171/3753 [13:03<4:13:39,  4.25s/it]  5%|▍         | 172/3753 [13:12<5:31:22,  5.55s/it]  5%|▍         | 173/3753 [13:16<4:57:37,  4.99s/it]  5%|▍         | 174/3753 [13:20<4:47:40,  4.82s/it]  5%|▍         | 175/3753 [13:25<4:40:12,  4.70s/it]  5%|▍         | 176/3753 [13:28<4:21:50,  4.39s/it]  5%|▍         | 177/3753 [13:33<4:23:27,  4.42s/it]  5%|▍         | 178/3753 [13:37<4:30:33,  4.54s/it]  5%|▍         | 179/3753 [13:41<4:14:17,  4.27s/it]  5%|▍         | 180/3753 [13:45<4:12:32,  4.24s/it]{'loss': 2.3657, 'grad_norm': 3497.2314453125, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.7854481935501099, 'weight_rejected': 0.09268777817487717, 'kl_term_chosen': 1.720794677734375, 'epoch': 0.047968021319120584}
                                                    {'loss': 2.3657, 'grad_norm': 3497.2314453125, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.7854481935501099, 'weight_rejected': 0.09268777817487717, 'kl_term_chosen': 1.720794677734375, 'epoch': 0.05}
  5%|▍         | 180/3753 [13:45<4:12:32,  4.24s/it]  5%|▍         | 181/3753 [13:50<4:17:29,  4.33s/it]  5%|▍         | 182/3753 [13:57<5:05:57,  5.14s/it]  5%|▍         | 183/3753 [14:02<4:57:35,  5.00s/it]  5%|▍         | 184/3753 [14:07<5:07:02,  5.16s/it]  5%|▍         | 185/3753 [14:12<5:02:30,  5.09s/it]  5%|▍         | 186/3753 [14:16<4:43:36,  4.77s/it]  5%|▍         | 187/3753 [14:20<4:28:44,  4.52s/it]  5%|▌         | 188/3753 [14:24<4:22:36,  4.42s/it]  5%|▌         | 189/3753 [14:31<5:07:42,  5.18s/it]  5%|▌         | 190/3753 [14:36<4:53:43,  4.95s/it]{'loss': 1.103, 'grad_norm': 1033.479736328125, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 0.48522406816482544, 'mean_ratio_rejected': 0.16913829743862152, 'weight_chosen': 1.2423694133758545, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': -0.361572265625, 'epoch': 0.05063291139240506}
                                                    {'loss': 1.103, 'grad_norm': 1033.479736328125, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 0.48522406816482544, 'mean_ratio_rejected': 0.16913829743862152, 'weight_chosen': 1.2423694133758545, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': -0.361572265625, 'epoch': 0.05}
  5%|▌         | 190/3753 [14:36<4:53:43,  4.95s/it]  5%|▌         | 191/3753 [14:39<4:30:54,  4.56s/it]  5%|▌         | 192/3753 [14:47<5:23:45,  5.45s/it]  5%|▌         | 193/3753 [14:51<5:03:09,  5.11s/it]  5%|▌         | 194/3753 [14:56<5:04:40,  5.14s/it]  5%|▌         | 195/3753 [15:00<4:47:00,  4.84s/it]  5%|▌         | 196/3753 [15:04<4:24:06,  4.45s/it]  5%|▌         | 197/3753 [15:13<5:40:52,  5.75s/it]  5%|▌         | 198/3753 [15:17<5:08:00,  5.20s/it]  5%|▌         | 199/3753 [15:22<5:15:52,  5.33s/it]  5%|▌         | 200/3753 [15:26<4:56:27,  5.01s/it]{'loss': 1.7405, 'grad_norm': 2204.640869140625, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.9815887212753296, 'weight_chosen': -0.5810436010360718, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 1.5243911743164062, 'epoch': 0.05329780146568954}
                                                    {'loss': 1.7405, 'grad_norm': 2204.640869140625, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.9815887212753296, 'weight_chosen': -0.5810436010360718, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 1.5243911743164062, 'epoch': 0.05}
  5%|▌         | 200/3753 [15:27<4:56:27,  5.01s/it]  5%|▌         | 201/3753 [15:33<5:24:16,  5.48s/it]  5%|▌         | 202/3753 [15:37<4:58:07,  5.04s/it]  5%|▌         | 203/3753 [15:42<4:57:12,  5.02s/it]  5%|▌         | 204/3753 [15:46<4:32:20,  4.60s/it]  5%|▌         | 205/3753 [15:50<4:23:04,  4.45s/it]  5%|▌         | 206/3753 [15:57<5:04:14,  5.15s/it]  6%|▌         | 207/3753 [16:01<4:50:47,  4.92s/it]  6%|▌         | 208/3753 [16:06<4:54:49,  4.99s/it]  6%|▌         | 209/3753 [16:11<4:55:55,  5.01s/it]  6%|▌         | 210/3753 [16:16<4:48:01,  4.88s/it]{'loss': 2.1191, 'grad_norm': 1825.18798828125, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 8.817402839660645, 'mean_ratio_rejected': 2.8147084712982178, 'weight_chosen': -0.2696268558502197, 'weight_rejected': 0.15304215252399445, 'kl_term_chosen': 1.0883636474609375, 'epoch': 0.05596269153897402}
                                                    {'loss': 2.1191, 'grad_norm': 1825.18798828125, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 8.817402839660645, 'mean_ratio_rejected': 2.8147084712982178, 'weight_chosen': -0.2696268558502197, 'weight_rejected': 0.15304215252399445, 'kl_term_chosen': 1.0883636474609375, 'epoch': 0.06}
  6%|▌         | 210/3753 [16:16<4:48:01,  4.88s/it]  6%|▌         | 211/3753 [16:21<4:58:06,  5.05s/it]  6%|▌         | 212/3753 [16:25<4:28:40,  4.55s/it]  6%|▌         | 213/3753 [16:29<4:30:02,  4.58s/it]  6%|▌         | 214/3753 [16:35<4:48:47,  4.90s/it]  6%|▌         | 215/3753 [16:39<4:33:15,  4.63s/it]  6%|▌         | 216/3753 [16:43<4:30:07,  4.58s/it]  6%|▌         | 217/3753 [16:47<4:16:02,  4.34s/it]  6%|▌         | 218/3753 [16:52<4:18:55,  4.39s/it]  6%|▌         | 219/3753 [16:55<4:08:13,  4.21s/it]  6%|▌         | 220/3753 [16:59<3:59:51,  4.07s/it]{'loss': 1.04, 'grad_norm': 2059.783935546875, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 5.514591217041016, 'mean_ratio_rejected': 5.309605598449707, 'weight_chosen': -0.17197191715240479, 'weight_rejected': 0.1200256198644638, 'kl_term_chosen': 0.85369873046875, 'epoch': 0.05862758161225849}
                                                    {'loss': 1.04, 'grad_norm': 2059.783935546875, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 5.514591217041016, 'mean_ratio_rejected': 5.309605598449707, 'weight_chosen': -0.17197191715240479, 'weight_rejected': 0.1200256198644638, 'kl_term_chosen': 0.85369873046875, 'epoch': 0.06}
  6%|▌         | 220/3753 [16:59<3:59:51,  4.07s/it]  6%|▌         | 221/3753 [17:03<3:52:55,  3.96s/it]  6%|▌         | 222/3753 [17:07<4:00:50,  4.09s/it]  6%|▌         | 223/3753 [17:11<3:48:28,  3.88s/it]  6%|▌         | 224/3753 [17:15<3:50:19,  3.92s/it]  6%|▌         | 225/3753 [17:19<3:55:05,  4.00s/it]  6%|▌         | 226/3753 [17:23<3:51:53,  3.94s/it]  6%|▌         | 227/3753 [17:28<4:13:58,  4.32s/it]  6%|▌         | 228/3753 [17:31<4:01:31,  4.11s/it]  6%|▌         | 229/3753 [17:36<4:12:04,  4.29s/it]  6%|▌         | 230/3753 [17:43<4:51:41,  4.97s/it]{'loss': 1.7875, 'grad_norm': 1287.681640625, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 0.8687090277671814, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.0075843334197998, 'weight_rejected': 0.1490352898836136, 'kl_term_chosen': -0.07037353515625, 'epoch': 0.06129247168554297}
                                                    {'loss': 1.7875, 'grad_norm': 1287.681640625, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 0.8687090277671814, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.0075843334197998, 'weight_rejected': 0.1490352898836136, 'kl_term_chosen': -0.07037353515625, 'epoch': 0.06}
  6%|▌         | 230/3753 [17:43<4:51:41,  4.97s/it]  6%|▌         | 231/3753 [17:48<5:03:51,  5.18s/it]  6%|▌         | 232/3753 [17:53<4:47:55,  4.91s/it]  6%|▌         | 233/3753 [17:58<4:47:18,  4.90s/it]  6%|▌         | 234/3753 [18:03<4:53:27,  5.00s/it]  6%|▋         | 235/3753 [18:11<5:56:37,  6.08s/it]  6%|▋         | 236/3753 [18:16<5:24:36,  5.54s/it]  6%|▋         | 237/3753 [18:19<4:47:45,  4.91s/it]  6%|▋         | 238/3753 [18:24<4:42:43,  4.83s/it]  6%|▋         | 239/3753 [18:29<4:42:54,  4.83s/it]  6%|▋         | 240/3753 [18:33<4:36:11,  4.72s/it]{'loss': 2.2395, 'grad_norm': 1489.6331787109375, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 0.22975687682628632, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.5665098428726196, 'weight_rejected': 0.17781086266040802, 'kl_term_chosen': -0.7353668212890625, 'epoch': 0.06395736175882745}
                                                    {'loss': 2.2395, 'grad_norm': 1489.6331787109375, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 0.22975687682628632, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.5665098428726196, 'weight_rejected': 0.17781086266040802, 'kl_term_chosen': -0.7353668212890625, 'epoch': 0.06}
  6%|▋         | 240/3753 [18:33<4:36:11,  4.72s/it]  6%|▋         | 241/3753 [18:37<4:25:10,  4.53s/it]  6%|▋         | 242/3753 [18:41<4:17:54,  4.41s/it]  6%|▋         | 243/3753 [18:46<4:20:10,  4.45s/it]  7%|▋         | 244/3753 [18:52<4:43:57,  4.86s/it]  7%|▋         | 245/3753 [18:56<4:38:13,  4.76s/it]  7%|▋         | 246/3753 [19:00<4:18:43,  4.43s/it]  7%|▋         | 247/3753 [19:07<5:03:40,  5.20s/it]  7%|▋         | 248/3753 [19:12<5:00:26,  5.14s/it]  7%|▋         | 249/3753 [19:17<5:04:49,  5.22s/it]  7%|▋         | 250/3753 [19:22<5:02:34,  5.18s/it]{'loss': 3.2839, 'grad_norm': 1149.4876708984375, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.4885048866271973, 'weight_chosen': -0.31897854804992676, 'weight_rejected': 0.14804719388484955, 'kl_term_chosen': 1.2137680053710938, 'epoch': 0.06662225183211193}
                                                    {'loss': 3.2839, 'grad_norm': 1149.4876708984375, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.4885048866271973, 'weight_chosen': -0.31897854804992676, 'weight_rejected': 0.14804719388484955, 'kl_term_chosen': 1.2137680053710938, 'epoch': 0.07}
  7%|▋         | 250/3753 [19:22<5:02:34,  5.18s/it]  7%|▋         | 251/3753 [19:29<5:27:42,  5.61s/it]  7%|▋         | 252/3753 [19:34<5:20:04,  5.49s/it]  7%|▋         | 253/3753 [19:39<5:05:47,  5.24s/it]  7%|▋         | 254/3753 [19:42<4:37:26,  4.76s/it]  7%|▋         | 255/3753 [19:46<4:22:13,  4.50s/it]  7%|▋         | 256/3753 [19:50<4:06:25,  4.23s/it]  7%|▋         | 257/3753 [19:54<4:10:18,  4.30s/it]  7%|▋         | 258/3753 [19:58<4:04:25,  4.20s/it]  7%|▋         | 259/3753 [20:02<3:52:26,  3.99s/it]  7%|▋         | 260/3753 [20:07<4:04:49,  4.21s/it]{'loss': 3.2644, 'grad_norm': 777.9563598632812, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 1.1199383735656738, 'mean_ratio_rejected': 1.4385011196136475, 'weight_chosen': 0.8305677771568298, 'weight_rejected': 0.13386748731136322, 'kl_term_chosen': 0.056636810302734375, 'epoch': 0.06928714190539641}
                                                    {'loss': 3.2644, 'grad_norm': 777.9563598632812, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 1.1199383735656738, 'mean_ratio_rejected': 1.4385011196136475, 'weight_chosen': 0.8305677771568298, 'weight_rejected': 0.13386748731136322, 'kl_term_chosen': 0.056636810302734375, 'epoch': 0.07}
  7%|▋         | 260/3753 [20:07<4:04:49,  4.21s/it]  7%|▋         | 261/3753 [20:11<4:11:08,  4.32s/it]  7%|▋         | 262/3753 [20:16<4:14:13,  4.37s/it]  7%|▋         | 263/3753 [20:20<4:17:20,  4.42s/it]  7%|▋         | 264/3753 [20:24<4:09:48,  4.30s/it]  7%|▋         | 265/3753 [20:28<4:04:53,  4.21s/it]  7%|▋         | 266/3753 [20:32<3:59:17,  4.12s/it]  7%|▋         | 267/3753 [20:36<3:55:31,  4.05s/it]  7%|▋         | 268/3753 [20:41<4:10:36,  4.31s/it]  7%|▋         | 269/3753 [20:44<3:52:27,  4.00s/it]  7%|▋         | 270/3753 [20:49<4:02:22,  4.18s/it]{'loss': 3.2297, 'grad_norm': 1816.328369140625, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.0430136919021606, 'weight_chosen': -0.5636076331138611, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': 1.5391845703125, 'epoch': 0.07195203197868089}
                                                    {'loss': 3.2297, 'grad_norm': 1816.328369140625, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.0430136919021606, 'weight_chosen': -0.5636076331138611, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': 1.5391845703125, 'epoch': 0.07}
  7%|▋         | 270/3753 [20:49<4:02:22,  4.18s/it]  7%|▋         | 271/3753 [20:53<4:10:25,  4.32s/it]  7%|▋         | 272/3753 [20:58<4:09:33,  4.30s/it]  7%|▋         | 273/3753 [21:01<3:58:19,  4.11s/it]  7%|▋         | 274/3753 [21:05<3:51:18,  3.99s/it]  7%|▋         | 275/3753 [21:09<3:52:42,  4.01s/it]  7%|▋         | 276/3753 [21:13<3:45:12,  3.89s/it]  7%|▋         | 277/3753 [21:18<4:10:52,  4.33s/it]  7%|▋         | 278/3753 [21:21<3:52:47,  4.02s/it]  7%|▋         | 279/3753 [21:26<4:03:42,  4.21s/it]  7%|▋         | 280/3753 [21:31<4:12:32,  4.36s/it]{'loss': 5.7508, 'grad_norm': 560.6461791992188, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.3880929946899414, 'mean_ratio_rejected': 0.7486168742179871, 'weight_chosen': 1.4037134647369385, 'weight_rejected': 0.07263670116662979, 'kl_term_chosen': -0.4732551574707031, 'epoch': 0.07461692205196535}
                                                    {'loss': 5.7508, 'grad_norm': 560.6461791992188, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.3880929946899414, 'mean_ratio_rejected': 0.7486168742179871, 'weight_chosen': 1.4037134647369385, 'weight_rejected': 0.07263670116662979, 'kl_term_chosen': -0.4732551574707031, 'epoch': 0.07}
  7%|▋         | 280/3753 [21:31<4:12:32,  4.36s/it]  7%|▋         | 281/3753 [21:35<4:09:09,  4.31s/it]  8%|▊         | 282/3753 [21:41<4:38:40,  4.82s/it]  8%|▊         | 283/3753 [21:45<4:32:34,  4.71s/it]  8%|▊         | 284/3753 [21:50<4:23:18,  4.55s/it]  8%|▊         | 285/3753 [21:57<5:09:41,  5.36s/it]  8%|▊         | 286/3753 [22:01<4:42:11,  4.88s/it]  8%|▊         | 287/3753 [22:05<4:28:33,  4.65s/it]  8%|▊         | 288/3753 [22:13<5:39:29,  5.88s/it]  8%|▊         | 289/3753 [22:18<5:18:48,  5.52s/it]  8%|▊         | 290/3753 [22:27<6:12:20,  6.45s/it]{'loss': 2.6124, 'grad_norm': 976.0882568359375, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 3.617826461791992, 'weight_chosen': -0.7819032073020935, 'weight_rejected': 0.20946967601776123, 'kl_term_chosen': 1.535369873046875, 'epoch': 0.07728181212524983}
                                                    {'loss': 2.6124, 'grad_norm': 976.0882568359375, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 3.617826461791992, 'weight_chosen': -0.7819032073020935, 'weight_rejected': 0.20946967601776123, 'kl_term_chosen': 1.535369873046875, 'epoch': 0.08}
  8%|▊         | 290/3753 [22:27<6:12:20,  6.45s/it]  8%|▊         | 291/3753 [22:30<5:24:51,  5.63s/it]  8%|▊         | 292/3753 [22:36<5:30:57,  5.74s/it]  8%|▊         | 293/3753 [22:40<4:54:20,  5.10s/it]  8%|▊         | 294/3753 [22:44<4:38:36,  4.83s/it]  8%|▊         | 295/3753 [22:49<4:37:45,  4.82s/it]  8%|▊         | 296/3753 [22:53<4:21:26,  4.54s/it]  8%|▊         | 297/3753 [22:57<4:19:40,  4.51s/it]  8%|▊         | 298/3753 [23:03<4:43:12,  4.92s/it]  8%|▊         | 299/3753 [23:08<4:32:32,  4.73s/it]  8%|▊         | 300/3753 [23:12<4:25:46,  4.62s/it]{'loss': 8.7748, 'grad_norm': 1308.8739013671875, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.8875300884246826, 'weight_chosen': -1.1755132675170898, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 2.0996551513671875, 'epoch': 0.07994670219853431}
                                                    {'loss': 8.7748, 'grad_norm': 1308.8739013671875, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.8875300884246826, 'weight_chosen': -1.1755132675170898, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 2.0996551513671875, 'epoch': 0.08}
  8%|▊         | 300/3753 [23:12<4:25:46,  4.62s/it]  8%|▊         | 301/3753 [23:16<4:19:44,  4.51s/it]  8%|▊         | 302/3753 [23:21<4:26:21,  4.63s/it]  8%|▊         | 303/3753 [23:26<4:28:24,  4.67s/it]  8%|▊         | 304/3753 [23:29<4:02:51,  4.22s/it]  8%|▊         | 305/3753 [23:33<3:59:24,  4.17s/it]  8%|▊         | 306/3753 [23:37<3:53:22,  4.06s/it]  8%|▊         | 307/3753 [23:42<4:04:26,  4.26s/it]  8%|▊         | 308/3753 [23:47<4:29:52,  4.70s/it]  8%|▊         | 309/3753 [23:52<4:26:09,  4.64s/it]  8%|▊         | 310/3753 [23:56<4:17:07,  4.48s/it]{'loss': 7.5869, 'grad_norm': 482.84759521484375, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 5.302702903747559, 'mean_ratio_rejected': 1.461879014968872, 'weight_chosen': -0.17043942213058472, 'weight_rejected': 0.22815649211406708, 'kl_term_chosen': 0.8341083526611328, 'epoch': 0.08261159227181879}
                                                    {'loss': 7.5869, 'grad_norm': 482.84759521484375, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 5.302702903747559, 'mean_ratio_rejected': 1.461879014968872, 'weight_chosen': -0.17043942213058472, 'weight_rejected': 0.22815649211406708, 'kl_term_chosen': 0.8341083526611328, 'epoch': 0.08}
  8%|▊         | 310/3753 [23:56<4:17:07,  4.48s/it]  8%|▊         | 311/3753 [24:00<4:13:51,  4.43s/it]  8%|▊         | 312/3753 [24:04<4:06:58,  4.31s/it]  8%|▊         | 313/3753 [24:08<4:06:06,  4.29s/it]  8%|▊         | 314/3753 [24:15<4:52:23,  5.10s/it]  8%|▊         | 315/3753 [24:19<4:27:39,  4.67s/it]  8%|▊         | 316/3753 [24:23<4:13:24,  4.42s/it]  8%|▊         | 317/3753 [24:27<4:06:32,  4.31s/it]  8%|▊         | 318/3753 [24:32<4:10:23,  4.37s/it]  8%|▊         | 319/3753 [24:36<4:06:26,  4.31s/it]  9%|▊         | 320/3753 [24:40<4:13:49,  4.44s/it]{'loss': 20.1595, 'grad_norm': 500.91455078125, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.0662376880645752, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': 2.003448486328125, 'epoch': 0.08527648234510327}
                                                    {'loss': 20.1595, 'grad_norm': 500.91455078125, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.0662376880645752, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': 2.003448486328125, 'epoch': 0.09}
  9%|▊         | 320/3753 [24:41<4:13:49,  4.44s/it]  9%|▊         | 321/3753 [24:45<4:15:32,  4.47s/it]  9%|▊         | 322/3753 [24:49<4:07:00,  4.32s/it]  9%|▊         | 323/3753 [24:52<3:52:19,  4.06s/it]  9%|▊         | 324/3753 [25:00<4:45:17,  4.99s/it]  9%|▊         | 325/3753 [25:04<4:35:02,  4.81s/it]  9%|▊         | 326/3753 [25:08<4:13:49,  4.44s/it]  9%|▊         | 327/3753 [25:12<4:09:07,  4.36s/it]  9%|▊         | 328/3753 [25:16<4:01:56,  4.24s/it]  9%|▉         | 329/3753 [25:20<4:05:55,  4.31s/it]  9%|▉         | 330/3753 [25:25<4:15:22,  4.48s/it]{'loss': 2.9776, 'grad_norm': 808.4815063476562, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 2.859797239303589, 'mean_ratio_rejected': 0.5568429231643677, 'weight_chosen': 0.33616286516189575, 'weight_rejected': 0.22135066986083984, 'kl_term_chosen': 0.5253753662109375, 'epoch': 0.08794137241838774}
                                                    {'loss': 2.9776, 'grad_norm': 808.4815063476562, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 2.859797239303589, 'mean_ratio_rejected': 0.5568429231643677, 'weight_chosen': 0.33616286516189575, 'weight_rejected': 0.22135066986083984, 'kl_term_chosen': 0.5253753662109375, 'epoch': 0.09}
  9%|▉         | 330/3753 [25:25<4:15:22,  4.48s/it]  9%|▉         | 331/3753 [25:29<4:07:04,  4.33s/it]  9%|▉         | 332/3753 [25:33<4:01:12,  4.23s/it]  9%|▉         | 333/3753 [25:37<4:04:39,  4.29s/it]  9%|▉         | 334/3753 [25:45<5:06:53,  5.39s/it]  9%|▉         | 335/3753 [25:50<4:56:30,  5.20s/it]  9%|▉         | 336/3753 [25:53<4:24:12,  4.64s/it]  9%|▉         | 337/3753 [25:58<4:25:55,  4.67s/it]  9%|▉         | 338/3753 [26:02<4:06:51,  4.34s/it]  9%|▉         | 339/3753 [26:05<3:53:36,  4.11s/it]  9%|▉         | 340/3753 [26:10<3:58:17,  4.19s/it]{'loss': 20.4594, 'grad_norm': 1002.445068359375, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.329329967498779, 'weight_rejected': 0.7826625108718872, 'kl_term_chosen': -6.085687637329102, 'epoch': 0.09060626249167222}
                                                    {'loss': 20.4594, 'grad_norm': 1002.445068359375, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.329329967498779, 'weight_rejected': 0.7826625108718872, 'kl_term_chosen': -6.085687637329102, 'epoch': 0.09}
  9%|▉         | 340/3753 [26:10<3:58:17,  4.19s/it]  9%|▉         | 341/3753 [26:13<3:49:14,  4.03s/it]  9%|▉         | 342/3753 [26:17<3:46:35,  3.99s/it]  9%|▉         | 343/3753 [26:22<4:00:04,  4.22s/it]  9%|▉         | 344/3753 [26:26<3:52:56,  4.10s/it]  9%|▉         | 345/3753 [26:32<4:19:15,  4.56s/it]  9%|▉         | 346/3753 [26:36<4:10:01,  4.40s/it]  9%|▉         | 347/3753 [26:40<4:11:30,  4.43s/it]  9%|▉         | 348/3753 [26:45<4:26:37,  4.70s/it]  9%|▉         | 349/3753 [26:49<4:09:12,  4.39s/it]  9%|▉         | 350/3753 [26:54<4:15:01,  4.50s/it]{'loss': 8.7051, 'grad_norm': 833.7348022460938, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.4008359909057617, 'weight_rejected': 0.2186693549156189, 'kl_term_chosen': -1.5664291381835938, 'epoch': 0.09327115256495669}
                                                    {'loss': 8.7051, 'grad_norm': 833.7348022460938, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.4008359909057617, 'weight_rejected': 0.2186693549156189, 'kl_term_chosen': -1.5664291381835938, 'epoch': 0.09}
  9%|▉         | 350/3753 [26:54<4:15:01,  4.50s/it]  9%|▉         | 351/3753 [26:58<4:04:53,  4.32s/it]  9%|▉         | 352/3753 [27:01<3:46:42,  4.00s/it]  9%|▉         | 353/3753 [27:05<3:48:31,  4.03s/it]  9%|▉         | 354/3753 [27:10<3:57:09,  4.19s/it]  9%|▉         | 355/3753 [27:15<4:23:51,  4.66s/it]  9%|▉         | 356/3753 [27:20<4:25:04,  4.68s/it] 10%|▉         | 357/3753 [27:24<4:15:57,  4.52s/it] 10%|▉         | 358/3753 [27:29<4:18:37,  4.57s/it] 10%|▉         | 359/3753 [27:33<4:11:47,  4.45s/it] 10%|▉         | 360/3753 [27:37<3:59:07,  4.23s/it]{'loss': 14.7008, 'grad_norm': 2697.26416015625, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.205972909927368, 'weight_rejected': 0.16667540371418, 'kl_term_chosen': 2.7502899169921875, 'epoch': 0.09593604263824117}
                                                    {'loss': 14.7008, 'grad_norm': 2697.26416015625, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.205972909927368, 'weight_rejected': 0.16667540371418, 'kl_term_chosen': 2.7502899169921875, 'epoch': 0.1}
 10%|▉         | 360/3753 [27:37<3:59:07,  4.23s/it] 10%|▉         | 361/3753 [27:41<4:05:45,  4.35s/it] 10%|▉         | 362/3753 [27:46<4:06:15,  4.36s/it] 10%|▉         | 363/3753 [27:50<4:01:52,  4.28s/it] 10%|▉         | 364/3753 [27:54<4:05:02,  4.34s/it] 10%|▉         | 365/3753 [27:58<3:49:37,  4.07s/it] 10%|▉         | 366/3753 [28:01<3:37:00,  3.84s/it] 10%|▉         | 367/3753 [28:05<3:43:49,  3.97s/it] 10%|▉         | 368/3753 [28:11<4:03:21,  4.31s/it] 10%|▉         | 369/3753 [28:15<4:05:35,  4.35s/it] 10%|▉         | 370/3753 [28:19<4:02:13,  4.30s/it]{'loss': 22.0354, 'grad_norm': 679.8215942382812, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.4635231494903564, 'weight_rejected': 0.20561504364013672, 'kl_term_chosen': -2.599212646484375, 'epoch': 0.09860093271152565}
                                                    {'loss': 22.0354, 'grad_norm': 679.8215942382812, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.4635231494903564, 'weight_rejected': 0.20561504364013672, 'kl_term_chosen': -2.599212646484375, 'epoch': 0.1}
 10%|▉         | 370/3753 [28:19<4:02:13,  4.30s/it] 10%|▉         | 371/3753 [28:23<3:51:45,  4.11s/it] 10%|▉         | 372/3753 [28:27<3:58:30,  4.23s/it] 10%|▉         | 373/3753 [28:31<3:55:49,  4.19s/it] 10%|▉         | 374/3753 [28:39<4:46:36,  5.09s/it] 10%|▉         | 375/3753 [28:44<4:53:58,  5.22s/it] 10%|█         | 376/3753 [28:53<5:57:53,  6.36s/it] 10%|█         | 377/3753 [29:00<6:00:46,  6.41s/it] 10%|█         | 378/3753 [29:03<5:16:25,  5.63s/it] 10%|█         | 379/3753 [29:07<4:43:40,  5.04s/it] 10%|█         | 380/3753 [29:12<4:38:10,  4.95s/it]{'loss': 16.0365, 'grad_norm': 386.60052490234375, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.915103912353516, 'weight_rejected': 0.02595735713839531, 'kl_term_chosen': 9.875465393066406, 'epoch': 0.10126582278481013}
                                                    {'loss': 16.0365, 'grad_norm': 386.60052490234375, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.915103912353516, 'weight_rejected': 0.02595735713839531, 'kl_term_chosen': 9.875465393066406, 'epoch': 0.1}
 10%|█         | 380/3753 [29:12<4:38:10,  4.95s/it] 10%|█         | 381/3753 [29:16<4:23:15,  4.68s/it] 10%|█         | 382/3753 [29:21<4:23:48,  4.70s/it] 10%|█         | 383/3753 [29:25<4:11:09,  4.47s/it] 10%|█         | 384/3753 [29:30<4:25:00,  4.72s/it] 10%|█         | 385/3753 [29:40<5:51:18,  6.26s/it] 10%|█         | 386/3753 [29:43<5:06:54,  5.47s/it] 10%|█         | 387/3753 [29:48<4:49:08,  5.15s/it] 10%|█         | 388/3753 [29:52<4:38:36,  4.97s/it] 10%|█         | 389/3753 [29:57<4:33:56,  4.89s/it] 10%|█         | 390/3753 [30:03<4:51:50,  5.21s/it]{'loss': 22.5066, 'grad_norm': 948.3665161132812, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 7.21852445602417, 'weight_rejected': 0.8164063692092896, 'kl_term_chosen': -6.579689025878906, 'epoch': 0.1039307128580946}
                                                    {'loss': 22.5066, 'grad_norm': 948.3665161132812, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 7.21852445602417, 'weight_rejected': 0.8164063692092896, 'kl_term_chosen': -6.579689025878906, 'epoch': 0.1}
 10%|█         | 390/3753 [30:03<4:51:50,  5.21s/it] 10%|█         | 391/3753 [30:07<4:37:36,  4.95s/it] 10%|█         | 392/3753 [30:11<4:17:55,  4.60s/it] 10%|█         | 393/3753 [30:16<4:21:59,  4.68s/it] 10%|█         | 394/3753 [30:20<4:13:04,  4.52s/it] 11%|█         | 395/3753 [30:25<4:19:13,  4.63s/it] 11%|█         | 396/3753 [30:34<5:25:25,  5.82s/it] 11%|█         | 397/3753 [30:37<4:45:11,  5.10s/it] 11%|█         | 398/3753 [30:43<4:56:47,  5.31s/it] 11%|█         | 399/3753 [30:48<4:54:55,  5.28s/it] 11%|█         | 400/3753 [30:52<4:35:07,  4.92s/it]{'loss': 3.7201, 'grad_norm': 322.55255126953125, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 10.02733039855957, 'weight_rejected': 0.25091278553009033, 'kl_term_chosen': -9.332199096679688, 'epoch': 0.10659560293137908}
                                                    {'loss': 3.7201, 'grad_norm': 322.55255126953125, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 10.02733039855957, 'weight_rejected': 0.25091278553009033, 'kl_term_chosen': -9.332199096679688, 'epoch': 0.11}
 11%|█         | 400/3753 [30:52<4:35:07,  4.92s/it] 11%|█         | 401/3753 [30:56<4:19:38,  4.65s/it] 11%|█         | 402/3753 [31:01<4:20:53,  4.67s/it] 11%|█         | 403/3753 [31:04<3:56:53,  4.24s/it] 11%|█         | 404/3753 [31:08<3:56:06,  4.23s/it] 11%|█         | 405/3753 [31:14<4:12:02,  4.52s/it] 11%|█         | 406/3753 [31:18<4:08:22,  4.45s/it] 11%|█         | 407/3753 [31:22<3:57:33,  4.26s/it] 11%|█         | 408/3753 [31:26<4:07:28,  4.44s/it] 11%|█         | 409/3753 [31:31<4:02:35,  4.35s/it] 11%|█         | 410/3753 [31:35<4:07:44,  4.45s/it]{'loss': 5.8629, 'grad_norm': 396.02655029296875, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 12.038588523864746, 'weight_rejected': 0.28776782751083374, 'kl_term_chosen': -11.391681671142578, 'epoch': 0.10926049300466356}
                                                    {'loss': 5.8629, 'grad_norm': 396.02655029296875, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 12.038588523864746, 'weight_rejected': 0.28776782751083374, 'kl_term_chosen': -11.391681671142578, 'epoch': 0.11}
 11%|█         | 410/3753 [31:35<4:07:44,  4.45s/it] 11%|█         | 411/3753 [31:40<4:17:34,  4.62s/it] 11%|█         | 412/3753 [31:44<4:05:27,  4.41s/it] 11%|█         | 413/3753 [31:50<4:23:02,  4.73s/it] 11%|█         | 414/3753 [31:55<4:24:24,  4.75s/it] 11%|█         | 415/3753 [31:59<4:15:06,  4.59s/it] 11%|█         | 416/3753 [32:03<4:11:44,  4.53s/it] 11%|█         | 417/3753 [32:07<4:02:33,  4.36s/it] 11%|█         | 418/3753 [32:11<3:55:16,  4.23s/it] 11%|█         | 419/3753 [32:15<3:50:24,  4.15s/it] 11%|█         | 420/3753 [32:19<3:46:22,  4.08s/it]{'loss': 28.3324, 'grad_norm': 155.38587951660156, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.782458305358887, 'weight_rejected': 0.2727987766265869, 'kl_term_chosen': -5.131103515625, 'epoch': 0.11192538307794804}
                                                    {'loss': 28.3324, 'grad_norm': 155.38587951660156, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.782458305358887, 'weight_rejected': 0.2727987766265869, 'kl_term_chosen': -5.131103515625, 'epoch': 0.11}
 11%|█         | 420/3753 [32:19<3:46:22,  4.08s/it] 11%|█         | 421/3753 [32:23<3:52:34,  4.19s/it] 11%|█         | 422/3753 [32:28<3:53:44,  4.21s/it] 11%|█▏        | 423/3753 [32:31<3:44:49,  4.05s/it] 11%|█▏        | 424/3753 [32:34<3:28:34,  3.76s/it] 11%|█▏        | 425/3753 [32:39<3:35:57,  3.89s/it] 11%|█▏        | 426/3753 [32:43<3:44:39,  4.05s/it] 11%|█▏        | 427/3753 [32:48<3:53:26,  4.21s/it] 11%|█▏        | 428/3753 [32:52<3:58:28,  4.30s/it] 11%|█▏        | 429/3753 [32:56<3:53:55,  4.22s/it] 11%|█▏        | 430/3753 [33:01<4:04:45,  4.42s/it]{'loss': 68.2893, 'grad_norm': 299.2908630371094, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.2049495428800583, 'mean_ratio_rejected': 0.41542696952819824, 'weight_chosen': 1.3561139106750488, 'weight_rejected': 0.27125170826911926, 'kl_term_chosen': -0.7924957275390625, 'epoch': 0.1145902731512325}
                                                    {'loss': 68.2893, 'grad_norm': 299.2908630371094, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.2049495428800583, 'mean_ratio_rejected': 0.41542696952819824, 'weight_chosen': 1.3561139106750488, 'weight_rejected': 0.27125170826911926, 'kl_term_chosen': -0.7924957275390625, 'epoch': 0.11}
 11%|█▏        | 430/3753 [33:01<4:04:45,  4.42s/it] 11%|█▏        | 431/3753 [33:05<3:52:00,  4.19s/it] 12%|█▏        | 432/3753 [33:13<5:04:00,  5.49s/it] 12%|█▏        | 433/3753 [33:17<4:41:10,  5.08s/it] 12%|█▏        | 434/3753 [33:21<4:19:14,  4.69s/it] 12%|█▏        | 435/3753 [33:25<4:03:45,  4.41s/it] 12%|█▏        | 436/3753 [33:29<4:02:25,  4.39s/it] 12%|█▏        | 437/3753 [33:33<3:59:49,  4.34s/it] 12%|█▏        | 438/3753 [33:39<4:15:28,  4.62s/it] 12%|█▏        | 439/3753 [33:43<4:07:53,  4.49s/it] 12%|█▏        | 440/3753 [33:47<3:59:11,  4.33s/it]{'loss': 43.7953, 'grad_norm': 0.0, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.52694320678711, 'weight_rejected': 0.048136770725250244, 'kl_term_chosen': 9.481590270996094, 'epoch': 0.11725516322451698}
                                                    {'loss': 43.7953, 'grad_norm': 0.0, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.52694320678711, 'weight_rejected': 0.048136770725250244, 'kl_term_chosen': 9.481590270996094, 'epoch': 0.12}
 12%|█▏        | 440/3753 [33:47<3:59:11,  4.33s/it] 12%|█▏        | 441/3753 [33:53<4:25:50,  4.82s/it] 12%|█▏        | 442/3753 [33:57<4:21:32,  4.74s/it] 12%|█▏        | 443/3753 [34:01<3:55:59,  4.28s/it] 12%|█▏        | 444/3753 [34:06<4:09:04,  4.52s/it] 12%|█▏        | 445/3753 [34:09<3:51:55,  4.21s/it] 12%|█▏        | 446/3753 [34:14<3:57:26,  4.31s/it] 12%|█▏        | 447/3753 [34:18<3:58:08,  4.32s/it] 12%|█▏        | 448/3753 [34:21<3:40:02,  3.99s/it] 12%|█▏        | 449/3753 [34:27<4:03:27,  4.42s/it] 12%|█▏        | 450/3753 [34:31<4:00:39,  4.37s/it]{'loss': 30.0672, 'grad_norm': 1318.77294921875, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.340210914611816, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 8.2335205078125, 'epoch': 0.11992005329780146}
                                                    {'loss': 30.0672, 'grad_norm': 1318.77294921875, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.340210914611816, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 8.2335205078125, 'epoch': 0.12}
 12%|█▏        | 450/3753 [34:31<4:00:39,  4.37s/it] 12%|█▏        | 451/3753 [34:35<3:57:24,  4.31s/it] 12%|█▏        | 452/3753 [34:40<4:10:57,  4.56s/it] 12%|█▏        | 453/3753 [34:44<3:53:04,  4.24s/it] 12%|█▏        | 454/3753 [34:49<4:16:24,  4.66s/it] 12%|█▏        | 455/3753 [34:54<4:12:22,  4.59s/it] 12%|█▏        | 456/3753 [35:00<4:34:13,  4.99s/it] 12%|█▏        | 457/3753 [35:04<4:19:27,  4.72s/it] 12%|█▏        | 458/3753 [35:08<4:04:49,  4.46s/it] 12%|█▏        | 459/3753 [35:12<4:01:00,  4.39s/it] 12%|█▏        | 460/3753 [35:18<4:24:41,  4.82s/it]{'loss': 19.0173, 'grad_norm': 632.8556518554688, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 0.12329940497875214, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.9650499820709229, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': -1.04656982421875, 'epoch': 0.12258494337108594}
                                                    {'loss': 19.0173, 'grad_norm': 632.8556518554688, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 0.12329940497875214, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.9650499820709229, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': -1.04656982421875, 'epoch': 0.12}
 12%|█▏        | 460/3753 [35:18<4:24:41,  4.82s/it] 12%|█▏        | 461/3753 [35:21<4:03:19,  4.43s/it] 12%|█▏        | 462/3753 [35:24<3:36:09,  3.94s/it] 12%|█▏        | 463/3753 [35:28<3:41:55,  4.05s/it] 12%|█▏        | 464/3753 [35:32<3:43:49,  4.08s/it] 12%|█▏        | 465/3753 [35:36<3:41:54,  4.05s/it] 12%|█▏        | 466/3753 [35:41<3:49:41,  4.19s/it] 12%|█▏        | 467/3753 [35:45<3:49:49,  4.20s/it] 12%|█▏        | 468/3753 [35:53<4:48:09,  5.26s/it] 12%|█▏        | 469/3753 [35:58<4:50:26,  5.31s/it] 13%|█▎        | 470/3753 [36:04<5:03:40,  5.55s/it]{'loss': 43.9256, 'grad_norm': 282.3626708984375, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -12.627240180969238, 'weight_rejected': 0.08151976019144058, 'kl_term_chosen': 13.572235107421875, 'epoch': 0.1252498334443704}
                                                    {'loss': 43.9256, 'grad_norm': 282.3626708984375, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -12.627240180969238, 'weight_rejected': 0.08151976019144058, 'kl_term_chosen': 13.572235107421875, 'epoch': 0.13}
 13%|█▎        | 470/3753 [36:05<5:03:40,  5.55s/it] 13%|█▎        | 471/3753 [36:10<5:04:52,  5.57s/it] 13%|█▎        | 472/3753 [36:14<4:34:04,  5.01s/it] 13%|█▎        | 473/3753 [36:17<3:57:57,  4.35s/it] 13%|█▎        | 474/3753 [36:21<3:59:34,  4.38s/it] 13%|█▎        | 475/3753 [36:26<4:02:08,  4.43s/it] 13%|█▎        | 476/3753 [36:30<3:54:02,  4.29s/it] 13%|█▎        | 477/3753 [36:34<3:55:58,  4.32s/it] 13%|█▎        | 478/3753 [36:38<3:50:42,  4.23s/it] 13%|█▎        | 479/3753 [36:44<4:16:18,  4.70s/it] 13%|█▎        | 480/3753 [36:48<4:15:37,  4.69s/it]{'loss': 56.5228, 'grad_norm': 800.3235473632812, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 14.929912567138672, 'weight_rejected': 0.23792988061904907, 'kl_term_chosen': -14.353370666503906, 'epoch': 0.1279147235176549}
                                                    {'loss': 56.5228, 'grad_norm': 800.3235473632812, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 14.929912567138672, 'weight_rejected': 0.23792988061904907, 'kl_term_chosen': -14.353370666503906, 'epoch': 0.13}
 13%|█▎        | 480/3753 [36:49<4:15:37,  4.69s/it] 13%|█▎        | 481/3753 [36:53<4:19:32,  4.76s/it] 13%|█▎        | 482/3753 [36:57<4:03:41,  4.47s/it] 13%|█▎        | 483/3753 [37:01<3:56:49,  4.35s/it] 13%|█▎        | 484/3753 [37:05<3:48:25,  4.19s/it] 13%|█▎        | 485/3753 [37:09<3:38:52,  4.02s/it] 13%|█▎        | 486/3753 [37:14<3:55:49,  4.33s/it] 13%|█▎        | 487/3753 [37:19<4:05:22,  4.51s/it] 13%|█▎        | 488/3753 [37:23<3:57:27,  4.36s/it] 13%|█▎        | 489/3753 [37:27<4:04:08,  4.49s/it] 13%|█▎        | 490/3753 [37:33<4:18:11,  4.75s/it]{'loss': 23.4965, 'grad_norm': 930.5587158203125, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 0.5429278612136841, 'mean_ratio_rejected': 0.20315612852573395, 'weight_chosen': 1.2495663166046143, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': -0.305389404296875, 'epoch': 0.13057961359093936}
                                                    {'loss': 23.4965, 'grad_norm': 930.5587158203125, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 0.5429278612136841, 'mean_ratio_rejected': 0.20315612852573395, 'weight_chosen': 1.2495663166046143, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': -0.305389404296875, 'epoch': 0.13}
 13%|█▎        | 490/3753 [37:33<4:18:11,  4.75s/it] 13%|█▎        | 491/3753 [37:38<4:20:20,  4.79s/it] 13%|█▎        | 492/3753 [37:41<4:03:16,  4.48s/it] 13%|█▎        | 493/3753 [37:51<5:32:35,  6.12s/it] 13%|█▎        | 494/3753 [37:55<4:58:04,  5.49s/it] 13%|█▎        | 495/3753 [37:59<4:22:49,  4.84s/it] 13%|█▎        | 496/3753 [38:04<4:22:56,  4.84s/it] 13%|█▎        | 497/3753 [38:07<4:02:58,  4.48s/it] 13%|█▎        | 498/3753 [38:15<5:01:00,  5.55s/it] 13%|█▎        | 499/3753 [38:21<5:12:10,  5.76s/it] 13%|█▎        | 500/3753 [38:26<4:53:25,  5.41s/it]{'loss': 1.6684, 'grad_norm': 0.0, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.90122127532959, 'weight_rejected': 0.22270013391971588, 'kl_term_chosen': -6.2587890625, 'epoch': 0.13324450366422386}
                                                    {'loss': 1.6684, 'grad_norm': 0.0, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.90122127532959, 'weight_rejected': 0.22270013391971588, 'kl_term_chosen': -6.2587890625, 'epoch': 0.13}
 13%|█▎        | 500/3753 [38:26<4:53:25,  5.41s/it] 13%|█▎        | 501/3753 [38:30<4:34:08,  5.06s/it] 13%|█▎        | 502/3753 [38:38<5:24:08,  5.98s/it] 13%|█▎        | 503/3753 [38:43<4:56:03,  5.47s/it] 13%|█▎        | 504/3753 [38:47<4:34:56,  5.08s/it] 13%|█▎        | 505/3753 [38:50<4:10:59,  4.64s/it] 13%|█▎        | 506/3753 [38:54<3:56:17,  4.37s/it] 14%|█▎        | 507/3753 [38:59<4:06:05,  4.55s/it] 14%|█▎        | 508/3753 [39:04<4:16:08,  4.74s/it] 14%|█▎        | 509/3753 [39:08<4:03:29,  4.50s/it] 14%|█▎        | 510/3753 [39:13<4:09:22,  4.61s/it]{'loss': 0.8616, 'grad_norm': 3851.009033203125, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 10.039690971374512, 'weight_rejected': 0.03358950838446617, 'kl_term_chosen': -9.083709716796875, 'epoch': 0.13590939373750832}
                                                    {'loss': 0.8616, 'grad_norm': 3851.009033203125, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 10.039690971374512, 'weight_rejected': 0.03358950838446617, 'kl_term_chosen': -9.083709716796875, 'epoch': 0.14}
 14%|█▎        | 510/3753 [39:13<4:09:22,  4.61s/it] 14%|█▎        | 511/3753 [39:18<4:04:38,  4.53s/it] 14%|█▎        | 512/3753 [39:21<3:50:59,  4.28s/it] 14%|█▎        | 513/3753 [39:29<4:41:11,  5.21s/it] 14%|█▎        | 514/3753 [39:34<4:36:34,  5.12s/it] 14%|█▎        | 515/3753 [39:39<4:37:08,  5.14s/it] 14%|█▎        | 516/3753 [39:43<4:24:13,  4.90s/it] 14%|█▍        | 517/3753 [39:47<4:02:43,  4.50s/it] 14%|█▍        | 518/3753 [39:51<3:53:06,  4.32s/it] 14%|█▍        | 519/3753 [39:56<4:04:05,  4.53s/it] 14%|█▍        | 520/3753 [40:01<4:17:29,  4.78s/it]{'loss': 14.1332, 'grad_norm': 405.5523681640625, 'learning_rate': 9.955821687527552e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.750220537185669, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 4.673259735107422, 'epoch': 0.13857428381079281}
                                                    {'loss': 14.1332, 'grad_norm': 405.5523681640625, 'learning_rate': 9.955821687527552e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.750220537185669, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 4.673259735107422, 'epoch': 0.14}
 14%|█▍        | 520/3753 [40:01<4:17:29,  4.78s/it] 14%|█▍        | 521/3753 [40:05<4:10:27,  4.65s/it] 14%|█▍        | 522/3753 [40:10<4:06:57,  4.59s/it] 14%|█▍        | 523/3753 [40:15<4:26:32,  4.95s/it] 14%|█▍        | 524/3753 [40:20<4:19:52,  4.83s/it] 14%|█▍        | 525/3753 [40:24<4:05:30,  4.56s/it] 14%|█▍        | 526/3753 [40:28<3:51:03,  4.30s/it] 14%|█▍        | 527/3753 [40:31<3:40:14,  4.10s/it] 14%|█▍        | 528/3753 [40:36<3:48:11,  4.25s/it] 14%|█▍        | 529/3753 [40:39<3:34:02,  3.98s/it] 14%|█▍        | 530/3753 [40:43<3:36:47,  4.04s/it]{'loss': 20.1578, 'grad_norm': 0.0, 'learning_rate': 9.94943765952491e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.05645751953125, 'weight_rejected': 0.332852303981781, 'kl_term_chosen': -3.620555877685547, 'epoch': 0.14123917388407728}
                                                    {'loss': 20.1578, 'grad_norm': 0.0, 'learning_rate': 9.94943765952491e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.05645751953125, 'weight_rejected': 0.332852303981781, 'kl_term_chosen': -3.620555877685547, 'epoch': 0.14}
 14%|█▍        | 530/3753 [40:43<3:36:47,  4.04s/it] 14%|█▍        | 531/3753 [40:47<3:28:59,  3.89s/it] 14%|█▍        | 532/3753 [40:52<3:41:17,  4.12s/it] 14%|█▍        | 533/3753 [40:57<3:53:56,  4.36s/it] 14%|█▍        | 534/3753 [41:00<3:39:45,  4.10s/it] 14%|█▍        | 535/3753 [41:04<3:43:58,  4.18s/it] 14%|█▍        | 536/3753 [41:09<3:49:52,  4.29s/it] 14%|█▍        | 537/3753 [41:14<3:59:34,  4.47s/it] 14%|█▍        | 538/3753 [41:17<3:42:58,  4.16s/it] 14%|█▍        | 539/3753 [41:21<3:31:34,  3.95s/it] 14%|█▍        | 540/3753 [41:24<3:19:52,  3.73s/it]{'loss': 37.9813, 'grad_norm': 224.55401611328125, 'learning_rate': 9.942625289827702e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -11.162293434143066, 'weight_rejected': 0.1233656257390976, 'kl_term_chosen': 12.090702056884766, 'epoch': 0.14390406395736177}
                                                    {'loss': 37.9813, 'grad_norm': 224.55401611328125, 'learning_rate': 9.942625289827702e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -11.162293434143066, 'weight_rejected': 0.1233656257390976, 'kl_term_chosen': 12.090702056884766, 'epoch': 0.14}
 14%|█▍        | 540/3753 [41:24<3:19:52,  3.73s/it] 14%|█▍        | 541/3753 [41:28<3:17:18,  3.69s/it] 14%|█▍        | 542/3753 [41:32<3:23:20,  3.80s/it] 14%|█▍        | 543/3753 [41:35<3:17:03,  3.68s/it] 14%|█▍        | 544/3753 [41:39<3:29:29,  3.92s/it] 15%|█▍        | 545/3753 [41:43<3:28:16,  3.90s/it] 15%|█▍        | 546/3753 [41:47<3:20:30,  3.75s/it] 15%|█▍        | 547/3753 [41:51<3:36:53,  4.06s/it] 15%|█▍        | 548/3753 [41:59<4:31:38,  5.09s/it] 15%|█▍        | 549/3753 [42:03<4:12:34,  4.73s/it] 15%|█▍        | 550/3753 [42:08<4:17:46,  4.83s/it]{'loss': 52.1429, 'grad_norm': 936.1998291015625, 'learning_rate': 9.935385168002298e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -12.489984512329102, 'weight_rejected': 0.07585817575454712, 'kl_term_chosen': 13.42626953125, 'epoch': 0.14656895403064624}
                                                    {'loss': 52.1429, 'grad_norm': 936.1998291015625, 'learning_rate': 9.935385168002298e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -12.489984512329102, 'weight_rejected': 0.07585817575454712, 'kl_term_chosen': 13.42626953125, 'epoch': 0.15}
 15%|█▍        | 550/3753 [42:08<4:17:46,  4.83s/it] 15%|█▍        | 551/3753 [42:12<4:11:30,  4.71s/it] 15%|█▍        | 552/3753 [42:16<3:48:46,  4.29s/it] 15%|█▍        | 553/3753 [42:20<3:42:23,  4.17s/it] 15%|█▍        | 554/3753 [42:24<3:50:46,  4.33s/it] 15%|█▍        | 555/3753 [42:28<3:48:49,  4.29s/it] 15%|█▍        | 556/3753 [42:33<3:48:01,  4.28s/it] 15%|█▍        | 557/3753 [42:38<4:08:35,  4.67s/it] 15%|█▍        | 558/3753 [42:43<4:02:07,  4.55s/it] 15%|█▍        | 559/3753 [42:47<3:53:49,  4.39s/it] 15%|█▍        | 560/3753 [42:51<3:49:08,  4.31s/it]{'loss': 31.5934, 'grad_norm': 665.5762939453125, 'learning_rate': 9.927717920634233e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.717587471008301, 'weight_rejected': 0.18713268637657166, 'kl_term_chosen': 7.5959014892578125, 'epoch': 0.1492338441039307}
                                                    {'loss': 31.5934, 'grad_norm': 665.5762939453125, 'learning_rate': 9.927717920634233e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.717587471008301, 'weight_rejected': 0.18713268637657166, 'kl_term_chosen': 7.5959014892578125, 'epoch': 0.15}
 15%|█▍        | 560/3753 [42:51<3:49:08,  4.31s/it] 15%|█▍        | 561/3753 [42:54<3:41:01,  4.15s/it] 15%|█▍        | 562/3753 [43:00<3:59:10,  4.50s/it] 15%|█▌        | 563/3753 [43:04<3:53:18,  4.39s/it] 15%|█▌        | 564/3753 [43:08<3:46:58,  4.27s/it] 15%|█▌        | 565/3753 [43:13<3:57:32,  4.47s/it] 15%|█▌        | 566/3753 [43:17<3:57:33,  4.47s/it] 15%|█▌        | 567/3753 [43:22<4:04:36,  4.61s/it] 15%|█▌        | 568/3753 [43:30<4:53:23,  5.53s/it] 15%|█▌        | 569/3753 [43:34<4:31:27,  5.12s/it] 15%|█▌        | 570/3753 [43:37<4:03:56,  4.60s/it]{'loss': 30.8057, 'grad_norm': 512.21240234375, 'learning_rate': 9.919624211273986e-07, 'mean_ratio_chosen': 0.4346335828304291, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.387313723564148, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': -0.4166259765625, 'epoch': 0.1518987341772152}
                                                    {'loss': 30.8057, 'grad_norm': 512.21240234375, 'learning_rate': 9.919624211273986e-07, 'mean_ratio_chosen': 0.4346335828304291, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.387313723564148, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': -0.4166259765625, 'epoch': 0.15}
 15%|█▌        | 570/3753 [43:38<4:03:56,  4.60s/it] 15%|█▌        | 571/3753 [43:43<4:20:05,  4.90s/it] 15%|█▌        | 572/3753 [43:46<3:54:56,  4.43s/it] 15%|█▌        | 573/3753 [43:50<3:43:42,  4.22s/it] 15%|█▌        | 574/3753 [43:54<3:39:07,  4.14s/it] 15%|█▌        | 575/3753 [44:02<4:38:05,  5.25s/it] 15%|█▌        | 576/3753 [44:06<4:24:26,  4.99s/it] 15%|█▌        | 577/3753 [44:11<4:23:55,  4.99s/it] 15%|█▌        | 578/3753 [44:16<4:15:35,  4.83s/it] 15%|█▌        | 579/3753 [44:19<3:49:30,  4.34s/it] 15%|█▌        | 580/3753 [44:23<3:49:33,  4.34s/it]{'loss': 41.8278, 'grad_norm': 869.7496948242188, 'learning_rate': 9.911104740379551e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.5853986740112305, 'weight_rejected': 0.8499711751937866, 'kl_term_chosen': -5.4756927490234375, 'epoch': 0.15456362425049966}
                                                    {'loss': 41.8278, 'grad_norm': 869.7496948242188, 'learning_rate': 9.911104740379551e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.5853986740112305, 'weight_rejected': 0.8499711751937866, 'kl_term_chosen': -5.4756927490234375, 'epoch': 0.15}
 15%|█▌        | 580/3753 [44:23<3:49:33,  4.34s/it] 15%|█▌        | 581/3753 [44:27<3:41:14,  4.18s/it] 16%|█▌        | 582/3753 [44:32<3:50:52,  4.37s/it] 16%|█▌        | 583/3753 [44:36<3:42:27,  4.21s/it] 16%|█▌        | 584/3753 [44:39<3:28:10,  3.94s/it] 16%|█▌        | 585/3753 [44:43<3:29:44,  3.97s/it] 16%|█▌        | 586/3753 [44:47<3:24:58,  3.88s/it] 16%|█▌        | 587/3753 [44:51<3:37:31,  4.12s/it] 16%|█▌        | 588/3753 [44:56<3:46:57,  4.30s/it] 16%|█▌        | 589/3753 [45:02<4:06:35,  4.68s/it] 16%|█▌        | 590/3753 [45:05<3:47:42,  4.32s/it]{'loss': 45.1923, 'grad_norm': 429.95062255859375, 'learning_rate': 9.902160245255826e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.1060709953308105, 'weight_rejected': 0.12592275440692902, 'kl_term_chosen': 7.9801483154296875, 'epoch': 0.15722851432378415}
                                                    {'loss': 45.1923, 'grad_norm': 429.95062255859375, 'learning_rate': 9.902160245255826e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.1060709953308105, 'weight_rejected': 0.12592275440692902, 'kl_term_chosen': 7.9801483154296875, 'epoch': 0.16}
 16%|█▌        | 590/3753 [45:05<3:47:42,  4.32s/it] 16%|█▌        | 591/3753 [45:09<3:46:32,  4.30s/it] 16%|█▌        | 592/3753 [45:13<3:38:02,  4.14s/it] 16%|█▌        | 593/3753 [45:19<4:01:11,  4.58s/it] 16%|█▌        | 594/3753 [45:23<3:53:43,  4.44s/it] 16%|█▌        | 595/3753 [45:26<3:37:45,  4.14s/it] 16%|█▌        | 596/3753 [45:30<3:35:11,  4.09s/it] 16%|█▌        | 597/3753 [45:34<3:29:29,  3.98s/it] 16%|█▌        | 598/3753 [45:38<3:34:27,  4.08s/it] 16%|█▌        | 599/3753 [45:43<3:48:06,  4.34s/it] 16%|█▌        | 600/3753 [45:48<3:59:00,  4.55s/it]{'loss': 46.0768, 'grad_norm': 50.3231201171875, 'learning_rate': 9.892791499990784e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -4.131438255310059, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 5.0929718017578125, 'epoch': 0.15989340439706862}
                                                    {'loss': 46.0768, 'grad_norm': 50.3231201171875, 'learning_rate': 9.892791499990784e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -4.131438255310059, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 5.0929718017578125, 'epoch': 0.16}
 16%|█▌        | 600/3753 [45:48<3:59:00,  4.55s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 16%|█▌        | 601/3753 [46:52<19:33:06, 22.33s/it] 16%|█▌        | 602/3753 [46:57<14:50:49, 16.96s/it] 16%|█▌        | 603/3753 [47:02<11:43:44, 13.40s/it] 16%|█▌        | 604/3753 [47:06<9:15:53, 10.59s/it]  16%|█▌        | 605/3753 [47:10<7:30:00,  8.58s/it] 16%|█▌        | 606/3753 [47:14<6:26:18,  7.37s/it] 16%|█▌        | 607/3753 [47:18<5:23:34,  6.17s/it] 16%|█▌        | 608/3753 [47:22<4:51:28,  5.56s/it] 16%|█▌        | 609/3753 [47:26<4:39:04,  5.33s/it] 16%|█▋        | 610/3753 [47:30<4:06:35,  4.71s/it]{'loss': 28.9852, 'grad_norm': 1108.9146728515625, 'learning_rate': 9.882999315388504e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.461414337158203, 'weight_rejected': 0.14033624529838562, 'kl_term_chosen': -4.6237945556640625, 'epoch': 0.1625582944703531}
                                                    {'loss': 28.9852, 'grad_norm': 1108.9146728515625, 'learning_rate': 9.882999315388504e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.461414337158203, 'weight_rejected': 0.14033624529838562, 'kl_term_chosen': -4.6237945556640625, 'epoch': 0.16}
 16%|█▋        | 610/3753 [47:30<4:06:35,  4.71s/it] 16%|█▋        | 611/3753 [47:33<3:38:35,  4.17s/it]W1208 12:09:35.645000 4415 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
W1208 12:09:35.648000 4415 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 4498 closing signal SIGTERM
W1208 12:09:35.651000 4415 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 4499 closing signal SIGTERM
W1208 12:09:35.652000 4415 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 4500 closing signal SIGTERM
W1208 12:09:35.652000 4415 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 4501 closing signal SIGTERM
Traceback (most recent call last):
  File "/root/miniconda3/envs/advan/bin/accelerate", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/launch.py", line 1222, in launch_command
    multi_gpu_launcher(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/launch.py", line 853, in multi_gpu_launcher
    distrib_run.run(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py", line 138, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 715, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 879, in _invoke_run
    time.sleep(monitor_interval)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 4415 got signal: 15
