nohup: ignoring input
[W1123 12:10:24.312243252 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 42
⚙️  Running in WANDB offline mode
设置随机种子为: 42
⚙️  Running in WANDB offline mode
设置随机种子为: 42
设置随机种子为: 42
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.75it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.52it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.84it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 99.48it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.24it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.72it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.17it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.23it/s]
[W1123 12:10:30.801127426 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1123 12:10:30.809181537 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1123 12:10:30.810068261 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1123 12:10:30.815111061 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2_truncation.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
初始化 CustomSymPOTrainer...初始化 CustomSymPOTrainer...

/rlhf_code/code/implement_final_v3_no_kl_term2_truncation.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
/rlhf_code/code/implement_final_v3_no_kl_term2_truncation.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2_truncation.py:56: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /root/wandb/offline-run-20251123_121037-cw577sa1
  0%|          | 0/3753 [00:00<?, ?it/s]--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -50.5
Sample 0 - pi_logp_chosen:  -50.24790573120117
Sample 0 - Difference (pi - ref): 0.2520942687988281
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -108.0
Sample 0 - pi_logp_chosen:  -107.10874938964844
Sample 0 - Difference (pi - ref): 0.8912506103515625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -126.5
Sample 0 - pi_logp_chosen:  -125.88667297363281
Sample 0 - Difference (pi - ref): 0.6133270263671875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -242.0
Sample 0 - pi_logp_chosen:  -242.8450927734375
Sample 0 - Difference (pi - ref): -0.8450927734375
---------------------------------
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -76.0
Sample 0 - pi_logp_chosen:  -75.99889373779297
Sample 0 - Difference (pi - ref): 0.00110626220703125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---Sample 0 - ref_logp_chosen: -258.0
Sample 0 - pi_logp_chosen:  -257.1895446777344
Sample 0 - Difference (pi - ref): 0.810455322265625
---------------------------------

Sample 0 - ref_logp_chosen: -217.0
Sample 0 - pi_logp_chosen:  -217.67721557617188
Sample 0 - Difference (pi - ref): -0.677215576171875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -394.0
Sample 0 - pi_logp_chosen:  -394.5501708984375
Sample 0 - Difference (pi - ref): -0.5501708984375
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -78.0
Sample 0 - pi_logp_chosen:  -77.8389892578125
Sample 0 - Difference (pi - ref): 0.1610107421875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -174.0
Sample 0 - pi_logp_chosen:  -174.40147399902344
Sample 0 - Difference (pi - ref): -0.4014739990234375
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -362.0
Sample 0 - pi_logp_chosen:  -359.7122802734375
Sample 0 - Difference (pi - ref): 2.2877197265625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -468.0
Sample 0 - pi_logp_chosen:  -465.5644836425781
Sample 0 - Difference (pi - ref): 2.435516357421875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -88.0
Sample 0 - pi_logp_chosen:  -88.28606414794922
Sample 0 - Difference (pi - ref): -0.28606414794921875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -106.0
Sample 0 - pi_logp_chosen:  -105.8554916381836
Sample 0 - Difference (pi - ref): 0.14450836181640625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -255.0
Sample 0 - pi_logp_chosen:  -255.6888885498047
Sample 0 - Difference (pi - ref): -0.6888885498046875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -260.0
Sample 0 - pi_logp_chosen:  -259.95977783203125
Sample 0 - Difference (pi - ref): 0.04022216796875
---------------------------------
  0%|          | 1/3753 [00:04<4:54:41,  4.71s/it]{'loss': 0.1199, 'grad_norm': 1761.8013916015625, 'learning_rate': 0.0, 'mean_ratio_chosen': 0.502133846282959, 'mean_ratio_rejected': 0.48519444465637207, 'weight_chosen': 1.2663661241531372, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': -0.34444427490234375, 'epoch': 0.0002664890073284477}
                                                  {'loss': 0.1199, 'grad_norm': 1761.8013916015625, 'learning_rate': 0.0, 'mean_ratio_chosen': 0.502133846282959, 'mean_ratio_rejected': 0.48519444465637207, 'weight_chosen': 1.2663661241531372, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': -0.34444427490234375, 'epoch': 0.0}
  0%|          | 1/3753 [00:04<4:54:41,  4.71s/it]  0%|          | 2/3753 [00:10<5:21:58,  5.15s/it]  0%|          | 3/3753 [00:14<5:07:25,  4.92s/it]  0%|          | 4/3753 [00:18<4:42:59,  4.53s/it]  0%|          | 5/3753 [00:22<4:30:26,  4.33s/it]  0%|          | 6/3753 [00:28<4:54:05,  4.71s/it]  0%|          | 7/3753 [00:32<4:42:45,  4.53s/it]  0%|          | 8/3753 [00:36<4:40:00,  4.49s/it]  0%|          | 9/3753 [00:40<4:22:49,  4.21s/it]  0%|          | 10/3753 [00:43<4:11:10,  4.03s/it]{'loss': -0.4043, 'grad_norm': 1581.0849609375, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 2.80405592918396, 'mean_ratio_rejected': 1.1111465692520142, 'weight_chosen': -0.2704484462738037, 'weight_rejected': 0.4163219630718231, 'kl_term_chosen': 0.515533447265625, 'epoch': 0.002664890073284477}
                                                   {'loss': -0.4043, 'grad_norm': 1581.0849609375, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 2.80405592918396, 'mean_ratio_rejected': 1.1111465692520142, 'weight_chosen': -0.2704484462738037, 'weight_rejected': 0.4163219630718231, 'kl_term_chosen': 0.515533447265625, 'epoch': 0.0}
  0%|          | 10/3753 [00:44<4:11:10,  4.03s/it]  0%|          | 11/3753 [00:48<4:21:11,  4.19s/it]  0%|          | 12/3753 [00:53<4:36:18,  4.43s/it]  0%|          | 13/3753 [00:57<4:33:58,  4.40s/it]  0%|          | 14/3753 [01:01<4:27:21,  4.29s/it]  0%|          | 15/3753 [01:05<4:16:46,  4.12s/it]  0%|          | 16/3753 [01:09<4:11:12,  4.03s/it]  0%|          | 17/3753 [01:13<4:07:13,  3.97s/it]  0%|          | 18/3753 [01:18<4:23:13,  4.23s/it]  1%|          | 19/3753 [01:21<4:06:35,  3.96s/it]  1%|          | 20/3753 [01:25<4:04:48,  3.93s/it]{'loss': -0.4202, 'grad_norm': 1975.9517822265625, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 1.5949625968933105, 'mean_ratio_rejected': 1.0396807193756104, 'weight_chosen': 0.49916666746139526, 'weight_rejected': 0.29665425419807434, 'kl_term_chosen': 0.23342514038085938, 'epoch': 0.005329780146568954}
                                                   {'loss': -0.4202, 'grad_norm': 1975.9517822265625, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 1.5949625968933105, 'mean_ratio_rejected': 1.0396807193756104, 'weight_chosen': 0.49916666746139526, 'weight_rejected': 0.29665425419807434, 'kl_term_chosen': 0.23342514038085938, 'epoch': 0.01}
  1%|          | 20/3753 [01:25<4:04:48,  3.93s/it]  1%|          | 21/3753 [01:29<4:05:27,  3.95s/it]  1%|          | 22/3753 [01:35<4:55:48,  4.76s/it]  1%|          | 23/3753 [01:40<5:02:08,  4.86s/it]  1%|          | 24/3753 [01:44<4:32:29,  4.38s/it]  1%|          | 25/3753 [01:48<4:29:15,  4.33s/it]  1%|          | 26/3753 [01:51<4:04:47,  3.94s/it]  1%|          | 27/3753 [01:55<4:05:43,  3.96s/it]  1%|          | 28/3753 [01:59<4:06:22,  3.97s/it]  1%|          | 29/3753 [02:03<4:03:34,  3.92s/it]  1%|          | 30/3753 [02:07<4:07:46,  3.99s/it]{'loss': -0.2098, 'grad_norm': 2116.14599609375, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 3.293917655944824, 'mean_ratio_rejected': 1.2087082862854004, 'weight_chosen': 0.031912386417388916, 'weight_rejected': 0.5987815260887146, 'kl_term_chosen': 0.596038818359375, 'epoch': 0.007994670219853431}
                                                   {'loss': -0.2098, 'grad_norm': 2116.14599609375, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 3.293917655944824, 'mean_ratio_rejected': 1.2087082862854004, 'weight_chosen': 0.031912386417388916, 'weight_rejected': 0.5987815260887146, 'kl_term_chosen': 0.596038818359375, 'epoch': 0.01}
  1%|          | 30/3753 [02:07<4:07:46,  3.99s/it]  1%|          | 31/3753 [02:12<4:31:24,  4.38s/it]  1%|          | 32/3753 [02:16<4:14:42,  4.11s/it]  1%|          | 33/3753 [02:19<4:05:07,  3.95s/it]  1%|          | 34/3753 [02:24<4:09:28,  4.02s/it]  1%|          | 35/3753 [02:28<4:14:28,  4.11s/it]  1%|          | 36/3753 [02:33<4:26:38,  4.30s/it]  1%|          | 37/3753 [02:38<4:52:19,  4.72s/it]  1%|          | 38/3753 [02:43<4:44:50,  4.60s/it]  1%|          | 39/3753 [02:47<4:47:35,  4.65s/it]  1%|          | 40/3753 [02:51<4:37:23,  4.48s/it]{'loss': 0.2114, 'grad_norm': 1652.51025390625, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 2.0674548149108887, 'mean_ratio_rejected': 1.7529001235961914, 'weight_chosen': 0.3946352005004883, 'weight_rejected': 0.1276526302099228, 'kl_term_chosen': 0.3631591796875, 'epoch': 0.010659560293137908}
                                                   {'loss': 0.2114, 'grad_norm': 1652.51025390625, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 2.0674548149108887, 'mean_ratio_rejected': 1.7529001235961914, 'weight_chosen': 0.3946352005004883, 'weight_rejected': 0.1276526302099228, 'kl_term_chosen': 0.3631591796875, 'epoch': 0.01}
  1%|          | 40/3753 [02:52<4:37:23,  4.48s/it]  1%|          | 41/3753 [02:56<4:34:43,  4.44s/it]  1%|          | 42/3753 [02:59<4:07:19,  4.00s/it]  1%|          | 43/3753 [03:03<4:16:55,  4.16s/it]  1%|          | 44/3753 [03:07<4:11:27,  4.07s/it]  1%|          | 45/3753 [03:12<4:32:24,  4.41s/it]  1%|          | 46/3753 [03:17<4:43:01,  4.58s/it]  1%|▏         | 47/3753 [03:20<4:12:25,  4.09s/it]  1%|▏         | 48/3753 [03:24<4:11:21,  4.07s/it]  1%|▏         | 49/3753 [03:28<4:13:07,  4.10s/it]  1%|▏         | 50/3753 [03:32<4:04:36,  3.96s/it]{'loss': 0.9291, 'grad_norm': 2532.953125, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 1.7111972570419312, 'mean_ratio_rejected': 3.7809925079345703, 'weight_chosen': 0.5947949886322021, 'weight_rejected': 0.6851073503494263, 'kl_term_chosen': 0.2685966491699219, 'epoch': 0.013324450366422385}
                                                   {'loss': 0.9291, 'grad_norm': 2532.953125, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 1.7111972570419312, 'mean_ratio_rejected': 3.7809925079345703, 'weight_chosen': 0.5947949886322021, 'weight_rejected': 0.6851073503494263, 'kl_term_chosen': 0.2685966491699219, 'epoch': 0.01}
  1%|▏         | 50/3753 [03:32<4:04:36,  3.96s/it]  1%|▏         | 51/3753 [03:37<4:13:58,  4.12s/it]  1%|▏         | 52/3753 [03:41<4:24:09,  4.28s/it]  1%|▏         | 53/3753 [03:47<4:52:47,  4.75s/it]  1%|▏         | 54/3753 [03:51<4:28:56,  4.36s/it]  1%|▏         | 55/3753 [03:56<4:50:10,  4.71s/it]  1%|▏         | 56/3753 [04:01<4:48:30,  4.68s/it]  2%|▏         | 57/3753 [04:05<4:49:20,  4.70s/it]  2%|▏         | 58/3753 [04:09<4:26:21,  4.33s/it]  2%|▏         | 59/3753 [04:12<4:09:07,  4.05s/it]  2%|▏         | 60/3753 [04:15<3:51:57,  3.77s/it]{'loss': 0.216, 'grad_norm': 1332.7152099609375, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 1.6338077783584595, 'mean_ratio_rejected': 0.561837911605835, 'weight_chosen': -0.21524208784103394, 'weight_rejected': 0.937210738658905, 'kl_term_chosen': 0.24545669555664062, 'epoch': 0.015989340439706862}
                                                   {'loss': 0.216, 'grad_norm': 1332.7152099609375, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 1.6338077783584595, 'mean_ratio_rejected': 0.561837911605835, 'weight_chosen': -0.21524208784103394, 'weight_rejected': 0.937210738658905, 'kl_term_chosen': 0.24545669555664062, 'epoch': 0.02}
  2%|▏         | 60/3753 [04:15<3:51:57,  3.77s/it]  2%|▏         | 61/3753 [04:20<4:15:50,  4.16s/it]  2%|▏         | 62/3753 [04:25<4:24:50,  4.31s/it]  2%|▏         | 63/3753 [04:29<4:23:11,  4.28s/it]  2%|▏         | 64/3753 [04:34<4:26:18,  4.33s/it]  2%|▏         | 65/3753 [04:38<4:18:22,  4.20s/it]  2%|▏         | 66/3753 [04:42<4:26:37,  4.34s/it]  2%|▏         | 67/3753 [04:47<4:35:32,  4.49s/it]  2%|▏         | 68/3753 [04:51<4:20:55,  4.25s/it]  2%|▏         | 69/3753 [04:55<4:26:48,  4.35s/it]  2%|▏         | 70/3753 [04:59<4:14:48,  4.15s/it]{'loss': 0.4878, 'grad_norm': 2442.020263671875, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 3.9367728233337402, 'weight_chosen': -0.31313663721084595, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 1.2763671875, 'epoch': 0.018654230512991338}
                                                   {'loss': 0.4878, 'grad_norm': 2442.020263671875, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 3.9367728233337402, 'weight_chosen': -0.31313663721084595, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 1.2763671875, 'epoch': 0.02}
  2%|▏         | 70/3753 [04:59<4:14:48,  4.15s/it]  2%|▏         | 71/3753 [05:04<4:23:14,  4.29s/it]  2%|▏         | 72/3753 [05:08<4:30:17,  4.41s/it]  2%|▏         | 73/3753 [05:12<4:18:28,  4.21s/it]  2%|▏         | 74/3753 [05:16<4:09:32,  4.07s/it]  2%|▏         | 75/3753 [05:20<4:01:33,  3.94s/it]  2%|▏         | 76/3753 [05:24<4:15:16,  4.17s/it]  2%|▏         | 77/3753 [05:27<3:56:56,  3.87s/it]  2%|▏         | 78/3753 [05:32<4:15:46,  4.18s/it]  2%|▏         | 79/3753 [05:37<4:20:16,  4.25s/it]  2%|▏         | 80/3753 [05:42<4:33:38,  4.47s/it]{'loss': 0.4592, 'grad_norm': 2205.42578125, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 5.0902886390686035, 'mean_ratio_rejected': 6.897243976593018, 'weight_chosen': 0.1147415041923523, 'weight_rejected': 0.10230471193790436, 'kl_term_chosen': 0.8136672973632812, 'epoch': 0.021319120586275817}
                                                   {'loss': 0.4592, 'grad_norm': 2205.42578125, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 5.0902886390686035, 'mean_ratio_rejected': 6.897243976593018, 'weight_chosen': 0.1147415041923523, 'weight_rejected': 0.10230471193790436, 'kl_term_chosen': 0.8136672973632812, 'epoch': 0.02}
  2%|▏         | 80/3753 [05:42<4:33:38,  4.47s/it]  2%|▏         | 81/3753 [05:46<4:38:56,  4.56s/it]  2%|▏         | 82/3753 [05:50<4:25:09,  4.33s/it]  2%|▏         | 83/3753 [05:55<4:37:28,  4.54s/it]  2%|▏         | 84/3753 [06:00<4:45:19,  4.67s/it]  2%|▏         | 85/3753 [06:04<4:22:53,  4.30s/it]  2%|▏         | 86/3753 [06:07<4:05:42,  4.02s/it]  2%|▏         | 87/3753 [06:12<4:24:14,  4.32s/it]  2%|▏         | 88/3753 [06:16<4:15:17,  4.18s/it]  2%|▏         | 89/3753 [06:20<4:14:32,  4.17s/it]  2%|▏         | 90/3753 [06:24<4:15:52,  4.19s/it]{'loss': 0.8181, 'grad_norm': 2977.9716796875, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 9.856054306030273, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.3548092842102051, 'weight_rejected': 0.15002880990505219, 'kl_term_chosen': 1.14404296875, 'epoch': 0.023984010659560292}
                                                   {'loss': 0.8181, 'grad_norm': 2977.9716796875, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 9.856054306030273, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.3548092842102051, 'weight_rejected': 0.15002880990505219, 'kl_term_chosen': 1.14404296875, 'epoch': 0.02}
  2%|▏         | 90/3753 [06:24<4:15:52,  4.19s/it]  2%|▏         | 91/3753 [06:28<3:59:49,  3.93s/it]  2%|▏         | 92/3753 [06:32<4:00:21,  3.94s/it]  2%|▏         | 93/3753 [06:36<4:08:11,  4.07s/it]  3%|▎         | 94/3753 [06:40<4:02:11,  3.97s/it]  3%|▎         | 95/3753 [06:46<4:51:20,  4.78s/it]  3%|▎         | 96/3753 [06:51<4:39:53,  4.59s/it]  3%|▎         | 97/3753 [06:55<4:33:27,  4.49s/it]  3%|▎         | 98/3753 [07:01<4:57:43,  4.89s/it]  3%|▎         | 99/3753 [07:04<4:31:14,  4.45s/it]  3%|▎         | 100/3753 [07:08<4:17:46,  4.23s/it]{'loss': 0.9126, 'grad_norm': 3587.0625, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 2.2454514503479004, 'mean_ratio_rejected': 1.6667563915252686, 'weight_chosen': 0.2234979271888733, 'weight_rejected': 0.14414885640144348, 'kl_term_chosen': 0.4044532775878906, 'epoch': 0.02664890073284477}
                                                    {'loss': 0.9126, 'grad_norm': 3587.0625, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 2.2454514503479004, 'mean_ratio_rejected': 1.6667563915252686, 'weight_chosen': 0.2234979271888733, 'weight_rejected': 0.14414885640144348, 'kl_term_chosen': 0.4044532775878906, 'epoch': 0.03}
  3%|▎         | 100/3753 [07:08<4:17:46,  4.23s/it]  3%|▎         | 101/3753 [07:12<4:22:16,  4.31s/it]  3%|▎         | 102/3753 [07:16<4:19:09,  4.26s/it]  3%|▎         | 103/3753 [07:20<4:09:09,  4.10s/it]  3%|▎         | 104/3753 [07:26<4:37:05,  4.56s/it]  3%|▎         | 105/3753 [07:30<4:27:16,  4.40s/it]  3%|▎         | 106/3753 [07:35<4:44:52,  4.69s/it]  3%|▎         | 107/3753 [07:40<4:46:24,  4.71s/it]  3%|▎         | 108/3753 [07:44<4:33:37,  4.50s/it]  3%|▎         | 109/3753 [07:48<4:23:07,  4.33s/it]  3%|▎         | 110/3753 [07:52<4:15:34,  4.21s/it]{'loss': 0.2034, 'grad_norm': 1590.2109375, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 6.969287872314453, 'mean_ratio_rejected': 6.419528007507324, 'weight_chosen': -0.05708003044128418, 'weight_rejected': 0.04146226868033409, 'kl_term_chosen': 0.9707565307617188, 'epoch': 0.029313790806129246}
                                                    {'loss': 0.2034, 'grad_norm': 1590.2109375, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 6.969287872314453, 'mean_ratio_rejected': 6.419528007507324, 'weight_chosen': -0.05708003044128418, 'weight_rejected': 0.04146226868033409, 'kl_term_chosen': 0.9707565307617188, 'epoch': 0.03}
  3%|▎         | 110/3753 [07:52<4:15:34,  4.21s/it]  3%|▎         | 111/3753 [07:57<4:34:10,  4.52s/it]  3%|▎         | 112/3753 [08:01<4:24:15,  4.35s/it]  3%|▎         | 113/3753 [08:04<4:05:14,  4.04s/it]  3%|▎         | 114/3753 [08:08<3:56:20,  3.90s/it]  3%|▎         | 115/3753 [08:12<3:54:40,  3.87s/it]  3%|▎         | 116/3753 [08:16<4:03:58,  4.02s/it]  3%|▎         | 117/3753 [08:20<4:06:58,  4.08s/it]  3%|▎         | 118/3753 [08:25<4:14:33,  4.20s/it]  3%|▎         | 119/3753 [08:28<4:04:56,  4.04s/it]  3%|▎         | 120/3753 [08:33<4:13:12,  4.18s/it]{'loss': 1.2796, 'grad_norm': 2010.7613525390625, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 2.4514856338500977, 'mean_ratio_rejected': 0.4487041234970093, 'weight_chosen': 0.38820743560791016, 'weight_rejected': 0.49502578377723694, 'kl_term_chosen': 0.4483470916748047, 'epoch': 0.031978680879413725}
                                                    {'loss': 1.2796, 'grad_norm': 2010.7613525390625, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 2.4514856338500977, 'mean_ratio_rejected': 0.4487041234970093, 'weight_chosen': 0.38820743560791016, 'weight_rejected': 0.49502578377723694, 'kl_term_chosen': 0.4483470916748047, 'epoch': 0.03}
  3%|▎         | 120/3753 [08:33<4:13:12,  4.18s/it]  3%|▎         | 121/3753 [08:37<4:15:12,  4.22s/it]  3%|▎         | 122/3753 [08:42<4:20:05,  4.30s/it]  3%|▎         | 123/3753 [08:46<4:24:29,  4.37s/it]  3%|▎         | 124/3753 [08:50<4:16:47,  4.25s/it]  3%|▎         | 125/3753 [08:55<4:21:29,  4.32s/it]  3%|▎         | 126/3753 [09:00<4:31:50,  4.50s/it]  3%|▎         | 127/3753 [09:03<4:15:55,  4.23s/it]  3%|▎         | 128/3753 [09:08<4:18:42,  4.28s/it]  3%|▎         | 129/3753 [09:13<4:47:26,  4.76s/it]  3%|▎         | 130/3753 [09:18<4:43:40,  4.70s/it]{'loss': 0.6092, 'grad_norm': 1411.26513671875, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.4146796464920044, 'weight_chosen': -1.218078851699829, 'weight_rejected': 0.10970578342676163, 'kl_term_chosen': 1.5155487060546875, 'epoch': 0.034643570952698204}
                                                    {'loss': 0.6092, 'grad_norm': 1411.26513671875, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.4146796464920044, 'weight_chosen': -1.218078851699829, 'weight_rejected': 0.10970578342676163, 'kl_term_chosen': 1.5155487060546875, 'epoch': 0.03}
  3%|▎         | 130/3753 [09:18<4:43:40,  4.70s/it]  3%|▎         | 131/3753 [09:22<4:29:25,  4.46s/it]  4%|▎         | 132/3753 [09:25<4:08:18,  4.11s/it]  4%|▎         | 133/3753 [09:30<4:13:33,  4.20s/it]  4%|▎         | 134/3753 [09:34<4:20:08,  4.31s/it]  4%|▎         | 135/3753 [09:38<4:11:17,  4.17s/it]  4%|▎         | 136/3753 [09:42<3:59:46,  3.98s/it]  4%|▎         | 137/3753 [09:45<3:55:01,  3.90s/it]  4%|▎         | 138/3753 [09:50<4:05:51,  4.08s/it]  4%|▎         | 139/3753 [09:54<3:59:17,  3.97s/it]  4%|▎         | 140/3753 [09:58<4:15:16,  4.24s/it]{'loss': 0.8247, 'grad_norm': 1249.4794921875, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 0.5269629955291748, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.179976224899292, 'weight_rejected': 0.14706450700759888, 'kl_term_chosen': -0.3203125, 'epoch': 0.037308461025982675}
                                                    {'loss': 0.8247, 'grad_norm': 1249.4794921875, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 0.5269629955291748, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.179976224899292, 'weight_rejected': 0.14706450700759888, 'kl_term_chosen': -0.3203125, 'epoch': 0.04}
  4%|▎         | 140/3753 [09:59<4:15:16,  4.24s/it]  4%|▍         | 141/3753 [10:02<4:10:22,  4.16s/it]  4%|▍         | 142/3753 [10:07<4:26:25,  4.43s/it]  4%|▍         | 143/3753 [10:12<4:20:23,  4.33s/it]  4%|▍         | 144/3753 [10:17<4:46:50,  4.77s/it]  4%|▍         | 145/3753 [10:22<4:39:47,  4.65s/it]  4%|▍         | 146/3753 [10:27<4:45:54,  4.76s/it]  4%|▍         | 147/3753 [10:30<4:11:19,  4.18s/it]  4%|▍         | 148/3753 [10:34<4:24:01,  4.39s/it]  4%|▍         | 149/3753 [10:38<4:13:06,  4.21s/it]  4%|▍         | 150/3753 [10:42<4:13:52,  4.23s/it]{'loss': 1.1969, 'grad_norm': 2129.946533203125, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 1.1599141359329224, 'mean_ratio_rejected': 0.40370991826057434, 'weight_chosen': 0.26128673553466797, 'weight_rejected': 0.5903069972991943, 'kl_term_chosen': 0.0741729736328125, 'epoch': 0.039973351099267154}
                                                    {'loss': 1.1969, 'grad_norm': 2129.946533203125, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 1.1599141359329224, 'mean_ratio_rejected': 0.40370991826057434, 'weight_chosen': 0.26128673553466797, 'weight_rejected': 0.5903069972991943, 'kl_term_chosen': 0.0741729736328125, 'epoch': 0.04}
  4%|▍         | 150/3753 [10:43<4:13:52,  4.23s/it]  4%|▍         | 151/3753 [10:48<4:29:06,  4.48s/it]  4%|▍         | 152/3753 [10:52<4:20:48,  4.35s/it]  4%|▍         | 153/3753 [10:56<4:26:06,  4.44s/it]  4%|▍         | 154/3753 [11:01<4:24:45,  4.41s/it]  4%|▍         | 155/3753 [11:05<4:18:19,  4.31s/it]  4%|▍         | 156/3753 [11:09<4:16:46,  4.28s/it]  4%|▍         | 157/3753 [11:13<4:10:50,  4.19s/it]  4%|▍         | 158/3753 [11:17<4:17:40,  4.30s/it]  4%|▍         | 159/3753 [11:21<4:12:40,  4.22s/it]  4%|▍         | 160/3753 [11:26<4:15:19,  4.26s/it]{'loss': 1.2903, 'grad_norm': 1586.383544921875, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 3.6658380031585693, 'mean_ratio_rejected': 0.9984905123710632, 'weight_chosen': 0.03050076961517334, 'weight_rejected': 0.3372035324573517, 'kl_term_chosen': 0.6495285034179688, 'epoch': 0.04263824117255163}
                                                    {'loss': 1.2903, 'grad_norm': 1586.383544921875, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 3.6658380031585693, 'mean_ratio_rejected': 0.9984905123710632, 'weight_chosen': 0.03050076961517334, 'weight_rejected': 0.3372035324573517, 'kl_term_chosen': 0.6495285034179688, 'epoch': 0.04}
  4%|▍         | 160/3753 [11:26<4:15:19,  4.26s/it]  4%|▍         | 161/3753 [11:30<4:06:45,  4.12s/it]  4%|▍         | 162/3753 [11:34<4:07:21,  4.13s/it]  4%|▍         | 163/3753 [11:37<3:54:57,  3.93s/it]  4%|▍         | 164/3753 [11:43<4:23:01,  4.40s/it]  4%|▍         | 165/3753 [11:47<4:25:03,  4.43s/it]  4%|▍         | 166/3753 [11:51<4:06:20,  4.12s/it]  4%|▍         | 167/3753 [11:55<4:19:27,  4.34s/it]  4%|▍         | 168/3753 [12:01<4:35:03,  4.60s/it]  5%|▍         | 169/3753 [12:04<4:16:32,  4.29s/it]  5%|▍         | 170/3753 [12:08<3:58:32,  3.99s/it]{'loss': 0.795, 'grad_norm': 2145.290283203125, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 9.95368766784668, 'mean_ratio_rejected': 1.6533315181732178, 'weight_chosen': -0.2766242027282715, 'weight_rejected': 0.13568955659866333, 'kl_term_chosen': 1.1489715576171875, 'epoch': 0.04530313124583611}
                                                    {'loss': 0.795, 'grad_norm': 2145.290283203125, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 9.95368766784668, 'mean_ratio_rejected': 1.6533315181732178, 'weight_chosen': -0.2766242027282715, 'weight_rejected': 0.13568955659866333, 'kl_term_chosen': 1.1489715576171875, 'epoch': 0.05}
  5%|▍         | 170/3753 [12:08<3:58:32,  3.99s/it]  5%|▍         | 171/3753 [12:12<4:08:10,  4.16s/it]  5%|▍         | 172/3753 [12:17<4:13:15,  4.24s/it]  5%|▍         | 173/3753 [12:21<4:09:21,  4.18s/it]  5%|▍         | 174/3753 [12:25<4:12:03,  4.23s/it]  5%|▍         | 175/3753 [12:29<4:15:31,  4.28s/it]  5%|▍         | 176/3753 [12:33<4:01:36,  4.05s/it]  5%|▍         | 177/3753 [12:37<4:07:43,  4.16s/it]  5%|▍         | 178/3753 [12:42<4:20:39,  4.37s/it]  5%|▍         | 179/3753 [12:46<4:04:36,  4.11s/it]  5%|▍         | 180/3753 [12:50<4:05:29,  4.12s/it]{'loss': 1.0509, 'grad_norm': 3663.817138671875, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 3.3305084705352783, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.33378398418426514, 'weight_rejected': 0.09268777817487717, 'kl_term_chosen': 0.6015625, 'epoch': 0.047968021319120584}
                                                    {'loss': 1.0509, 'grad_norm': 3663.817138671875, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 3.3305084705352783, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.33378398418426514, 'weight_rejected': 0.09268777817487717, 'kl_term_chosen': 0.6015625, 'epoch': 0.05}
  5%|▍         | 180/3753 [12:50<4:05:29,  4.12s/it]  5%|▍         | 181/3753 [12:54<4:12:42,  4.24s/it]  5%|▍         | 182/3753 [13:00<4:47:07,  4.82s/it]  5%|▍         | 183/3753 [13:05<4:43:12,  4.76s/it]  5%|▍         | 184/3753 [13:10<4:52:09,  4.91s/it]  5%|▍         | 185/3753 [13:15<4:48:59,  4.86s/it]  5%|▍         | 186/3753 [13:19<4:34:28,  4.62s/it]  5%|▍         | 187/3753 [13:23<4:21:57,  4.41s/it]  5%|▌         | 188/3753 [13:27<4:13:09,  4.26s/it]  5%|▌         | 189/3753 [13:33<4:47:46,  4.84s/it]  5%|▌         | 190/3753 [13:37<4:37:49,  4.68s/it]{'loss': 0.5587, 'grad_norm': 1027.8953857421875, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 4.746625900268555, 'mean_ratio_rejected': 0.28701236844062805, 'weight_chosen': 0.10208004713058472, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 0.778717041015625, 'epoch': 0.05063291139240506}
                                                    {'loss': 0.5587, 'grad_norm': 1027.8953857421875, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 4.746625900268555, 'mean_ratio_rejected': 0.28701236844062805, 'weight_chosen': 0.10208004713058472, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 0.778717041015625, 'epoch': 0.05}
  5%|▌         | 190/3753 [13:38<4:37:49,  4.68s/it]  5%|▌         | 191/3753 [13:41<4:21:45,  4.41s/it]  5%|▌         | 192/3753 [13:45<4:04:36,  4.12s/it]  5%|▌         | 193/3753 [13:49<4:03:15,  4.10s/it]  5%|▌         | 194/3753 [13:54<4:21:19,  4.41s/it]  5%|▌         | 195/3753 [13:58<4:19:59,  4.38s/it]  5%|▌         | 196/3753 [14:02<4:03:40,  4.11s/it]  5%|▌         | 197/3753 [14:07<4:33:32,  4.62s/it]  5%|▌         | 198/3753 [14:11<4:20:17,  4.39s/it]  5%|▌         | 199/3753 [14:16<4:33:07,  4.61s/it]  5%|▌         | 200/3753 [14:21<4:32:05,  4.59s/it]{'loss': 2.1846, 'grad_norm': 1056.0411376953125, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.1638989448547363, 'weight_chosen': -0.8932307958602905, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 1.836578369140625, 'epoch': 0.05329780146568954}
                                                    {'loss': 2.1846, 'grad_norm': 1056.0411376953125, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.1638989448547363, 'weight_chosen': -0.8932307958602905, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 1.836578369140625, 'epoch': 0.05}
  5%|▌         | 200/3753 [14:21<4:32:05,  4.59s/it]  5%|▌         | 201/3753 [14:25<4:25:29,  4.48s/it]  5%|▌         | 202/3753 [14:29<4:10:49,  4.24s/it]  5%|▌         | 203/3753 [14:33<4:07:29,  4.18s/it]  5%|▌         | 204/3753 [14:37<3:57:30,  4.02s/it]  5%|▌         | 205/3753 [14:40<3:51:21,  3.91s/it]  5%|▌         | 206/3753 [14:46<4:21:36,  4.43s/it]  6%|▌         | 207/3753 [14:50<4:14:04,  4.30s/it]  6%|▌         | 208/3753 [14:55<4:26:43,  4.51s/it]  6%|▌         | 209/3753 [14:59<4:20:23,  4.41s/it]  6%|▌         | 210/3753 [15:04<4:21:10,  4.42s/it]{'loss': 2.0072, 'grad_norm': 711.314697265625, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 4.66982889175415, 'mean_ratio_rejected': 1.6396644115447998, 'weight_chosen': 0.04817557334899902, 'weight_rejected': 0.15304215252399445, 'kl_term_chosen': 0.7705612182617188, 'epoch': 0.05596269153897402}
                                                    {'loss': 2.0072, 'grad_norm': 711.314697265625, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 4.66982889175415, 'mean_ratio_rejected': 1.6396644115447998, 'weight_chosen': 0.04817557334899902, 'weight_rejected': 0.15304215252399445, 'kl_term_chosen': 0.7705612182617188, 'epoch': 0.06}
  6%|▌         | 210/3753 [15:04<4:21:10,  4.42s/it]  6%|▌         | 211/3753 [15:09<4:34:57,  4.66s/it]  6%|▌         | 212/3753 [15:13<4:20:40,  4.42s/it]  6%|▌         | 213/3753 [15:17<4:21:39,  4.43s/it]  6%|▌         | 214/3753 [15:23<4:45:00,  4.83s/it]  6%|▌         | 215/3753 [15:27<4:30:26,  4.59s/it]  6%|▌         | 216/3753 [15:31<4:23:39,  4.47s/it]  6%|▌         | 217/3753 [15:35<4:08:46,  4.22s/it]  6%|▌         | 218/3753 [15:40<4:21:51,  4.44s/it]  6%|▌         | 219/3753 [15:43<4:08:58,  4.23s/it]  6%|▌         | 220/3753 [15:47<4:00:53,  4.09s/it]{'loss': 0.814, 'grad_norm': 1494.804443359375, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 7.670400619506836, 'mean_ratio_rejected': 0.6124781370162964, 'weight_chosen': -0.33695757389068604, 'weight_rejected': 0.1200256198644638, 'kl_term_chosen': 1.0186843872070312, 'epoch': 0.05862758161225849}
                                                    {'loss': 0.814, 'grad_norm': 1494.804443359375, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 7.670400619506836, 'mean_ratio_rejected': 0.6124781370162964, 'weight_chosen': -0.33695757389068604, 'weight_rejected': 0.1200256198644638, 'kl_term_chosen': 1.0186843872070312, 'epoch': 0.06}
  6%|▌         | 220/3753 [15:47<4:00:53,  4.09s/it]  6%|▌         | 221/3753 [15:51<3:53:23,  3.96s/it]  6%|▌         | 222/3753 [15:55<3:56:34,  4.02s/it]  6%|▌         | 223/3753 [15:59<3:51:38,  3.94s/it]  6%|▌         | 224/3753 [16:02<3:48:59,  3.89s/it]  6%|▌         | 225/3753 [16:07<3:56:10,  4.02s/it]  6%|▌         | 226/3753 [16:10<3:50:46,  3.93s/it]  6%|▌         | 227/3753 [16:16<4:13:39,  4.32s/it]  6%|▌         | 228/3753 [16:19<4:00:16,  4.09s/it]  6%|▌         | 229/3753 [16:24<4:13:03,  4.31s/it]  6%|▌         | 230/3753 [16:30<4:38:43,  4.75s/it]{'loss': 2.2192, 'grad_norm': 1342.1258544921875, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 0.762805700302124, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.0725867748260498, 'weight_rejected': 0.1490352898836136, 'kl_term_chosen': -0.1353759765625, 'epoch': 0.06129247168554297}
                                                    {'loss': 2.2192, 'grad_norm': 1342.1258544921875, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 0.762805700302124, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.0725867748260498, 'weight_rejected': 0.1490352898836136, 'kl_term_chosen': -0.1353759765625, 'epoch': 0.06}
  6%|▌         | 230/3753 [16:30<4:38:43,  4.75s/it]  6%|▌         | 231/3753 [16:34<4:29:37,  4.59s/it]  6%|▌         | 232/3753 [16:38<4:21:56,  4.46s/it]  6%|▌         | 233/3753 [16:43<4:26:12,  4.54s/it]  6%|▌         | 234/3753 [16:48<4:41:47,  4.80s/it]  6%|▋         | 235/3753 [16:53<4:34:30,  4.68s/it]  6%|▋         | 236/3753 [16:57<4:25:32,  4.53s/it]  6%|▋         | 237/3753 [17:00<4:06:29,  4.21s/it]  6%|▋         | 238/3753 [17:05<4:06:18,  4.20s/it]  6%|▋         | 239/3753 [17:10<4:18:49,  4.42s/it]  6%|▋         | 240/3753 [17:14<4:26:54,  4.56s/it]{'loss': 1.5282, 'grad_norm': 1533.238525390625, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 0.6754681468009949, 'mean_ratio_rejected': 0.33423304557800293, 'weight_chosen': 1.0273176431655884, 'weight_rejected': 0.17781086266040802, 'kl_term_chosen': -0.19617462158203125, 'epoch': 0.06395736175882745}
                                                    {'loss': 1.5282, 'grad_norm': 1533.238525390625, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 0.6754681468009949, 'mean_ratio_rejected': 0.33423304557800293, 'weight_chosen': 1.0273176431655884, 'weight_rejected': 0.17781086266040802, 'kl_term_chosen': -0.19617462158203125, 'epoch': 0.06}
  6%|▋         | 240/3753 [17:15<4:26:54,  4.56s/it]  6%|▋         | 241/3753 [17:18<4:15:36,  4.37s/it]  6%|▋         | 242/3753 [17:23<4:13:45,  4.34s/it]  6%|▋         | 243/3753 [17:27<4:14:35,  4.35s/it]  7%|▋         | 244/3753 [17:31<4:14:39,  4.35s/it]  7%|▋         | 245/3753 [17:36<4:13:20,  4.33s/it]  7%|▋         | 246/3753 [17:39<4:02:25,  4.15s/it]  7%|▋         | 247/3753 [17:44<4:03:41,  4.17s/it]  7%|▋         | 248/3753 [17:47<3:45:57,  3.87s/it]  7%|▋         | 249/3753 [17:52<4:03:01,  4.16s/it]  7%|▋         | 250/3753 [17:57<4:23:37,  4.52s/it]{'loss': 2.4171, 'grad_norm': 1479.8143310546875, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 0.6429351568222046, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.115645170211792, 'weight_rejected': 0.14804719388484955, 'kl_term_chosen': -0.220855712890625, 'epoch': 0.06662225183211193}
                                                    {'loss': 2.4171, 'grad_norm': 1479.8143310546875, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 0.6429351568222046, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.115645170211792, 'weight_rejected': 0.14804719388484955, 'kl_term_chosen': -0.220855712890625, 'epoch': 0.07}
  7%|▋         | 250/3753 [17:57<4:23:37,  4.52s/it]  7%|▋         | 251/3753 [18:03<4:48:19,  4.94s/it]  7%|▋         | 252/3753 [18:08<4:50:01,  4.97s/it]  7%|▋         | 253/3753 [18:13<4:47:05,  4.92s/it]  7%|▋         | 254/3753 [18:16<4:21:33,  4.49s/it]  7%|▋         | 255/3753 [18:20<4:12:15,  4.33s/it]  7%|▋         | 256/3753 [18:24<3:59:24,  4.11s/it]  7%|▋         | 257/3753 [18:28<4:05:49,  4.22s/it]  7%|▋         | 258/3753 [18:32<3:59:46,  4.12s/it]  7%|▋         | 259/3753 [18:36<3:49:21,  3.94s/it]  7%|▋         | 260/3753 [18:40<4:04:08,  4.19s/it]{'loss': 4.78, 'grad_norm': 1276.9913330078125, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 0.8226152062416077, 'mean_ratio_rejected': 1.315649151802063, 'weight_chosen': 0.9848379492759705, 'weight_rejected': 0.13386748731136322, 'kl_term_chosen': -0.09763336181640625, 'epoch': 0.06928714190539641}
                                                    {'loss': 4.78, 'grad_norm': 1276.9913330078125, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 0.8226152062416077, 'mean_ratio_rejected': 1.315649151802063, 'weight_chosen': 0.9848379492759705, 'weight_rejected': 0.13386748731136322, 'kl_term_chosen': -0.09763336181640625, 'epoch': 0.07}
  7%|▋         | 260/3753 [18:41<4:04:08,  4.19s/it]  7%|▋         | 261/3753 [18:45<4:07:59,  4.26s/it]  7%|▋         | 262/3753 [18:49<4:07:50,  4.26s/it]  7%|▋         | 263/3753 [18:54<4:16:59,  4.42s/it]  7%|▋         | 264/3753 [18:58<4:08:10,  4.27s/it]  7%|▋         | 265/3753 [19:02<4:03:29,  4.19s/it]  7%|▋         | 266/3753 [19:06<3:56:44,  4.07s/it]  7%|▋         | 267/3753 [19:09<3:51:26,  3.98s/it]  7%|▋         | 268/3753 [19:14<4:09:34,  4.30s/it]  7%|▋         | 269/3753 [19:18<3:56:31,  4.07s/it]  7%|▋         | 270/3753 [19:22<4:03:43,  4.20s/it]{'loss': 5.7385, 'grad_norm': 1323.405029296875, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 1.7165976762771606, 'mean_ratio_rejected': 2.8055965900421143, 'weight_chosen': 0.7054048180580139, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': 0.270172119140625, 'epoch': 0.07195203197868089}
                                                    {'loss': 5.7385, 'grad_norm': 1323.405029296875, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 1.7165976762771606, 'mean_ratio_rejected': 2.8055965900421143, 'weight_chosen': 0.7054048180580139, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': 0.270172119140625, 'epoch': 0.07}
  7%|▋         | 270/3753 [19:23<4:03:43,  4.20s/it]  7%|▋         | 271/3753 [19:27<4:12:36,  4.35s/it]  7%|▋         | 272/3753 [19:31<4:11:10,  4.33s/it]  7%|▋         | 273/3753 [19:35<3:56:51,  4.08s/it]  7%|▋         | 274/3753 [19:39<3:54:41,  4.05s/it]  7%|▋         | 275/3753 [19:43<3:54:30,  4.05s/it]  7%|▋         | 276/3753 [19:47<3:46:25,  3.91s/it]  7%|▋         | 277/3753 [19:51<4:00:00,  4.14s/it]  7%|▋         | 278/3753 [19:55<3:45:13,  3.89s/it]  7%|▋         | 279/3753 [19:59<3:58:33,  4.12s/it]  7%|▋         | 280/3753 [20:04<4:14:32,  4.40s/it]{'loss': 4.5628, 'grad_norm': 864.8048095703125, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.1203348636627197, 'weight_rejected': 0.07263670116662979, 'kl_term_chosen': -2.1898765563964844, 'epoch': 0.07461692205196535}
                                                    {'loss': 4.5628, 'grad_norm': 864.8048095703125, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.1203348636627197, 'weight_rejected': 0.07263670116662979, 'kl_term_chosen': -2.1898765563964844, 'epoch': 0.07}
  7%|▋         | 280/3753 [20:04<4:14:32,  4.40s/it]  7%|▋         | 281/3753 [20:08<4:07:27,  4.28s/it]  8%|▊         | 282/3753 [20:13<4:21:16,  4.52s/it]  8%|▊         | 283/3753 [20:17<4:15:21,  4.42s/it]  8%|▊         | 284/3753 [20:22<4:08:53,  4.30s/it]  8%|▊         | 285/3753 [20:27<4:36:15,  4.78s/it]  8%|▊         | 286/3753 [20:31<4:21:15,  4.52s/it]  8%|▊         | 287/3753 [20:35<4:07:11,  4.28s/it]  8%|▊         | 288/3753 [20:40<4:12:40,  4.38s/it]  8%|▊         | 289/3753 [20:44<4:16:24,  4.44s/it]  8%|▊         | 290/3753 [20:50<4:39:03,  4.84s/it]{'loss': 3.3557, 'grad_norm': 1358.9349365234375, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 0.8437821865081787, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.8383970856666565, 'weight_rejected': 0.20946967601776123, 'kl_term_chosen': -0.084930419921875, 'epoch': 0.07728181212524983}
                                                    {'loss': 3.3557, 'grad_norm': 1358.9349365234375, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 0.8437821865081787, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.8383970856666565, 'weight_rejected': 0.20946967601776123, 'kl_term_chosen': -0.084930419921875, 'epoch': 0.08}
  8%|▊         | 290/3753 [20:50<4:39:03,  4.84s/it]  8%|▊         | 291/3753 [20:54<4:21:01,  4.52s/it]  8%|▊         | 292/3753 [20:59<4:35:01,  4.77s/it]  8%|▊         | 293/3753 [21:03<4:15:15,  4.43s/it]  8%|▊         | 294/3753 [21:07<4:12:18,  4.38s/it]  8%|▊         | 295/3753 [21:12<4:19:29,  4.50s/it]  8%|▊         | 296/3753 [21:16<4:06:18,  4.27s/it]  8%|▊         | 297/3753 [21:20<4:12:35,  4.39s/it]  8%|▊         | 298/3753 [21:26<4:28:55,  4.67s/it]  8%|▊         | 299/3753 [21:30<4:26:09,  4.62s/it]  8%|▊         | 300/3753 [21:34<4:15:58,  4.45s/it]{'loss': 4.3677, 'grad_norm': 1055.8875732421875, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 7.653331756591797, 'weight_chosen': -2.3561620712280273, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 3.280303955078125, 'epoch': 0.07994670219853431}
                                                    {'loss': 4.3677, 'grad_norm': 1055.8875732421875, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 7.653331756591797, 'weight_chosen': -2.3561620712280273, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 3.280303955078125, 'epoch': 0.08}
  8%|▊         | 300/3753 [21:34<4:15:58,  4.45s/it]  8%|▊         | 301/3753 [21:38<4:10:22,  4.35s/it]  8%|▊         | 302/3753 [21:43<4:22:03,  4.56s/it]  8%|▊         | 303/3753 [21:48<4:24:34,  4.60s/it]  8%|▊         | 304/3753 [21:51<3:57:52,  4.14s/it]  8%|▊         | 305/3753 [21:55<3:57:31,  4.13s/it]  8%|▊         | 306/3753 [21:59<3:52:13,  4.04s/it]  8%|▊         | 307/3753 [22:03<3:58:07,  4.15s/it]  8%|▊         | 308/3753 [22:08<4:13:28,  4.41s/it]  8%|▊         | 309/3753 [22:13<4:14:57,  4.44s/it]  8%|▊         | 310/3753 [22:17<4:06:57,  4.30s/it]{'loss': 8.184, 'grad_norm': 848.7265625, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 0.21477054059505463, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.4327614307403564, 'weight_rejected': 0.22815649211406708, 'kl_term_chosen': -0.7690925598144531, 'epoch': 0.08261159227181879}
                                                    {'loss': 8.184, 'grad_norm': 848.7265625, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 0.21477054059505463, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.4327614307403564, 'weight_rejected': 0.22815649211406708, 'kl_term_chosen': -0.7690925598144531, 'epoch': 0.08}
  8%|▊         | 310/3753 [22:17<4:06:57,  4.30s/it]  8%|▊         | 311/3753 [22:21<4:10:27,  4.37s/it]  8%|▊         | 312/3753 [22:25<4:02:17,  4.22s/it]  8%|▊         | 313/3753 [22:30<4:03:12,  4.24s/it]  8%|▊         | 314/3753 [22:35<4:22:58,  4.59s/it]  8%|▊         | 315/3753 [22:39<4:05:50,  4.29s/it]  8%|▊         | 316/3753 [22:42<3:57:13,  4.14s/it]  8%|▊         | 317/3753 [22:46<3:53:21,  4.07s/it]  8%|▊         | 318/3753 [22:51<3:59:28,  4.18s/it]  8%|▊         | 319/3753 [22:55<4:01:25,  4.22s/it]  9%|▊         | 320/3753 [23:00<4:09:14,  4.36s/it]{'loss': 3.5558, 'grad_norm': 1768.4376220703125, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 0.8821737170219421, 'mean_ratio_rejected': 9.022370338439941, 'weight_chosen': 0.9998939037322998, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': -0.06268310546875, 'epoch': 0.08527648234510327}
                                                    {'loss': 3.5558, 'grad_norm': 1768.4376220703125, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 0.8821737170219421, 'mean_ratio_rejected': 9.022370338439941, 'weight_chosen': 0.9998939037322998, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': -0.06268310546875, 'epoch': 0.09}
  9%|▊         | 320/3753 [23:00<4:09:14,  4.36s/it]  9%|▊         | 321/3753 [23:04<4:10:23,  4.38s/it]  9%|▊         | 322/3753 [23:08<4:05:06,  4.29s/it]  9%|▊         | 323/3753 [23:12<3:49:04,  4.01s/it]  9%|▊         | 324/3753 [23:17<4:15:44,  4.47s/it]  9%|▊         | 325/3753 [23:21<4:13:04,  4.43s/it]  9%|▊         | 326/3753 [23:25<3:58:28,  4.18s/it]  9%|▊         | 327/3753 [23:29<3:59:55,  4.20s/it]  9%|▊         | 328/3753 [23:33<3:53:02,  4.08s/it]  9%|▉         | 329/3753 [23:37<3:57:38,  4.16s/it]  9%|▉         | 330/3753 [23:43<4:13:56,  4.45s/it]{'loss': 7.1022, 'grad_norm': 1083.3551025390625, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 2.6223361492156982, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.379505455493927, 'weight_rejected': 0.22135066986083984, 'kl_term_chosen': 0.48203277587890625, 'epoch': 0.08794137241838774}
                                                    {'loss': 7.1022, 'grad_norm': 1083.3551025390625, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 2.6223361492156982, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.379505455493927, 'weight_rejected': 0.22135066986083984, 'kl_term_chosen': 0.48203277587890625, 'epoch': 0.09}
  9%|▉         | 330/3753 [23:43<4:13:56,  4.45s/it]  9%|▉         | 331/3753 [23:47<4:05:20,  4.30s/it]  9%|▉         | 332/3753 [23:50<3:57:29,  4.17s/it]  9%|▉         | 333/3753 [23:55<4:02:47,  4.26s/it]  9%|▉         | 334/3753 [23:59<4:02:07,  4.25s/it]  9%|▉         | 335/3753 [24:04<4:10:13,  4.39s/it]  9%|▉         | 336/3753 [24:07<3:56:06,  4.15s/it]  9%|▉         | 337/3753 [24:12<4:03:15,  4.27s/it]  9%|▉         | 338/3753 [24:15<3:48:27,  4.01s/it]  9%|▉         | 339/3753 [24:19<3:42:30,  3.91s/it]  9%|▉         | 340/3753 [24:23<3:48:25,  4.02s/it]{'loss': 8.0062, 'grad_norm': 1681.1083984375, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 1.1208102703094482, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.18661653995513916, 'weight_rejected': 0.7826625108718872, 'kl_term_chosen': 0.057025909423828125, 'epoch': 0.09060626249167222}
                                                    {'loss': 8.0062, 'grad_norm': 1681.1083984375, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 1.1208102703094482, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.18661653995513916, 'weight_rejected': 0.7826625108718872, 'kl_term_chosen': 0.057025909423828125, 'epoch': 0.09}
  9%|▉         | 340/3753 [24:23<3:48:25,  4.02s/it]  9%|▉         | 341/3753 [24:27<3:46:33,  3.98s/it]  9%|▉         | 342/3753 [24:31<3:47:02,  3.99s/it]  9%|▉         | 343/3753 [24:36<3:55:03,  4.14s/it]  9%|▉         | 344/3753 [24:40<3:52:33,  4.09s/it]  9%|▉         | 345/3753 [24:45<4:13:04,  4.46s/it]  9%|▉         | 346/3753 [24:49<4:07:42,  4.36s/it]  9%|▉         | 347/3753 [24:54<4:13:36,  4.47s/it]  9%|▉         | 348/3753 [24:59<4:25:40,  4.68s/it]  9%|▉         | 349/3753 [25:03<4:09:54,  4.40s/it]  9%|▉         | 350/3753 [25:07<4:10:23,  4.41s/it]{'loss': 5.199, 'grad_norm': 1355.00439453125, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 0.9603269100189209, 'mean_ratio_rejected': 2.470043897628784, 'weight_chosen': 0.8546476364135742, 'weight_rejected': 0.2186693549156189, 'kl_term_chosen': -0.02024078369140625, 'epoch': 0.09327115256495669}
                                                    {'loss': 5.199, 'grad_norm': 1355.00439453125, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 0.9603269100189209, 'mean_ratio_rejected': 2.470043897628784, 'weight_chosen': 0.8546476364135742, 'weight_rejected': 0.2186693549156189, 'kl_term_chosen': -0.02024078369140625, 'epoch': 0.09}
  9%|▉         | 350/3753 [25:07<4:10:23,  4.41s/it]  9%|▉         | 351/3753 [25:11<4:02:02,  4.27s/it]  9%|▉         | 352/3753 [25:15<3:47:11,  4.01s/it]  9%|▉         | 353/3753 [25:19<3:51:52,  4.09s/it]  9%|▉         | 354/3753 [25:23<3:54:30,  4.14s/it]  9%|▉         | 355/3753 [25:28<4:09:25,  4.40s/it]  9%|▉         | 356/3753 [25:32<4:05:35,  4.34s/it] 10%|▉         | 357/3753 [25:37<4:04:44,  4.32s/it] 10%|▉         | 358/3753 [25:41<4:09:10,  4.40s/it] 10%|▉         | 359/3753 [25:45<4:04:26,  4.32s/it] 10%|▉         | 360/3753 [25:49<3:55:37,  4.17s/it]{'loss': 3.7472, 'grad_norm': 1847.456787109375, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 0.6115117073059082, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.7902276515960693, 'weight_rejected': 0.16667540371418, 'kl_term_chosen': -0.24591064453125, 'epoch': 0.09593604263824117}
                                                    {'loss': 3.7472, 'grad_norm': 1847.456787109375, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 0.6115117073059082, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.7902276515960693, 'weight_rejected': 0.16667540371418, 'kl_term_chosen': -0.24591064453125, 'epoch': 0.1}
 10%|▉         | 360/3753 [25:49<3:55:37,  4.17s/it] 10%|▉         | 361/3753 [25:54<4:00:54,  4.26s/it] 10%|▉         | 362/3753 [25:58<4:00:41,  4.26s/it] 10%|▉         | 363/3753 [26:02<4:02:33,  4.29s/it] 10%|▉         | 364/3753 [26:07<4:05:49,  4.35s/it] 10%|▉         | 365/3753 [26:10<3:47:06,  4.02s/it] 10%|▉         | 366/3753 [26:13<3:38:35,  3.87s/it] 10%|▉         | 367/3753 [26:17<3:40:27,  3.91s/it] 10%|▉         | 368/3753 [26:22<3:59:46,  4.25s/it] 10%|▉         | 369/3753 [26:27<4:03:36,  4.32s/it] 10%|▉         | 370/3753 [26:31<4:01:11,  4.28s/it]{'loss': 6.1158, 'grad_norm': 1575.255859375, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 5.130486488342285, 'weight_chosen': 2.6413986682891846, 'weight_rejected': 0.20561504364013672, 'kl_term_chosen': -1.7770881652832031, 'epoch': 0.09860093271152565}
                                                    {'loss': 6.1158, 'grad_norm': 1575.255859375, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 5.130486488342285, 'weight_chosen': 2.6413986682891846, 'weight_rejected': 0.20561504364013672, 'kl_term_chosen': -1.7770881652832031, 'epoch': 0.1}
 10%|▉         | 370/3753 [26:31<4:01:11,  4.28s/it] 10%|▉         | 371/3753 [26:35<3:47:26,  4.04s/it] 10%|▉         | 372/3753 [26:39<3:59:24,  4.25s/it] 10%|▉         | 373/3753 [26:43<3:51:36,  4.11s/it] 10%|▉         | 374/3753 [26:48<3:58:37,  4.24s/it] 10%|▉         | 375/3753 [26:53<4:19:12,  4.60s/it] 10%|█         | 376/3753 [26:58<4:27:31,  4.75s/it] 10%|█         | 377/3753 [27:03<4:20:57,  4.64s/it] 10%|█         | 378/3753 [27:06<4:00:38,  4.28s/it] 10%|█         | 379/3753 [27:09<3:44:45,  4.00s/it] 10%|█         | 380/3753 [27:14<3:58:05,  4.24s/it]{'loss': 5.6481, 'grad_norm': 679.9923706054688, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.4999964237213135, 'weight_rejected': 0.02595735713839531, 'kl_term_chosen': 2.460357666015625, 'epoch': 0.10126582278481013}
                                                    {'loss': 5.6481, 'grad_norm': 679.9923706054688, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.4999964237213135, 'weight_rejected': 0.02595735713839531, 'kl_term_chosen': 2.460357666015625, 'epoch': 0.1}
 10%|█         | 380/3753 [27:14<3:58:05,  4.24s/it] 10%|█         | 381/3753 [27:18<3:57:56,  4.23s/it] 10%|█         | 382/3753 [27:23<3:57:34,  4.23s/it] 10%|█         | 383/3753 [27:27<3:53:58,  4.17s/it] 10%|█         | 384/3753 [27:32<4:11:12,  4.47s/it] 10%|█         | 385/3753 [27:37<4:24:27,  4.71s/it] 10%|█         | 386/3753 [27:41<4:08:20,  4.43s/it] 10%|█         | 387/3753 [27:45<4:05:12,  4.37s/it] 10%|█         | 388/3753 [27:50<4:05:44,  4.38s/it] 10%|█         | 389/3753 [27:54<4:06:45,  4.40s/it] 10%|█         | 390/3753 [27:58<4:06:15,  4.39s/it]{'loss': 18.4144, 'grad_norm': 382.97357177734375, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 1.3947750329971313, 'mean_ratio_rejected': 0.15099585056304932, 'weight_chosen': 0.4724687337875366, 'weight_rejected': 0.8164063692092896, 'kl_term_chosen': 0.1663665771484375, 'epoch': 0.1039307128580946}
                                                    {'loss': 18.4144, 'grad_norm': 382.97357177734375, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 1.3947750329971313, 'mean_ratio_rejected': 0.15099585056304932, 'weight_chosen': 0.4724687337875366, 'weight_rejected': 0.8164063692092896, 'kl_term_chosen': 0.1663665771484375, 'epoch': 0.1}
 10%|█         | 390/3753 [27:58<4:06:15,  4.39s/it] 10%|█         | 391/3753 [28:03<4:09:43,  4.46s/it] 10%|█         | 392/3753 [28:07<4:00:34,  4.29s/it] 10%|█         | 393/3753 [28:11<4:00:56,  4.30s/it] 10%|█         | 394/3753 [28:16<4:02:03,  4.32s/it] 11%|█         | 395/3753 [28:20<4:07:16,  4.42s/it] 11%|█         | 396/3753 [28:25<4:08:43,  4.45s/it] 11%|█         | 397/3753 [28:28<3:53:30,  4.17s/it] 11%|█         | 398/3753 [28:32<3:51:33,  4.14s/it] 11%|█         | 399/3753 [28:37<3:58:30,  4.27s/it] 11%|█         | 400/3753 [28:41<3:54:52,  4.20s/it]{'loss': 14.0974, 'grad_norm': 200.94464111328125, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.340826034545898, 'weight_rejected': 0.25091278553009033, 'kl_term_chosen': -3.6456947326660156, 'epoch': 0.10659560293137908}
                                                    {'loss': 14.0974, 'grad_norm': 200.94464111328125, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.340826034545898, 'weight_rejected': 0.25091278553009033, 'kl_term_chosen': -3.6456947326660156, 'epoch': 0.11}
 11%|█         | 400/3753 [28:41<3:54:52,  4.20s/it] 11%|█         | 401/3753 [28:45<3:51:44,  4.15s/it] 11%|█         | 402/3753 [28:50<4:03:50,  4.37s/it] 11%|█         | 403/3753 [28:53<3:46:35,  4.06s/it] 11%|█         | 404/3753 [28:57<3:46:36,  4.06s/it] 11%|█         | 405/3753 [29:02<3:55:02,  4.21s/it] 11%|█         | 406/3753 [29:06<3:54:11,  4.20s/it] 11%|█         | 407/3753 [29:10<3:47:29,  4.08s/it] 11%|█         | 408/3753 [29:15<4:04:54,  4.39s/it] 11%|█         | 409/3753 [29:19<4:00:00,  4.31s/it] 11%|█         | 410/3753 [29:23<4:02:51,  4.36s/it]{'loss': 3.4754, 'grad_norm': 385.07159423828125, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.566877841949463, 'weight_rejected': 0.28776782751083374, 'kl_term_chosen': -2.919971466064453, 'epoch': 0.10926049300466356}
                                                    {'loss': 3.4754, 'grad_norm': 385.07159423828125, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.566877841949463, 'weight_rejected': 0.28776782751083374, 'kl_term_chosen': -2.919971466064453, 'epoch': 0.11}
 11%|█         | 410/3753 [29:24<4:02:51,  4.36s/it] 11%|█         | 411/3753 [29:28<4:09:54,  4.49s/it] 11%|█         | 412/3753 [29:32<4:00:15,  4.31s/it] 11%|█         | 413/3753 [29:38<4:21:25,  4.70s/it] 11%|█         | 414/3753 [29:43<4:23:12,  4.73s/it] 11%|█         | 415/3753 [29:47<4:11:21,  4.52s/it] 11%|█         | 416/3753 [29:51<4:10:25,  4.50s/it] 11%|█         | 417/3753 [29:55<3:59:16,  4.30s/it] 11%|█         | 418/3753 [29:59<3:52:42,  4.19s/it] 11%|█         | 419/3753 [30:03<3:52:58,  4.19s/it] 11%|█         | 420/3753 [30:07<3:46:27,  4.08s/it]{'loss': 25.5128, 'grad_norm': 990.7787475585938, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.802332878112793, 'weight_rejected': 0.2727987766265869, 'kl_term_chosen': -3.1509780883789062, 'epoch': 0.11192538307794804}
                                                    {'loss': 25.5128, 'grad_norm': 990.7787475585938, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.802332878112793, 'weight_rejected': 0.2727987766265869, 'kl_term_chosen': -3.1509780883789062, 'epoch': 0.11}
 11%|█         | 420/3753 [30:07<3:46:27,  4.08s/it] 11%|█         | 421/3753 [30:11<3:50:56,  4.16s/it] 11%|█         | 422/3753 [30:15<3:51:58,  4.18s/it] 11%|█▏        | 423/3753 [30:19<3:43:45,  4.03s/it] 11%|█▏        | 424/3753 [30:22<3:30:14,  3.79s/it] 11%|█▏        | 425/3753 [30:27<3:39:21,  3.95s/it] 11%|█▏        | 426/3753 [30:31<3:44:36,  4.05s/it] 11%|█▏        | 427/3753 [30:36<3:54:07,  4.22s/it] 11%|█▏        | 428/3753 [30:40<3:56:44,  4.27s/it] 11%|█▏        | 429/3753 [30:44<3:52:56,  4.20s/it] 11%|█▏        | 430/3753 [30:49<4:04:15,  4.41s/it]{'loss': 12.9239, 'grad_norm': 42.6142578125, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 8.370319366455078, 'weight_rejected': 0.27125170826911926, 'kl_term_chosen': -7.80670166015625, 'epoch': 0.1145902731512325}
                                                    {'loss': 12.9239, 'grad_norm': 42.6142578125, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 8.370319366455078, 'weight_rejected': 0.27125170826911926, 'kl_term_chosen': -7.80670166015625, 'epoch': 0.11}
 11%|█▏        | 430/3753 [30:49<4:04:15,  4.41s/it] 11%|█▏        | 431/3753 [30:53<3:54:02,  4.23s/it] 12%|█▏        | 432/3753 [30:58<4:05:50,  4.44s/it] 12%|█▏        | 433/3753 [31:02<4:00:59,  4.36s/it] 12%|█▏        | 434/3753 [31:06<3:51:23,  4.18s/it] 12%|█▏        | 435/3753 [31:09<3:45:44,  4.08s/it] 12%|█▏        | 436/3753 [31:14<3:51:55,  4.20s/it] 12%|█▏        | 437/3753 [31:18<3:51:26,  4.19s/it] 12%|█▏        | 438/3753 [31:23<3:59:10,  4.33s/it] 12%|█▏        | 439/3753 [31:27<3:56:53,  4.29s/it] 12%|█▏        | 440/3753 [31:31<3:51:38,  4.20s/it]{'loss': 4.1638, 'grad_norm': 39.20624542236328, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.1800028383731842, 'weight_chosen': -1.064151406288147, 'weight_rejected': 0.048136770725250244, 'kl_term_chosen': 2.018798828125, 'epoch': 0.11725516322451698}
                                                    {'loss': 4.1638, 'grad_norm': 39.20624542236328, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.1800028383731842, 'weight_chosen': -1.064151406288147, 'weight_rejected': 0.048136770725250244, 'kl_term_chosen': 2.018798828125, 'epoch': 0.12}
 12%|█▏        | 440/3753 [31:31<3:51:38,  4.20s/it] 12%|█▏        | 441/3753 [31:35<3:44:42,  4.07s/it] 12%|█▏        | 442/3753 [31:39<3:51:24,  4.19s/it] 12%|█▏        | 443/3753 [31:42<3:24:20,  3.70s/it] 12%|█▏        | 444/3753 [31:46<3:38:18,  3.96s/it] 12%|█▏        | 445/3753 [31:50<3:28:27,  3.78s/it] 12%|█▏        | 446/3753 [31:54<3:41:26,  4.02s/it] 12%|█▏        | 447/3753 [31:59<3:51:01,  4.19s/it] 12%|█▏        | 448/3753 [32:02<3:36:37,  3.93s/it] 12%|█▏        | 449/3753 [32:07<3:52:04,  4.21s/it] 12%|█▏        | 450/3753 [32:11<3:52:33,  4.22s/it]{'loss': 19.4284, 'grad_norm': 1497.1607666015625, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.475022315979004, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 6.3683319091796875, 'epoch': 0.11992005329780146}
                                                    {'loss': 19.4284, 'grad_norm': 1497.1607666015625, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.475022315979004, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 6.3683319091796875, 'epoch': 0.12}
 12%|█▏        | 450/3753 [32:11<3:52:33,  4.22s/it] 12%|█▏        | 451/3753 [32:15<3:51:53,  4.21s/it] 12%|█▏        | 452/3753 [32:20<3:54:11,  4.26s/it] 12%|█▏        | 453/3753 [32:23<3:43:48,  4.07s/it] 12%|█▏        | 454/3753 [32:29<4:11:08,  4.57s/it] 12%|█▏        | 455/3753 [32:33<4:04:17,  4.44s/it] 12%|█▏        | 456/3753 [32:37<3:52:22,  4.23s/it] 12%|█▏        | 457/3753 [32:41<3:50:12,  4.19s/it] 12%|█▏        | 458/3753 [32:45<3:46:34,  4.13s/it] 12%|█▏        | 459/3753 [32:49<3:50:49,  4.20s/it] 12%|█▏        | 460/3753 [32:55<4:15:52,  4.66s/it]{'loss': 31.9603, 'grad_norm': 600.5513916015625, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.028022527694702, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': 2.946502685546875, 'epoch': 0.12258494337108594}
                                                    {'loss': 31.9603, 'grad_norm': 600.5513916015625, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.028022527694702, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': 2.946502685546875, 'epoch': 0.12}
 12%|█▏        | 460/3753 [32:55<4:15:52,  4.66s/it] 12%|█▏        | 461/3753 [32:59<3:54:40,  4.28s/it] 12%|█▏        | 462/3753 [33:01<3:30:13,  3.83s/it] 12%|█▏        | 463/3753 [33:06<3:40:03,  4.01s/it] 12%|█▏        | 464/3753 [33:10<3:44:09,  4.09s/it] 12%|█▏        | 465/3753 [33:14<3:45:46,  4.12s/it] 12%|█▏        | 466/3753 [33:18<3:45:21,  4.11s/it] 12%|█▏        | 467/3753 [33:23<3:46:58,  4.14s/it] 12%|█▏        | 468/3753 [33:27<3:51:54,  4.24s/it] 12%|█▏        | 469/3753 [33:32<4:09:09,  4.55s/it] 13%|█▎        | 470/3753 [33:38<4:30:28,  4.94s/it]{'loss': 18.749, 'grad_norm': 431.493896484375, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 0.3023509085178375, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.5430781841278076, 'weight_rejected': 0.08151976019144058, 'kl_term_chosen': -0.59808349609375, 'epoch': 0.1252498334443704}
                                                    {'loss': 18.749, 'grad_norm': 431.493896484375, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 0.3023509085178375, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.5430781841278076, 'weight_rejected': 0.08151976019144058, 'kl_term_chosen': -0.59808349609375, 'epoch': 0.13}
 13%|█▎        | 470/3753 [33:38<4:30:28,  4.94s/it] 13%|█▎        | 471/3753 [33:44<4:40:50,  5.13s/it] 13%|█▎        | 472/3753 [33:47<4:11:52,  4.61s/it] 13%|█▎        | 473/3753 [33:50<3:42:23,  4.07s/it] 13%|█▎        | 474/3753 [33:55<3:51:01,  4.23s/it] 13%|█▎        | 475/3753 [33:59<3:58:02,  4.36s/it] 13%|█▎        | 476/3753 [34:03<3:54:08,  4.29s/it] 13%|█▎        | 477/3753 [34:08<3:54:19,  4.29s/it] 13%|█▎        | 478/3753 [34:12<3:47:33,  4.17s/it] 13%|█▎        | 479/3753 [34:17<4:06:18,  4.51s/it] 13%|█▎        | 480/3753 [34:22<4:10:11,  4.59s/it]{'loss': 12.396, 'grad_norm': 1528.203857421875, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.7767678499221802, 'weight_rejected': 0.23792988061904907, 'kl_term_chosen': -1.200225830078125, 'epoch': 0.1279147235176549}
                                                    {'loss': 12.396, 'grad_norm': 1528.203857421875, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.7767678499221802, 'weight_rejected': 0.23792988061904907, 'kl_term_chosen': -1.200225830078125, 'epoch': 0.13}
 13%|█▎        | 480/3753 [34:22<4:10:11,  4.59s/it] 13%|█▎        | 481/3753 [34:27<4:17:20,  4.72s/it] 13%|█▎        | 482/3753 [34:30<4:03:05,  4.46s/it] 13%|█▎        | 483/3753 [34:34<3:50:59,  4.24s/it] 13%|█▎        | 484/3753 [34:38<3:44:25,  4.12s/it] 13%|█▎        | 485/3753 [34:42<3:36:00,  3.97s/it] 13%|█▎        | 486/3753 [34:46<3:42:20,  4.08s/it] 13%|█▎        | 487/3753 [34:51<3:55:33,  4.33s/it] 13%|█▎        | 488/3753 [34:55<3:44:16,  4.12s/it] 13%|█▎        | 489/3753 [34:59<3:55:00,  4.32s/it] 13%|█▎        | 490/3753 [35:04<4:01:44,  4.45s/it]{'loss': 30.354, 'grad_norm': 388.5398864746094, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.3048083782196045, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': 4.248985290527344, 'epoch': 0.13057961359093936}
                                                    {'loss': 30.354, 'grad_norm': 388.5398864746094, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.3048083782196045, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': 4.248985290527344, 'epoch': 0.13}
 13%|█▎        | 490/3753 [35:04<4:01:44,  4.45s/it] 13%|█▎        | 491/3753 [35:09<4:10:51,  4.61s/it] 13%|█▎        | 492/3753 [35:13<3:58:50,  4.39s/it] 13%|█▎        | 493/3753 [35:19<4:21:40,  4.82s/it] 13%|█▎        | 494/3753 [35:23<4:06:45,  4.54s/it] 13%|█▎        | 495/3753 [35:26<3:47:10,  4.18s/it] 13%|█▎        | 496/3753 [35:31<3:57:58,  4.38s/it] 13%|█▎        | 497/3753 [35:35<3:49:44,  4.23s/it] 13%|█▎        | 498/3753 [35:40<4:03:09,  4.48s/it] 13%|█▎        | 499/3753 [35:45<4:14:45,  4.70s/it] 13%|█▎        | 500/3753 [35:49<4:10:34,  4.62s/it]{'loss': 15.7388, 'grad_norm': 611.1222534179688, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.4054253101348877, 'weight_rejected': 0.22270013391971588, 'kl_term_chosen': -2.7629928588867188, 'epoch': 0.13324450366422386}
                                                    {'loss': 15.7388, 'grad_norm': 611.1222534179688, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.4054253101348877, 'weight_rejected': 0.22270013391971588, 'kl_term_chosen': -2.7629928588867188, 'epoch': 0.13}
 13%|█▎        | 500/3753 [35:50<4:10:34,  4.62s/it] 13%|█▎        | 501/3753 [35:54<4:04:03,  4.50s/it] 13%|█▎        | 502/3753 [35:58<4:09:27,  4.60s/it] 13%|█▎        | 503/3753 [36:03<4:06:28,  4.55s/it] 13%|█▎        | 504/3753 [36:07<3:56:14,  4.36s/it] 13%|█▎        | 505/3753 [36:11<3:46:00,  4.18s/it] 13%|█▎        | 506/3753 [36:14<3:38:46,  4.04s/it] 14%|█▎        | 507/3753 [36:19<3:50:11,  4.25s/it] 14%|█▎        | 508/3753 [36:24<4:06:41,  4.56s/it] 14%|█▎        | 509/3753 [36:28<3:58:55,  4.42s/it] 14%|█▎        | 510/3753 [36:33<4:02:53,  4.49s/it]{'loss': 33.8273, 'grad_norm': 366.5464172363281, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -12.9332857131958, 'weight_rejected': 0.03358950838446617, 'kl_term_chosen': 13.889266967773438, 'epoch': 0.13590939373750832}
                                                    {'loss': 33.8273, 'grad_norm': 366.5464172363281, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -12.9332857131958, 'weight_rejected': 0.03358950838446617, 'kl_term_chosen': 13.889266967773438, 'epoch': 0.14}
 14%|█▎        | 510/3753 [36:33<4:02:53,  4.49s/it] 14%|█▎        | 511/3753 [36:37<4:00:00,  4.44s/it] 14%|█▎        | 512/3753 [36:41<3:47:45,  4.22s/it] 14%|█▎        | 513/3753 [36:44<3:32:59,  3.94s/it] 14%|█▎        | 514/3753 [36:49<3:50:56,  4.28s/it] 14%|█▎        | 515/3753 [36:55<4:03:27,  4.51s/it] 14%|█▎        | 516/3753 [36:59<4:01:56,  4.48s/it] 14%|█▍        | 517/3753 [37:03<3:46:50,  4.21s/it] 14%|█▍        | 518/3753 [37:06<3:41:52,  4.12s/it] 14%|█▍        | 519/3753 [37:11<3:55:40,  4.37s/it] 14%|█▍        | 520/3753 [37:17<4:11:54,  4.67s/it]{'loss': 38.5896, 'grad_norm': 612.7659301757812, 'learning_rate': 9.955821687527552e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -8.142123222351074, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 9.065162658691406, 'epoch': 0.13857428381079281}
                                                    {'loss': 38.5896, 'grad_norm': 612.7659301757812, 'learning_rate': 9.955821687527552e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -8.142123222351074, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 9.065162658691406, 'epoch': 0.14}
 14%|█▍        | 520/3753 [37:17<4:11:54,  4.67s/it] 14%|█▍        | 521/3753 [37:21<4:09:15,  4.63s/it] 14%|█▍        | 522/3753 [37:26<4:03:41,  4.53s/it] 14%|█▍        | 523/3753 [37:30<4:00:20,  4.46s/it] 14%|█▍        | 524/3753 [37:34<4:01:33,  4.49s/it] 14%|█▍        | 525/3753 [37:39<3:56:45,  4.40s/it] 14%|█▍        | 526/3753 [37:42<3:37:14,  4.04s/it] 14%|█▍        | 527/3753 [37:46<3:33:39,  3.97s/it] 14%|█▍        | 528/3753 [37:50<3:42:57,  4.15s/it] 14%|█▍        | 529/3753 [37:54<3:30:26,  3.92s/it] 14%|█▍        | 530/3753 [37:58<3:34:05,  3.99s/it]{'loss': 16.5427, 'grad_norm': 278.03021240234375, 'learning_rate': 9.94943765952491e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 20.56525421142578, 'weight_rejected': 0.332852303981781, 'kl_term_chosen': -20.129352569580078, 'epoch': 0.14123917388407728}
                                                    {'loss': 16.5427, 'grad_norm': 278.03021240234375, 'learning_rate': 9.94943765952491e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 20.56525421142578, 'weight_rejected': 0.332852303981781, 'kl_term_chosen': -20.129352569580078, 'epoch': 0.14}
 14%|█▍        | 530/3753 [37:58<3:34:05,  3.99s/it] 14%|█▍        | 531/3753 [38:01<3:28:10,  3.88s/it] 14%|█▍        | 532/3753 [38:06<3:37:52,  4.06s/it] 14%|█▍        | 533/3753 [38:10<3:39:52,  4.10s/it] 14%|█▍        | 534/3753 [38:13<3:29:41,  3.91s/it] 14%|█▍        | 535/3753 [38:18<3:37:04,  4.05s/it] 14%|█▍        | 536/3753 [38:23<3:48:45,  4.27s/it] 14%|█▍        | 537/3753 [38:27<3:56:33,  4.41s/it] 14%|█▍        | 538/3753 [38:31<3:41:36,  4.14s/it] 14%|█▍        | 539/3753 [38:34<3:30:44,  3.93s/it] 14%|█▍        | 540/3753 [38:38<3:18:41,  3.71s/it]{'loss': 8.0922, 'grad_norm': 0.0, 'learning_rate': 9.942625289827702e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.34912949800491333, 'weight_rejected': 0.1233656257390976, 'kl_term_chosen': 1.2775382995605469, 'epoch': 0.14390406395736177}
                                                    {'loss': 8.0922, 'grad_norm': 0.0, 'learning_rate': 9.942625289827702e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.34912949800491333, 'weight_rejected': 0.1233656257390976, 'kl_term_chosen': 1.2775382995605469, 'epoch': 0.14}
 14%|█▍        | 540/3753 [38:38<3:18:41,  3.71s/it] 14%|█▍        | 541/3753 [38:41<3:16:39,  3.67s/it] 14%|█▍        | 542/3753 [38:45<3:24:55,  3.83s/it] 14%|█▍        | 543/3753 [38:48<3:13:36,  3.62s/it] 14%|█▍        | 544/3753 [38:53<3:29:46,  3.92s/it] 15%|█▍        | 545/3753 [38:57<3:28:21,  3.90s/it] 15%|█▍        | 546/3753 [39:00<3:20:48,  3.76s/it] 15%|█▍        | 547/3753 [39:05<3:29:57,  3.93s/it] 15%|█▍        | 548/3753 [39:09<3:43:45,  4.19s/it] 15%|█▍        | 549/3753 [39:13<3:39:02,  4.10s/it] 15%|█▍        | 550/3753 [39:18<3:51:57,  4.35s/it]{'loss': 16.8489, 'grad_norm': 340.6753845214844, 'learning_rate': 9.935385168002298e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -10.155527114868164, 'weight_rejected': 0.07585817575454712, 'kl_term_chosen': 11.091812133789062, 'epoch': 0.14656895403064624}
                                                    {'loss': 16.8489, 'grad_norm': 340.6753845214844, 'learning_rate': 9.935385168002298e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -10.155527114868164, 'weight_rejected': 0.07585817575454712, 'kl_term_chosen': 11.091812133789062, 'epoch': 0.15}
 15%|█▍        | 550/3753 [39:18<3:51:57,  4.35s/it] 15%|█▍        | 551/3753 [39:23<3:53:32,  4.38s/it] 15%|█▍        | 552/3753 [39:26<3:36:09,  4.05s/it] 15%|█▍        | 553/3753 [39:30<3:37:06,  4.07s/it] 15%|█▍        | 554/3753 [39:35<3:42:18,  4.17s/it] 15%|█▍        | 555/3753 [39:39<3:47:23,  4.27s/it] 15%|█▍        | 556/3753 [39:43<3:41:59,  4.17s/it] 15%|█▍        | 557/3753 [39:47<3:42:25,  4.18s/it] 15%|█▍        | 558/3753 [39:51<3:42:23,  4.18s/it] 15%|█▍        | 559/3753 [39:56<3:43:30,  4.20s/it] 15%|█▍        | 560/3753 [39:59<3:35:09,  4.04s/it]{'loss': 30.996, 'grad_norm': 219.311767578125, 'learning_rate': 9.927717920634233e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.853062391281128, 'weight_rejected': 0.18713268637657166, 'kl_term_chosen': 4.731376647949219, 'epoch': 0.1492338441039307}
                                                    {'loss': 30.996, 'grad_norm': 219.311767578125, 'learning_rate': 9.927717920634233e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.853062391281128, 'weight_rejected': 0.18713268637657166, 'kl_term_chosen': 4.731376647949219, 'epoch': 0.15}
 15%|█▍        | 560/3753 [39:59<3:35:09,  4.04s/it]