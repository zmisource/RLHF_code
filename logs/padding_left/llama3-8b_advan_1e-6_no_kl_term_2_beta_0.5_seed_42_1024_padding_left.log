nohup: ignoring input
[W1201 12:02:42.246187130 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.47it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.44it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.78it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.32it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]加载作为参考的SFT模型 (Reference Model)...
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.67it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.14it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.27it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.62it/s]
[W1201 12:02:48.825977447 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1201 12:02:48.836704803 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1201 12:02:48.842767705 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1201 12:02:48.846756114 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /wandb/offline-run-20251201_120256-vitqzwd9
  0%|          | 0/3753 [00:00<?, ?it/s]--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ------ Sanity Check at Step 0 ---

Sample 0 - ref_logp_chosen: -44.5
Sample 0 - pi_logp_chosen:  -44.146331787109375
Difference: 0.353668212890625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -100.5
Sample 0 - pi_logp_chosen:  -100.34402465820312
Difference: 0.155975341796875
---------------------------------
Sample 0 - ref_logp_chosen: -112.0
Sample 0 - pi_logp_chosen:  -111.70196533203125
Difference: 0.29803466796875
---------------------------------
Sample 0 - ref_logp_chosen: -234.0
Sample 0 - pi_logp_chosen:  -233.57894897460938
Difference: 0.421051025390625
---------------------------------
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -65.5
Sample 0 - pi_logp_chosen:  -65.91077423095703
Difference: -0.41077423095703125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -209.0
Sample 0 - ref_logp_chosen: -246.0
Sample 0 - pi_logp_chosen:  -208.26136779785156Sample 0 - pi_logp_chosen:  -246.4385986328125

Difference: -0.4385986328125
---------------------------------
Difference: 0.7386322021484375
---------------------------------
Sample 0 - ref_logp_chosen: -380.0
Sample 0 - pi_logp_chosen:  -379.3063659667969
Difference: 0.693634033203125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -70.0
Sample 0 - pi_logp_chosen:  -70.18619537353516
Difference: -0.18619537353515625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -167.0
Sample 0 - pi_logp_chosen:  -167.149169921875
Difference: -0.149169921875
---------------------------------
Sample 0 - ref_logp_chosen: -350.0
Sample 0 - pi_logp_chosen:  -349.3069152832031
Difference: 0.693084716796875
---------------------------------
Sample 0 - ref_logp_chosen: -452.0
Sample 0 - pi_logp_chosen:  -453.64239501953125
Difference: -1.64239501953125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -81.5
Sample 0 - pi_logp_chosen:  -81.75975036621094
Difference: -0.2597503662109375
---------------------------------
Sample 0 - ref_logp_chosen: -98.5
Sample 0 - pi_logp_chosen:  -98.78225708007812
Difference: -0.282257080078125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -251.0
Sample 0 - pi_logp_chosen:  -249.6898956298828
Difference: 1.3101043701171875
---------------------------------
Sample 0 - ref_logp_chosen: -368.0
Sample 0 - pi_logp_chosen:  -367.3233337402344
Difference: 0.676666259765625
---------------------------------
  0%|          | 1/3753 [00:04<4:15:43,  4.09s/it]{'loss': -0.3594, 'grad_norm': 2179.931396484375, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 2.1782100200653076, 'weight_chosen': 0.2668696641921997, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 0.6550521850585938, 'epoch': 0.0002664890073284477}
                                                  {'loss': -0.3594, 'grad_norm': 2179.931396484375, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 2.1782100200653076, 'weight_chosen': 0.2668696641921997, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 0.6550521850585938, 'epoch': 0.0}
  0%|          | 1/3753 [00:04<4:15:43,  4.09s/it]  0%|          | 2/3753 [00:08<4:09:58,  4.00s/it]  0%|          | 3/3753 [00:11<4:09:07,  3.99s/it]  0%|          | 4/3753 [00:15<4:05:08,  3.92s/it]  0%|          | 5/3753 [00:19<3:59:42,  3.84s/it]  0%|          | 6/3753 [00:24<4:19:12,  4.15s/it]  0%|          | 7/3753 [00:27<4:01:48,  3.87s/it]  0%|          | 8/3753 [00:31<3:54:11,  3.75s/it]  0%|          | 9/3753 [00:34<3:51:19,  3.71s/it]  0%|          | 10/3753 [00:38<3:49:19,  3.68s/it]{'loss': -0.3869, 'grad_norm': 2266.75537109375, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 1.0807299613952637, 'mean_ratio_rejected': 0.49859127402305603, 'weight_chosen': 0.2062666416168213, 'weight_rejected': 0.4163219630718231, 'kl_term_chosen': 0.038818359375, 'epoch': 0.002664890073284477}
                                                   {'loss': -0.3869, 'grad_norm': 2266.75537109375, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 1.0807299613952637, 'mean_ratio_rejected': 0.49859127402305603, 'weight_chosen': 0.2062666416168213, 'weight_rejected': 0.4163219630718231, 'kl_term_chosen': 0.038818359375, 'epoch': 0.0}
  0%|          | 10/3753 [00:38<3:49:19,  3.68s/it]  0%|          | 11/3753 [00:42<3:51:54,  3.72s/it]  0%|          | 12/3753 [00:45<3:55:14,  3.77s/it]  0%|          | 13/3753 [00:50<4:00:47,  3.86s/it]  0%|          | 14/3753 [00:53<3:57:46,  3.82s/it]  0%|          | 15/3753 [00:57<3:53:35,  3.75s/it]  0%|          | 16/3753 [01:00<3:47:41,  3.66s/it]  0%|          | 17/3753 [01:04<3:55:29,  3.78s/it]  0%|          | 18/3753 [01:08<3:54:28,  3.77s/it]  1%|          | 19/3753 [01:11<3:46:36,  3.64s/it]  1%|          | 20/3753 [01:15<3:43:09,  3.59s/it]{'loss': -0.369, 'grad_norm': 2242.0205078125, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 0.9786402583122253, 'mean_ratio_rejected': 1.5872663259506226, 'weight_chosen': 0.7433874011039734, 'weight_rejected': 0.29665425419807434, 'kl_term_chosen': -0.01079559326171875, 'epoch': 0.005329780146568954}
                                                   {'loss': -0.369, 'grad_norm': 2242.0205078125, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 0.9786402583122253, 'mean_ratio_rejected': 1.5872663259506226, 'weight_chosen': 0.7433874011039734, 'weight_rejected': 0.29665425419807434, 'kl_term_chosen': -0.01079559326171875, 'epoch': 0.01}
  1%|          | 20/3753 [01:15<3:43:09,  3.59s/it]  1%|          | 21/3753 [01:18<3:41:18,  3.56s/it]  1%|          | 22/3753 [01:22<3:50:11,  3.70s/it]  1%|          | 23/3753 [01:27<3:59:19,  3.85s/it]  1%|          | 24/3753 [01:30<3:48:41,  3.68s/it]  1%|          | 25/3753 [01:34<3:52:05,  3.74s/it]  1%|          | 26/3753 [01:37<3:33:25,  3.44s/it]  1%|          | 27/3753 [01:40<3:41:11,  3.56s/it]  1%|          | 28/3753 [01:44<3:40:32,  3.55s/it]  1%|          | 29/3753 [01:48<3:42:56,  3.59s/it]  1%|          | 30/3753 [01:51<3:44:39,  3.62s/it]{'loss': -0.1245, 'grad_norm': 2187.63232421875, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 2.0834317207336426, 'mean_ratio_rejected': 2.0868918895721436, 'weight_chosen': 0.2609429955482483, 'weight_rejected': 0.5987815260887146, 'kl_term_chosen': 0.3670082092285156, 'epoch': 0.007994670219853431}
                                                   {'loss': -0.1245, 'grad_norm': 2187.63232421875, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 2.0834317207336426, 'mean_ratio_rejected': 2.0868918895721436, 'weight_chosen': 0.2609429955482483, 'weight_rejected': 0.5987815260887146, 'kl_term_chosen': 0.3670082092285156, 'epoch': 0.01}
  1%|          | 30/3753 [01:51<3:44:39,  3.62s/it]  1%|          | 31/3753 [01:55<3:49:36,  3.70s/it]  1%|          | 32/3753 [01:58<3:38:29,  3.52s/it]  1%|          | 33/3753 [02:02<3:34:31,  3.46s/it]  1%|          | 34/3753 [02:05<3:41:23,  3.57s/it]  1%|          | 35/3753 [02:09<3:46:40,  3.66s/it]  1%|          | 36/3753 [02:13<3:48:56,  3.70s/it]  1%|          | 37/3753 [02:17<3:54:21,  3.78s/it]  1%|          | 38/3753 [02:21<3:49:03,  3.70s/it]  1%|          | 39/3753 [02:24<3:50:54,  3.73s/it]  1%|          | 40/3753 [02:29<4:00:02,  3.88s/it]{'loss': 0.6224, 'grad_norm': 5056.55029296875, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 2.9031929969787598, 'mean_ratio_rejected': 5.299204349517822, 'weight_chosen': 0.22488880157470703, 'weight_rejected': 0.1276526302099228, 'kl_term_chosen': 0.5329055786132812, 'epoch': 0.010659560293137908}
                                                   {'loss': 0.6224, 'grad_norm': 5056.55029296875, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 2.9031929969787598, 'mean_ratio_rejected': 5.299204349517822, 'weight_chosen': 0.22488880157470703, 'weight_rejected': 0.1276526302099228, 'kl_term_chosen': 0.5329055786132812, 'epoch': 0.01}
  1%|          | 40/3753 [02:29<4:00:02,  3.88s/it]  1%|          | 41/3753 [02:32<3:52:51,  3.76s/it]  1%|          | 42/3753 [02:35<3:37:00,  3.51s/it]  1%|          | 43/3753 [02:39<3:42:21,  3.60s/it]  1%|          | 44/3753 [02:42<3:41:12,  3.58s/it]  1%|          | 45/3753 [02:47<3:57:19,  3.84s/it]  1%|          | 46/3753 [02:51<3:59:42,  3.88s/it]  1%|▏         | 47/3753 [02:54<3:42:14,  3.60s/it]  1%|▏         | 48/3753 [02:57<3:45:48,  3.66s/it]  1%|▏         | 49/3753 [03:01<3:47:20,  3.68s/it]  1%|▏         | 50/3753 [03:04<3:38:23,  3.54s/it]{'loss': 0.5106, 'grad_norm': 1731.9083251953125, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 1.1920726299285889, 'mean_ratio_rejected': 2.336949586868286, 'weight_chosen': 0.7755448818206787, 'weight_rejected': 0.6851073503494263, 'kl_term_chosen': 0.08784675598144531, 'epoch': 0.013324450366422385}
                                                   {'loss': 0.5106, 'grad_norm': 1731.9083251953125, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 1.1920726299285889, 'mean_ratio_rejected': 2.336949586868286, 'weight_chosen': 0.7755448818206787, 'weight_rejected': 0.6851073503494263, 'kl_term_chosen': 0.08784675598144531, 'epoch': 0.01}
  1%|▏         | 50/3753 [03:05<3:38:23,  3.54s/it]  1%|▏         | 51/3753 [03:09<3:49:35,  3.72s/it]  1%|▏         | 52/3753 [03:12<3:50:33,  3.74s/it]  1%|▏         | 53/3753 [03:16<3:55:17,  3.82s/it]  1%|▏         | 54/3753 [03:20<3:48:59,  3.71s/it]  1%|▏         | 55/3753 [03:24<3:54:33,  3.81s/it]  1%|▏         | 56/3753 [03:28<3:56:02,  3.83s/it]  2%|▏         | 57/3753 [03:32<4:00:43,  3.91s/it]  2%|▏         | 58/3753 [03:35<3:52:20,  3.77s/it]  2%|▏         | 59/3753 [03:39<3:52:27,  3.78s/it]  2%|▏         | 60/3753 [03:42<3:40:47,  3.59s/it]{'loss': 0.3935, 'grad_norm': 2044.5947265625, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 0.9317540526390076, 'mean_ratio_rejected': 0.9736021757125854, 'weight_chosen': 0.06555777788162231, 'weight_rejected': 0.937210738658905, 'kl_term_chosen': -0.035343170166015625, 'epoch': 0.015989340439706862}
                                                   {'loss': 0.3935, 'grad_norm': 2044.5947265625, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 0.9317540526390076, 'mean_ratio_rejected': 0.9736021757125854, 'weight_chosen': 0.06555777788162231, 'weight_rejected': 0.937210738658905, 'kl_term_chosen': -0.035343170166015625, 'epoch': 0.02}
  2%|▏         | 60/3753 [03:42<3:40:47,  3.59s/it]  2%|▏         | 61/3753 [03:46<3:48:36,  3.72s/it]  2%|▏         | 62/3753 [03:50<3:55:27,  3.83s/it]  2%|▏         | 63/3753 [03:54<3:52:59,  3.79s/it]  2%|▏         | 64/3753 [03:58<3:51:48,  3.77s/it]  2%|▏         | 65/3753 [04:01<3:46:57,  3.69s/it]  2%|▏         | 66/3753 [04:06<3:57:38,  3.87s/it]  2%|▏         | 67/3753 [04:09<3:59:23,  3.90s/it]  2%|▏         | 68/3753 [04:13<3:58:03,  3.88s/it]  2%|▏         | 69/3753 [04:17<3:55:24,  3.83s/it]  2%|▏         | 70/3753 [04:21<3:51:05,  3.76s/it]{'loss': 0.2439, 'grad_norm': 1807.1409912109375, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 4.252836227416992, 'weight_chosen': -0.541926920413971, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 1.505157470703125, 'epoch': 0.018654230512991338}
                                                   {'loss': 0.2439, 'grad_norm': 1807.1409912109375, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 4.252836227416992, 'weight_chosen': -0.541926920413971, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 1.505157470703125, 'epoch': 0.02}
  2%|▏         | 70/3753 [04:21<3:51:05,  3.76s/it]  2%|▏         | 71/3753 [04:25<3:56:39,  3.86s/it]  2%|▏         | 72/3753 [04:29<4:01:50,  3.94s/it]  2%|▏         | 73/3753 [04:33<3:57:40,  3.88s/it]  2%|▏         | 74/3753 [04:36<3:57:34,  3.87s/it]  2%|▏         | 75/3753 [04:40<3:51:24,  3.77s/it]  2%|▏         | 76/3753 [04:44<3:52:05,  3.79s/it]  2%|▏         | 77/3753 [04:47<3:41:02,  3.61s/it]  2%|▏         | 78/3753 [04:51<3:46:54,  3.70s/it]  2%|▏         | 79/3753 [04:55<3:50:55,  3.77s/it]  2%|▏         | 80/3753 [04:59<3:51:57,  3.79s/it]{'loss': 0.3288, 'grad_norm': 2157.833251953125, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 3.2662150859832764, 'mean_ratio_rejected': 2.6545026302337646, 'weight_chosen': 0.3365928530693054, 'weight_rejected': 0.10230471193790436, 'kl_term_chosen': 0.5918159484863281, 'epoch': 0.021319120586275817}
                                                   {'loss': 0.3288, 'grad_norm': 2157.833251953125, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 3.2662150859832764, 'mean_ratio_rejected': 2.6545026302337646, 'weight_chosen': 0.3365928530693054, 'weight_rejected': 0.10230471193790436, 'kl_term_chosen': 0.5918159484863281, 'epoch': 0.02}
  2%|▏         | 80/3753 [04:59<3:51:57,  3.79s/it]  2%|▏         | 81/3753 [05:03<3:53:15,  3.81s/it]  2%|▏         | 82/3753 [05:06<3:53:10,  3.81s/it]  2%|▏         | 83/3753 [05:10<3:53:31,  3.82s/it]  2%|▏         | 84/3753 [05:14<3:54:33,  3.84s/it]  2%|▏         | 85/3753 [05:18<3:50:49,  3.78s/it]  2%|▏         | 86/3753 [05:21<3:42:10,  3.64s/it]  2%|▏         | 87/3753 [05:25<3:48:32,  3.74s/it]  2%|▏         | 88/3753 [05:29<3:46:21,  3.71s/it]  2%|▏         | 89/3753 [05:33<3:50:50,  3.78s/it]  2%|▏         | 90/3753 [05:36<3:50:30,  3.78s/it]{'loss': 0.7598, 'grad_norm': 1701.1468505859375, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 4.369862079620361, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.05186796188354492, 'weight_rejected': 0.15002880990505219, 'kl_term_chosen': 0.73736572265625, 'epoch': 0.023984010659560292}
                                                   {'loss': 0.7598, 'grad_norm': 1701.1468505859375, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 4.369862079620361, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.05186796188354492, 'weight_rejected': 0.15002880990505219, 'kl_term_chosen': 0.73736572265625, 'epoch': 0.02}
  2%|▏         | 90/3753 [05:36<3:50:30,  3.78s/it]  2%|▏         | 91/3753 [05:40<3:44:20,  3.68s/it]  2%|▏         | 92/3753 [05:43<3:39:20,  3.59s/it]  2%|▏         | 93/3753 [05:47<3:38:16,  3.58s/it]  3%|▎         | 94/3753 [05:50<3:40:33,  3.62s/it]  3%|▎         | 95/3753 [05:54<3:45:32,  3.70s/it]  3%|▎         | 96/3753 [05:58<3:48:11,  3.74s/it]  3%|▎         | 97/3753 [06:02<3:47:12,  3.73s/it]  3%|▎         | 98/3753 [06:06<3:48:36,  3.75s/it]  3%|▎         | 99/3753 [06:09<3:45:38,  3.71s/it]  3%|▎         | 100/3753 [06:13<3:40:25,  3.62s/it]{'loss': 0.548, 'grad_norm': 1978.38671875, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 0.7033544182777405, 'mean_ratio_rejected': 1.4633854627609253, 'weight_chosen': 0.8038983941078186, 'weight_rejected': 0.14414885640144348, 'kl_term_chosen': -0.1759471893310547, 'epoch': 0.02664890073284477}
                                                    {'loss': 0.548, 'grad_norm': 1978.38671875, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 0.7033544182777405, 'mean_ratio_rejected': 1.4633854627609253, 'weight_chosen': 0.8038983941078186, 'weight_rejected': 0.14414885640144348, 'kl_term_chosen': -0.1759471893310547, 'epoch': 0.03}
  3%|▎         | 100/3753 [06:13<3:40:25,  3.62s/it]  3%|▎         | 101/3753 [06:17<3:43:28,  3.67s/it]  3%|▎         | 102/3753 [06:20<3:41:52,  3.65s/it]  3%|▎         | 103/3753 [06:24<3:38:48,  3.60s/it]  3%|▎         | 104/3753 [06:27<3:43:17,  3.67s/it]  3%|▎         | 105/3753 [06:31<3:44:05,  3.69s/it]  3%|▎         | 106/3753 [06:35<3:48:41,  3.76s/it]  3%|▎         | 107/3753 [06:39<3:54:41,  3.86s/it]  3%|▎         | 108/3753 [06:43<3:55:45,  3.88s/it]  3%|▎         | 109/3753 [06:47<3:46:57,  3.74s/it]  3%|▎         | 110/3753 [06:50<3:42:32,  3.67s/it]{'loss': 0.6088, 'grad_norm': 1072.62109375, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 6.44563627243042, 'weight_chosen': -0.24133753776550293, 'weight_rejected': 0.04146226868033409, 'kl_term_chosen': 1.1550140380859375, 'epoch': 0.029313790806129246}
                                                    {'loss': 0.6088, 'grad_norm': 1072.62109375, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 6.44563627243042, 'weight_chosen': -0.24133753776550293, 'weight_rejected': 0.04146226868033409, 'kl_term_chosen': 1.1550140380859375, 'epoch': 0.03}
  3%|▎         | 110/3753 [06:50<3:42:32,  3.67s/it]  3%|▎         | 111/3753 [06:54<3:49:54,  3.79s/it]  3%|▎         | 112/3753 [06:58<3:44:48,  3.70s/it]  3%|▎         | 113/3753 [07:01<3:41:10,  3.65s/it]  3%|▎         | 114/3753 [07:05<3:43:18,  3.68s/it]  3%|▎         | 115/3753 [07:08<3:41:23,  3.65s/it]  3%|▎         | 116/3753 [07:13<3:50:49,  3.81s/it]  3%|▎         | 117/3753 [07:16<3:45:49,  3.73s/it]  3%|▎         | 118/3753 [07:20<3:49:27,  3.79s/it]  3%|▎         | 119/3753 [07:24<3:45:37,  3.73s/it]  3%|▎         | 120/3753 [07:28<3:48:47,  3.78s/it]{'loss': 0.721, 'grad_norm': 861.9705200195312, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 1.0304886102676392, 'mean_ratio_rejected': 0.28896787762641907, 'weight_chosen': 0.821537971496582, 'weight_rejected': 0.49502578377723694, 'kl_term_chosen': 0.015016555786132812, 'epoch': 0.031978680879413725}
                                                    {'loss': 0.721, 'grad_norm': 861.9705200195312, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 1.0304886102676392, 'mean_ratio_rejected': 0.28896787762641907, 'weight_chosen': 0.821537971496582, 'weight_rejected': 0.49502578377723694, 'kl_term_chosen': 0.015016555786132812, 'epoch': 0.03}
  3%|▎         | 120/3753 [07:28<3:48:47,  3.78s/it]  3%|▎         | 121/3753 [07:31<3:47:40,  3.76s/it]  3%|▎         | 122/3753 [07:35<3:51:13,  3.82s/it]  3%|▎         | 123/3753 [07:39<3:46:57,  3.75s/it]  3%|▎         | 124/3753 [07:42<3:44:24,  3.71s/it]  3%|▎         | 125/3753 [07:46<3:48:38,  3.78s/it]  3%|▎         | 126/3753 [07:50<3:52:13,  3.84s/it]  3%|▎         | 127/3753 [07:54<3:48:00,  3.77s/it]  3%|▎         | 128/3753 [07:58<3:45:41,  3.74s/it]  3%|▎         | 129/3753 [08:02<3:54:48,  3.89s/it]  3%|▎         | 130/3753 [08:06<3:51:11,  3.83s/it]{'loss': 0.9395, 'grad_norm': 2637.84765625, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.3396156430244446, 'weight_chosen': -0.9001619219779968, 'weight_rejected': 0.10970578342676163, 'kl_term_chosen': 1.1976318359375, 'epoch': 0.034643570952698204}
                                                    {'loss': 0.9395, 'grad_norm': 2637.84765625, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.3396156430244446, 'weight_chosen': -0.9001619219779968, 'weight_rejected': 0.10970578342676163, 'kl_term_chosen': 1.1976318359375, 'epoch': 0.03}
  3%|▎         | 130/3753 [08:06<3:51:11,  3.83s/it]  3%|▎         | 131/3753 [08:10<3:53:21,  3.87s/it]  4%|▎         | 132/3753 [08:13<3:40:03,  3.65s/it]  4%|▎         | 133/3753 [08:17<3:44:33,  3.72s/it]  4%|▎         | 134/3753 [08:20<3:45:19,  3.74s/it]  4%|▎         | 135/3753 [08:24<3:38:31,  3.62s/it]  4%|▎         | 136/3753 [08:27<3:40:30,  3.66s/it]  4%|▎         | 137/3753 [08:31<3:40:33,  3.66s/it]  4%|▎         | 138/3753 [08:35<3:45:48,  3.75s/it]  4%|▎         | 139/3753 [08:39<3:44:10,  3.72s/it]  4%|▎         | 140/3753 [08:42<3:40:50,  3.67s/it]{'loss': 0.7967, 'grad_norm': 1585.0438232421875, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.3908220529556274, 'weight_chosen': -0.4896252155303955, 'weight_rejected': 0.14706450700759888, 'kl_term_chosen': 1.3492889404296875, 'epoch': 0.037308461025982675}
                                                    {'loss': 0.7967, 'grad_norm': 1585.0438232421875, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.3908220529556274, 'weight_chosen': -0.4896252155303955, 'weight_rejected': 0.14706450700759888, 'kl_term_chosen': 1.3492889404296875, 'epoch': 0.04}
  4%|▎         | 140/3753 [08:42<3:40:50,  3.67s/it]  4%|▍         | 141/3753 [08:46<3:41:55,  3.69s/it]  4%|▍         | 142/3753 [08:50<3:45:17,  3.74s/it]  4%|▍         | 143/3753 [08:54<3:47:56,  3.79s/it]  4%|▍         | 144/3753 [08:58<3:53:45,  3.89s/it]  4%|▍         | 145/3753 [09:02<3:52:11,  3.86s/it]  4%|▍         | 146/3753 [09:06<3:56:53,  3.94s/it]  4%|▍         | 147/3753 [09:09<3:42:58,  3.71s/it]  4%|▍         | 148/3753 [09:13<3:45:43,  3.76s/it]  4%|▍         | 149/3753 [09:17<3:45:28,  3.75s/it]  4%|▍         | 150/3753 [09:21<3:50:18,  3.84s/it]{'loss': 1.3667, 'grad_norm': 1523.7020263671875, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 0.48364222049713135, 'mean_ratio_rejected': 0.17485381662845612, 'weight_chosen': 0.698664665222168, 'weight_rejected': 0.5903069972991943, 'kl_term_chosen': -0.3632049560546875, 'epoch': 0.039973351099267154}
                                                    {'loss': 1.3667, 'grad_norm': 1523.7020263671875, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 0.48364222049713135, 'mean_ratio_rejected': 0.17485381662845612, 'weight_chosen': 0.698664665222168, 'weight_rejected': 0.5903069972991943, 'kl_term_chosen': -0.3632049560546875, 'epoch': 0.04}
  4%|▍         | 150/3753 [09:21<3:50:18,  3.84s/it]  4%|▍         | 151/3753 [09:24<3:49:25,  3.82s/it]  4%|▍         | 152/3753 [09:28<3:45:30,  3.76s/it]  4%|▍         | 153/3753 [09:32<3:54:55,  3.92s/it]  4%|▍         | 154/3753 [09:36<3:43:52,  3.73s/it]  4%|▍         | 155/3753 [09:39<3:40:35,  3.68s/it]  4%|▍         | 156/3753 [09:43<3:45:02,  3.75s/it]  4%|▍         | 157/3753 [09:46<3:38:23,  3.64s/it]  4%|▍         | 158/3753 [09:51<3:49:56,  3.84s/it]  4%|▍         | 159/3753 [09:54<3:47:12,  3.79s/it]  4%|▍         | 160/3753 [09:58<3:51:52,  3.87s/it]{'loss': 1.1798, 'grad_norm': 1499.6119384765625, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 0.9377661347389221, 'mean_ratio_rejected': 1.5893385410308838, 'weight_chosen': 0.7121566534042358, 'weight_rejected': 0.3372035324573517, 'kl_term_chosen': -0.03212738037109375, 'epoch': 0.04263824117255163}
                                                    {'loss': 1.1798, 'grad_norm': 1499.6119384765625, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 0.9377661347389221, 'mean_ratio_rejected': 1.5893385410308838, 'weight_chosen': 0.7121566534042358, 'weight_rejected': 0.3372035324573517, 'kl_term_chosen': -0.03212738037109375, 'epoch': 0.04}
  4%|▍         | 160/3753 [09:59<3:51:52,  3.87s/it]  4%|▍         | 161/3753 [10:02<3:42:25,  3.72s/it]  4%|▍         | 162/3753 [10:05<3:40:10,  3.68s/it]  4%|▍         | 163/3753 [10:09<3:32:49,  3.56s/it]  4%|▍         | 164/3753 [10:13<3:47:02,  3.80s/it]  4%|▍         | 165/3753 [10:17<3:41:43,  3.71s/it]  4%|▍         | 166/3753 [10:20<3:36:28,  3.62s/it]  4%|▍         | 167/3753 [10:24<3:37:44,  3.64s/it]  4%|▍         | 168/3753 [10:28<3:47:58,  3.82s/it]  5%|▍         | 169/3753 [10:31<3:41:40,  3.71s/it]  5%|▍         | 170/3753 [10:35<3:37:31,  3.64s/it]{'loss': 1.3722, 'grad_norm': 803.98486328125, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 5.202977180480957, 'mean_ratio_rejected': 4.071046352386475, 'weight_chosen': 0.047731876373291016, 'weight_rejected': 0.13568955659866333, 'kl_term_chosen': 0.824615478515625, 'epoch': 0.04530313124583611}
                                                    {'loss': 1.3722, 'grad_norm': 803.98486328125, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 5.202977180480957, 'mean_ratio_rejected': 4.071046352386475, 'weight_chosen': 0.047731876373291016, 'weight_rejected': 0.13568955659866333, 'kl_term_chosen': 0.824615478515625, 'epoch': 0.05}
  5%|▍         | 170/3753 [10:35<3:37:31,  3.64s/it]  5%|▍         | 171/3753 [10:39<3:45:44,  3.78s/it]  5%|▍         | 172/3753 [10:43<3:49:30,  3.85s/it]  5%|▍         | 173/3753 [10:47<3:49:25,  3.85s/it]  5%|▍         | 174/3753 [10:51<3:48:32,  3.83s/it]  5%|▍         | 175/3753 [10:54<3:44:12,  3.76s/it]  5%|▍         | 176/3753 [10:58<3:40:54,  3.71s/it]  5%|▍         | 177/3753 [11:01<3:41:15,  3.71s/it]  5%|▍         | 178/3753 [11:05<3:42:32,  3.73s/it]  5%|▍         | 179/3753 [11:09<3:36:53,  3.64s/it]  5%|▍         | 180/3753 [11:12<3:33:05,  3.58s/it]{'loss': 1.9038, 'grad_norm': 1567.604736328125, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 4.300997734069824, 'weight_chosen': -0.42019855976104736, 'weight_rejected': 0.09268777817487717, 'kl_term_chosen': 1.3555450439453125, 'epoch': 0.047968021319120584}
                                                    {'loss': 1.9038, 'grad_norm': 1567.604736328125, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 4.300997734069824, 'weight_chosen': -0.42019855976104736, 'weight_rejected': 0.09268777817487717, 'kl_term_chosen': 1.3555450439453125, 'epoch': 0.05}
  5%|▍         | 180/3753 [11:12<3:33:05,  3.58s/it]  5%|▍         | 181/3753 [11:16<3:38:10,  3.66s/it]  5%|▍         | 182/3753 [11:20<3:43:53,  3.76s/it]  5%|▍         | 183/3753 [11:24<3:42:30,  3.74s/it]  5%|▍         | 184/3753 [11:28<3:49:16,  3.85s/it]  5%|▍         | 185/3753 [11:32<3:55:47,  3.96s/it]  5%|▍         | 186/3753 [11:36<3:51:12,  3.89s/it]  5%|▍         | 187/3753 [11:40<3:53:29,  3.93s/it]  5%|▌         | 188/3753 [11:44<3:54:39,  3.95s/it]  5%|▌         | 189/3753 [11:48<3:53:22,  3.93s/it]  5%|▌         | 190/3753 [11:51<3:52:03,  3.91s/it]{'loss': 1.4915, 'grad_norm': 1325.7081298828125, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 2.0651848316192627, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.5181872248649597, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 0.36260986328125, 'epoch': 0.05063291139240506}
                                                    {'loss': 1.4915, 'grad_norm': 1325.7081298828125, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 2.0651848316192627, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.5181872248649597, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 0.36260986328125, 'epoch': 0.05}
  5%|▌         | 190/3753 [11:52<3:52:03,  3.91s/it]  5%|▌         | 191/3753 [11:55<3:41:46,  3.74s/it]  5%|▌         | 192/3753 [11:58<3:35:27,  3.63s/it]  5%|▌         | 193/3753 [12:02<3:41:29,  3.73s/it]  5%|▌         | 194/3753 [12:06<3:37:56,  3.67s/it]  5%|▌         | 195/3753 [12:09<3:37:47,  3.67s/it]  5%|▌         | 196/3753 [12:13<3:38:21,  3.68s/it]  5%|▌         | 197/3753 [12:17<3:41:13,  3.73s/it]  5%|▌         | 198/3753 [12:20<3:36:09,  3.65s/it]  5%|▌         | 199/3753 [12:24<3:38:51,  3.69s/it]  5%|▌         | 200/3753 [12:28<3:45:16,  3.80s/it]{'loss': 2.2428, 'grad_norm': 1264.850830078125, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.9984905123710632, 'weight_chosen': -0.9727061986923218, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 1.9160537719726562, 'epoch': 0.05329780146568954}
                                                    {'loss': 2.2428, 'grad_norm': 1264.850830078125, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.9984905123710632, 'weight_chosen': -0.9727061986923218, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 1.9160537719726562, 'epoch': 0.05}
  5%|▌         | 200/3753 [12:28<3:45:16,  3.80s/it]  5%|▌         | 201/3753 [12:32<3:38:50,  3.70s/it]  5%|▌         | 202/3753 [12:35<3:34:25,  3.62s/it]  5%|▌         | 203/3753 [12:38<3:28:09,  3.52s/it]  5%|▌         | 204/3753 [12:42<3:31:44,  3.58s/it]  5%|▌         | 205/3753 [12:45<3:26:22,  3.49s/it]  5%|▌         | 206/3753 [12:49<3:30:15,  3.56s/it]  6%|▌         | 207/3753 [12:53<3:32:41,  3.60s/it]  6%|▌         | 208/3753 [12:57<3:35:17,  3.64s/it]  6%|▌         | 209/3753 [13:00<3:39:28,  3.72s/it]  6%|▌         | 210/3753 [13:04<3:43:32,  3.79s/it]{'loss': 2.8045, 'grad_norm': 1076.1416015625, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 0.7293306589126587, 'mean_ratio_rejected': 0.6844322085380554, 'weight_chosen': 0.976550817489624, 'weight_rejected': 0.15304215252399445, 'kl_term_chosen': -0.15781402587890625, 'epoch': 0.05596269153897402}
                                                    {'loss': 2.8045, 'grad_norm': 1076.1416015625, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 0.7293306589126587, 'mean_ratio_rejected': 0.6844322085380554, 'weight_chosen': 0.976550817489624, 'weight_rejected': 0.15304215252399445, 'kl_term_chosen': -0.15781402587890625, 'epoch': 0.06}
  6%|▌         | 210/3753 [13:05<3:43:32,  3.79s/it]  6%|▌         | 211/3753 [13:08<3:44:02,  3.80s/it]  6%|▌         | 212/3753 [13:12<3:39:27,  3.72s/it]  6%|▌         | 213/3753 [13:16<3:44:55,  3.81s/it]  6%|▌         | 214/3753 [13:20<3:44:07,  3.80s/it]  6%|▌         | 215/3753 [13:23<3:46:07,  3.83s/it]  6%|▌         | 216/3753 [13:27<3:45:17,  3.82s/it]  6%|▌         | 217/3753 [13:31<3:43:26,  3.79s/it]  6%|▌         | 218/3753 [13:35<3:48:40,  3.88s/it]  6%|▌         | 219/3753 [13:39<3:41:56,  3.77s/it]  6%|▌         | 220/3753 [13:42<3:41:39,  3.76s/it]{'loss': 2.3999, 'grad_norm': 2850.64404296875, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 7.012383460998535, 'weight_chosen': -0.6792656183242798, 'weight_rejected': 0.1200256198644638, 'kl_term_chosen': 1.360992431640625, 'epoch': 0.05862758161225849}
                                                    {'loss': 2.3999, 'grad_norm': 2850.64404296875, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 7.012383460998535, 'weight_chosen': -0.6792656183242798, 'weight_rejected': 0.1200256198644638, 'kl_term_chosen': 1.360992431640625, 'epoch': 0.06}
  6%|▌         | 220/3753 [13:42<3:41:39,  3.76s/it]  6%|▌         | 221/3753 [13:46<3:33:20,  3.62s/it]  6%|▌         | 222/3753 [13:49<3:33:32,  3.63s/it]  6%|▌         | 223/3753 [13:53<3:29:42,  3.56s/it]  6%|▌         | 224/3753 [13:56<3:25:34,  3.50s/it]  6%|▌         | 225/3753 [14:00<3:36:01,  3.67s/it]  6%|▌         | 226/3753 [14:03<3:30:10,  3.58s/it]  6%|▌         | 227/3753 [14:07<3:36:42,  3.69s/it]  6%|▌         | 228/3753 [14:11<3:29:31,  3.57s/it]  6%|▌         | 229/3753 [14:15<3:40:01,  3.75s/it]  6%|▌         | 230/3753 [14:19<3:44:06,  3.82s/it]{'loss': 2.3289, 'grad_norm': 1422.710205078125, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.3932487964630127, 'weight_rejected': 0.1490352898836136, 'kl_term_chosen': 1.3304595947265625, 'epoch': 0.06129247168554297}
                                                    {'loss': 2.3289, 'grad_norm': 1422.710205078125, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.3932487964630127, 'weight_rejected': 0.1490352898836136, 'kl_term_chosen': 1.3304595947265625, 'epoch': 0.06}
  6%|▌         | 230/3753 [14:19<3:44:06,  3.82s/it]  6%|▌         | 231/3753 [14:23<3:45:51,  3.85s/it]  6%|▌         | 232/3753 [14:27<3:46:40,  3.86s/it]  6%|▌         | 233/3753 [14:31<3:49:05,  3.90s/it]  6%|▌         | 234/3753 [14:34<3:44:32,  3.83s/it]  6%|▋         | 235/3753 [14:38<3:45:29,  3.85s/it]  6%|▋         | 236/3753 [14:42<3:45:57,  3.85s/it]  6%|▋         | 237/3753 [14:46<3:41:17,  3.78s/it]  6%|▋         | 238/3753 [14:49<3:41:39,  3.78s/it]  6%|▋         | 239/3753 [14:54<3:46:38,  3.87s/it]  6%|▋         | 240/3753 [14:57<3:39:13,  3.74s/it]{'loss': 2.5245, 'grad_norm': 1661.9013671875, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.58927583694458, 'weight_rejected': 0.17781086266040802, 'kl_term_chosen': -1.7581329345703125, 'epoch': 0.06395736175882745}
                                                    {'loss': 2.5245, 'grad_norm': 1661.9013671875, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.58927583694458, 'weight_rejected': 0.17781086266040802, 'kl_term_chosen': -1.7581329345703125, 'epoch': 0.06}
  6%|▋         | 240/3753 [14:57<3:39:13,  3.74s/it]  6%|▋         | 241/3753 [15:01<3:38:39,  3.74s/it]  6%|▋         | 242/3753 [15:04<3:39:22,  3.75s/it]  6%|▋         | 243/3753 [15:08<3:41:43,  3.79s/it]  7%|▋         | 244/3753 [15:12<3:43:04,  3.81s/it]  7%|▋         | 245/3753 [15:16<3:38:46,  3.74s/it]  7%|▋         | 246/3753 [15:19<3:35:10,  3.68s/it]  7%|▋         | 247/3753 [15:23<3:39:21,  3.75s/it]  7%|▋         | 248/3753 [15:27<3:31:25,  3.62s/it]  7%|▋         | 249/3753 [15:31<3:37:59,  3.73s/it]  7%|▋         | 250/3753 [15:35<3:44:10,  3.84s/it]{'loss': 3.988, 'grad_norm': 1032.9794921875, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.0615832805633545, 'weight_rejected': 0.14804719388484955, 'kl_term_chosen': -2.1667938232421875, 'epoch': 0.06662225183211193}
                                                    {'loss': 3.988, 'grad_norm': 1032.9794921875, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.0615832805633545, 'weight_rejected': 0.14804719388484955, 'kl_term_chosen': -2.1667938232421875, 'epoch': 0.07}
  7%|▋         | 250/3753 [15:35<3:44:10,  3.84s/it]  7%|▋         | 251/3753 [15:38<3:41:45,  3.80s/it]  7%|▋         | 252/3753 [15:42<3:35:18,  3.69s/it]  7%|▋         | 253/3753 [15:46<3:37:17,  3.73s/it]  7%|▋         | 254/3753 [15:49<3:29:56,  3.60s/it]  7%|▋         | 255/3753 [15:53<3:34:53,  3.69s/it]  7%|▋         | 256/3753 [15:56<3:28:57,  3.59s/it]  7%|▋         | 257/3753 [16:00<3:30:20,  3.61s/it]  7%|▋         | 258/3753 [16:03<3:30:01,  3.61s/it]  7%|▋         | 259/3753 [16:07<3:27:26,  3.56s/it]  7%|▋         | 260/3753 [16:11<3:34:16,  3.68s/it]{'loss': 8.0879, 'grad_norm': 1237.8331298828125, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 0.38418954610824585, 'mean_ratio_rejected': 0.14887620508670807, 'weight_chosen': 1.3655142784118652, 'weight_rejected': 0.13386748731136322, 'kl_term_chosen': -0.47830963134765625, 'epoch': 0.06928714190539641}
                                                    {'loss': 8.0879, 'grad_norm': 1237.8331298828125, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 0.38418954610824585, 'mean_ratio_rejected': 0.14887620508670807, 'weight_chosen': 1.3655142784118652, 'weight_rejected': 0.13386748731136322, 'kl_term_chosen': -0.47830963134765625, 'epoch': 0.07}
  7%|▋         | 260/3753 [16:11<3:34:16,  3.68s/it]  7%|▋         | 261/3753 [16:15<3:33:47,  3.67s/it]  7%|▋         | 262/3753 [16:18<3:32:45,  3.66s/it]  7%|▋         | 263/3753 [16:22<3:30:57,  3.63s/it]  7%|▋         | 264/3753 [16:25<3:31:32,  3.64s/it]  7%|▋         | 265/3753 [16:29<3:33:05,  3.67s/it]  7%|▋         | 266/3753 [16:33<3:35:34,  3.71s/it]  7%|▋         | 267/3753 [16:37<3:34:04,  3.68s/it]  7%|▋         | 268/3753 [16:40<3:39:03,  3.77s/it]  7%|▋         | 269/3753 [16:44<3:33:06,  3.67s/it]  7%|▋         | 270/3753 [16:48<3:41:45,  3.82s/it]{'loss': 11.7249, 'grad_norm': 2790.377197265625, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.768380641937256, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': 6.74395751953125, 'epoch': 0.07195203197868089}
                                                    {'loss': 11.7249, 'grad_norm': 2790.377197265625, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.768380641937256, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': 6.74395751953125, 'epoch': 0.07}
  7%|▋         | 270/3753 [16:48<3:41:45,  3.82s/it]  7%|▋         | 271/3753 [16:52<3:46:22,  3.90s/it]  7%|▋         | 272/3753 [16:56<3:50:04,  3.97s/it]  7%|▋         | 273/3753 [17:00<3:40:05,  3.79s/it]  7%|▋         | 274/3753 [17:03<3:35:53,  3.72s/it]  7%|▋         | 275/3753 [17:07<3:42:34,  3.84s/it]  7%|▋         | 276/3753 [17:11<3:39:17,  3.78s/it]  7%|▋         | 277/3753 [17:15<3:39:59,  3.80s/it]  7%|▋         | 278/3753 [17:18<3:31:14,  3.65s/it]  7%|▋         | 279/3753 [17:22<3:34:40,  3.71s/it]  7%|▋         | 280/3753 [17:25<3:30:23,  3.63s/it]{'loss': 15.3135, 'grad_norm': 477.4251403808594, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.2152559757232666, 'weight_rejected': 0.07263670116662979, 'kl_term_chosen': -1.2847976684570312, 'epoch': 0.07461692205196535}
                                                    {'loss': 15.3135, 'grad_norm': 477.4251403808594, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.2152559757232666, 'weight_rejected': 0.07263670116662979, 'kl_term_chosen': -1.2847976684570312, 'epoch': 0.07}
  7%|▋         | 280/3753 [17:26<3:30:23,  3.63s/it]  7%|▋         | 281/3753 [17:30<3:40:04,  3.80s/it]  8%|▊         | 282/3753 [17:34<3:41:55,  3.84s/it]  8%|▊         | 283/3753 [17:37<3:41:31,  3.83s/it]  8%|▊         | 284/3753 [17:41<3:36:29,  3.74s/it]  8%|▊         | 285/3753 [17:45<3:37:21,  3.76s/it]  8%|▊         | 286/3753 [17:48<3:35:24,  3.73s/it]  8%|▊         | 287/3753 [17:52<3:30:43,  3.65s/it]  8%|▊         | 288/3753 [17:56<3:36:18,  3.75s/it]  8%|▊         | 289/3753 [18:00<3:38:07,  3.78s/it]  8%|▊         | 290/3753 [18:04<3:40:54,  3.83s/it]{'loss': 12.7915, 'grad_norm': 1775.1112060546875, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 0.41518616676330566, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.1929807662963867, 'weight_rejected': 0.20946967601776123, 'kl_term_chosen': -0.43951416015625, 'epoch': 0.07728181212524983}
                                                    {'loss': 12.7915, 'grad_norm': 1775.1112060546875, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 0.41518616676330566, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.1929807662963867, 'weight_rejected': 0.20946967601776123, 'kl_term_chosen': -0.43951416015625, 'epoch': 0.08}
  8%|▊         | 290/3753 [18:04<3:40:54,  3.83s/it]  8%|▊         | 291/3753 [18:07<3:38:21,  3.78s/it]  8%|▊         | 292/3753 [18:11<3:37:52,  3.78s/it]  8%|▊         | 293/3753 [18:15<3:38:07,  3.78s/it]  8%|▊         | 294/3753 [18:19<3:39:18,  3.80s/it]  8%|▊         | 295/3753 [18:22<3:35:33,  3.74s/it]  8%|▊         | 296/3753 [18:26<3:30:57,  3.66s/it]  8%|▊         | 297/3753 [18:30<3:32:42,  3.69s/it]  8%|▊         | 298/3753 [18:34<3:38:06,  3.79s/it]  8%|▊         | 299/3753 [18:38<3:42:52,  3.87s/it]  8%|▊         | 300/3753 [18:41<3:35:42,  3.75s/it]{'loss': 3.1556, 'grad_norm': 1207.6796875, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.8005120754241943, 'weight_chosen': -0.8485479950904846, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 1.7726898193359375, 'epoch': 0.07994670219853431}
                                                    {'loss': 3.1556, 'grad_norm': 1207.6796875, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.8005120754241943, 'weight_chosen': -0.8485479950904846, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 1.7726898193359375, 'epoch': 0.08}
  8%|▊         | 300/3753 [18:41<3:35:42,  3.75s/it]  8%|▊         | 301/3753 [18:45<3:31:33,  3.68s/it]  8%|▊         | 302/3753 [18:49<3:39:03,  3.81s/it]  8%|▊         | 303/3753 [18:52<3:32:04,  3.69s/it]  8%|▊         | 304/3753 [18:55<3:26:29,  3.59s/it]  8%|▊         | 305/3753 [18:59<3:33:40,  3.72s/it]  8%|▊         | 306/3753 [19:03<3:34:40,  3.74s/it]  8%|▊         | 307/3753 [19:07<3:29:25,  3.65s/it]  8%|▊         | 308/3753 [19:11<3:33:03,  3.71s/it]  8%|▊         | 309/3753 [19:14<3:34:10,  3.73s/it]  8%|▊         | 310/3753 [19:18<3:37:41,  3.79s/it]{'loss': 9.5614, 'grad_norm': 513.0494384765625, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 3.0828263759613037, 'mean_ratio_rejected': 0.839358389377594, 'weight_chosen': 0.10074549913406372, 'weight_rejected': 0.22815649211406708, 'kl_term_chosen': 0.5629234313964844, 'epoch': 0.08261159227181879}
                                                    {'loss': 9.5614, 'grad_norm': 513.0494384765625, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 3.0828263759613037, 'mean_ratio_rejected': 0.839358389377594, 'weight_chosen': 0.10074549913406372, 'weight_rejected': 0.22815649211406708, 'kl_term_chosen': 0.5629234313964844, 'epoch': 0.08}
  8%|▊         | 310/3753 [19:18<3:37:41,  3.79s/it]  8%|▊         | 311/3753 [19:22<3:28:45,  3.64s/it]  8%|▊         | 312/3753 [19:25<3:21:37,  3.52s/it]  8%|▊         | 313/3753 [19:28<3:21:59,  3.52s/it]  8%|▊         | 314/3753 [19:32<3:31:00,  3.68s/it]  8%|▊         | 315/3753 [19:36<3:30:19,  3.67s/it]  8%|▊         | 316/3753 [19:40<3:27:55,  3.63s/it]  8%|▊         | 317/3753 [19:44<3:33:55,  3.74s/it]  8%|▊         | 318/3753 [19:47<3:31:42,  3.70s/it]  8%|▊         | 319/3753 [19:51<3:29:15,  3.66s/it]  9%|▊         | 320/3753 [19:55<3:33:35,  3.73s/it]{'loss': 24.673, 'grad_norm': 772.5106201171875, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.139357805252075, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': 3.076568603515625, 'epoch': 0.08527648234510327}
                                                    {'loss': 24.673, 'grad_norm': 772.5106201171875, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.139357805252075, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': 3.076568603515625, 'epoch': 0.09}
  9%|▊         | 320/3753 [19:55<3:33:35,  3.73s/it]  9%|▊         | 321/3753 [19:59<3:38:21,  3.82s/it]  9%|▊         | 322/3753 [20:02<3:38:04,  3.81s/it]  9%|▊         | 323/3753 [20:06<3:32:27,  3.72s/it]  9%|▊         | 324/3753 [20:10<3:35:06,  3.76s/it]  9%|▊         | 325/3753 [20:13<3:29:45,  3.67s/it]  9%|▊         | 326/3753 [20:17<3:30:25,  3.68s/it]  9%|▊         | 327/3753 [20:21<3:36:23,  3.79s/it]  9%|▊         | 328/3753 [20:25<3:36:45,  3.80s/it]  9%|▉         | 329/3753 [20:29<3:35:31,  3.78s/it]  9%|▉         | 330/3753 [20:32<3:35:02,  3.77s/it]{'loss': 1.4281, 'grad_norm': 1018.120361328125, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.355022668838501, 'weight_rejected': 0.22135066986083984, 'kl_term_chosen': -1.4934844970703125, 'epoch': 0.08794137241838774}
                                                    {'loss': 1.4281, 'grad_norm': 1018.120361328125, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.355022668838501, 'weight_rejected': 0.22135066986083984, 'kl_term_chosen': -1.4934844970703125, 'epoch': 0.09}
  9%|▉         | 330/3753 [20:32<3:35:02,  3.77s/it]  9%|▉         | 331/3753 [20:36<3:29:36,  3.68s/it]  9%|▉         | 332/3753 [20:40<3:37:15,  3.81s/it]  9%|▉         | 333/3753 [20:44<3:39:11,  3.85s/it]  9%|▉         | 334/3753 [20:47<3:33:49,  3.75s/it]  9%|▉         | 335/3753 [20:51<3:36:15,  3.80s/it]  9%|▉         | 336/3753 [20:54<3:24:52,  3.60s/it]  9%|▉         | 337/3753 [20:58<3:30:16,  3.69s/it]  9%|▉         | 338/3753 [21:02<3:31:12,  3.71s/it]  9%|▉         | 339/3753 [21:06<3:28:42,  3.67s/it]  9%|▉         | 340/3753 [21:09<3:30:23,  3.70s/it]{'loss': 7.4582, 'grad_norm': 574.569580078125, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 7.524652004241943, 'weight_rejected': 0.7826625108718872, 'kl_term_chosen': -7.281009674072266, 'epoch': 0.09060626249167222}
                                                    {'loss': 7.4582, 'grad_norm': 574.569580078125, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 7.524652004241943, 'weight_rejected': 0.7826625108718872, 'kl_term_chosen': -7.281009674072266, 'epoch': 0.09}
  9%|▉         | 340/3753 [21:09<3:30:23,  3.70s/it]  9%|▉         | 341/3753 [21:13<3:26:16,  3.63s/it]  9%|▉         | 342/3753 [21:16<3:26:06,  3.63s/it]  9%|▉         | 343/3753 [21:20<3:29:07,  3.68s/it]  9%|▉         | 344/3753 [21:24<3:24:21,  3.60s/it]  9%|▉         | 345/3753 [21:27<3:27:45,  3.66s/it]  9%|▉         | 346/3753 [21:31<3:26:38,  3.64s/it]  9%|▉         | 347/3753 [21:35<3:32:38,  3.75s/it]  9%|▉         | 348/3753 [21:39<3:32:08,  3.74s/it]  9%|▉         | 349/3753 [21:42<3:30:08,  3.70s/it]  9%|▉         | 350/3753 [21:46<3:33:00,  3.76s/it]{'loss': 15.7508, 'grad_norm': 1124.2659912109375, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.7285356521606445, 'weight_rejected': 0.2186693549156189, 'kl_term_chosen': 4.5629425048828125, 'epoch': 0.09327115256495669}
                                                    {'loss': 15.7508, 'grad_norm': 1124.2659912109375, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.7285356521606445, 'weight_rejected': 0.2186693549156189, 'kl_term_chosen': 4.5629425048828125, 'epoch': 0.09}
  9%|▉         | 350/3753 [21:46<3:33:00,  3.76s/it]  9%|▉         | 351/3753 [21:50<3:25:15,  3.62s/it]  9%|▉         | 352/3753 [21:53<3:18:59,  3.51s/it]  9%|▉         | 353/3753 [21:56<3:19:56,  3.53s/it]  9%|▉         | 354/3753 [22:00<3:22:23,  3.57s/it]  9%|▉         | 355/3753 [22:04<3:20:12,  3.54s/it]  9%|▉         | 356/3753 [22:08<3:27:40,  3.67s/it] 10%|▉         | 357/3753 [22:11<3:28:56,  3.69s/it] 10%|▉         | 358/3753 [22:15<3:28:29,  3.68s/it] 10%|▉         | 359/3753 [22:19<3:26:17,  3.65s/it] 10%|▉         | 360/3753 [22:22<3:30:12,  3.72s/it]{'loss': 13.8073, 'grad_norm': 91.24372100830078, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.316015243530273, 'weight_rejected': 0.16667540371418, 'kl_term_chosen': -3.771697998046875, 'epoch': 0.09593604263824117}
                                                    {'loss': 13.8073, 'grad_norm': 91.24372100830078, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.316015243530273, 'weight_rejected': 0.16667540371418, 'kl_term_chosen': -3.771697998046875, 'epoch': 0.1}
 10%|▉         | 360/3753 [22:22<3:30:12,  3.72s/it] 10%|▉         | 361/3753 [22:26<3:35:10,  3.81s/it] 10%|▉         | 362/3753 [22:30<3:30:52,  3.73s/it] 10%|▉         | 363/3753 [22:33<3:26:28,  3.65s/it] 10%|▉         | 364/3753 [22:37<3:28:41,  3.69s/it] 10%|▉         | 365/3753 [22:40<3:21:17,  3.56s/it] 10%|▉         | 366/3753 [22:44<3:18:31,  3.52s/it] 10%|▉         | 367/3753 [22:48<3:23:56,  3.61s/it] 10%|▉         | 368/3753 [22:51<3:25:00,  3.63s/it] 10%|▉         | 369/3753 [22:55<3:29:08,  3.71s/it] 10%|▉         | 370/3753 [22:59<3:29:12,  3.71s/it]{'loss': 4.3011, 'grad_norm': 504.0722961425781, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.439467430114746, 'weight_rejected': 0.20561504364013672, 'kl_term_chosen': -5.575157165527344, 'epoch': 0.09860093271152565}
                                                    {'loss': 4.3011, 'grad_norm': 504.0722961425781, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.439467430114746, 'weight_rejected': 0.20561504364013672, 'kl_term_chosen': -5.575157165527344, 'epoch': 0.1}
 10%|▉         | 370/3753 [22:59<3:29:12,  3.71s/it] 10%|▉         | 371/3753 [23:03<3:26:45,  3.67s/it] 10%|▉         | 372/3753 [23:07<3:34:45,  3.81s/it] 10%|▉         | 373/3753 [23:11<3:35:48,  3.83s/it] 10%|▉         | 374/3753 [23:14<3:31:43,  3.76s/it] 10%|▉         | 375/3753 [23:18<3:34:40,  3.81s/it] 10%|█         | 376/3753 [23:22<3:39:35,  3.90s/it] 10%|█         | 377/3753 [23:26<3:42:43,  3.96s/it] 10%|█         | 378/3753 [23:30<3:33:34,  3.80s/it] 10%|█         | 379/3753 [23:33<3:23:20,  3.62s/it] 10%|█         | 380/3753 [23:37<3:29:12,  3.72s/it]{'loss': 8.6196, 'grad_norm': 1039.115234375, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.09733247756958, 'weight_rejected': 0.02595735713839531, 'kl_term_chosen': 5.0576934814453125, 'epoch': 0.10126582278481013}
                                                    {'loss': 8.6196, 'grad_norm': 1039.115234375, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.09733247756958, 'weight_rejected': 0.02595735713839531, 'kl_term_chosen': 5.0576934814453125, 'epoch': 0.1}
 10%|█         | 380/3753 [23:37<3:29:12,  3.72s/it] 10%|█         | 381/3753 [23:41<3:30:57,  3.75s/it] 10%|█         | 382/3753 [23:44<3:27:32,  3.69s/it] 10%|█         | 383/3753 [23:48<3:30:17,  3.74s/it] 10%|█         | 384/3753 [23:52<3:34:42,  3.82s/it] 10%|█         | 385/3753 [23:56<3:38:37,  3.89s/it] 10%|█         | 386/3753 [24:00<3:32:53,  3.79s/it] 10%|█         | 387/3753 [24:03<3:29:17,  3.73s/it] 10%|█         | 388/3753 [24:07<3:31:29,  3.77s/it] 10%|█         | 389/3753 [24:11<3:32:40,  3.79s/it] 10%|█         | 390/3753 [24:15<3:30:31,  3.76s/it]{'loss': 12.4107, 'grad_norm': 974.8528442382812, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.11977881193161011, 'weight_chosen': 2.1700358390808105, 'weight_rejected': 0.8164063692092896, 'kl_term_chosen': -1.5312004089355469, 'epoch': 0.1039307128580946}
                                                    {'loss': 12.4107, 'grad_norm': 974.8528442382812, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.11977881193161011, 'weight_chosen': 2.1700358390808105, 'weight_rejected': 0.8164063692092896, 'kl_term_chosen': -1.5312004089355469, 'epoch': 0.1}
 10%|█         | 390/3753 [24:15<3:30:31,  3.76s/it] 10%|█         | 391/3753 [24:18<3:29:04,  3.73s/it] 10%|█         | 392/3753 [24:22<3:23:42,  3.64s/it] 10%|█         | 393/3753 [24:26<3:25:33,  3.67s/it] 10%|█         | 394/3753 [24:30<3:30:23,  3.76s/it] 11%|█         | 395/3753 [24:34<3:35:02,  3.84s/it] 11%|█         | 396/3753 [24:38<3:37:24,  3.89s/it] 11%|█         | 397/3753 [24:41<3:28:59,  3.74s/it] 11%|█         | 398/3753 [24:44<3:21:41,  3.61s/it] 11%|█         | 399/3753 [24:48<3:27:20,  3.71s/it] 11%|█         | 400/3753 [24:52<3:20:22,  3.59s/it]{'loss': 16.9525, 'grad_norm': 806.4555053710938, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 3.8122026920318604, 'mean_ratio_rejected': 0.48433640599250793, 'weight_chosen': 0.02602750062942505, 'weight_rejected': 0.25091278553009033, 'kl_term_chosen': 0.6691036224365234, 'epoch': 0.10659560293137908}
                                                    {'loss': 16.9525, 'grad_norm': 806.4555053710938, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 3.8122026920318604, 'mean_ratio_rejected': 0.48433640599250793, 'weight_chosen': 0.02602750062942505, 'weight_rejected': 0.25091278553009033, 'kl_term_chosen': 0.6691036224365234, 'epoch': 0.11}
 11%|█         | 400/3753 [24:52<3:20:22,  3.59s/it] 11%|█         | 401/3753 [24:55<3:24:29,  3.66s/it] 11%|█         | 402/3753 [24:59<3:28:38,  3.74s/it] 11%|█         | 403/3753 [25:02<3:20:01,  3.58s/it] 11%|█         | 404/3753 [25:06<3:23:51,  3.65s/it] 11%|█         | 405/3753 [25:10<3:19:59,  3.58s/it] 11%|█         | 406/3753 [25:14<3:26:31,  3.70s/it] 11%|█         | 407/3753 [25:17<3:20:43,  3.60s/it] 11%|█         | 408/3753 [25:21<3:25:03,  3.68s/it] 11%|█         | 409/3753 [25:25<3:29:09,  3.75s/it] 11%|█         | 410/3753 [25:28<3:27:20,  3.72s/it]{'loss': 7.6941, 'grad_norm': 679.8385620117188, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.619913578033447, 'weight_rejected': 0.28776782751083374, 'kl_term_chosen': -4.9730072021484375, 'epoch': 0.10926049300466356}
                                                    {'loss': 7.6941, 'grad_norm': 679.8385620117188, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.619913578033447, 'weight_rejected': 0.28776782751083374, 'kl_term_chosen': -4.9730072021484375, 'epoch': 0.11}
 11%|█         | 410/3753 [25:29<3:27:20,  3.72s/it] 11%|█         | 411/3753 [25:33<3:33:13,  3.83s/it] 11%|█         | 412/3753 [25:36<3:33:30,  3.83s/it] 11%|█         | 413/3753 [25:40<3:37:01,  3.90s/it] 11%|█         | 414/3753 [25:44<3:38:43,  3.93s/it] 11%|█         | 415/3753 [25:48<3:36:51,  3.90s/it] 11%|█         | 416/3753 [25:52<3:40:01,  3.96s/it] 11%|█         | 417/3753 [25:56<3:37:16,  3.91s/it] 11%|█         | 418/3753 [26:00<3:32:37,  3.83s/it] 11%|█         | 419/3753 [26:03<3:29:50,  3.78s/it] 11%|█         | 420/3753 [26:07<3:31:11,  3.80s/it]{'loss': 35.3286, 'grad_norm': 861.761474609375, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 0.3846910893917084, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.1290122270584106, 'weight_rejected': 0.2727987766265869, 'kl_term_chosen': -0.4776573181152344, 'epoch': 0.11192538307794804}
                                                    {'loss': 35.3286, 'grad_norm': 861.761474609375, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 0.3846910893917084, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.1290122270584106, 'weight_rejected': 0.2727987766265869, 'kl_term_chosen': -0.4776573181152344, 'epoch': 0.11}
 11%|█         | 420/3753 [26:07<3:31:11,  3.80s/it] 11%|█         | 421/3753 [26:11<3:25:30,  3.70s/it] 11%|█         | 422/3753 [26:15<3:27:31,  3.74s/it] 11%|█▏        | 423/3753 [26:18<3:26:55,  3.73s/it] 11%|█▏        | 424/3753 [26:21<3:15:57,  3.53s/it] 11%|█▏        | 425/3753 [26:25<3:21:35,  3.63s/it] 11%|█▏        | 426/3753 [26:29<3:15:37,  3.53s/it] 11%|█▏        | 427/3753 [26:33<3:25:35,  3.71s/it] 11%|█▏        | 428/3753 [26:37<3:30:32,  3.80s/it] 11%|█▏        | 429/3753 [26:40<3:30:14,  3.80s/it] 11%|█▏        | 430/3753 [26:44<3:26:56,  3.74s/it]{'loss': 31.3981, 'grad_norm': 451.3595886230469, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 24.006549835205078, 'weight_rejected': 0.27125170826911926, 'kl_term_chosen': -23.44293212890625, 'epoch': 0.1145902731512325}
                                                    {'loss': 31.3981, 'grad_norm': 451.3595886230469, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 24.006549835205078, 'weight_rejected': 0.27125170826911926, 'kl_term_chosen': -23.44293212890625, 'epoch': 0.11}
 11%|█▏        | 430/3753 [26:44<3:26:56,  3.74s/it] 11%|█▏        | 431/3753 [26:48<3:24:24,  3.69s/it] 12%|█▏        | 432/3753 [26:52<3:29:16,  3.78s/it] 12%|█▏        | 433/3753 [26:55<3:29:41,  3.79s/it] 12%|█▏        | 434/3753 [26:59<3:28:06,  3.76s/it] 12%|█▏        | 435/3753 [27:03<3:23:23,  3.68s/it] 12%|█▏        | 436/3753 [27:07<3:29:51,  3.80s/it] 12%|█▏        | 437/3753 [27:10<3:19:52,  3.62s/it] 12%|█▏        | 438/3753 [27:13<3:16:31,  3.56s/it] 12%|█▏        | 439/3753 [27:17<3:25:48,  3.73s/it] 12%|█▏        | 440/3753 [27:21<3:18:57,  3.60s/it]{'loss': 8.0855, 'grad_norm': 0.0, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.344546914100647, 'weight_rejected': 0.048136770725250244, 'kl_term_chosen': 1.2991943359375, 'epoch': 0.11725516322451698}
                                                    {'loss': 8.0855, 'grad_norm': 0.0, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.344546914100647, 'weight_rejected': 0.048136770725250244, 'kl_term_chosen': 1.2991943359375, 'epoch': 0.12}
 12%|█▏        | 440/3753 [27:21<3:18:57,  3.60s/it] 12%|█▏        | 441/3753 [27:24<3:17:39,  3.58s/it] 12%|█▏        | 442/3753 [27:28<3:23:43,  3.69s/it] 12%|█▏        | 443/3753 [27:31<3:03:13,  3.32s/it] 12%|█▏        | 444/3753 [27:34<3:10:17,  3.45s/it] 12%|█▏        | 445/3753 [27:38<3:06:58,  3.39s/it] 12%|█▏        | 446/3753 [27:41<3:11:54,  3.48s/it] 12%|█▏        | 447/3753 [27:45<3:13:32,  3.51s/it] 12%|█▏        | 448/3753 [27:48<3:08:56,  3.43s/it] 12%|█▏        | 449/3753 [27:52<3:16:23,  3.57s/it] 12%|█▏        | 450/3753 [27:55<3:12:50,  3.50s/it]{'loss': 10.2271, 'grad_norm': 72.4171371459961, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.889603614807129, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 6.7829132080078125, 'epoch': 0.11992005329780146}
                                                    {'loss': 10.2271, 'grad_norm': 72.4171371459961, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.889603614807129, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 6.7829132080078125, 'epoch': 0.12}
 12%|█▏        | 450/3753 [27:56<3:12:50,  3.50s/it] 12%|█▏        | 451/3753 [27:59<3:14:15,  3.53s/it] 12%|█▏        | 452/3753 [28:03<3:23:18,  3.70s/it] 12%|█▏        | 453/3753 [28:07<3:19:43,  3.63s/it] 12%|█▏        | 454/3753 [28:10<3:22:42,  3.69s/it] 12%|█▏        | 455/3753 [28:15<3:31:32,  3.85s/it] 12%|█▏        | 456/3753 [28:18<3:26:54,  3.77s/it] 12%|█▏        | 457/3753 [28:22<3:27:31,  3.78s/it] 12%|█▏        | 458/3753 [28:26<3:27:37,  3.78s/it] 12%|█▏        | 459/3753 [28:30<3:27:00,  3.77s/it] 12%|█▏        | 460/3753 [28:34<3:32:00,  3.86s/it]{'loss': 16.8314, 'grad_norm': 995.395751953125, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 0.14096498489379883, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.898102045059204, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': -0.9796218872070312, 'epoch': 0.12258494337108594}
                                                    {'loss': 16.8314, 'grad_norm': 995.395751953125, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 0.14096498489379883, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.898102045059204, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': -0.9796218872070312, 'epoch': 0.12}
 12%|█▏        | 460/3753 [28:34<3:32:00,  3.86s/it] 12%|█▏        | 461/3753 [28:37<3:26:14,  3.76s/it] 12%|█▏        | 462/3753 [28:40<3:10:18,  3.47s/it] 12%|█▏        | 463/3753 [28:44<3:18:14,  3.62s/it] 12%|█▏        | 464/3753 [28:48<3:18:31,  3.62s/it] 12%|█▏        | 465/3753 [28:51<3:13:49,  3.54s/it] 12%|█▏        | 466/3753 [28:55<3:18:11,  3.62s/it] 12%|█▏        | 467/3753 [28:59<3:21:11,  3.67s/it] 12%|█▏        | 468/3753 [29:02<3:25:49,  3.76s/it] 12%|█▏        | 469/3753 [29:06<3:25:46,  3.76s/it] 13%|█▎        | 470/3753 [29:10<3:20:31,  3.66s/it]{'loss': 29.3767, 'grad_norm': 81.01374816894531, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -9.0818452835083, 'weight_rejected': 0.08151976019144058, 'kl_term_chosen': 10.026840209960938, 'epoch': 0.1252498334443704}
                                                    {'loss': 29.3767, 'grad_norm': 81.01374816894531, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -9.0818452835083, 'weight_rejected': 0.08151976019144058, 'kl_term_chosen': 10.026840209960938, 'epoch': 0.13}
 13%|█▎        | 470/3753 [29:10<3:20:31,  3.66s/it] 13%|█▎        | 471/3753 [29:14<3:25:02,  3.75s/it] 13%|█▎        | 472/3753 [29:17<3:21:55,  3.69s/it] 13%|█▎        | 473/3753 [29:20<3:10:06,  3.48s/it] 13%|█▎        | 474/3753 [29:24<3:18:58,  3.64s/it] 13%|█▎        | 475/3753 [29:28<3:15:11,  3.57s/it] 13%|█▎        | 476/3753 [29:31<3:10:28,  3.49s/it] 13%|█▎        | 477/3753 [29:35<3:13:21,  3.54s/it] 13%|█▎        | 478/3753 [29:39<3:20:14,  3.67s/it] 13%|█▎        | 479/3753 [29:42<3:20:56,  3.68s/it] 13%|█▎        | 480/3753 [29:46<3:30:15,  3.85s/it]{'loss': 28.8889, 'grad_norm': 116.75199127197266, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 13.337116241455078, 'weight_rejected': 0.23792988061904907, 'kl_term_chosen': -12.760574340820312, 'epoch': 0.1279147235176549}
                                                    {'loss': 28.8889, 'grad_norm': 116.75199127197266, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 13.337116241455078, 'weight_rejected': 0.23792988061904907, 'kl_term_chosen': -12.760574340820312, 'epoch': 0.13}
 13%|█▎        | 480/3753 [29:47<3:30:15,  3.85s/it] 13%|█▎        | 481/3753 [29:50<3:28:15,  3.82s/it] 13%|█▎        | 482/3753 [29:54<3:22:52,  3.72s/it] 13%|█▎        | 483/3753 [29:57<3:17:55,  3.63s/it] 13%|█▎        | 484/3753 [30:01<3:19:14,  3.66s/it] 13%|█▎        | 485/3753 [30:04<3:17:37,  3.63s/it] 13%|█▎        | 486/3753 [30:08<3:18:33,  3.65s/it] 13%|█▎        | 487/3753 [30:12<3:23:18,  3.74s/it] 13%|█▎        | 488/3753 [30:15<3:18:18,  3.64s/it] 13%|█▎        | 489/3753 [30:19<3:20:54,  3.69s/it] 13%|█▎        | 490/3753 [30:23<3:22:37,  3.73s/it]{'loss': 45.4008, 'grad_norm': 569.4349975585938, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.45687198638916, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': -5.5126953125, 'epoch': 0.13057961359093936}
                                                    {'loss': 45.4008, 'grad_norm': 569.4349975585938, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.45687198638916, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': -5.5126953125, 'epoch': 0.13}
 13%|█▎        | 490/3753 [30:23<3:22:37,  3.73s/it] 13%|█▎        | 491/3753 [30:27<3:26:20,  3.80s/it] 13%|█▎        | 492/3753 [30:31<3:27:08,  3.81s/it] 13%|█▎        | 493/3753 [30:35<3:29:09,  3.85s/it] 13%|█▎        | 494/3753 [30:38<3:21:26,  3.71s/it] 13%|█▎        | 495/3753 [30:42<3:18:29,  3.66s/it] 13%|█▎        | 496/3753 [30:46<3:23:58,  3.76s/it] 13%|█▎        | 497/3753 [30:50<3:24:47,  3.77s/it] 13%|█▎        | 498/3753 [30:53<3:20:01,  3.69s/it] 13%|█▎        | 499/3753 [30:57<3:21:23,  3.71s/it] 13%|█▎        | 500/3753 [31:01<3:20:56,  3.71s/it]{'loss': 48.2264, 'grad_norm': 751.6030883789062, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.9317825436592102, 'weight_chosen': -5.47255802154541, 'weight_rejected': 0.22270013391971588, 'kl_term_chosen': 6.114990234375, 'epoch': 0.13324450366422386}
                                                    {'loss': 48.2264, 'grad_norm': 751.6030883789062, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.9317825436592102, 'weight_chosen': -5.47255802154541, 'weight_rejected': 0.22270013391971588, 'kl_term_chosen': 6.114990234375, 'epoch': 0.13}
 13%|█▎        | 500/3753 [31:01<3:20:56,  3.71s/it] 13%|█▎        | 501/3753 [31:05<3:29:58,  3.87s/it] 13%|█▎        | 502/3753 [31:09<3:27:58,  3.84s/it] 13%|█▎        | 503/3753 [31:12<3:27:46,  3.84s/it] 13%|█▎        | 504/3753 [31:16<3:22:30,  3.74s/it] 13%|█▎        | 505/3753 [31:19<3:17:11,  3.64s/it] 13%|█▎        | 506/3753 [31:23<3:15:04,  3.60s/it] 14%|█▎        | 507/3753 [31:27<3:17:31,  3.65s/it] 14%|█▎        | 508/3753 [31:31<3:24:06,  3.77s/it] 14%|█▎        | 509/3753 [31:34<3:22:18,  3.74s/it] 14%|█▎        | 510/3753 [31:38<3:22:29,  3.75s/it]{'loss': 27.2973, 'grad_norm': 861.7540893554688, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.9039734601974487, 'weight_rejected': 0.03358950838446617, 'kl_term_chosen': 2.859954833984375, 'epoch': 0.13590939373750832}
                                                    {'loss': 27.2973, 'grad_norm': 861.7540893554688, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.9039734601974487, 'weight_rejected': 0.03358950838446617, 'kl_term_chosen': 2.859954833984375, 'epoch': 0.14}
 14%|█▎        | 510/3753 [31:38<3:22:29,  3.75s/it] 14%|█▎        | 511/3753 [31:42<3:19:15,  3.69s/it] 14%|█▎        | 512/3753 [31:45<3:14:47,  3.61s/it] 14%|█▎        | 513/3753 [31:49<3:14:59,  3.61s/it] 14%|█▎        | 514/3753 [31:53<3:22:25,  3.75s/it] 14%|█▎        | 515/3753 [31:56<3:21:34,  3.74s/it] 14%|█▎        | 516/3753 [32:00<3:19:40,  3.70s/it] 14%|█▍        | 517/3753 [32:03<3:09:46,  3.52s/it] 14%|█▍        | 518/3753 [32:07<3:11:07,  3.54s/it] 14%|█▍        | 519/3753 [32:11<3:15:09,  3.62s/it] 14%|█▍        | 520/3753 [32:15<3:25:10,  3.81s/it]{'loss': 14.5588, 'grad_norm': 479.9527893066406, 'learning_rate': 9.955821687527552e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.827899217605591, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 4.750938415527344, 'epoch': 0.13857428381079281}
                                                    {'loss': 14.5588, 'grad_norm': 479.9527893066406, 'learning_rate': 9.955821687527552e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.827899217605591, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 4.750938415527344, 'epoch': 0.14}
 14%|█▍        | 520/3753 [32:15<3:25:10,  3.81s/it] 14%|█▍        | 521/3753 [32:18<3:22:01,  3.75s/it] 14%|█▍        | 522/3753 [32:22<3:22:27,  3.76s/it] 14%|█▍        | 523/3753 [32:26<3:26:50,  3.84s/it] 14%|█▍        | 524/3753 [32:30<3:26:25,  3.84s/it] 14%|█▍        | 525/3753 [32:34<3:27:30,  3.86s/it] 14%|█▍        | 526/3753 [32:37<3:19:19,  3.71s/it] 14%|█▍        | 527/3753 [32:41<3:16:01,  3.65s/it] 14%|█▍        | 528/3753 [32:44<3:09:12,  3.52s/it] 14%|█▍        | 529/3753 [32:47<3:08:09,  3.50s/it] 14%|█▍        | 530/3753 [32:51<3:15:02,  3.63s/it]{'loss': 15.5749, 'grad_norm': 216.06336975097656, 'learning_rate': 9.94943765952491e-07, 'mean_ratio_chosen': 0.10621696710586548, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.5570372343063354, 'weight_rejected': 0.332852303981781, 'kl_term_chosen': -1.1211357116699219, 'epoch': 0.14123917388407728}
                                                    {'loss': 15.5749, 'grad_norm': 216.06336975097656, 'learning_rate': 9.94943765952491e-07, 'mean_ratio_chosen': 0.10621696710586548, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.5570372343063354, 'weight_rejected': 0.332852303981781, 'kl_term_chosen': -1.1211357116699219, 'epoch': 0.14}
 14%|█▍        | 530/3753 [32:52<3:15:02,  3.63s/it] 14%|█▍        | 531/3753 [32:55<3:15:19,  3.64s/it] 14%|█▍        | 532/3753 [32:59<3:13:36,  3.61s/it] 14%|█▍        | 533/3753 [33:02<3:12:54,  3.59s/it] 14%|█▍        | 534/3753 [33:06<3:09:08,  3.53s/it] 14%|█▍        | 535/3753 [33:09<3:13:26,  3.61s/it] 14%|█▍        | 536/3753 [33:13<3:16:13,  3.66s/it] 14%|█▍        | 537/3753 [33:17<3:27:09,  3.86s/it] 14%|█▍        | 538/3753 [33:21<3:15:34,  3.65s/it] 14%|█▍        | 539/3753 [33:24<3:12:29,  3.59s/it] 14%|█▍        | 540/3753 [33:27<3:03:45,  3.43s/it]{'loss': 21.7628, 'grad_norm': 109.96321868896484, 'learning_rate': 9.942625289827702e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.59511661529541, 'weight_rejected': 0.1233656257390976, 'kl_term_chosen': 9.52352523803711, 'epoch': 0.14390406395736177}
                                                    {'loss': 21.7628, 'grad_norm': 109.96321868896484, 'learning_rate': 9.942625289827702e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.59511661529541, 'weight_rejected': 0.1233656257390976, 'kl_term_chosen': 9.52352523803711, 'epoch': 0.14}
 14%|█▍        | 540/3753 [33:27<3:03:45,  3.43s/it] 14%|█▍        | 541/3753 [33:31<3:05:58,  3.47s/it] 14%|█▍        | 542/3753 [33:35<3:16:32,  3.67s/it] 14%|█▍        | 543/3753 [33:38<3:07:52,  3.51s/it] 14%|█▍        | 544/3753 [33:42<3:13:35,  3.62s/it] 15%|█▍        | 545/3753 [33:45<3:10:46,  3.57s/it] 15%|█▍        | 546/3753 [33:49<3:10:43,  3.57s/it] 15%|█▍        | 547/3753 [33:53<3:14:56,  3.65s/it] 15%|█▍        | 548/3753 [33:57<3:22:59,  3.80s/it] 15%|█▍        | 549/3753 [34:00<3:16:39,  3.68s/it] 15%|█▍        | 550/3753 [34:04<3:21:16,  3.77s/it]{'loss': 46.0434, 'grad_norm': 0.0, 'learning_rate': 9.935385168002298e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -12.550470352172852, 'weight_rejected': 0.07585817575454712, 'kl_term_chosen': 13.48675537109375, 'epoch': 0.14656895403064624}
                                                    {'loss': 46.0434, 'grad_norm': 0.0, 'learning_rate': 9.935385168002298e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -12.550470352172852, 'weight_rejected': 0.07585817575454712, 'kl_term_chosen': 13.48675537109375, 'epoch': 0.15}
 15%|█▍        | 550/3753 [34:04<3:21:16,  3.77s/it] 15%|█▍        | 551/3753 [34:08<3:22:21,  3.79s/it] 15%|█▍        | 552/3753 [34:12<3:19:26,  3.74s/it] 15%|█▍        | 553/3753 [34:16<3:24:36,  3.84s/it] 15%|█▍        | 554/3753 [34:20<3:23:41,  3.82s/it] 15%|█▍        | 555/3753 [34:23<3:21:56,  3.79s/it] 15%|█▍        | 556/3753 [34:27<3:17:41,  3.71s/it] 15%|█▍        | 557/3753 [34:30<3:12:49,  3.62s/it] 15%|█▍        | 558/3753 [34:34<3:22:08,  3.80s/it] 15%|█▍        | 559/3753 [34:38<3:26:00,  3.87s/it] 15%|█▍        | 560/3753 [34:42<3:20:49,  3.77s/it]{'loss': 50.373, 'grad_norm': 131.83094787597656, 'learning_rate': 9.927717920634233e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -13.62822437286377, 'weight_rejected': 0.18713268637657166, 'kl_term_chosen': 14.506538391113281, 'epoch': 0.1492338441039307}
                                                    {'loss': 50.373, 'grad_norm': 131.83094787597656, 'learning_rate': 9.927717920634233e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -13.62822437286377, 'weight_rejected': 0.18713268637657166, 'kl_term_chosen': 14.506538391113281, 'epoch': 0.15}
 15%|█▍        | 560/3753 [34:42<3:20:49,  3.77s/it] 15%|█▍        | 561/3753 [34:46<3:18:43,  3.74s/it] 15%|█▍        | 562/3753 [34:49<3:15:32,  3.68s/it] 15%|█▌        | 563/3753 [34:53<3:21:33,  3.79s/it] 15%|█▌        | 564/3753 [34:57<3:26:00,  3.88s/it] 15%|█▌        | 565/3753 [35:01<3:19:07,  3.75s/it] 15%|█▌        | 566/3753 [35:04<3:14:33,  3.66s/it] 15%|█▌        | 567/3753 [35:08<3:14:13,  3.66s/it] 15%|█▌        | 568/3753 [35:12<3:16:36,  3.70s/it] 15%|█▌        | 569/3753 [35:16<3:23:53,  3.84s/it] 15%|█▌        | 570/3753 [35:19<3:14:52,  3.67s/it]{'loss': 44.7264, 'grad_norm': 340.9856872558594, 'learning_rate': 9.919624211273986e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 3.5694427490234375, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': -2.5987548828125, 'epoch': 0.1518987341772152}
                                                    {'loss': 44.7264, 'grad_norm': 340.9856872558594, 'learning_rate': 9.919624211273986e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 3.5694427490234375, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': -2.5987548828125, 'epoch': 0.15}
 15%|█▌        | 570/3753 [35:19<3:14:52,  3.67s/it] 15%|█▌        | 571/3753 [35:23<3:16:14,  3.70s/it] 15%|█▌        | 572/3753 [35:26<3:07:27,  3.54s/it] 15%|█▌        | 573/3753 [35:29<3:03:57,  3.47s/it] 15%|█▌        | 574/3753 [35:33<3:02:40,  3.45s/it] 15%|█▌        | 575/3753 [35:37<3:19:46,  3.77s/it] 15%|█▌        | 576/3753 [35:41<3:25:50,  3.89s/it] 15%|█▌        | 577/3753 [35:45<3:24:12,  3.86s/it] 15%|█▌        | 578/3753 [35:49<3:21:33,  3.81s/it] 15%|█▌        | 579/3753 [35:52<3:11:37,  3.62s/it] 15%|█▌        | 580/3753 [35:56<3:17:37,  3.74s/it]{'loss': 30.5801, 'grad_norm': 142.28750610351562, 'learning_rate': 9.911104740379551e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.1517436504364014, 'weight_rejected': 0.8499711751937866, 'kl_term_chosen': -3.0420379638671875, 'epoch': 0.15456362425049966}
                                                    {'loss': 30.5801, 'grad_norm': 142.28750610351562, 'learning_rate': 9.911104740379551e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.1517436504364014, 'weight_rejected': 0.8499711751937866, 'kl_term_chosen': -3.0420379638671875, 'epoch': 0.15}
 15%|█▌        | 580/3753 [35:56<3:17:37,  3.74s/it] 15%|█▌        | 581/3753 [36:00<3:14:44,  3.68s/it] 16%|█▌        | 582/3753 [36:03<3:11:30,  3.62s/it] 16%|█▌        | 583/3753 [36:07<3:10:07,  3.60s/it] 16%|█▌        | 584/3753 [36:10<3:03:41,  3.48s/it] 16%|█▌        | 585/3753 [36:13<3:02:08,  3.45s/it] 16%|█▌        | 586/3753 [36:17<3:12:19,  3.64s/it] 16%|█▌        | 587/3753 [36:21<3:18:12,  3.76s/it] 16%|█▌        | 588/3753 [36:25<3:17:03,  3.74s/it] 16%|█▌        | 589/3753 [36:29<3:21:19,  3.82s/it] 16%|█▌        | 590/3753 [36:33<3:15:58,  3.72s/it]{'loss': 6.8869, 'grad_norm': 436.7565612792969, 'learning_rate': 9.902160245255826e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.701347351074219, 'weight_rejected': 0.12592275440692902, 'kl_term_chosen': 9.575424194335938, 'epoch': 0.15722851432378415}
                                                    {'loss': 6.8869, 'grad_norm': 436.7565612792969, 'learning_rate': 9.902160245255826e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.701347351074219, 'weight_rejected': 0.12592275440692902, 'kl_term_chosen': 9.575424194335938, 'epoch': 0.16}
 16%|█▌        | 590/3753 [36:33<3:15:58,  3.72s/it] 16%|█▌        | 591/3753 [36:36<3:18:00,  3.76s/it] 16%|█▌        | 592/3753 [36:40<3:21:54,  3.83s/it] 16%|█▌        | 593/3753 [36:44<3:25:39,  3.90s/it] 16%|█▌        | 594/3753 [36:48<3:23:31,  3.87s/it] 16%|█▌        | 595/3753 [36:52<3:14:14,  3.69s/it] 16%|█▌        | 596/3753 [36:55<3:14:34,  3.70s/it] 16%|█▌        | 597/3753 [36:59<3:13:02,  3.67s/it] 16%|█▌        | 598/3753 [37:03<3:13:46,  3.69s/it] 16%|█▌        | 599/3753 [37:07<3:18:07,  3.77s/it] 16%|█▌        | 600/3753 [37:10<3:20:51,  3.82s/it]{'loss': 13.3276, 'grad_norm': 824.4778442382812, 'learning_rate': 9.892791499990784e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.885634422302246, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 5.84716796875, 'epoch': 0.15989340439706862}
                                                    {'loss': 13.3276, 'grad_norm': 824.4778442382812, 'learning_rate': 9.892791499990784e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.885634422302246, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 5.84716796875, 'epoch': 0.16}
 16%|█▌        | 600/3753 [37:11<3:20:51,  3.82s/it] 16%|█▌        | 601/3753 [37:14<3:14:50,  3.71s/it] 16%|█▌        | 602/3753 [37:18<3:13:06,  3.68s/it] 16%|█▌        | 603/3753 [37:22<3:21:29,  3.84s/it] 16%|█▌        | 604/3753 [37:26<3:23:22,  3.87s/it] 16%|█▌        | 605/3753 [37:29<3:19:56,  3.81s/it] 16%|█▌        | 606/3753 [37:33<3:20:27,  3.82s/it] 16%|█▌        | 607/3753 [37:36<3:11:17,  3.65s/it] 16%|█▌        | 608/3753 [37:40<3:16:12,  3.74s/it] 16%|█▌        | 609/3753 [37:44<3:19:30,  3.81s/it] 16%|█▋        | 610/3753 [37:48<3:13:07,  3.69s/it]{'loss': 17.896, 'grad_norm': 545.1463012695312, 'learning_rate': 9.882999315388504e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.2956960201263428, 'weight_rejected': 0.14033624529838562, 'kl_term_chosen': 3.1333160400390625, 'epoch': 0.1625582944703531}
                                                    {'loss': 17.896, 'grad_norm': 545.1463012695312, 'learning_rate': 9.882999315388504e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.2956960201263428, 'weight_rejected': 0.14033624529838562, 'kl_term_chosen': 3.1333160400390625, 'epoch': 0.16}
 16%|█▋        | 610/3753 [37:48<3:13:07,  3.69s/it] 16%|█▋        | 611/3753 [37:51<3:01:11,  3.46s/it] 16%|█▋        | 612/3753 [37:55<3:08:55,  3.61s/it] 16%|█▋        | 613/3753 [37:58<3:00:02,  3.44s/it] 16%|█▋        | 614/3753 [38:02<3:11:02,  3.65s/it] 16%|█▋        | 615/3753 [38:06<3:13:04,  3.69s/it] 16%|█▋        | 616/3753 [38:09<3:13:57,  3.71s/it] 16%|█▋        | 617/3753 [38:13<3:09:36,  3.63s/it] 16%|█▋        | 618/3753 [38:16<3:04:54,  3.54s/it] 16%|█▋        | 619/3753 [38:19<2:57:57,  3.41s/it] 17%|█▋        | 620/3753 [38:24<3:10:43,  3.65s/it]{'loss': 15.9409, 'grad_norm': 335.3148193359375, 'learning_rate': 9.872784538898985e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.386972904205322, 'weight_rejected': 0.46295860409736633, 'kl_term_chosen': -6.046268463134766, 'epoch': 0.16522318454363757}
                                                    {'loss': 15.9409, 'grad_norm': 335.3148193359375, 'learning_rate': 9.872784538898985e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.386972904205322, 'weight_rejected': 0.46295860409736633, 'kl_term_chosen': -6.046268463134766, 'epoch': 0.17}
 17%|█▋        | 620/3753 [38:24<3:10:43,  3.65s/it] 17%|█▋        | 621/3753 [38:27<3:15:57,  3.75s/it] 17%|█▋        | 622/3753 [38:31<3:10:07,  3.64s/it] 17%|█▋        | 623/3753 [38:34<3:09:41,  3.64s/it] 17%|█▋        | 624/3753 [38:38<3:07:40,  3.60s/it] 17%|█▋        | 625/3753 [38:42<3:07:12,  3.59s/it] 17%|█▋        | 626/3753 [38:46<3:13:59,  3.72s/it] 17%|█▋        | 627/3753 [38:49<3:13:06,  3.71s/it] 17%|█▋        | 628/3753 [38:53<3:13:23,  3.71s/it] 17%|█▋        | 629/3753 [38:57<3:14:37,  3.74s/it] 17%|█▋        | 630/3753 [39:00<3:12:24,  3.70s/it]{'loss': 34.7865, 'grad_norm': 0.0, 'learning_rate': 9.86214805454481e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.451777458190918, 'weight_rejected': 0.14033624529838562, 'kl_term_chosen': -4.342071533203125, 'epoch': 0.16788807461692204}
                                                    {'loss': 34.7865, 'grad_norm': 0.0, 'learning_rate': 9.86214805454481e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.451777458190918, 'weight_rejected': 0.14033624529838562, 'kl_term_chosen': -4.342071533203125, 'epoch': 0.17}
 17%|█▋        | 630/3753 [39:01<3:12:24,  3.70s/it] 17%|█▋        | 631/3753 [39:04<3:14:05,  3.73s/it] 17%|█▋        | 632/3753 [39:08<3:17:11,  3.79s/it] 17%|█▋        | 633/3753 [39:12<3:18:33,  3.82s/it] 17%|█▋        | 634/3753 [39:16<3:18:51,  3.83s/it] 17%|█▋        | 635/3753 [39:19<3:05:53,  3.58s/it] 17%|█▋        | 636/3753 [39:23<3:12:53,  3.71s/it] 17%|█▋        | 637/3753 [39:27<3:15:15,  3.76s/it] 17%|█▋        | 638/3753 [39:30<3:13:45,  3.73s/it] 17%|█▋        | 639/3753 [39:35<3:19:22,  3.84s/it] 17%|█▋        | 640/3753 [39:38<3:16:45,  3.79s/it]{'loss': 21.5535, 'grad_norm': 276.33953857421875, 'learning_rate': 9.851090782844644e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -13.042709350585938, 'weight_rejected': 0.07696083933115005, 'kl_term_chosen': 13.98605728149414, 'epoch': 0.17055296469020653}
                                                    {'loss': 21.5535, 'grad_norm': 276.33953857421875, 'learning_rate': 9.851090782844644e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -13.042709350585938, 'weight_rejected': 0.07696083933115005, 'kl_term_chosen': 13.98605728149414, 'epoch': 0.17}
 17%|█▋        | 640/3753 [39:38<3:16:45,  3.79s/it] 17%|█▋        | 641/3753 [39:42<3:13:41,  3.73s/it] 17%|█▋        | 642/3753 [39:46<3:18:45,  3.83s/it] 17%|█▋        | 643/3753 [39:50<3:21:56,  3.90s/it] 17%|█▋        | 644/3753 [39:54<3:20:37,  3.87s/it] 17%|█▋        | 645/3753 [39:57<3:15:57,  3.78s/it] 17%|█▋        | 646/3753 [40:01<3:12:44,  3.72s/it] 17%|█▋        | 647/3753 [40:05<3:12:19,  3.72s/it] 17%|█▋        | 648/3753 [40:08<3:05:59,  3.59s/it] 17%|█▋        | 649/3753 [40:12<3:10:32,  3.68s/it] 17%|█▋        | 650/3753 [40:15<3:08:26,  3.64s/it]{'loss': 14.6653, 'grad_norm': 109.86599731445312, 'learning_rate': 9.839613680733559e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 19.236705780029297, 'weight_rejected': 0.33982762694358826, 'kl_term_chosen': -18.483238220214844, 'epoch': 0.173217854763491}
                                                    {'loss': 14.6653, 'grad_norm': 109.86599731445312, 'learning_rate': 9.839613680733559e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 19.236705780029297, 'weight_rejected': 0.33982762694358826, 'kl_term_chosen': -18.483238220214844, 'epoch': 0.17}
 17%|█▋        | 650/3753 [40:15<3:08:26,  3.64s/it] 17%|█▋        | 651/3753 [40:19<3:12:18,  3.72s/it] 17%|█▋        | 652/3753 [40:23<3:06:44,  3.61s/it] 17%|█▋        | 653/3753 [40:26<3:09:03,  3.66s/it] 17%|█▋        | 654/3753 [40:31<3:17:57,  3.83s/it] 17%|█▋        | 655/3753 [40:34<3:11:35,  3.71s/it] 17%|█▋        | 656/3753 [40:38<3:14:13,  3.76s/it] 18%|█▊        | 657/3753 [40:42<3:12:34,  3.73s/it] 18%|█▊        | 658/3753 [40:45<3:10:33,  3.69s/it] 18%|█▊        | 659/3753 [40:49<3:08:33,  3.66s/it] 18%|█▊        | 660/3753 [40:52<3:09:20,  3.67s/it]{'loss': 51.2982, 'grad_norm': 832.1627807617188, 'learning_rate': 9.827717741480229e-07, 'mean_ratio_chosen': 4.42817497253418, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.6972688436508179, 'weight_rejected': 0.42919009923934937, 'kl_term_chosen': 0.7439937591552734, 'epoch': 0.1758827448367755}
                                                    {'loss': 51.2982, 'grad_norm': 832.1627807617188, 'learning_rate': 9.827717741480229e-07, 'mean_ratio_chosen': 4.42817497253418, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.6972688436508179, 'weight_rejected': 0.42919009923934937, 'kl_term_chosen': 0.7439937591552734, 'epoch': 0.18}
 18%|█▊        | 660/3753 [40:53<3:09:20,  3.67s/it] 18%|█▊        | 661/3753 [40:56<3:06:59,  3.63s/it] 18%|█▊        | 662/3753 [41:00<3:09:45,  3.68s/it] 18%|█▊        | 663/3753 [41:03<2:58:09,  3.46s/it] 18%|█▊        | 664/3753 [41:06<2:59:25,  3.49s/it] 18%|█▊        | 665/3753 [41:10<3:00:10,  3.50s/it] 18%|█▊        | 666/3753 [41:14<3:04:13,  3.58s/it] 18%|█▊        | 667/3753 [41:17<3:02:17,  3.54s/it] 18%|█▊        | 668/3753 [41:21<3:05:22,  3.61s/it] 18%|█▊        | 669/3753 [41:25<3:10:12,  3.70s/it] 18%|█▊        | 670/3753 [41:29<3:18:35,  3.86s/it]{'loss': 61.8003, 'grad_norm': 0.0, 'learning_rate': 9.815403994600958e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.639248847961426, 'weight_rejected': 0.07696083933115005, 'kl_term_chosen': 5.567657470703125, 'epoch': 0.17854763491005995}
                                                    {'loss': 61.8003, 'grad_norm': 0.0, 'learning_rate': 9.815403994600958e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.639248847961426, 'weight_rejected': 0.07696083933115005, 'kl_term_chosen': 5.567657470703125, 'epoch': 0.18}
 18%|█▊        | 670/3753 [41:29<3:18:35,  3.86s/it] 18%|█▊        | 671/3753 [41:33<3:16:38,  3.83s/it] 18%|█▊        | 672/3753 [41:36<3:13:37,  3.77s/it] 18%|█▊        | 673/3753 [41:40<3:10:07,  3.70s/it] 18%|█▊        | 674/3753 [41:43<3:04:32,  3.60s/it] 18%|█▊        | 675/3753 [41:47<3:08:21,  3.67s/it] 18%|█▊        | 676/3753 [41:51<3:08:24,  3.67s/it] 18%|█▊        | 677/3753 [41:55<3:13:00,  3.76s/it] 18%|█▊        | 678/3753 [41:58<3:10:59,  3.73s/it] 18%|█▊        | 679/3753 [42:02<3:12:56,  3.77s/it] 18%|█▊        | 680/3753 [42:06<3:16:17,  3.83s/it]{'loss': 67.7891, 'grad_norm': 0.0, 'learning_rate': 9.80267350577059e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.202354907989502, 'weight_rejected': 0.2689414322376251, 'kl_term_chosen': -4.479827880859375, 'epoch': 0.18121252498334445}
                                                    {'loss': 67.7891, 'grad_norm': 0.0, 'learning_rate': 9.80267350577059e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.202354907989502, 'weight_rejected': 0.2689414322376251, 'kl_term_chosen': -4.479827880859375, 'epoch': 0.18}
 18%|█▊        | 680/3753 [42:06<3:16:17,  3.83s/it] 18%|█▊        | 681/3753 [42:10<3:22:29,  3.95s/it] 18%|█▊        | 682/3753 [42:14<3:12:14,  3.76s/it] 18%|█▊        | 683/3753 [42:18<3:13:10,  3.78s/it] 18%|█▊        | 684/3753 [42:21<3:12:44,  3.77s/it] 18%|█▊        | 685/3753 [42:25<3:11:06,  3.74s/it] 18%|█▊        | 686/3753 [42:29<3:14:34,  3.81s/it] 18%|█▊        | 687/3753 [42:33<3:13:57,  3.80s/it] 18%|█▊        | 688/3753 [42:37<3:16:49,  3.85s/it] 18%|█▊        | 689/3753 [42:40<3:12:03,  3.76s/it] 18%|█▊        | 690/3753 [42:44<3:10:12,  3.73s/it]{'loss': 36.9827, 'grad_norm': 371.2971496582031, 'learning_rate': 9.78952737673028e-07, 'mean_ratio_chosen': 2.8965556621551514, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.23731905221939087, 'weight_rejected': 0.07696083933115005, 'kl_term_chosen': 0.5317611694335938, 'epoch': 0.1838774150566289}
                                                    {'loss': 36.9827, 'grad_norm': 371.2971496582031, 'learning_rate': 9.78952737673028e-07, 'mean_ratio_chosen': 2.8965556621551514, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.23731905221939087, 'weight_rejected': 0.07696083933115005, 'kl_term_chosen': 0.5317611694335938, 'epoch': 0.18}
 18%|█▊        | 690/3753 [42:44<3:10:12,  3.73s/it] 18%|█▊        | 691/3753 [42:47<3:06:04,  3.65s/it] 18%|█▊        | 692/3753 [42:51<2:59:03,  3.51s/it] 18%|█▊        | 693/3753 [42:54<3:02:30,  3.58s/it] 18%|█▊        | 694/3753 [42:58<3:02:39,  3.58s/it] 19%|█▊        | 695/3753 [43:02<3:03:46,  3.61s/it] 19%|█▊        | 696/3753 [43:05<3:08:29,  3.70s/it] 19%|█▊        | 697/3753 [43:09<3:09:56,  3.73s/it] 19%|█▊        | 698/3753 [43:14<3:18:06,  3.89s/it] 19%|█▊        | 699/3753 [43:17<3:14:20,  3.82s/it] 19%|█▊        | 700/3753 [43:21<3:15:54,  3.85s/it]{'loss': 22.5738, 'grad_norm': 51.0966682434082, 'learning_rate': 9.775966745192144e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 34.17029571533203, 'weight_rejected': 0.17441026866436005, 'kl_term_chosen': -33.21564865112305, 'epoch': 0.18654230512991338}
                                                    {'loss': 22.5738, 'grad_norm': 51.0966682434082, 'learning_rate': 9.775966745192144e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 34.17029571533203, 'weight_rejected': 0.17441026866436005, 'kl_term_chosen': -33.21564865112305, 'epoch': 0.19}
 19%|█▊        | 700/3753 [43:21<3:15:54,  3.85s/it] 19%|█▊        | 701/3753 [43:25<3:18:45,  3.91s/it] 19%|█▊        | 702/3753 [43:28<3:07:58,  3.70s/it] 19%|█▊        | 703/3753 [43:32<3:10:29,  3.75s/it] 19%|█▉        | 704/3753 [43:36<3:10:51,  3.76s/it] 19%|█▉        | 705/3753 [43:40<3:08:38,  3.71s/it] 19%|█▉        | 706/3753 [43:43<3:10:36,  3.75s/it] 19%|█▉        | 707/3753 [43:47<3:06:48,  3.68s/it] 19%|█▉        | 708/3753 [43:51<3:11:42,  3.78s/it] 19%|█▉        | 709/3753 [43:55<3:14:01,  3.82s/it] 19%|█▉        | 710/3753 [43:58<3:08:28,  3.72s/it]{'loss': 31.4655, 'grad_norm': 54.99213790893555, 'learning_rate': 9.761992784740795e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 23.052616119384766, 'weight_rejected': 0.03963883966207504, 'kl_term_chosen': -22.883758544921875, 'epoch': 0.18920719520319787}
                                                    {'loss': 31.4655, 'grad_norm': 54.99213790893555, 'learning_rate': 9.761992784740795e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 23.052616119384766, 'weight_rejected': 0.03963883966207504, 'kl_term_chosen': -22.883758544921875, 'epoch': 0.19}
 19%|█▉        | 710/3753 [43:58<3:08:28,  3.72s/it] 19%|█▉        | 711/3753 [44:02<3:06:34,  3.68s/it] 19%|█▉        | 712/3753 [44:06<3:08:03,  3.71s/it] 19%|█▉        | 713/3753 [44:10<3:11:19,  3.78s/it] 19%|█▉        | 714/3753 [44:14<3:12:21,  3.80s/it] 19%|█▉        | 715/3753 [44:18<3:16:44,  3.89s/it] 19%|█▉        | 716/3753 [44:22<3:18:05,  3.91s/it] 19%|█▉        | 717/3753 [44:25<3:11:33,  3.79s/it] 19%|█▉        | 718/3753 [44:28<3:05:15,  3.66s/it] 19%|█▉        | 719/3753 [44:32<3:03:05,  3.62s/it] 19%|█▉        | 720/3753 [44:36<3:03:14,  3.63s/it]{'loss': 25.4632, 'grad_norm': 669.025146484375, 'learning_rate': 9.747606704731785e-07, 'mean_ratio_chosen': 2.8412246704101562, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.3308178782463074, 'weight_rejected': 0.24508501589298248, 'kl_term_chosen': 0.5221176147460938, 'epoch': 0.19187208527648233}
                                                    {'loss': 25.4632, 'grad_norm': 669.025146484375, 'learning_rate': 9.747606704731785e-07, 'mean_ratio_chosen': 2.8412246704101562, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.3308178782463074, 'weight_rejected': 0.24508501589298248, 'kl_term_chosen': 0.5221176147460938, 'epoch': 0.19}
 19%|█▉        | 720/3753 [44:36<3:03:14,  3.63s/it] 19%|█▉        | 721/3753 [44:39<3:00:59,  3.58s/it] 19%|█▉        | 722/3753 [44:43<3:02:47,  3.62s/it] 19%|█▉        | 723/3753 [44:46<3:00:29,  3.57s/it] 19%|█▉        | 724/3753 [44:50<3:00:31,  3.58s/it] 19%|█▉        | 725/3753 [44:54<3:08:03,  3.73s/it] 19%|█▉        | 726/3753 [44:57<2:52:06,  3.41s/it] 19%|█▉        | 727/3753 [45:01<3:01:05,  3.59s/it] 19%|█▉        | 728/3753 [45:05<3:09:59,  3.77s/it] 19%|█▉        | 729/3753 [45:08<3:08:22,  3.74s/it] 19%|█▉        | 730/3753 [45:12<3:05:34,  3.68s/it]{'loss': 21.2918, 'grad_norm': 769.9283447265625, 'learning_rate': 9.732809750186936e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 49.45870590209961, 'weight_rejected': 0.45423004031181335, 'kl_term_chosen': -48.58123016357422, 'epoch': 0.19453697534976683}
                                                    {'loss': 21.2918, 'grad_norm': 769.9283447265625, 'learning_rate': 9.732809750186936e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 49.45870590209961, 'weight_rejected': 0.45423004031181335, 'kl_term_chosen': -48.58123016357422, 'epoch': 0.19}
 19%|█▉        | 730/3753 [45:12<3:05:34,  3.68s/it] 19%|█▉        | 731/3753 [45:16<3:08:52,  3.75s/it] 20%|█▉        | 732/3753 [45:20<3:10:58,  3.79s/it] 20%|█▉        | 733/3753 [45:23<3:08:36,  3.75s/it] 20%|█▉        | 734/3753 [45:27<3:07:10,  3.72s/it] 20%|█▉        | 735/3753 [45:30<2:56:14,  3.50s/it] 20%|█▉        | 736/3753 [45:34<3:02:55,  3.64s/it] 20%|█▉        | 737/3753 [45:38<3:00:57,  3.60s/it] 20%|█▉        | 738/3753 [45:41<3:04:50,  3.68s/it] 20%|█▉        | 739/3753 [45:45<3:07:50,  3.74s/it] 20%|█▉        | 740/3753 [45:49<3:09:23,  3.77s/it]{'loss': 22.4922, 'grad_norm': 30.28006362915039, 'learning_rate': 9.717603201686589e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 51.83573532104492, 'weight_rejected': 0.34953272342681885, 'kl_term_chosen': -51.39430236816406, 'epoch': 0.1972018654230513}
                                                    {'loss': 22.4922, 'grad_norm': 30.28006362915039, 'learning_rate': 9.717603201686589e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 51.83573532104492, 'weight_rejected': 0.34953272342681885, 'kl_term_chosen': -51.39430236816406, 'epoch': 0.2}
 20%|█▉        | 740/3753 [45:49<3:09:23,  3.77s/it] 20%|█▉        | 741/3753 [45:53<3:05:17,  3.69s/it] 20%|█▉        | 742/3753 [45:56<3:00:52,  3.60s/it] 20%|█▉        | 743/3753 [46:00<2:59:01,  3.57s/it] 20%|█▉        | 744/3753 [46:04<3:07:52,  3.75s/it] 20%|█▉        | 745/3753 [46:07<2:58:55,  3.57s/it] 20%|█▉        | 746/3753 [46:10<2:56:51,  3.53s/it] 20%|█▉        | 747/3753 [46:14<2:56:45,  3.53s/it] 20%|█▉        | 748/3753 [46:18<3:02:01,  3.63s/it] 20%|█▉        | 749/3753 [46:22<3:04:59,  3.70s/it] 20%|█▉        | 750/3753 [46:26<3:09:56,  3.80s/it]{'loss': 16.1472, 'grad_norm': 0.0, 'learning_rate': 9.701988375258787e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 31.686901092529297, 'weight_rejected': 0.19072403013706207, 'kl_term_chosen': -30.84197998046875, 'epoch': 0.19986675549633579}
                                                    {'loss': 16.1472, 'grad_norm': 0.0, 'learning_rate': 9.701988375258787e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 31.686901092529297, 'weight_rejected': 0.19072403013706207, 'kl_term_chosen': -30.84197998046875, 'epoch': 0.2}
 20%|█▉        | 750/3753 [46:26<3:09:56,  3.80s/it] 20%|██        | 751/3753 [46:29<3:08:10,  3.76s/it] 20%|██        | 752/3753 [46:33<3:04:32,  3.69s/it] 20%|██        | 753/3753 [46:36<2:53:40,  3.47s/it] 20%|██        | 754/3753 [46:40<3:01:35,  3.63s/it] 20%|██        | 755/3753 [46:44<3:10:24,  3.81s/it] 20%|██        | 756/3753 [46:47<3:02:21,  3.65s/it] 20%|██        | 757/3753 [46:51<2:59:55,  3.60s/it] 20%|██        | 758/3753 [46:54<2:52:20,  3.45s/it] 20%|██        | 759/3753 [46:58<3:01:28,  3.64s/it] 20%|██        | 760/3753 [47:02<3:04:25,  3.70s/it]{'loss': 18.0258, 'grad_norm': 383.2767333984375, 'learning_rate': 9.68596662226538e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 7.479640960693359, 'weight_rejected': 0.12940272688865662, 'kl_term_chosen': -6.553337097167969, 'epoch': 0.20253164556962025}
                                                    {'loss': 18.0258, 'grad_norm': 383.2767333984375, 'learning_rate': 9.68596662226538e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 7.479640960693359, 'weight_rejected': 0.12940272688865662, 'kl_term_chosen': -6.553337097167969, 'epoch': 0.2}
 20%|██        | 760/3753 [47:02<3:04:25,  3.70s/it] 20%|██        | 761/3753 [47:06<3:11:46,  3.85s/it] 20%|██        | 762/3753 [47:10<3:09:46,  3.81s/it] 20%|██        | 763/3753 [47:13<3:10:06,  3.81s/it] 20%|██        | 764/3753 [47:17<3:06:59,  3.75s/it] 20%|██        | 765/3753 [47:21<3:14:37,  3.91s/it] 20%|██        | 766/3753 [47:25<3:12:59,  3.88s/it] 20%|██        | 767/3753 [47:29<3:12:14,  3.86s/it] 20%|██        | 768/3753 [47:33<3:13:35,  3.89s/it] 20%|██        | 769/3753 [47:37<3:12:50,  3.88s/it] 21%|██        | 770/3753 [47:40<3:06:44,  3.76s/it]{'loss': 12.6883, 'grad_norm': 389.9893798828125, 'learning_rate': 9.66953932928506e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.642331123352051, 'weight_rejected': 0.16885694861412048, 'kl_term_chosen': -5.866386413574219, 'epoch': 0.20519653564290474}
                                                    {'loss': 12.6883, 'grad_norm': 389.9893798828125, 'learning_rate': 9.66953932928506e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.642331123352051, 'weight_rejected': 0.16885694861412048, 'kl_term_chosen': -5.866386413574219, 'epoch': 0.21}
 21%|██        | 770/3753 [47:40<3:06:44,  3.76s/it] 21%|██        | 771/3753 [47:44<3:06:55,  3.76s/it] 21%|██        | 772/3753 [47:47<3:00:34,  3.63s/it] 21%|██        | 773/3753 [47:51<3:00:11,  3.63s/it] 21%|██        | 774/3753 [47:55<2:59:39,  3.62s/it] 21%|██        | 775/3753 [47:58<2:55:26,  3.53s/it] 21%|██        | 776/3753 [48:02<3:02:42,  3.68s/it] 21%|██        | 777/3753 [48:06<3:04:36,  3.72s/it] 21%|██        | 778/3753 [48:10<3:04:58,  3.73s/it] 21%|██        | 779/3753 [48:13<3:05:27,  3.74s/it] 21%|██        | 780/3753 [48:17<3:05:42,  3.75s/it]{'loss': 16.508, 'grad_norm': 60.3621940612793, 'learning_rate': 9.652707917993383e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 24.60935401916504, 'weight_rejected': 0.3380771279335022, 'kl_term_chosen': -23.97503662109375, 'epoch': 0.2078614257161892}
                                                    {'loss': 16.508, 'grad_norm': 60.3621940612793, 'learning_rate': 9.652707917993383e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 24.60935401916504, 'weight_rejected': 0.3380771279335022, 'kl_term_chosen': -23.97503662109375, 'epoch': 0.21}
 21%|██        | 780/3753 [48:17<3:05:42,  3.75s/it] 21%|██        | 781/3753 [48:21<3:07:38,  3.79s/it] 21%|██        | 782/3753 [48:25<3:06:27,  3.77s/it] 21%|██        | 783/3753 [48:29<3:08:12,  3.80s/it] 21%|██        | 784/3753 [48:32<3:02:55,  3.70s/it] 21%|██        | 785/3753 [48:35<2:57:10,  3.58s/it] 21%|██        | 786/3753 [48:39<2:55:29,  3.55s/it] 21%|██        | 787/3753 [48:43<3:01:14,  3.67s/it] 21%|██        | 788/3753 [48:46<3:00:25,  3.65s/it] 21%|██        | 789/3753 [48:50<3:07:38,  3.80s/it] 21%|██        | 790/3753 [48:54<3:08:08,  3.81s/it]{'loss': 13.0347, 'grad_norm': 782.8965454101562, 'learning_rate': 9.635473845039716e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.415579795837402, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': 6.3629608154296875, 'epoch': 0.21052631578947367}
                                                    {'loss': 13.0347, 'grad_norm': 782.8965454101562, 'learning_rate': 9.635473845039716e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.415579795837402, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': 6.3629608154296875, 'epoch': 0.21}
 21%|██        | 790/3753 [48:54<3:08:08,  3.81s/it] 21%|██        | 791/3753 [48:58<3:06:06,  3.77s/it] 21%|██        | 792/3753 [49:02<3:05:19,  3.76s/it] 21%|██        | 793/3753 [49:05<3:00:02,  3.65s/it] 21%|██        | 794/3753 [49:09<3:03:21,  3.72s/it] 21%|██        | 795/3753 [49:13<3:10:36,  3.87s/it] 21%|██        | 796/3753 [49:17<3:10:19,  3.86s/it] 21%|██        | 797/3753 [49:21<3:11:03,  3.88s/it] 21%|██▏       | 798/3753 [49:24<3:05:09,  3.76s/it] 21%|██▏       | 799/3753 [49:28<3:07:06,  3.80s/it] 21%|██▏       | 800/3753 [49:32<3:05:27,  3.77s/it]{'loss': 0.5656, 'grad_norm': 0.0, 'learning_rate': 9.617838601921176e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 22.135013580322266, 'weight_rejected': 0.8322367072105408, 'kl_term_chosen': -21.53717041015625, 'epoch': 0.21319120586275817}
                                                    {'loss': 0.5656, 'grad_norm': 0.0, 'learning_rate': 9.617838601921176e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 22.135013580322266, 'weight_rejected': 0.8322367072105408, 'kl_term_chosen': -21.53717041015625, 'epoch': 0.21}
 21%|██▏       | 800/3753 [49:32<3:05:27,  3.77s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 21%|██▏       | 801/3753 [50:25<15:17:53, 18.66s/it] 21%|██▏       | 802/3753 [50:29<11:37:33, 14.18s/it] 21%|██▏       | 803/3753 [50:33<9:01:55, 11.02s/it]  21%|██▏       | 804/3753 [50:36<7:08:30,  8.72s/it] 21%|██▏       | 805/3753 [50:40<5:52:28,  7.17s/it] 21%|██▏       | 806/3753 [50:44<5:10:51,  6.33s/it] 22%|██▏       | 807/3753 [50:48<4:31:18,  5.53s/it] 22%|██▏       | 808/3753 [50:51<3:58:48,  4.87s/it] 22%|██▏       | 809/3753 [50:55<3:44:28,  4.57s/it] 22%|██▏       | 810/3753 [50:58<3:19:04,  4.06s/it]{'loss': -0.3718, 'grad_norm': 0.0, 'learning_rate': 9.599803714853558e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 24.778488159179688, 'weight_rejected': 0.09138210862874985, 'kl_term_chosen': -23.907012939453125, 'epoch': 0.21585609593604263}
                                                    {'loss': -0.3718, 'grad_norm': 0.0, 'learning_rate': 9.599803714853558e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 24.778488159179688, 'weight_rejected': 0.09138210862874985, 'kl_term_chosen': -23.907012939453125, 'epoch': 0.22}
 22%|██▏       | 810/3753 [50:58<3:19:04,  4.06s/it] 22%|██▏       | 811/3753 [51:01<3:11:19,  3.90s/it] 22%|██▏       | 812/3753 [51:05<3:08:08,  3.84s/it]