nohup: ignoring input
[W1114 05:07:36.090835320 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.75it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.16it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.95it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.81it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.34it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 98.60it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.75it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.58it/s]
[W1114 05:07:42.594028167 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1114 05:07:42.600094433 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1114 05:07:42.602511696 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1114 05:07:42.609196779 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...开始分布式训练...

The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /root/wandb/offline-run-20251114_050750-m8igu0ok
  0%|          | 0/3753 [00:00<?, ?it/s]--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -199.0
Sample 0 - pi_logp_chosen:  -198.81076049804688
Sample 0 - Difference (pi - ref): 0.189239501953125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -100.5
Sample 0 - pi_logp_chosen:  -100.34402465820312
Sample 0 - Difference (pi - ref): 0.155975341796875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -122.0
Sample 0 - pi_logp_chosen:  -121.57272338867188
Sample 0 - Difference (pi - ref): 0.427276611328125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -234.0
Sample 0 - pi_logp_chosen:  -233.57894897460938
Sample 0 - Difference (pi - ref): 0.421051025390625
---------------------------------
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -227.0
Sample 0 - pi_logp_chosen:  -227.50088500976562
Sample 0 - Difference (pi - ref): -0.500885009765625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -248.0
Sample 0 - pi_logp_chosen:  -248.47735595703125
Sample 0 - Difference (pi - ref): -0.47735595703125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -209.0
Sample 0 - pi_logp_chosen:  -208.26136779785156
Sample 0 - Difference (pi - ref): 0.7386322021484375
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -728.0
Sample 0 - pi_logp_chosen:  -730.50390625
Sample 0 - Difference (pi - ref): -2.50390625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -240.0
Sample 0 - pi_logp_chosen:  -240.2412567138672
Sample 0 - Difference (pi - ref): -0.2412567138671875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -253.0
Sample 0 - pi_logp_chosen:  -253.00314331054688
Sample 0 - Difference (pi - ref): -0.003143310546875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -350.0
Sample 0 - pi_logp_chosen:  -349.3069152832031
Sample 0 - Difference (pi - ref): 0.693084716796875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -452.0
Sample 0 - pi_logp_chosen:  -453.64239501953125
Sample 0 - Difference (pi - ref): -1.64239501953125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -127.5
Sample 0 - pi_logp_chosen:  -127.59747314453125
Sample 0 - Difference (pi - ref): -0.09747314453125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -98.5
Sample 0 - pi_logp_chosen:  -98.78225708007812
Sample 0 - Difference (pi - ref): -0.282257080078125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -251.0
Sample 0 - pi_logp_chosen:  -249.6898956298828
Sample 0 - Difference (pi - ref): 1.3101043701171875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -516.0
Sample 0 - pi_logp_chosen:  -514.2531127929688
Sample 0 - Difference (pi - ref): 1.74688720703125
---------------------------------
  0%|          | 1/3753 [00:04<4:56:21,  4.74s/it]{'loss': -0.4328, 'grad_norm': 4570.369140625, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 6.590037822723389, 'weight_chosen': 0.7909114360809326, 'weight_rejected': 0.23323677480220795, 'kl_term_chosen': 0.13101044297218323, 'kl_term_rejected': 0.18855591118335724, 'epoch': 0.0002664890073284477}
                                                  {'loss': -0.4328, 'grad_norm': 4570.369140625, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 6.590037822723389, 'weight_chosen': 0.7909114360809326, 'weight_rejected': 0.23323677480220795, 'kl_term_chosen': 0.13101044297218323, 'kl_term_rejected': 0.18855591118335724, 'epoch': 0.0}
  0%|          | 1/3753 [00:04<4:56:21,  4.74s/it]  0%|          | 2/3753 [00:10<5:19:10,  5.11s/it]  0%|          | 3/3753 [00:14<5:07:25,  4.92s/it]  0%|          | 4/3753 [00:18<4:43:16,  4.53s/it]  0%|          | 5/3753 [00:22<4:33:36,  4.38s/it]  0%|          | 6/3753 [00:28<4:55:19,  4.73s/it]  0%|          | 7/3753 [00:32<4:43:47,  4.55s/it]  0%|          | 8/3753 [00:36<4:42:49,  4.53s/it]  0%|          | 9/3753 [00:40<4:24:42,  4.24s/it]  0%|          | 10/3753 [00:44<4:14:31,  4.08s/it]{'loss': -0.6426, 'grad_norm': 5468.3583984375, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 0.5817659497261047, 'mean_ratio_rejected': 2.0553135871887207, 'weight_chosen': 0.2992537021636963, 'weight_rejected': 0.4883648157119751, 'kl_term_chosen': -0.054168701171875, 'kl_term_rejected': 0.07204284518957138, 'epoch': 0.002664890073284477}
                                                   {'loss': -0.6426, 'grad_norm': 5468.3583984375, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 0.5817659497261047, 'mean_ratio_rejected': 2.0553135871887207, 'weight_chosen': 0.2992537021636963, 'weight_rejected': 0.4883648157119751, 'kl_term_chosen': -0.054168701171875, 'kl_term_rejected': 0.07204284518957138, 'epoch': 0.0}
  0%|          | 10/3753 [00:44<4:14:31,  4.08s/it]  0%|          | 11/3753 [00:48<4:21:11,  4.19s/it]  0%|          | 12/3753 [00:53<4:34:45,  4.41s/it]  0%|          | 13/3753 [00:57<4:32:52,  4.38s/it]  0%|          | 14/3753 [01:01<4:26:44,  4.28s/it]  0%|          | 15/3753 [01:05<4:16:35,  4.12s/it]  0%|          | 16/3753 [01:09<4:10:41,  4.02s/it]  0%|          | 17/3753 [01:13<4:05:06,  3.94s/it]  0%|          | 18/3753 [01:18<4:22:03,  4.21s/it]  1%|          | 19/3753 [01:21<4:05:42,  3.95s/it]  1%|          | 20/3753 [01:25<4:04:23,  3.93s/it]{'loss': -0.6189, 'grad_norm': 5974.66064453125, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 0.8397170901298523, 'mean_ratio_rejected': 0.8883265852928162, 'weight_chosen': 0.7500608563423157, 'weight_rejected': 0.28481265902519226, 'kl_term_chosen': -0.017469024285674095, 'kl_term_rejected': -0.01184158306568861, 'epoch': 0.005329780146568954}
                                                   {'loss': -0.6189, 'grad_norm': 5974.66064453125, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 0.8397170901298523, 'mean_ratio_rejected': 0.8883265852928162, 'weight_chosen': 0.7500608563423157, 'weight_rejected': 0.28481265902519226, 'kl_term_chosen': -0.017469024285674095, 'kl_term_rejected': -0.01184158306568861, 'epoch': 0.01}
  1%|          | 20/3753 [01:25<4:04:23,  3.93s/it]  1%|          | 21/3753 [01:29<4:07:28,  3.98s/it]  1%|          | 22/3753 [01:36<5:14:37,  5.06s/it]  1%|          | 23/3753 [01:42<5:14:00,  5.05s/it]  1%|          | 24/3753 [01:45<4:40:58,  4.52s/it]  1%|          | 25/3753 [01:49<4:35:00,  4.43s/it]  1%|          | 26/3753 [01:52<4:09:01,  4.01s/it]  1%|          | 27/3753 [01:56<4:09:19,  4.01s/it]  1%|          | 28/3753 [02:00<4:05:54,  3.96s/it]  1%|          | 29/3753 [02:04<4:03:26,  3.92s/it]  1%|          | 30/3753 [02:08<4:07:46,  3.99s/it]{'loss': -1.1814, 'grad_norm': 8032.31103515625, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 1.6047641038894653, 'mean_ratio_rejected': 1.6548333168029785, 'weight_chosen': 0.5806535482406616, 'weight_rejected': 0.6491515636444092, 'kl_term_chosen': 0.04729766771197319, 'kl_term_rejected': 0.050370026379823685, 'epoch': 0.007994670219853431}
                                                   {'loss': -1.1814, 'grad_norm': 8032.31103515625, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 1.6047641038894653, 'mean_ratio_rejected': 1.6548333168029785, 'weight_chosen': 0.5806535482406616, 'weight_rejected': 0.6491515636444092, 'kl_term_chosen': 0.04729766771197319, 'kl_term_rejected': 0.050370026379823685, 'epoch': 0.01}
  1%|          | 30/3753 [02:08<4:07:46,  3.99s/it]  1%|          | 31/3753 [02:13<4:31:02,  4.37s/it]  1%|          | 32/3753 [02:17<4:16:50,  4.14s/it]  1%|          | 33/3753 [02:20<4:06:32,  3.98s/it]  1%|          | 34/3753 [02:27<4:54:31,  4.75s/it]  1%|          | 35/3753 [02:32<5:09:41,  5.00s/it]  1%|          | 36/3753 [02:39<5:31:17,  5.35s/it]  1%|          | 37/3753 [02:44<5:37:16,  5.45s/it]  1%|          | 38/3753 [02:49<5:15:30,  5.10s/it]  1%|          | 39/3753 [02:57<6:10:11,  5.98s/it]  1%|          | 40/3753 [03:01<5:34:49,  5.41s/it]{'loss': 0.1598, 'grad_norm': 7403.93603515625, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 1.6969611644744873, 'mean_ratio_rejected': 9.326684951782227, 'weight_chosen': 0.7049104571342468, 'weight_rejected': 0.3509405851364136, 'kl_term_chosen': 0.05288391187787056, 'kl_term_rejected': 0.22328796982765198, 'epoch': 0.010659560293137908}
                                                   {'loss': 0.1598, 'grad_norm': 7403.93603515625, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 1.6969611644744873, 'mean_ratio_rejected': 9.326684951782227, 'weight_chosen': 0.7049104571342468, 'weight_rejected': 0.3509405851364136, 'kl_term_chosen': 0.05288391187787056, 'kl_term_rejected': 0.22328796982765198, 'epoch': 0.01}
  1%|          | 40/3753 [03:01<5:34:49,  5.41s/it]  1%|          | 41/3753 [03:07<5:57:00,  5.77s/it]  1%|          | 42/3753 [03:10<5:05:40,  4.94s/it]  1%|          | 43/3753 [03:15<5:02:02,  4.88s/it]  1%|          | 44/3753 [03:19<4:45:03,  4.61s/it]  1%|          | 45/3753 [03:24<4:49:32,  4.69s/it]  1%|          | 46/3753 [03:29<4:54:19,  4.76s/it]  1%|▏         | 47/3753 [03:32<4:19:56,  4.21s/it]  1%|▏         | 48/3753 [03:36<4:16:34,  4.16s/it]  1%|▏         | 49/3753 [03:40<4:19:04,  4.20s/it]  1%|▏         | 50/3753 [03:44<4:12:45,  4.10s/it]{'loss': 2.4235, 'grad_norm': 3571.874267578125, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.534106969833374, 'weight_rejected': 0.9987761974334717, 'kl_term_chosen': 0.32928466796875, 'kl_term_rejected': 0.313668817281723, 'epoch': 0.013324450366422385}
                                                   {'loss': 2.4235, 'grad_norm': 3571.874267578125, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.534106969833374, 'weight_rejected': 0.9987761974334717, 'kl_term_chosen': 0.32928466796875, 'kl_term_rejected': 0.313668817281723, 'epoch': 0.01}
  1%|▏         | 50/3753 [03:44<4:12:45,  4.10s/it]  1%|▏         | 51/3753 [03:48<4:13:44,  4.11s/it]  1%|▏         | 52/3753 [03:53<4:24:08,  4.28s/it]  1%|▏         | 53/3753 [03:59<4:52:51,  4.75s/it]  1%|▏         | 54/3753 [04:02<4:28:55,  4.36s/it]  1%|▏         | 55/3753 [04:10<5:30:33,  5.36s/it]  1%|▏         | 56/3753 [04:18<6:14:45,  6.08s/it]  2%|▏         | 57/3753 [04:22<5:49:07,  5.67s/it]  2%|▏         | 58/3753 [04:26<5:07:57,  5.00s/it]  2%|▏         | 59/3753 [04:33<5:54:58,  5.77s/it]  2%|▏         | 60/3753 [04:36<5:05:59,  4.97s/it]{'loss': 5.8829, 'grad_norm': 0.0, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.20051011443138123, 'weight_rejected': 1.178142786026001, 'kl_term_chosen': 0.23072472214698792, 'kl_term_rejected': 0.24093209207057953, 'epoch': 0.015989340439706862}
                                                   {'loss': 5.8829, 'grad_norm': 0.0, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.20051011443138123, 'weight_rejected': 1.178142786026001, 'kl_term_chosen': 0.23072472214698792, 'kl_term_rejected': 0.24093209207057953, 'epoch': 0.02}
  2%|▏         | 60/3753 [04:36<5:05:59,  4.97s/it]  2%|▏         | 61/3753 [04:42<5:13:05,  5.09s/it]  2%|▏         | 62/3753 [04:46<4:58:07,  4.85s/it]  2%|▏         | 63/3753 [04:50<4:49:33,  4.71s/it]  2%|▏         | 64/3753 [04:56<4:59:34,  4.87s/it]  2%|▏         | 65/3753 [05:00<4:41:14,  4.58s/it]  2%|▏         | 66/3753 [05:04<4:46:27,  4.66s/it]  2%|▏         | 67/3753 [05:09<4:42:45,  4.60s/it]  2%|▏         | 68/3753 [05:13<4:25:59,  4.33s/it]  2%|▏         | 69/3753 [05:17<4:29:39,  4.39s/it]  2%|▏         | 70/3753 [05:21<4:16:30,  4.18s/it]{'loss': 7.8715, 'grad_norm': 0.0, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.143845796585083, 'weight_rejected': 0.607589840888977, 'kl_term_chosen': 0.819384753704071, 'kl_term_rejected': 0.562908947467804, 'epoch': 0.018654230512991338}
                                                   {'loss': 7.8715, 'grad_norm': 0.0, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.143845796585083, 'weight_rejected': 0.607589840888977, 'kl_term_chosen': 0.819384753704071, 'kl_term_rejected': 0.562908947467804, 'epoch': 0.02}
  2%|▏         | 70/3753 [05:21<4:16:30,  4.18s/it]  2%|▏         | 71/3753 [05:26<4:26:57,  4.35s/it]  2%|▏         | 72/3753 [05:30<4:29:24,  4.39s/it]  2%|▏         | 73/3753 [05:34<4:17:32,  4.20s/it]  2%|▏         | 74/3753 [05:37<4:08:41,  4.06s/it]  2%|▏         | 75/3753 [05:41<4:00:51,  3.93s/it]  2%|▏         | 76/3753 [05:47<4:32:53,  4.45s/it]  2%|▏         | 77/3753 [05:50<4:09:21,  4.07s/it]  2%|▏         | 78/3753 [05:55<4:25:13,  4.33s/it]  2%|▏         | 79/3753 [05:59<4:24:26,  4.32s/it]  2%|▏         | 80/3753 [06:04<4:34:44,  4.49s/it]{'loss': 7.8054, 'grad_norm': 0.0, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.6969329714775085, 'weight_rejected': 0.6996687650680542, 'kl_term_chosen': 1.625341773033142, 'kl_term_rejected': 0.597364068031311, 'epoch': 0.021319120586275817}
                                                   {'loss': 7.8054, 'grad_norm': 0.0, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.6969329714775085, 'weight_rejected': 0.6996687650680542, 'kl_term_chosen': 1.625341773033142, 'kl_term_rejected': 0.597364068031311, 'epoch': 0.02}
  2%|▏         | 80/3753 [06:04<4:34:44,  4.49s/it]  2%|▏         | 81/3753 [06:09<4:38:47,  4.56s/it]  2%|▏         | 82/3753 [06:13<4:24:43,  4.33s/it]  2%|▏         | 83/3753 [06:19<5:07:30,  5.03s/it]  2%|▏         | 84/3753 [06:24<5:01:02,  4.92s/it]  2%|▏         | 85/3753 [06:27<4:34:41,  4.49s/it]  2%|▏         | 86/3753 [06:31<4:13:42,  4.15s/it]  2%|▏         | 87/3753 [06:38<5:03:43,  4.97s/it]  2%|▏         | 88/3753 [06:41<4:41:42,  4.61s/it]  2%|▏         | 89/3753 [06:46<4:34:50,  4.50s/it]  2%|▏         | 90/3753 [06:50<4:25:58,  4.36s/it]{'loss': 7.25, 'grad_norm': 2818.84521484375, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.04573947191238403, 'weight_rejected': 1.1374921798706055, 'kl_term_chosen': 0.834973156452179, 'kl_term_rejected': 0.9874634146690369, 'epoch': 0.023984010659560292}
                                                   {'loss': 7.25, 'grad_norm': 2818.84521484375, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.04573947191238403, 'weight_rejected': 1.1374921798706055, 'kl_term_chosen': 0.834973156452179, 'kl_term_rejected': 0.9874634146690369, 'epoch': 0.02}
  2%|▏         | 90/3753 [06:50<4:25:58,  4.36s/it]  2%|▏         | 91/3753 [06:53<4:06:31,  4.04s/it]  2%|▏         | 92/3753 [06:57<4:04:24,  4.01s/it]  2%|▏         | 93/3753 [07:02<4:29:23,  4.42s/it]  3%|▎         | 94/3753 [07:06<4:19:10,  4.25s/it]  3%|▎         | 95/3753 [07:13<4:59:52,  4.92s/it]  3%|▎         | 96/3753 [07:17<4:43:06,  4.64s/it]  3%|▎         | 97/3753 [07:21<4:35:23,  4.52s/it]  3%|▎         | 98/3753 [07:27<4:57:50,  4.89s/it]  3%|▎         | 99/3753 [07:30<4:30:57,  4.45s/it]  3%|▎         | 100/3753 [07:34<4:15:48,  4.20s/it]{'loss': 6.0866, 'grad_norm': 2795.697021484375, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 6.439639568328857, 'mean_ratio_rejected': 7.336730480194092, 'weight_chosen': 0.4417039453983307, 'weight_rejected': 0.34343817830085754, 'kl_term_chosen': 0.18624725937843323, 'kl_term_rejected': 0.19928932189941406, 'epoch': 0.02664890073284477}
                                                    {'loss': 6.0866, 'grad_norm': 2795.697021484375, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 6.439639568328857, 'mean_ratio_rejected': 7.336730480194092, 'weight_chosen': 0.4417039453983307, 'weight_rejected': 0.34343817830085754, 'kl_term_chosen': 0.18624725937843323, 'kl_term_rejected': 0.19928932189941406, 'epoch': 0.03}
  3%|▎         | 100/3753 [07:34<4:15:48,  4.20s/it]  3%|▎         | 101/3753 [07:38<4:20:08,  4.27s/it]  3%|▎         | 102/3753 [07:42<4:16:48,  4.22s/it]  3%|▎         | 103/3753 [07:46<4:07:13,  4.06s/it]  3%|▎         | 104/3753 [07:51<4:34:56,  4.52s/it]  3%|▎         | 105/3753 [07:56<4:27:26,  4.40s/it]  3%|▎         | 106/3753 [08:01<4:50:15,  4.78s/it]  3%|▎         | 107/3753 [08:06<4:47:32,  4.73s/it]  3%|▎         | 108/3753 [08:10<4:34:55,  4.53s/it]  3%|▎         | 109/3753 [08:14<4:25:10,  4.37s/it]  3%|▎         | 110/3753 [08:18<4:17:56,  4.25s/it]{'loss': 6.9667, 'grad_norm': 3399.73681640625, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.8701568841934204, 'weight_rejected': 0.705982506275177, 'kl_term_chosen': 1.783833384513855, 'kl_term_rejected': 0.664520263671875, 'epoch': 0.029313790806129246}
                                                    {'loss': 6.9667, 'grad_norm': 3399.73681640625, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.8701568841934204, 'weight_rejected': 0.705982506275177, 'kl_term_chosen': 1.783833384513855, 'kl_term_rejected': 0.664520263671875, 'epoch': 0.03}
  3%|▎         | 110/3753 [08:18<4:17:56,  4.25s/it]  3%|▎         | 111/3753 [08:24<4:43:10,  4.67s/it]  3%|▎         | 112/3753 [08:27<4:25:23,  4.37s/it]  3%|▎         | 113/3753 [08:31<4:05:47,  4.05s/it]  3%|▎         | 114/3753 [08:34<3:56:30,  3.90s/it]  3%|▎         | 115/3753 [08:38<3:54:28,  3.87s/it]  3%|▎         | 116/3753 [08:43<4:09:22,  4.11s/it]  3%|▎         | 117/3753 [08:47<4:06:31,  4.07s/it]  3%|▎         | 118/3753 [08:51<4:11:47,  4.16s/it]  3%|▎         | 119/3753 [08:59<5:20:52,  5.30s/it]  3%|▎         | 120/3753 [09:03<5:04:39,  5.03s/it]{'loss': 8.2088, 'grad_norm': 212.1577606201172, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.0371811389923096, 'weight_chosen': -0.33626043796539307, 'weight_rejected': 0.49867644906044006, 'kl_term_chosen': 1.172814965248108, 'kl_term_rejected': 0.003650665283203125, 'epoch': 0.031978680879413725}
                                                    {'loss': 8.2088, 'grad_norm': 212.1577606201172, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.0371811389923096, 'weight_chosen': -0.33626043796539307, 'weight_rejected': 0.49867644906044006, 'kl_term_chosen': 1.172814965248108, 'kl_term_rejected': 0.003650665283203125, 'epoch': 0.03}
  3%|▎         | 120/3753 [09:03<5:04:39,  5.03s/it]  3%|▎         | 121/3753 [09:07<4:50:26,  4.80s/it]  3%|▎         | 122/3753 [09:12<4:46:30,  4.73s/it]  3%|▎         | 123/3753 [09:16<4:36:54,  4.58s/it]  3%|▎         | 124/3753 [09:20<4:22:13,  4.34s/it]  3%|▎         | 125/3753 [09:25<4:29:16,  4.45s/it]  3%|▎         | 126/3753 [09:30<4:37:30,  4.59s/it]  3%|▎         | 127/3753 [09:33<4:19:38,  4.30s/it]  3%|▎         | 128/3753 [09:38<4:24:19,  4.38s/it]  3%|▎         | 129/3753 [09:44<4:47:15,  4.76s/it]  3%|▎         | 130/3753 [09:48<4:42:47,  4.68s/it]{'loss': 9.2861, 'grad_norm': 1306.0570068359375, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.4456636309623718, 'weight_rejected': 1.495402216911316, 'kl_term_chosen': 0.743133544921875, 'kl_term_rejected': 1.3856964111328125, 'epoch': 0.034643570952698204}
                                                    {'loss': 9.2861, 'grad_norm': 1306.0570068359375, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.4456636309623718, 'weight_rejected': 1.495402216911316, 'kl_term_chosen': 0.743133544921875, 'kl_term_rejected': 1.3856964111328125, 'epoch': 0.03}
  3%|▎         | 130/3753 [09:48<4:42:47,  4.68s/it]  3%|▎         | 131/3753 [09:52<4:28:32,  4.45s/it]  4%|▎         | 132/3753 [09:55<4:07:26,  4.10s/it]  4%|▎         | 133/3753 [10:00<4:17:05,  4.26s/it]  4%|▎         | 134/3753 [10:04<4:19:02,  4.29s/it]  4%|▎         | 135/3753 [10:08<4:08:37,  4.12s/it]  4%|▎         | 136/3753 [10:11<3:57:43,  3.94s/it]  4%|▎         | 137/3753 [10:15<3:53:34,  3.88s/it]  4%|▎         | 138/3753 [10:20<4:07:33,  4.11s/it]  4%|▎         | 139/3753 [10:24<4:00:16,  3.99s/it]  4%|▎         | 140/3753 [10:28<4:16:19,  4.26s/it]{'loss': 6.1923, 'grad_norm': 1210.439208984375, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.519868791103363, 'weight_rejected': 0.45508453249931335, 'kl_term_chosen': 0.33979493379592896, 'kl_term_rejected': 0.3080200254917145, 'epoch': 0.037308461025982675}
                                                    {'loss': 6.1923, 'grad_norm': 1210.439208984375, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.519868791103363, 'weight_rejected': 0.45508453249931335, 'kl_term_chosen': 0.33979493379592896, 'kl_term_rejected': 0.3080200254917145, 'epoch': 0.04}
  4%|▎         | 140/3753 [10:29<4:16:19,  4.26s/it]  4%|▍         | 141/3753 [10:32<4:08:15,  4.12s/it]  4%|▍         | 142/3753 [10:39<4:51:03,  4.84s/it]  4%|▍         | 143/3753 [10:43<4:37:12,  4.61s/it]  4%|▍         | 144/3753 [10:49<4:59:38,  4.98s/it]  4%|▍         | 145/3753 [10:56<5:37:03,  5.61s/it]  4%|▍         | 146/3753 [11:01<5:29:10,  5.48s/it]  4%|▍         | 147/3753 [11:08<5:54:42,  5.90s/it]  4%|▍         | 148/3753 [11:13<5:39:47,  5.66s/it]  4%|▍         | 149/3753 [11:17<5:08:29,  5.14s/it]  4%|▍         | 150/3753 [11:24<5:39:01,  5.65s/it]{'loss': 7.2893, 'grad_norm': 4722.57666015625, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 1.356697916984558, 'mean_ratio_rejected': 6.043484210968018, 'weight_chosen': 0.3049543499946594, 'weight_rejected': 0.7702050805091858, 'kl_term_chosen': 0.03050537221133709, 'kl_term_rejected': 0.17989806830883026, 'epoch': 0.039973351099267154}
                                                    {'loss': 7.2893, 'grad_norm': 4722.57666015625, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 1.356697916984558, 'mean_ratio_rejected': 6.043484210968018, 'weight_chosen': 0.3049543499946594, 'weight_rejected': 0.7702050805091858, 'kl_term_chosen': 0.03050537221133709, 'kl_term_rejected': 0.17989806830883026, 'epoch': 0.04}
  4%|▍         | 150/3753 [11:24<5:39:01,  5.65s/it]  4%|▍         | 151/3753 [11:29<5:30:46,  5.51s/it]  4%|▍         | 152/3753 [11:33<5:01:25,  5.02s/it]  4%|▍         | 153/3753 [11:38<4:57:51,  4.96s/it]  4%|▍         | 154/3753 [11:42<4:46:07,  4.77s/it]  4%|▍         | 155/3753 [11:46<4:37:52,  4.63s/it]  4%|▍         | 156/3753 [11:50<4:30:50,  4.52s/it]  4%|▍         | 157/3753 [11:54<4:17:36,  4.30s/it]  4%|▍         | 158/3753 [11:59<4:25:16,  4.43s/it]  4%|▍         | 159/3753 [12:03<4:17:45,  4.30s/it]  4%|▍         | 160/3753 [12:08<4:22:25,  4.38s/it]{'loss': 5.5403, 'grad_norm': 3070.04541015625, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.0447998046875, 'weight_rejected': 0.7121379375457764, 'kl_term_chosen': 1.724829077720642, 'kl_term_rejected': 0.3749344050884247, 'epoch': 0.04263824117255163}
                                                    {'loss': 5.5403, 'grad_norm': 3070.04541015625, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.0447998046875, 'weight_rejected': 0.7121379375457764, 'kl_term_chosen': 1.724829077720642, 'kl_term_rejected': 0.3749344050884247, 'epoch': 0.04}
  4%|▍         | 160/3753 [12:08<4:22:25,  4.38s/it]  4%|▍         | 161/3753 [12:11<4:14:22,  4.25s/it]  4%|▍         | 162/3753 [12:16<4:11:32,  4.20s/it]  4%|▍         | 163/3753 [12:19<3:56:45,  3.96s/it]  4%|▍         | 164/3753 [12:26<4:45:59,  4.78s/it]  4%|▍         | 165/3753 [12:32<5:17:55,  5.32s/it]  4%|▍         | 166/3753 [12:36<4:46:33,  4.79s/it]  4%|▍         | 167/3753 [12:41<4:47:01,  4.80s/it]  4%|▍         | 168/3753 [12:46<4:53:34,  4.91s/it]  5%|▍         | 169/3753 [12:49<4:27:06,  4.47s/it]  5%|▍         | 170/3753 [12:52<4:05:37,  4.11s/it]{'loss': 7.0333, 'grad_norm': 2284.88232421875, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.6057960987091064, 'weight_rejected': 1.7753655910491943, 'kl_term_chosen': 0.2665512263774872, 'kl_term_rejected': 1.6396759748458862, 'epoch': 0.04530313124583611}
                                                    {'loss': 7.0333, 'grad_norm': 2284.88232421875, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.6057960987091064, 'weight_rejected': 1.7753655910491943, 'kl_term_chosen': 0.2665512263774872, 'kl_term_rejected': 1.6396759748458862, 'epoch': 0.05}
  5%|▍         | 170/3753 [12:53<4:05:37,  4.11s/it]  5%|▍         | 171/3753 [12:57<4:12:46,  4.23s/it]  5%|▍         | 172/3753 [13:06<5:30:53,  5.54s/it]  5%|▍         | 173/3753 [13:09<4:57:26,  4.99s/it]  5%|▍         | 174/3753 [13:14<4:45:15,  4.78s/it]  5%|▍         | 175/3753 [13:18<4:38:24,  4.67s/it]  5%|▍         | 176/3753 [13:22<4:19:23,  4.35s/it]  5%|▍         | 177/3753 [13:26<4:21:34,  4.39s/it]  5%|▍         | 178/3753 [13:31<4:28:21,  4.50s/it]  5%|▍         | 179/3753 [13:34<4:10:54,  4.21s/it]  5%|▍         | 180/3753 [13:39<4:10:49,  4.21s/it]{'loss': 7.1887, 'grad_norm': 2472.4453125, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.31895703077316284, 'weight_rejected': 0.4455900192260742, 'kl_term_chosen': 0.6163894534111023, 'kl_term_rejected': 0.35290223360061646, 'epoch': 0.047968021319120584}
                                                    {'loss': 7.1887, 'grad_norm': 2472.4453125, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.31895703077316284, 'weight_rejected': 0.4455900192260742, 'kl_term_chosen': 0.6163894534111023, 'kl_term_rejected': 0.35290223360061646, 'epoch': 0.05}
  5%|▍         | 180/3753 [13:39<4:10:49,  4.21s/it]  5%|▍         | 181/3753 [13:43<4:16:32,  4.31s/it]  5%|▍         | 182/3753 [13:50<5:04:18,  5.11s/it]  5%|▍         | 183/3753 [13:55<4:54:34,  4.95s/it]  5%|▍         | 184/3753 [14:00<5:01:20,  5.07s/it]  5%|▍         | 185/3753 [14:05<4:57:17,  5.00s/it]  5%|▍         | 186/3753 [14:09<4:39:43,  4.71s/it]  5%|▍         | 187/3753 [14:13<4:25:55,  4.47s/it]  5%|▌         | 188/3753 [14:17<4:19:31,  4.37s/it]  5%|▌         | 189/3753 [14:24<5:05:46,  5.15s/it]  5%|▌         | 190/3753 [14:28<4:50:12,  4.89s/it]{'loss': 7.3848, 'grad_norm': 517.9553833007812, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.982038676738739, 'weight_rejected': 0.3825080990791321, 'kl_term_chosen': 1.8628357648849487, 'kl_term_rejected': 0.2974090576171875, 'epoch': 0.05063291139240506}
                                                    {'loss': 7.3848, 'grad_norm': 517.9553833007812, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.982038676738739, 'weight_rejected': 0.3825080990791321, 'kl_term_chosen': 1.8628357648849487, 'kl_term_rejected': 0.2974090576171875, 'epoch': 0.05}
  5%|▌         | 190/3753 [14:28<4:50:12,  4.89s/it]  5%|▌         | 191/3753 [14:32<4:28:16,  4.52s/it]  5%|▌         | 192/3753 [14:39<5:18:36,  5.37s/it]  5%|▌         | 193/3753 [14:44<4:59:20,  5.05s/it]  5%|▌         | 194/3753 [14:49<5:01:11,  5.08s/it]  5%|▌         | 195/3753 [14:53<4:44:04,  4.79s/it]  5%|▌         | 196/3753 [14:56<4:20:28,  4.39s/it]  5%|▌         | 197/3753 [15:05<5:36:03,  5.67s/it]  5%|▌         | 198/3753 [15:09<5:05:03,  5.15s/it]  5%|▌         | 199/3753 [15:14<5:11:02,  5.25s/it]  5%|▌         | 200/3753 [15:19<4:52:57,  4.95s/it]{'loss': 11.9437, 'grad_norm': 1853.4659423828125, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.774664044380188, 'weight_rejected': 1.0497592687606812, 'kl_term_chosen': 2.7180116176605225, 'kl_term_rejected': 0.9939361810684204, 'epoch': 0.05329780146568954}
                                                    {'loss': 11.9437, 'grad_norm': 1853.4659423828125, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.774664044380188, 'weight_rejected': 1.0497592687606812, 'kl_term_chosen': 2.7180116176605225, 'kl_term_rejected': 0.9939361810684204, 'epoch': 0.05}
  5%|▌         | 200/3753 [15:19<4:52:57,  4.95s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
  5%|▌         | 201/3753 [16:21<21:46:25, 22.07s/it]  5%|▌         | 202/3753 [16:24<16:18:53, 16.54s/it]  5%|▌         | 203/3753 [16:29<12:50:15, 13.02s/it]  5%|▌         | 204/3753 [16:33<10:04:40, 10.22s/it]  5%|▌         | 205/3753 [16:37<8:10:28,  8.29s/it]   5%|▌         | 206/3753 [16:44<7:47:38,  7.91s/it]  6%|▌         | 207/3753 [16:47<6:37:01,  6.72s/it]  6%|▌         | 208/3753 [16:53<6:12:08,  6.30s/it]  6%|▌         | 209/3753 [16:58<5:49:57,  5.92s/it]  6%|▌         | 210/3753 [17:02<5:23:31,  5.48s/it]{'loss': 16.5326, 'grad_norm': 1513.76904296875, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.13584083318710327, 'weight_rejected': 0.9070475697517395, 'kl_term_chosen': 0.954577624797821, 'kl_term_rejected': 0.7540054321289062, 'epoch': 0.05596269153897402}
                                                    {'loss': 16.5326, 'grad_norm': 1513.76904296875, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.13584083318710327, 'weight_rejected': 0.9070475697517395, 'kl_term_chosen': 0.954577624797821, 'kl_term_rejected': 0.7540054321289062, 'epoch': 0.06}
  6%|▌         | 210/3753 [17:02<5:23:31,  5.48s/it]  6%|▌         | 211/3753 [17:08<5:20:29,  5.43s/it]  6%|▌         | 212/3753 [17:11<4:47:27,  4.87s/it]  6%|▌         | 213/3753 [17:16<4:41:27,  4.77s/it]  6%|▌         | 214/3753 [17:21<4:56:24,  5.03s/it]  6%|▌         | 215/3753 [17:25<4:40:14,  4.75s/it]  6%|▌         | 216/3753 [17:30<4:32:04,  4.62s/it]  6%|▌         | 217/3753 [17:33<4:14:32,  4.32s/it]  6%|▌         | 218/3753 [17:38<4:22:27,  4.45s/it]  6%|▌         | 219/3753 [17:42<4:07:03,  4.19s/it]  6%|▌         | 220/3753 [17:45<3:59:07,  4.06s/it]{'loss': 10.4848, 'grad_norm': 3623.619384765625, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 8.050293922424316, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.4731559455394745, 'weight_rejected': 0.42429810762405396, 'kl_term_chosen': 0.20857086777687073, 'kl_term_rejected': 0.30427247285842896, 'epoch': 0.05862758161225849}
                                                    {'loss': 10.4848, 'grad_norm': 3623.619384765625, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 8.050293922424316, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.4731559455394745, 'weight_rejected': 0.42429810762405396, 'kl_term_chosen': 0.20857086777687073, 'kl_term_rejected': 0.30427247285842896, 'epoch': 0.06}
  6%|▌         | 220/3753 [17:46<3:59:07,  4.06s/it]  6%|▌         | 221/3753 [17:49<3:54:23,  3.98s/it]  6%|▌         | 222/3753 [17:53<3:57:24,  4.03s/it]  6%|▌         | 223/3753 [17:57<3:48:15,  3.88s/it]  6%|▌         | 224/3753 [18:01<3:46:53,  3.86s/it]  6%|▌         | 225/3753 [18:05<3:52:33,  3.96s/it]  6%|▌         | 226/3753 [18:09<3:50:01,  3.91s/it]  6%|▌         | 227/3753 [18:14<4:15:16,  4.34s/it]  6%|▌         | 228/3753 [18:17<3:57:37,  4.04s/it]  6%|▌         | 229/3753 [18:22<4:13:44,  4.32s/it]  6%|▌         | 230/3753 [18:29<4:54:03,  5.01s/it]{'loss': 8.4583, 'grad_norm': 2372.479736328125, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.0379815101623535, 'weight_rejected': 0.8521084189414978, 'kl_term_chosen': 1.9751923084259033, 'kl_term_rejected': 0.7030731439590454, 'epoch': 0.06129247168554297}
                                                    {'loss': 8.4583, 'grad_norm': 2372.479736328125, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.0379815101623535, 'weight_rejected': 0.8521084189414978, 'kl_term_chosen': 1.9751923084259033, 'kl_term_rejected': 0.7030731439590454, 'epoch': 0.06}
  6%|▌         | 230/3753 [18:29<4:54:03,  5.01s/it]  6%|▌         | 231/3753 [18:35<5:06:15,  5.22s/it]  6%|▌         | 232/3753 [18:39<4:49:09,  4.93s/it]  6%|▌         | 233/3753 [18:44<4:47:52,  4.91s/it]  6%|▌         | 234/3753 [18:49<4:55:24,  5.04s/it]  6%|▋         | 235/3753 [18:57<5:51:16,  5.99s/it]  6%|▋         | 236/3753 [19:01<5:17:26,  5.42s/it]  6%|▋         | 237/3753 [19:05<4:42:50,  4.83s/it]  6%|▋         | 238/3753 [19:09<4:35:59,  4.71s/it]  6%|▋         | 239/3753 [19:14<4:37:41,  4.74s/it]  6%|▋         | 240/3753 [19:19<4:38:29,  4.76s/it]{'loss': 17.001, 'grad_norm': 966.7604370117188, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.7035495042800903, 'weight_rejected': -0.1986372023820877, 'kl_term_chosen': 2.5346925258636475, 'kl_term_rejected': -0.3764480650424957, 'epoch': 0.06395736175882745}
                                                    {'loss': 17.001, 'grad_norm': 966.7604370117188, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.7035495042800903, 'weight_rejected': -0.1986372023820877, 'kl_term_chosen': 2.5346925258636475, 'kl_term_rejected': -0.3764480650424957, 'epoch': 0.06}
  6%|▋         | 240/3753 [19:19<4:38:29,  4.76s/it]  6%|▋         | 241/3753 [19:23<4:25:44,  4.54s/it]  6%|▋         | 242/3753 [19:27<4:18:16,  4.41s/it]  6%|▋         | 243/3753 [19:32<4:18:08,  4.41s/it]  7%|▋         | 244/3753 [19:37<4:43:10,  4.84s/it]  7%|▋         | 245/3753 [19:41<4:29:31,  4.61s/it]  7%|▋         | 246/3753 [19:45<4:13:51,  4.34s/it]  7%|▋         | 247/3753 [19:52<4:58:36,  5.11s/it]  7%|▋         | 248/3753 [19:57<4:56:34,  5.08s/it]  7%|▋         | 249/3753 [20:02<4:55:06,  5.05s/it]  7%|▋         | 250/3753 [20:07<5:00:18,  5.14s/it]{'loss': 21.844, 'grad_norm': 0.0, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.843888521194458, 'weight_rejected': 0.9656650424003601, 'kl_term_chosen': 1.738677978515625, 'kl_term_rejected': 0.8176178336143494, 'epoch': 0.06662225183211193}
                                                    {'loss': 21.844, 'grad_norm': 0.0, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.843888521194458, 'weight_rejected': 0.9656650424003601, 'kl_term_chosen': 1.738677978515625, 'kl_term_rejected': 0.8176178336143494, 'epoch': 0.07}
  7%|▋         | 250/3753 [20:07<5:00:18,  5.14s/it]  7%|▋         | 251/3753 [20:14<5:21:41,  5.51s/it]  7%|▋         | 252/3753 [20:19<5:12:38,  5.36s/it]  7%|▋         | 253/3753 [20:23<5:00:28,  5.15s/it]  7%|▋         | 254/3753 [20:27<4:30:52,  4.64s/it]  7%|▋         | 255/3753 [20:31<4:19:47,  4.46s/it]  7%|▋         | 256/3753 [20:35<4:04:35,  4.20s/it]  7%|▋         | 257/3753 [20:39<4:11:27,  4.32s/it]  7%|▋         | 258/3753 [20:43<4:01:06,  4.14s/it]  7%|▋         | 259/3753 [20:46<3:50:04,  3.95s/it]  7%|▋         | 260/3753 [20:51<4:00:40,  4.13s/it]{'loss': 20.9888, 'grad_norm': 0.0, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.043950796127319336, 'weight_rejected': 0.915212094783783, 'kl_term_chosen': 0.9311553835868835, 'kl_term_rejected': 0.7813445925712585, 'epoch': 0.06928714190539641}
                                                    {'loss': 20.9888, 'grad_norm': 0.0, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.043950796127319336, 'weight_rejected': 0.915212094783783, 'kl_term_chosen': 0.9311553835868835, 'kl_term_rejected': 0.7813445925712585, 'epoch': 0.07}
  7%|▋         | 260/3753 [20:51<4:00:40,  4.13s/it]  7%|▋         | 261/3753 [20:55<4:07:17,  4.25s/it]  7%|▋         | 262/3753 [21:00<4:09:00,  4.28s/it]  7%|▋         | 263/3753 [21:04<4:14:39,  4.38s/it]  7%|▋         | 264/3753 [21:08<4:04:32,  4.21s/it]  7%|▋         | 265/3753 [21:12<4:01:20,  4.15s/it]  7%|▋         | 266/3753 [21:16<3:53:50,  4.02s/it]  7%|▋         | 267/3753 [21:20<3:51:33,  3.99s/it]  7%|▋         | 268/3753 [21:25<4:09:37,  4.30s/it]  7%|▋         | 269/3753 [21:28<3:53:02,  4.01s/it]  7%|▋         | 270/3753 [21:33<4:01:01,  4.15s/it]{'loss': 26.0254, 'grad_norm': 102.41748809814453, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.2752716541290283, 'weight_rejected': 1.5260570049285889, 'kl_term_chosen': 3.2508485317230225, 'kl_term_rejected': 1.4757263660430908, 'epoch': 0.07195203197868089}
                                                    {'loss': 26.0254, 'grad_norm': 102.41748809814453, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.2752716541290283, 'weight_rejected': 1.5260570049285889, 'kl_term_chosen': 3.2508485317230225, 'kl_term_rejected': 1.4757263660430908, 'epoch': 0.07}
  7%|▋         | 270/3753 [21:33<4:01:01,  4.15s/it]  7%|▋         | 271/3753 [21:37<4:06:56,  4.26s/it]  7%|▋         | 272/3753 [21:42<4:09:02,  4.29s/it]  7%|▋         | 273/3753 [21:45<3:59:30,  4.13s/it]  7%|▋         | 274/3753 [21:49<3:54:20,  4.04s/it]  7%|▋         | 275/3753 [21:53<3:51:36,  4.00s/it]  7%|▋         | 276/3753 [21:57<3:44:35,  3.88s/it]  7%|▋         | 277/3753 [22:02<4:06:44,  4.26s/it]  7%|▋         | 278/3753 [22:05<3:52:50,  4.02s/it]  7%|▋         | 279/3753 [22:10<4:05:39,  4.24s/it]  7%|▋         | 280/3753 [22:15<4:16:18,  4.43s/it]{'loss': 17.1898, 'grad_norm': 1335.9102783203125, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 4.1507391929626465, 'mean_ratio_rejected': 2.7911641597747803, 'weight_chosen': 0.7881295680999756, 'weight_rejected': 0.1752825677394867, 'kl_term_chosen': 0.1423286497592926, 'kl_term_rejected': 0.1026458740234375, 'epoch': 0.07461692205196535}
                                                    {'loss': 17.1898, 'grad_norm': 1335.9102783203125, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 4.1507391929626465, 'mean_ratio_rejected': 2.7911641597747803, 'weight_chosen': 0.7881295680999756, 'weight_rejected': 0.1752825677394867, 'kl_term_chosen': 0.1423286497592926, 'kl_term_rejected': 0.1026458740234375, 'epoch': 0.07}
  7%|▋         | 280/3753 [22:15<4:16:18,  4.43s/it]  7%|▋         | 281/3753 [22:19<4:08:36,  4.30s/it]  8%|▊         | 282/3753 [22:25<4:35:21,  4.76s/it]  8%|▊         | 283/3753 [22:29<4:27:32,  4.63s/it]  8%|▊         | 284/3753 [22:33<4:21:50,  4.53s/it]  8%|▊         | 285/3753 [22:41<5:10:29,  5.37s/it]  8%|▊         | 286/3753 [22:44<4:43:29,  4.91s/it]  8%|▊         | 287/3753 [22:48<4:25:46,  4.60s/it]  8%|▊         | 288/3753 [22:57<5:36:17,  5.82s/it]  8%|▊         | 289/3753 [23:02<5:20:42,  5.55s/it]  8%|▊         | 290/3753 [23:11<6:15:19,  6.50s/it]{'loss': 25.499, 'grad_norm': 2251.377197265625, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.7768586277961731, 'weight_rejected': 1.6497666835784912, 'kl_term_chosen': 1.5303252935409546, 'kl_term_rejected': 1.44029700756073, 'epoch': 0.07728181212524983}
                                                    {'loss': 25.499, 'grad_norm': 2251.377197265625, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.7768586277961731, 'weight_rejected': 1.6497666835784912, 'kl_term_chosen': 1.5303252935409546, 'kl_term_rejected': 1.44029700756073, 'epoch': 0.08}
  8%|▊         | 290/3753 [23:11<6:15:19,  6.50s/it]  8%|▊         | 291/3753 [23:14<5:28:44,  5.70s/it]  8%|▊         | 292/3753 [23:20<5:33:39,  5.78s/it]  8%|▊         | 293/3753 [23:24<4:56:28,  5.14s/it]  8%|▊         | 294/3753 [23:28<4:37:22,  4.81s/it]  8%|▊         | 295/3753 [23:33<4:41:41,  4.89s/it]  8%|▊         | 296/3753 [23:37<4:24:00,  4.58s/it]  8%|▊         | 297/3753 [23:42<4:23:48,  4.58s/it]  8%|▊         | 298/3753 [23:47<4:42:36,  4.91s/it]  8%|▊         | 299/3753 [23:52<4:31:50,  4.72s/it]  8%|▊         | 300/3753 [23:56<4:22:13,  4.56s/it]{'loss': 20.5019, 'grad_norm': 841.579833984375, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.4912497401237488, 'weight_rejected': 3.3233160972595215, 'kl_term_chosen': 1.4153915643692017, 'kl_term_rejected': 3.2706971168518066, 'epoch': 0.07994670219853431}
                                                    {'loss': 20.5019, 'grad_norm': 841.579833984375, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.4912497401237488, 'weight_rejected': 3.3233160972595215, 'kl_term_chosen': 1.4153915643692017, 'kl_term_rejected': 3.2706971168518066, 'epoch': 0.08}
  8%|▊         | 300/3753 [23:56<4:22:13,  4.56s/it]  8%|▊         | 301/3753 [24:00<4:16:41,  4.46s/it]  8%|▊         | 302/3753 [24:05<4:26:17,  4.63s/it]  8%|▊         | 303/3753 [24:10<4:25:14,  4.61s/it]  8%|▊         | 304/3753 [24:13<3:58:18,  4.15s/it]  8%|▊         | 305/3753 [24:17<3:54:06,  4.07s/it]  8%|▊         | 306/3753 [24:21<3:53:49,  4.07s/it]  8%|▊         | 307/3753 [24:25<4:04:36,  4.26s/it]  8%|▊         | 308/3753 [24:31<4:29:35,  4.70s/it]  8%|▊         | 309/3753 [24:36<4:26:06,  4.64s/it]  8%|▊         | 310/3753 [24:40<4:14:51,  4.44s/it]{'loss': 8.9661, 'grad_norm': 1144.02978515625, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.1293299198150635, 'weight_rejected': -0.9934789538383484, 'kl_term_chosen': -1.4656609296798706, 'kl_term_rejected': -1.2216354608535767, 'epoch': 0.08261159227181879}
                                                    {'loss': 8.9661, 'grad_norm': 1144.02978515625, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.1293299198150635, 'weight_rejected': -0.9934789538383484, 'kl_term_chosen': -1.4656609296798706, 'kl_term_rejected': -1.2216354608535767, 'epoch': 0.08}
  8%|▊         | 310/3753 [24:40<4:14:51,  4.44s/it]  8%|▊         | 311/3753 [24:44<4:12:31,  4.40s/it]  8%|▊         | 312/3753 [24:48<4:08:27,  4.33s/it]  8%|▊         | 313/3753 [24:52<4:09:20,  4.35s/it]  8%|▊         | 314/3753 [25:00<4:56:41,  5.18s/it]  8%|▊         | 315/3753 [25:03<4:30:28,  4.72s/it]  8%|▊         | 316/3753 [25:07<4:11:06,  4.38s/it]  8%|▊         | 317/3753 [25:11<4:04:56,  4.28s/it]  8%|▊         | 318/3753 [25:15<4:11:14,  4.39s/it]  8%|▊         | 319/3753 [25:20<4:07:07,  4.32s/it]  9%|▊         | 320/3753 [25:24<4:12:42,  4.42s/it]{'loss': 14.4042, 'grad_norm': 197.518798828125, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.04291003942489624, 'weight_rejected': 3.7844643592834473, 'kl_term_chosen': 0.980120837688446, 'kl_term_rejected': 3.7436187267303467, 'epoch': 0.08527648234510327}
                                                    {'loss': 14.4042, 'grad_norm': 197.518798828125, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.04291003942489624, 'weight_rejected': 3.7844643592834473, 'kl_term_chosen': 0.980120837688446, 'kl_term_rejected': 3.7436187267303467, 'epoch': 0.09}
  9%|▊         | 320/3753 [25:24<4:12:42,  4.42s/it]  9%|▊         | 321/3753 [25:29<4:15:29,  4.47s/it]  9%|▊         | 322/3753 [25:33<4:04:30,  4.28s/it]  9%|▊         | 323/3753 [25:36<3:52:41,  4.07s/it]  9%|▊         | 324/3753 [25:44<4:48:24,  5.05s/it]  9%|▊         | 325/3753 [25:48<4:40:31,  4.91s/it]  9%|▊         | 326/3753 [25:52<4:17:33,  4.51s/it]  9%|▊         | 327/3753 [25:56<4:09:13,  4.36s/it]  9%|▊         | 328/3753 [26:00<4:01:56,  4.24s/it]  9%|▉         | 329/3753 [26:04<4:05:35,  4.30s/it]  9%|▉         | 330/3753 [26:09<4:16:49,  4.50s/it]{'loss': 25.3467, 'grad_norm': 225.70831298828125, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.29268544912338257, 'weight_rejected': 4.509277820587158, 'kl_term_chosen': 1.1542236804962158, 'kl_term_rejected': 4.287927150726318, 'epoch': 0.08794137241838774}
                                                    {'loss': 25.3467, 'grad_norm': 225.70831298828125, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.29268544912338257, 'weight_rejected': 4.509277820587158, 'kl_term_chosen': 1.1542236804962158, 'kl_term_rejected': 4.287927150726318, 'epoch': 0.09}
  9%|▉         | 330/3753 [26:09<4:16:49,  4.50s/it]  9%|▉         | 331/3753 [26:13<4:07:21,  4.34s/it]  9%|▉         | 332/3753 [26:17<3:58:59,  4.19s/it]  9%|▉         | 333/3753 [26:21<4:01:00,  4.23s/it]  9%|▉         | 334/3753 [26:29<5:03:53,  5.33s/it]  9%|▉         | 335/3753 [26:34<4:53:20,  5.15s/it]  9%|▉         | 336/3753 [26:37<4:26:17,  4.68s/it]  9%|▉         | 337/3753 [26:42<4:24:04,  4.64s/it]  9%|▉         | 338/3753 [26:45<4:02:59,  4.27s/it]  9%|▉         | 339/3753 [26:49<3:50:47,  4.06s/it]  9%|▉         | 340/3753 [26:53<3:56:08,  4.15s/it]{'loss': 26.9754, 'grad_norm': 207.42555236816406, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.883612871170044, 'weight_rejected': -2.1281051635742188, 'kl_term_chosen': -1.6399704217910767, 'kl_term_rejected': -2.9107677936553955, 'epoch': 0.09060626249167222}
                                                    {'loss': 26.9754, 'grad_norm': 207.42555236816406, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.883612871170044, 'weight_rejected': -2.1281051635742188, 'kl_term_chosen': -1.6399704217910767, 'kl_term_rejected': -2.9107677936553955, 'epoch': 0.09}
  9%|▉         | 340/3753 [26:53<3:56:08,  4.15s/it]  9%|▉         | 341/3753 [26:57<3:50:08,  4.05s/it]  9%|▉         | 342/3753 [27:01<3:49:34,  4.04s/it]  9%|▉         | 343/3753 [27:06<3:56:59,  4.17s/it]  9%|▉         | 344/3753 [27:09<3:50:47,  4.06s/it]  9%|▉         | 345/3753 [27:15<4:15:46,  4.50s/it]  9%|▉         | 346/3753 [27:19<4:09:39,  4.40s/it]  9%|▉         | 347/3753 [27:24<4:13:34,  4.47s/it]  9%|▉         | 348/3753 [27:29<4:25:59,  4.69s/it]  9%|▉         | 349/3753 [27:33<4:06:28,  4.34s/it]  9%|▉         | 350/3753 [27:37<4:08:32,  4.38s/it]{'loss': 21.6718, 'grad_norm': 1676.2796630859375, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 0.23962491750717163, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.9772748947143555, 'weight_rejected': 3.242549419403076, 'kl_term_chosen': -0.1428680419921875, 'kl_term_rejected': 3.0238800048828125, 'epoch': 0.09327115256495669}
                                                    {'loss': 21.6718, 'grad_norm': 1676.2796630859375, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 0.23962491750717163, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.9772748947143555, 'weight_rejected': 3.242549419403076, 'kl_term_chosen': -0.1428680419921875, 'kl_term_rejected': 3.0238800048828125, 'epoch': 0.09}
  9%|▉         | 350/3753 [27:37<4:08:32,  4.38s/it]  9%|▉         | 351/3753 [27:41<4:02:40,  4.28s/it]  9%|▉         | 352/3753 [27:45<3:49:04,  4.04s/it]  9%|▉         | 353/3753 [27:49<3:52:46,  4.11s/it]  9%|▉         | 354/3753 [27:53<3:55:12,  4.15s/it]  9%|▉         | 355/3753 [27:59<4:25:09,  4.68s/it]  9%|▉         | 356/3753 [28:03<4:18:21,  4.56s/it] 10%|▉         | 357/3753 [28:08<4:13:20,  4.48s/it] 10%|▉         | 358/3753 [28:12<4:13:23,  4.48s/it] 10%|▉         | 359/3753 [28:16<4:06:59,  4.37s/it] 10%|▉         | 360/3753 [28:20<3:53:34,  4.13s/it]{'loss': 23.1195, 'grad_norm': 474.4326477050781, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -4.036691665649414, 'weight_rejected': -0.16622255742549896, 'kl_term_chosen': 4.5810089111328125, 'kl_term_rejected': -0.33289796113967896, 'epoch': 0.09593604263824117}
                                                    {'loss': 23.1195, 'grad_norm': 474.4326477050781, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -4.036691665649414, 'weight_rejected': -0.16622255742549896, 'kl_term_chosen': 4.5810089111328125, 'kl_term_rejected': -0.33289796113967896, 'epoch': 0.1}
 10%|▉         | 360/3753 [28:20<3:53:34,  4.13s/it] 10%|▉         | 361/3753 [28:24<3:59:17,  4.23s/it] 10%|▉         | 362/3753 [28:28<4:00:53,  4.26s/it] 10%|▉         | 363/3753 [28:33<4:00:09,  4.25s/it] 10%|▉         | 364/3753 [28:37<4:07:40,  4.38s/it] 10%|▉         | 365/3753 [28:41<3:50:30,  4.08s/it] 10%|▉         | 366/3753 [28:44<3:37:29,  3.85s/it] 10%|▉         | 367/3753 [28:48<3:41:51,  3.93s/it] 10%|▉         | 368/3753 [28:53<3:56:20,  4.19s/it] 10%|▉         | 369/3753 [28:58<4:02:57,  4.31s/it] 10%|▉         | 370/3753 [29:02<4:02:05,  4.29s/it]{'loss': 36.0535, 'grad_norm': 433.6731872558594, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.3814506530761719, 'weight_rejected': -0.13303852081298828, 'kl_term_chosen': -0.5171402096748352, 'kl_term_rejected': -0.338653564453125, 'epoch': 0.09860093271152565}
                                                    {'loss': 36.0535, 'grad_norm': 433.6731872558594, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.3814506530761719, 'weight_rejected': -0.13303852081298828, 'kl_term_chosen': -0.5171402096748352, 'kl_term_rejected': -0.338653564453125, 'epoch': 0.1}
 10%|▉         | 370/3753 [29:02<4:02:05,  4.29s/it] 10%|▉         | 371/3753 [29:05<3:48:13,  4.05s/it] 10%|▉         | 372/3753 [29:10<3:56:24,  4.20s/it] 10%|▉         | 373/3753 [29:14<3:51:17,  4.11s/it] 10%|▉         | 374/3753 [29:21<4:45:00,  5.06s/it] 10%|▉         | 375/3753 [29:27<4:53:28,  5.21s/it] 10%|█         | 376/3753 [29:36<5:56:06,  6.33s/it] 10%|█         | 377/3753 [29:42<5:56:58,  6.34s/it] 10%|█         | 378/3753 [29:46<5:10:43,  5.52s/it] 10%|█         | 379/3753 [29:49<4:41:40,  5.01s/it] 10%|█         | 380/3753 [29:54<4:38:48,  4.96s/it]{'loss': 39.1636, 'grad_norm': 126.15106201171875, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.4029293060302734, 'weight_rejected': 2.251122236251831, 'kl_term_chosen': 2.363290548324585, 'kl_term_rejected': 2.2251648902893066, 'epoch': 0.10126582278481013}
                                                    {'loss': 39.1636, 'grad_norm': 126.15106201171875, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.4029293060302734, 'weight_rejected': 2.251122236251831, 'kl_term_chosen': 2.363290548324585, 'kl_term_rejected': 2.2251648902893066, 'epoch': 0.1}
 10%|█         | 380/3753 [29:54<4:38:48,  4.96s/it] 10%|█         | 381/3753 [29:58<4:25:39,  4.73s/it] 10%|█         | 382/3753 [30:03<4:21:05,  4.65s/it] 10%|█         | 383/3753 [30:07<4:06:35,  4.39s/it] 10%|█         | 384/3753 [30:12<4:19:45,  4.63s/it] 10%|█         | 385/3753 [30:22<5:51:30,  6.26s/it] 10%|█         | 386/3753 [30:25<5:04:42,  5.43s/it] 10%|█         | 387/3753 [30:30<4:46:37,  5.11s/it] 10%|█         | 388/3753 [30:34<4:34:26,  4.89s/it] 10%|█         | 389/3753 [30:39<4:26:40,  4.76s/it] 10%|█         | 390/3753 [30:45<4:48:56,  5.15s/it]{'loss': 29.2134, 'grad_norm': 413.66961669921875, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.3699191808700562, 'weight_rejected': 2.244378089904785, 'kl_term_chosen': 2.0087544918060303, 'kl_term_rejected': 1.4279717206954956, 'epoch': 0.1039307128580946}
                                                    {'loss': 29.2134, 'grad_norm': 413.66961669921875, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.3699191808700562, 'weight_rejected': 2.244378089904785, 'kl_term_chosen': 2.0087544918060303, 'kl_term_rejected': 1.4279717206954956, 'epoch': 0.1}
 10%|█         | 390/3753 [30:45<4:48:56,  5.15s/it] 10%|█         | 391/3753 [30:49<4:40:50,  5.01s/it] 10%|█         | 392/3753 [30:53<4:24:02,  4.71s/it] 10%|█         | 393/3753 [30:58<4:25:27,  4.74s/it] 10%|█         | 394/3753 [31:02<4:15:33,  4.56s/it] 11%|█         | 395/3753 [31:07<4:16:28,  4.58s/it] 11%|█         | 396/3753 [31:16<5:28:09,  5.87s/it] 11%|█         | 397/3753 [31:19<4:47:09,  5.13s/it] 11%|█         | 398/3753 [31:25<4:54:09,  5.26s/it] 11%|█         | 399/3753 [31:30<4:59:29,  5.36s/it] 11%|█         | 400/3753 [31:34<4:37:17,  4.96s/it]{'loss': 37.5763, 'grad_norm': 0.0, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.1593527793884277, 'weight_rejected': 2.213193893432617, 'kl_term_chosen': 1.854483962059021, 'kl_term_rejected': 1.9622811079025269, 'epoch': 0.10659560293137908}
                                                    {'loss': 37.5763, 'grad_norm': 0.0, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.1593527793884277, 'weight_rejected': 2.213193893432617, 'kl_term_chosen': 1.854483962059021, 'kl_term_rejected': 1.9622811079025269, 'epoch': 0.11}
 11%|█         | 400/3753 [31:34<4:37:17,  4.96s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 11%|█         | 401/3753 [32:32<19:12:19, 20.63s/it] 11%|█         | 402/3753 [32:36<14:45:33, 15.86s/it] 11%|█         | 403/3753 [32:39<11:13:14, 12.06s/it] 11%|█         | 404/3753 [32:44<8:59:10,  9.66s/it]  11%|█         | 405/3753 [32:49<7:48:47,  8.40s/it] 11%|█         | 406/3753 [32:53<6:39:59,  7.17s/it] 11%|█         | 407/3753 [32:57<5:43:23,  6.16s/it] 11%|█         | 408/3753 [33:02<5:23:41,  5.81s/it] 11%|█         | 409/3753 [33:06<4:53:03,  5.26s/it] 11%|█         | 410/3753 [33:10<4:37:16,  4.98s/it]{'loss': 43.3082, 'grad_norm': 2010.787109375, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.18193577229976654, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.8173166513442993, 'weight_rejected': -2.0944273471832275, 'kl_term_chosen': -0.17041015625, 'kl_term_rejected': -2.382195234298706, 'epoch': 0.10926049300466356}
                                                    {'loss': 43.3082, 'grad_norm': 2010.787109375, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.18193577229976654, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.8173166513442993, 'weight_rejected': -2.0944273471832275, 'kl_term_chosen': -0.17041015625, 'kl_term_rejected': -2.382195234298706, 'epoch': 0.11}
 11%|█         | 410/3753 [33:11<4:37:16,  4.98s/it] 11%|█         | 411/3753 [33:15<4:37:51,  4.99s/it] 11%|█         | 412/3753 [33:19<4:19:34,  4.66s/it] 11%|█         | 413/3753 [33:25<4:34:50,  4.94s/it] 11%|█         | 414/3753 [33:30<4:34:35,  4.93s/it] 11%|█         | 415/3753 [33:34<4:16:52,  4.62s/it] 11%|█         | 416/3753 [33:38<4:12:33,  4.54s/it] 11%|█         | 417/3753 [33:42<4:04:50,  4.40s/it] 11%|█         | 418/3753 [33:46<3:57:00,  4.26s/it] 11%|█         | 419/3753 [33:50<3:51:52,  4.17s/it] 11%|█         | 420/3753 [33:54<3:46:23,  4.08s/it]{'loss': 46.4831, 'grad_norm': 0.0, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.496387004852295, 'weight_rejected': 1.5618269443511963, 'kl_term_chosen': 6.147741794586182, 'kl_term_rejected': 1.2890281677246094, 'epoch': 0.11192538307794804}
                                                    {'loss': 46.4831, 'grad_norm': 0.0, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.496387004852295, 'weight_rejected': 1.5618269443511963, 'kl_term_chosen': 6.147741794586182, 'kl_term_rejected': 1.2890281677246094, 'epoch': 0.11}
 11%|█         | 420/3753 [33:54<3:46:23,  4.08s/it] 11%|█         | 421/3753 [33:58<3:50:55,  4.16s/it] 11%|█         | 422/3753 [34:02<3:50:01,  4.14s/it] 11%|█▏        | 423/3753 [34:06<3:44:24,  4.04s/it] 11%|█▏        | 424/3753 [34:09<3:28:26,  3.76s/it] 11%|█▏        | 425/3753 [34:13<3:36:05,  3.90s/it] 11%|█▏        | 426/3753 [34:18<3:42:00,  4.00s/it] 11%|█▏        | 427/3753 [34:22<3:51:46,  4.18s/it] 11%|█▏        | 428/3753 [34:27<3:56:01,  4.26s/it] 11%|█▏        | 429/3753 [34:31<3:53:12,  4.21s/it] 11%|█▏        | 430/3753 [34:36<4:04:30,  4.41s/it]{'loss': 45.4665, 'grad_norm': 495.0005798339844, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.070422410964966, 'weight_chosen': -4.800419807434082, 'weight_rejected': 0.34402698278427124, 'kl_term_chosen': 5.364037990570068, 'kl_term_rejected': 0.07277526706457138, 'epoch': 0.1145902731512325}
                                                    {'loss': 45.4665, 'grad_norm': 495.0005798339844, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.070422410964966, 'weight_chosen': -4.800419807434082, 'weight_rejected': 0.34402698278427124, 'kl_term_chosen': 5.364037990570068, 'kl_term_rejected': 0.07277526706457138, 'epoch': 0.11}
 11%|█▏        | 430/3753 [34:36<4:04:30,  4.41s/it] 11%|█▏        | 431/3753 [34:40<3:54:02,  4.23s/it] 12%|█▏        | 432/3753 [34:48<5:01:58,  5.46s/it] 12%|█▏        | 433/3753 [34:52<4:38:58,  5.04s/it] 12%|█▏        | 434/3753 [34:56<4:19:56,  4.70s/it] 12%|█▏        | 435/3753 [35:00<4:04:36,  4.42s/it] 12%|█▏        | 436/3753 [35:04<4:03:15,  4.40s/it] 12%|█▏        | 437/3753 [35:08<3:59:47,  4.34s/it] 12%|█▏        | 438/3753 [35:13<4:11:34,  4.55s/it] 12%|█▏        | 439/3753 [35:18<4:09:47,  4.52s/it] 12%|█▏        | 440/3753 [35:22<4:02:50,  4.40s/it]{'loss': 38.8602, 'grad_norm': 1074.73828125, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.146304607391357, 'weight_rejected': 1.3328032493591309, 'kl_term_chosen': 5.1009521484375, 'kl_term_rejected': 1.2846664190292358, 'epoch': 0.11725516322451698}
                                                    {'loss': 38.8602, 'grad_norm': 1074.73828125, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.146304607391357, 'weight_rejected': 1.3328032493591309, 'kl_term_chosen': 5.1009521484375, 'kl_term_rejected': 1.2846664190292358, 'epoch': 0.12}
 12%|█▏        | 440/3753 [35:22<4:02:50,  4.40s/it] 12%|█▏        | 441/3753 [35:28<4:25:10,  4.80s/it] 12%|█▏        | 442/3753 [35:32<4:22:45,  4.76s/it] 12%|█▏        | 443/3753 [35:35<3:44:41,  4.07s/it] 12%|█▏        | 444/3753 [35:40<4:00:58,  4.37s/it] 12%|█▏        | 445/3753 [35:43<3:48:35,  4.15s/it] 12%|█▏        | 446/3753 [35:48<3:55:40,  4.28s/it] 12%|█▏        | 447/3753 [35:52<3:57:02,  4.30s/it] 12%|█▏        | 448/3753 [35:56<3:41:41,  4.02s/it] 12%|█▏        | 449/3753 [36:01<3:57:26,  4.31s/it] 12%|█▏        | 450/3753 [36:05<3:58:09,  4.33s/it]{'loss': 29.9012, 'grad_norm': 1171.1514892578125, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.5228565335273743, 'weight_rejected': 5.146957874298096, 'kl_term_chosen': 0.370452880859375, 'kl_term_rejected': 5.091134548187256, 'epoch': 0.11992005329780146}
                                                    {'loss': 29.9012, 'grad_norm': 1171.1514892578125, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.5228565335273743, 'weight_rejected': 5.146957874298096, 'kl_term_chosen': 0.370452880859375, 'kl_term_rejected': 5.091134548187256, 'epoch': 0.12}
 12%|█▏        | 450/3753 [36:05<3:58:09,  4.33s/it] 12%|█▏        | 451/3753 [36:09<4:00:12,  4.36s/it] 12%|█▏        | 452/3753 [36:15<4:15:42,  4.65s/it] 12%|█▏        | 453/3753 [36:18<3:56:32,  4.30s/it] 12%|█▏        | 454/3753 [36:24<4:16:05,  4.66s/it] 12%|█▏        | 455/3753 [36:28<4:07:51,  4.51s/it] 12%|█▏        | 456/3753 [36:34<4:34:55,  5.00s/it] 12%|█▏        | 457/3753 [36:38<4:21:52,  4.77s/it] 12%|█▏        | 458/3753 [36:42<4:06:37,  4.49s/it] 12%|█▏        | 459/3753 [36:46<4:02:21,  4.41s/it] 12%|█▏        | 460/3753 [36:52<4:20:42,  4.75s/it]{'loss': 27.1486, 'grad_norm': 1182.4979248046875, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -6.220520973205566, 'weight_rejected': -0.2310781180858612, 'kl_term_chosen': 7.139001369476318, 'kl_term_rejected': -0.27192384004592896, 'epoch': 0.12258494337108594}
                                                    {'loss': 27.1486, 'grad_norm': 1182.4979248046875, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -6.220520973205566, 'weight_rejected': -0.2310781180858612, 'kl_term_chosen': 7.139001369476318, 'kl_term_rejected': -0.27192384004592896, 'epoch': 0.12}
 12%|█▏        | 460/3753 [36:52<4:20:42,  4.75s/it] 12%|█▏        | 461/3753 [36:55<4:00:13,  4.38s/it] 12%|█▏        | 462/3753 [36:58<3:36:20,  3.94s/it] 12%|█▏        | 463/3753 [37:03<3:44:38,  4.10s/it] 12%|█▏        | 464/3753 [37:07<3:45:48,  4.12s/it] 12%|█▏        | 465/3753 [37:11<3:43:23,  4.08s/it] 12%|█▏        | 466/3753 [37:15<3:45:46,  4.12s/it] 12%|█▏        | 467/3753 [37:19<3:47:36,  4.16s/it] 12%|█▏        | 468/3753 [37:27<4:51:54,  5.33s/it] 12%|█▏        | 469/3753 [37:33<4:52:41,  5.35s/it] 13%|█▎        | 470/3753 [37:39<5:02:11,  5.52s/it]{'loss': 34.3453, 'grad_norm': 60.73802947998047, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -7.980548858642578, 'weight_rejected': -2.9932544231414795, 'kl_term_chosen': 8.925543785095215, 'kl_term_rejected': -3.0747742652893066, 'epoch': 0.1252498334443704}
                                                    {'loss': 34.3453, 'grad_norm': 60.73802947998047, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -7.980548858642578, 'weight_rejected': -2.9932544231414795, 'kl_term_chosen': 8.925543785095215, 'kl_term_rejected': -3.0747742652893066, 'epoch': 0.13}
 13%|█▎        | 470/3753 [37:39<5:02:11,  5.52s/it] 13%|█▎        | 471/3753 [37:44<5:02:59,  5.54s/it] 13%|█▎        | 472/3753 [37:48<4:30:15,  4.94s/it] 13%|█▎        | 473/3753 [37:51<3:59:50,  4.39s/it] 13%|█▎        | 474/3753 [37:55<4:01:02,  4.41s/it] 13%|█▎        | 475/3753 [38:00<4:03:26,  4.46s/it] 13%|█▎        | 476/3753 [38:04<3:54:41,  4.30s/it] 13%|█▎        | 477/3753 [38:08<3:54:48,  4.30s/it] 13%|█▎        | 478/3753 [38:12<3:51:43,  4.25s/it] 13%|█▎        | 479/3753 [38:18<4:19:23,  4.75s/it] 13%|█▎        | 480/3753 [38:23<4:17:58,  4.73s/it]{'loss': 52.5079, 'grad_norm': 6.946856498718262, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.6092400550842285, 'weight_rejected': 1.981971263885498, 'kl_term_chosen': 6.185781955718994, 'kl_term_rejected': 1.7440414428710938, 'epoch': 0.1279147235176549}
                                                    {'loss': 52.5079, 'grad_norm': 6.946856498718262, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.6092400550842285, 'weight_rejected': 1.981971263885498, 'kl_term_chosen': 6.185781955718994, 'kl_term_rejected': 1.7440414428710938, 'epoch': 0.13}
 13%|█▎        | 480/3753 [38:23<4:17:58,  4.73s/it] 13%|█▎        | 481/3753 [38:28<4:21:38,  4.80s/it] 13%|█▎        | 482/3753 [38:32<4:02:58,  4.46s/it] 13%|█▎        | 483/3753 [38:35<3:53:06,  4.28s/it] 13%|█▎        | 484/3753 [38:40<3:50:14,  4.23s/it] 13%|█▎        | 485/3753 [38:43<3:40:17,  4.04s/it] 13%|█▎        | 486/3753 [38:48<3:56:35,  4.35s/it] 13%|█▎        | 487/3753 [38:53<4:04:01,  4.48s/it] 13%|█▎        | 488/3753 [38:57<3:50:43,  4.24s/it] 13%|█▎        | 489/3753 [39:02<3:59:20,  4.40s/it] 13%|█▎        | 490/3753 [39:07<4:19:08,  4.77s/it]{'loss': 55.3699, 'grad_norm': 1142.034423828125, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.0469698905944824, 'weight_rejected': 2.925139904022217, 'kl_term_chosen': 2.9911468029022217, 'kl_term_rejected': 2.870941162109375, 'epoch': 0.13057961359093936}
                                                    {'loss': 55.3699, 'grad_norm': 1142.034423828125, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.0469698905944824, 'weight_rejected': 2.925139904022217, 'kl_term_chosen': 2.9911468029022217, 'kl_term_rejected': 2.870941162109375, 'epoch': 0.13}
 13%|█▎        | 490/3753 [39:07<4:19:08,  4.77s/it] 13%|█▎        | 491/3753 [39:12<4:21:14,  4.81s/it] 13%|█▎        | 492/3753 [39:16<4:04:12,  4.49s/it] 13%|█▎        | 493/3753 [39:26<5:33:59,  6.15s/it] 13%|█▎        | 494/3753 [39:30<4:55:27,  5.44s/it] 13%|█▎        | 495/3753 [39:33<4:25:22,  4.89s/it] 13%|█▎        | 496/3753 [39:38<4:24:57,  4.88s/it] 13%|█▎        | 497/3753 [39:42<4:04:31,  4.51s/it] 13%|█▎        | 498/3753 [39:49<4:57:57,  5.49s/it] 13%|█▎        | 499/3753 [39:56<5:12:31,  5.76s/it] 13%|█▎        | 500/3753 [40:00<4:53:40,  5.42s/it]{'loss': 50.0984, 'grad_norm': 441.3103942871094, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.0085464715957642, 'weight_rejected': 1.1136422157287598, 'kl_term_chosen': 1.650978922843933, 'kl_term_rejected': 0.8909420371055603, 'epoch': 0.13324450366422386}
                                                    {'loss': 50.0984, 'grad_norm': 441.3103942871094, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.0085464715957642, 'weight_rejected': 1.1136422157287598, 'kl_term_chosen': 1.650978922843933, 'kl_term_rejected': 0.8909420371055603, 'epoch': 0.13}
 13%|█▎        | 500/3753 [40:01<4:53:40,  5.42s/it] 13%|█▎        | 501/3753 [40:05<4:37:55,  5.13s/it] 13%|█▎        | 502/3753 [40:13<5:26:20,  6.02s/it] 13%|█▎        | 503/3753 [40:17<4:57:43,  5.50s/it] 13%|█▎        | 504/3753 [40:21<4:30:54,  5.00s/it] 13%|█▎        | 505/3753 [40:25<4:10:15,  4.62s/it] 13%|█▎        | 506/3753 [40:29<3:55:52,  4.36s/it] 14%|█▎        | 507/3753 [40:34<4:10:22,  4.63s/it] 14%|█▎        | 508/3753 [40:39<4:19:09,  4.79s/it] 14%|█▎        | 509/3753 [40:43<4:05:42,  4.54s/it] 14%|█▎        | 510/3753 [40:48<4:04:24,  4.52s/it]{'loss': 40.3036, 'grad_norm': 4102.20703125, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.3726990222930908, 'weight_rejected': -0.302293062210083, 'kl_term_chosen': 1.328680396080017, 'kl_term_rejected': -0.3358825743198395, 'epoch': 0.13590939373750832}
                                                    {'loss': 40.3036, 'grad_norm': 4102.20703125, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.3726990222930908, 'weight_rejected': -0.302293062210083, 'kl_term_chosen': 1.328680396080017, 'kl_term_rejected': -0.3358825743198395, 'epoch': 0.14}
 14%|█▎        | 510/3753 [40:48<4:04:24,  4.52s/it] 14%|█▎        | 511/3753 [40:52<4:03:31,  4.51s/it] 14%|█▎        | 512/3753 [40:56<3:54:04,  4.33s/it] 14%|█▎        | 513/3753 [41:03<4:43:18,  5.25s/it] 14%|█▎        | 514/3753 [41:08<4:36:05,  5.11s/it] 14%|█▎        | 515/3753 [41:13<4:35:04,  5.10s/it] 14%|█▎        | 516/3753 [41:17<4:20:38,  4.83s/it] 14%|█▍        | 517/3753 [41:21<4:02:23,  4.49s/it] 14%|█▍        | 518/3753 [41:25<3:56:38,  4.39s/it] 14%|█▍        | 519/3753 [41:30<4:04:18,  4.53s/it] 14%|█▍        | 520/3753 [41:35<4:16:04,  4.75s/it]{'loss': 41.8225, 'grad_norm': 47.88703155517578, 'learning_rate': 9.955821687527552e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.746965408325195, 'weight_rejected': 1.8955678939819336, 'kl_term_chosen': 5.670004367828369, 'kl_term_rejected': 1.8429489135742188, 'epoch': 0.13857428381079281}
                                                    {'loss': 41.8225, 'grad_norm': 47.88703155517578, 'learning_rate': 9.955821687527552e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.746965408325195, 'weight_rejected': 1.8955678939819336, 'kl_term_chosen': 5.670004367828369, 'kl_term_rejected': 1.8429489135742188, 'epoch': 0.14}
 14%|█▍        | 520/3753 [41:35<4:16:04,  4.75s/it] 14%|█▍        | 521/3753 [41:40<4:09:08,  4.63s/it] 14%|█▍        | 522/3753 [41:44<4:05:33,  4.56s/it] 14%|█▍        | 523/3753 [41:50<4:31:12,  5.04s/it] 14%|█▍        | 524/3753 [41:55<4:25:19,  4.93s/it] 14%|█▍        | 525/3753 [41:59<4:09:34,  4.64s/it] 14%|█▍        | 526/3753 [42:02<3:46:21,  4.21s/it] 14%|█▍        | 527/3753 [42:06<3:36:46,  4.03s/it] 14%|█▍        | 528/3753 [42:11<3:49:27,  4.27s/it] 14%|█▍        | 529/3753 [42:14<3:36:56,  4.04s/it] 14%|█▍        | 530/3753 [42:18<3:38:50,  4.07s/it]{'loss': 39.6219, 'grad_norm': 1093.1861572265625, 'learning_rate': 9.94943765952491e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.149165630340576, 'weight_rejected': -0.11008098721504211, 'kl_term_chosen': 2.5850670337677, 'kl_term_rejected': -0.4429332911968231, 'epoch': 0.14123917388407728}
                                                    {'loss': 39.6219, 'grad_norm': 1093.1861572265625, 'learning_rate': 9.94943765952491e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.149165630340576, 'weight_rejected': -0.11008098721504211, 'kl_term_chosen': 2.5850670337677, 'kl_term_rejected': -0.4429332911968231, 'epoch': 0.14}
 14%|█▍        | 530/3753 [42:18<3:38:50,  4.07s/it] 14%|█▍        | 531/3753 [42:22<3:28:28,  3.88s/it] 14%|█▍        | 532/3753 [42:26<3:36:21,  4.03s/it] 14%|█▍        | 533/3753 [42:31<3:49:31,  4.28s/it] 14%|█▍        | 534/3753 [42:34<3:38:58,  4.08s/it] 14%|█▍        | 535/3753 [42:39<3:45:20,  4.20s/it] 14%|█▍        | 536/3753 [42:43<3:50:45,  4.30s/it] 14%|█▍        | 537/3753 [42:48<3:57:57,  4.44s/it] 14%|█▍        | 538/3753 [42:52<3:39:02,  4.09s/it] 14%|█▍        | 539/3753 [42:55<3:31:01,  3.94s/it] 14%|█▍        | 540/3753 [42:58<3:21:13,  3.76s/it]{'loss': 29.3987, 'grad_norm': 664.2882690429688, 'learning_rate': 9.942625289827702e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.9255539774894714, 'weight_rejected': 3.9004836082458496, 'kl_term_chosen': 1.853962779045105, 'kl_term_rejected': 3.777117967605591, 'epoch': 0.14390406395736177}
                                                    {'loss': 29.3987, 'grad_norm': 664.2882690429688, 'learning_rate': 9.942625289827702e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.9255539774894714, 'weight_rejected': 3.9004836082458496, 'kl_term_chosen': 1.853962779045105, 'kl_term_rejected': 3.777117967605591, 'epoch': 0.14}
 14%|█▍        | 540/3753 [42:59<3:21:13,  3.76s/it] 14%|█▍        | 541/3753 [43:02<3:20:29,  3.75s/it] 14%|█▍        | 542/3753 [43:06<3:23:33,  3.80s/it] 14%|█▍        | 543/3753 [43:09<3:12:49,  3.60s/it] 14%|█▍        | 544/3753 [43:14<3:26:15,  3.86s/it] 15%|█▍        | 545/3753 [43:18<3:30:06,  3.93s/it] 15%|█▍        | 546/3753 [43:21<3:22:03,  3.78s/it] 15%|█▍        | 547/3753 [43:26<3:40:21,  4.12s/it] 15%|█▍        | 548/3753 [43:33<4:31:45,  5.09s/it] 15%|█▍        | 549/3753 [43:37<4:12:32,  4.73s/it] 15%|█▍        | 550/3753 [43:42<4:16:29,  4.80s/it]{'loss': 14.0984, 'grad_norm': 564.1066284179688, 'learning_rate': 9.935385168002298e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.674896717071533, 'weight_rejected': -1.823732852935791, 'kl_term_chosen': 4.611181735992432, 'kl_term_rejected': -1.899591088294983, 'epoch': 0.14656895403064624}
                                                    {'loss': 14.0984, 'grad_norm': 564.1066284179688, 'learning_rate': 9.935385168002298e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.674896717071533, 'weight_rejected': -1.823732852935791, 'kl_term_chosen': 4.611181735992432, 'kl_term_rejected': -1.899591088294983, 'epoch': 0.15}
 15%|█▍        | 550/3753 [43:42<4:16:29,  4.80s/it] 15%|█▍        | 551/3753 [43:47<4:12:18,  4.73s/it] 15%|█▍        | 552/3753 [43:50<3:51:10,  4.33s/it] 15%|█▍        | 553/3753 [43:54<3:44:06,  4.20s/it] 15%|█▍        | 554/3753 [43:59<3:47:28,  4.27s/it] 15%|█▍        | 555/3753 [44:03<3:48:37,  4.29s/it] 15%|█▍        | 556/3753 [44:07<3:46:32,  4.25s/it] 15%|█▍        | 557/3753 [44:13<4:12:58,  4.75s/it] 15%|█▍        | 558/3753 [44:17<4:06:23,  4.63s/it] 15%|█▍        | 559/3753 [44:21<3:56:57,  4.45s/it] 15%|█▍        | 560/3753 [44:25<3:44:45,  4.22s/it]{'loss': 12.4346, 'grad_norm': 515.7142333984375, 'learning_rate': 9.927717920634233e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.562947154045105, 'weight_rejected': 6.0058369636535645, 'kl_term_chosen': 0.3153671324253082, 'kl_term_rejected': 5.818704128265381, 'epoch': 0.1492338441039307}
                                                    {'loss': 12.4346, 'grad_norm': 515.7142333984375, 'learning_rate': 9.927717920634233e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.562947154045105, 'weight_rejected': 6.0058369636535645, 'kl_term_chosen': 0.3153671324253082, 'kl_term_rejected': 5.818704128265381, 'epoch': 0.15}
 15%|█▍        | 560/3753 [44:25<3:44:45,  4.22s/it] 15%|█▍        | 561/3753 [44:29<3:36:13,  4.06s/it] 15%|█▍        | 562/3753 [44:34<3:58:44,  4.49s/it] 15%|█▌        | 563/3753 [44:38<3:53:02,  4.38s/it] 15%|█▌        | 564/3753 [44:43<3:48:52,  4.31s/it] 15%|█▌        | 565/3753 [44:47<3:56:15,  4.45s/it] 15%|█▌        | 566/3753 [44:52<3:54:08,  4.41s/it] 15%|█▌        | 567/3753 [44:57<4:02:42,  4.57s/it] 15%|█▌        | 568/3753 [45:05<4:56:06,  5.58s/it] 15%|█▌        | 569/3753 [45:09<4:35:22,  5.19s/it] 15%|█▌        | 570/3753 [45:12<4:06:43,  4.65s/it]{'loss': 27.9317, 'grad_norm': 1722.7222900390625, 'learning_rate': 9.919624211273986e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.11390060186386108, 'weight_rejected': 8.29372501373291, 'kl_term_chosen': 0.8567871451377869, 'kl_term_rejected': 8.239526748657227, 'epoch': 0.1518987341772152}
                                                    {'loss': 27.9317, 'grad_norm': 1722.7222900390625, 'learning_rate': 9.919624211273986e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.11390060186386108, 'weight_rejected': 8.29372501373291, 'kl_term_chosen': 0.8567871451377869, 'kl_term_rejected': 8.239526748657227, 'epoch': 0.15}
 15%|█▌        | 570/3753 [45:12<4:06:43,  4.65s/it] 15%|█▌        | 571/3753 [45:17<4:15:51,  4.82s/it] 15%|█▌        | 572/3753 [45:21<3:51:07,  4.36s/it] 15%|█▌        | 573/3753 [45:25<3:43:10,  4.21s/it] 15%|█▌        | 574/3753 [45:29<3:40:52,  4.17s/it] 15%|█▌        | 575/3753 [45:37<4:41:16,  5.31s/it] 15%|█▌        | 576/3753 [45:41<4:26:47,  5.04s/it] 15%|█▌        | 577/3753 [45:46<4:19:00,  4.89s/it] 15%|█▌        | 578/3753 [45:50<4:16:18,  4.84s/it] 15%|█▌        | 579/3753 [45:54<3:51:56,  4.38s/it] 15%|█▌        | 580/3753 [45:58<3:51:34,  4.38s/it]{'loss': 29.4563, 'grad_norm': 373.29412841796875, 'learning_rate': 9.911104740379551e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.3966960906982422, 'weight_rejected': 2.2753045558929443, 'kl_term_chosen': 0.5064018368721008, 'kl_term_rejected': 1.4253333806991577, 'epoch': 0.15456362425049966}
                                                    {'loss': 29.4563, 'grad_norm': 373.29412841796875, 'learning_rate': 9.911104740379551e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.3966960906982422, 'weight_rejected': 2.2753045558929443, 'kl_term_chosen': 0.5064018368721008, 'kl_term_rejected': 1.4253333806991577, 'epoch': 0.15}
 15%|█▌        | 580/3753 [45:58<3:51:34,  4.38s/it] 15%|█▌        | 581/3753 [46:02<3:43:21,  4.22s/it] 16%|█▌        | 582/3753 [46:06<3:48:23,  4.32s/it] 16%|█▌        | 583/3753 [46:10<3:37:53,  4.12s/it] 16%|█▌        | 584/3753 [46:13<3:22:59,  3.84s/it] 16%|█▌        | 585/3753 [46:17<3:26:49,  3.92s/it] 16%|█▌        | 586/3753 [46:21<3:24:43,  3.88s/it] 16%|█▌        | 587/3753 [46:26<3:35:17,  4.08s/it] 16%|█▌        | 588/3753 [46:30<3:43:11,  4.23s/it] 16%|█▌        | 589/3753 [46:36<4:05:35,  4.66s/it] 16%|█▌        | 590/3753 [46:39<3:46:52,  4.30s/it]{'loss': 36.5866, 'grad_norm': 0.0, 'learning_rate': 9.902160245255826e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.035365104675293, 'weight_rejected': 2.0845561027526855, 'kl_term_chosen': 6.90944242477417, 'kl_term_rejected': 1.9586334228515625, 'epoch': 0.15722851432378415}
                                                    {'loss': 36.5866, 'grad_norm': 0.0, 'learning_rate': 9.902160245255826e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.035365104675293, 'weight_rejected': 2.0845561027526855, 'kl_term_chosen': 6.90944242477417, 'kl_term_rejected': 1.9586334228515625, 'epoch': 0.16}
 16%|█▌        | 590/3753 [46:39<3:46:52,  4.30s/it] 16%|█▌        | 591/3753 [46:44<3:48:10,  4.33s/it] 16%|█▌        | 592/3753 [46:48<3:41:21,  4.20s/it] 16%|█▌        | 593/3753 [46:53<3:59:04,  4.54s/it] 16%|█▌        | 594/3753 [46:57<3:52:28,  4.42s/it] 16%|█▌        | 595/3753 [47:01<3:38:21,  4.15s/it] 16%|█▌        | 596/3753 [47:05<3:37:18,  4.13s/it] 16%|█▌        | 597/3753 [47:08<3:30:49,  4.01s/it] 16%|█▌        | 598/3753 [47:13<3:35:40,  4.10s/it] 16%|█▌        | 599/3753 [47:18<3:45:48,  4.30s/it] 16%|█▌        | 600/3753 [47:23<3:57:27,  4.52s/it]{'loss': 39.91, 'grad_norm': 1989.1900634765625, 'learning_rate': 9.892791499990784e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 8.10934829711914, 'weight_chosen': -4.593108177185059, 'weight_rejected': 0.29440081119537354, 'kl_term_chosen': 5.5546417236328125, 'kl_term_rejected': 0.20930175483226776, 'epoch': 0.15989340439706862}
                                                    {'loss': 39.91, 'grad_norm': 1989.1900634765625, 'learning_rate': 9.892791499990784e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 8.10934829711914, 'weight_chosen': -4.593108177185059, 'weight_rejected': 0.29440081119537354, 'kl_term_chosen': 5.5546417236328125, 'kl_term_rejected': 0.20930175483226776, 'epoch': 0.16}
 16%|█▌        | 600/3753 [47:23<3:57:27,  4.52s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 16%|█▌        | 601/3753 [48:20<17:48:53, 20.35s/it] 16%|█▌        | 602/3753 [48:24<13:37:51, 15.57s/it] 16%|█▌        | 603/3753 [48:29<10:54:27, 12.47s/it] 16%|█▌        | 604/3753 [48:34<8:41:23,  9.93s/it]  16%|█▌        | 605/3753 [48:38<7:09:37,  8.19s/it] 16%|█▌        | 606/3753 [48:42<6:07:26,  7.01s/it] 16%|█▌        | 607/3753 [48:45<5:10:02,  5.91s/it] 16%|█▌        | 608/3753 [48:49<4:42:15,  5.38s/it] 16%|█▌        | 609/3753 [48:54<4:33:55,  5.23s/it] 16%|█▋        | 610/3753 [48:58<4:03:06,  4.64s/it]{'loss': 43.4685, 'grad_norm': 1593.636474609375, 'learning_rate': 9.882999315388504e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.005562782287598, 'weight_rejected': 1.062937617301941, 'kl_term_chosen': 4.843182563781738, 'kl_term_rejected': 0.9226013422012329, 'epoch': 0.1625582944703531}
                                                    {'loss': 43.4685, 'grad_norm': 1593.636474609375, 'learning_rate': 9.882999315388504e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.005562782287598, 'weight_rejected': 1.062937617301941, 'kl_term_chosen': 4.843182563781738, 'kl_term_rejected': 0.9226013422012329, 'epoch': 0.16}
 16%|█▋        | 610/3753 [48:58<4:03:06,  4.64s/it] 16%|█▋        | 611/3753 [49:01<3:37:53,  4.16s/it] 16%|█▋        | 612/3753 [49:09<4:51:35,  5.57s/it] 16%|█▋        | 613/3753 [49:13<4:17:59,  4.93s/it] 16%|█▋        | 614/3753 [49:18<4:25:10,  5.07s/it] 16%|█▋        | 615/3753 [49:22<4:10:04,  4.78s/it] 16%|█▋        | 616/3753 [49:27<4:06:47,  4.72s/it] 16%|█▋        | 617/3753 [49:31<3:54:43,  4.49s/it] 16%|█▋        | 618/3753 [49:34<3:39:42,  4.20s/it] 16%|█▋        | 619/3753 [49:37<3:20:06,  3.83s/it] 17%|█▋        | 620/3753 [49:43<3:53:47,  4.48s/it]{'loss': 50.5354, 'grad_norm': 205.7445831298828, 'learning_rate': 9.872784538898985e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -8.473956108093262, 'weight_rejected': -0.29336920380592346, 'kl_term_chosen': 8.814661026000977, 'kl_term_rejected': -0.7563278079032898, 'epoch': 0.16522318454363757}
                                                    {'loss': 50.5354, 'grad_norm': 205.7445831298828, 'learning_rate': 9.872784538898985e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -8.473956108093262, 'weight_rejected': -0.29336920380592346, 'kl_term_chosen': 8.814661026000977, 'kl_term_rejected': -0.7563278079032898, 'epoch': 0.17}
 17%|█▋        | 620/3753 [49:43<3:53:47,  4.48s/it] 17%|█▋        | 621/3753 [49:51<4:39:45,  5.36s/it] 17%|█▋        | 622/3753 [49:54<4:11:59,  4.83s/it] 17%|█▋        | 623/3753 [49:58<3:58:56,  4.58s/it] 17%|█▋        | 624/3753 [50:03<3:52:45,  4.46s/it] 17%|█▋        | 625/3753 [50:06<3:43:41,  4.29s/it] 17%|█▋        | 626/3753 [50:10<3:38:48,  4.20s/it] 17%|█▋        | 627/3753 [50:17<4:10:18,  4.80s/it] 17%|█▋        | 628/3753 [50:22<4:11:31,  4.83s/it] 17%|█▋        | 629/3753 [50:27<4:17:03,  4.94s/it] 17%|█▋        | 630/3753 [50:31<4:09:54,  4.80s/it]{'loss': 52.4259, 'grad_norm': 2987.59423828125, 'learning_rate': 9.86214805454481e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -10.225517272949219, 'weight_rejected': 1.5904629230499268, 'kl_term_chosen': 10.335223197937012, 'kl_term_rejected': 1.4501266479492188, 'epoch': 0.16788807461692204}
                                                    {'loss': 52.4259, 'grad_norm': 2987.59423828125, 'learning_rate': 9.86214805454481e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -10.225517272949219, 'weight_rejected': 1.5904629230499268, 'kl_term_chosen': 10.335223197937012, 'kl_term_rejected': 1.4501266479492188, 'epoch': 0.17}
 17%|█▋        | 630/3753 [50:31<4:09:54,  4.80s/it] 17%|█▋        | 631/3753 [50:36<4:09:38,  4.80s/it] 17%|█▋        | 632/3753 [50:40<3:57:40,  4.57s/it] 17%|█▋        | 633/3753 [50:46<4:16:40,  4.94s/it] 17%|█▋        | 634/3753 [50:51<4:13:19,  4.87s/it] 17%|█▋        | 635/3753 [50:54<3:54:51,  4.52s/it] 17%|█▋        | 636/3753 [50:59<3:51:13,  4.45s/it] 17%|█▋        | 637/3753 [51:02<3:39:48,  4.23s/it] 17%|█▋        | 638/3753 [51:06<3:31:00,  4.06s/it] 17%|█▋        | 639/3753 [51:15<4:50:30,  5.60s/it] 17%|█▋        | 640/3753 [51:19<4:30:49,  5.22s/it]{'loss': 50.0748, 'grad_norm': 421.8207092285156, 'learning_rate': 9.851090782844644e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.086831569671631, 'weight_rejected': 2.7514069080352783, 'kl_term_chosen': 7.030179023742676, 'kl_term_rejected': 2.6744461059570312, 'epoch': 0.17055296469020653}
                                                    {'loss': 50.0748, 'grad_norm': 421.8207092285156, 'learning_rate': 9.851090782844644e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.086831569671631, 'weight_rejected': 2.7514069080352783, 'kl_term_chosen': 7.030179023742676, 'kl_term_rejected': 2.6744461059570312, 'epoch': 0.17}
 17%|█▋        | 640/3753 [51:20<4:30:49,  5.22s/it] 17%|█▋        | 641/3753 [51:27<5:03:12,  5.85s/it] 17%|█▋        | 642/3753 [51:35<5:37:37,  6.51s/it] 17%|█▋        | 643/3753 [51:39<5:03:17,  5.85s/it] 17%|█▋        | 644/3753 [51:43<4:38:52,  5.38s/it] 17%|█▋        | 645/3753 [51:48<4:27:27,  5.16s/it] 17%|█▋        | 646/3753 [51:52<4:06:54,  4.77s/it] 17%|█▋        | 647/3753 [51:56<3:56:40,  4.57s/it] 17%|█▋        | 648/3753 [51:59<3:33:21,  4.12s/it] 17%|█▋        | 649/3753 [52:04<3:37:47,  4.21s/it] 17%|█▋        | 650/3753 [52:07<3:30:44,  4.07s/it]{'loss': 50.4399, 'grad_norm': 0.0, 'learning_rate': 9.839613680733559e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.9866721630096436, 'weight_rejected': 3.1797893047332764, 'kl_term_chosen': 2.7401387691497803, 'kl_term_rejected': 2.8399617671966553, 'epoch': 0.173217854763491}
                                                    {'loss': 50.4399, 'grad_norm': 0.0, 'learning_rate': 9.839613680733559e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.9866721630096436, 'weight_rejected': 3.1797893047332764, 'kl_term_chosen': 2.7401387691497803, 'kl_term_rejected': 2.8399617671966553, 'epoch': 0.17}
 17%|█▋        | 650/3753 [52:07<3:30:44,  4.07s/it] 17%|█▋        | 651/3753 [52:16<4:46:16,  5.54s/it] 17%|█▋        | 652/3753 [52:22<4:49:38,  5.60s/it] 17%|█▋        | 653/3753 [52:27<4:41:47,  5.45s/it] 17%|█▋        | 654/3753 [52:36<5:40:39,  6.60s/it] 17%|█▋        | 655/3753 [52:40<4:56:57,  5.75s/it] 17%|█▋        | 656/3753 [52:44<4:33:29,  5.30s/it] 18%|█▊        | 657/3753 [52:48<4:12:24,  4.89s/it] 18%|█▊        | 658/3753 [52:55<4:38:56,  5.41s/it] 18%|█▊        | 659/3753 [52:58<4:06:54,  4.79s/it] 18%|█▊        | 660/3753 [53:03<4:03:29,  4.72s/it]{'loss': 53.4137, 'grad_norm': 0.0, 'learning_rate': 9.827717741480229e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.9068120718002319, 'weight_rejected': 2.511218309402466, 'kl_term_chosen': 0.9535369873046875, 'kl_term_rejected': 2.0820281505584717, 'epoch': 0.1758827448367755}
                                                    {'loss': 53.4137, 'grad_norm': 0.0, 'learning_rate': 9.827717741480229e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.9068120718002319, 'weight_rejected': 2.511218309402466, 'kl_term_chosen': 0.9535369873046875, 'kl_term_rejected': 2.0820281505584717, 'epoch': 0.18}
 18%|█▊        | 660/3753 [53:03<4:03:29,  4.72s/it] 18%|█▊        | 661/3753 [53:07<3:50:06,  4.47s/it] 18%|█▊        | 662/3753 [53:14<4:40:46,  5.45s/it] 18%|█▊        | 663/3753 [53:18<4:05:13,  4.76s/it] 18%|█▊        | 664/3753 [53:22<3:54:59,  4.56s/it] 18%|█▊        | 665/3753 [53:28<4:21:53,  5.09s/it] 18%|█▊        | 666/3753 [53:33<4:17:47,  5.01s/it] 18%|█▊        | 667/3753 [53:37<3:58:46,  4.64s/it] 18%|█▊        | 668/3753 [53:41<3:46:41,  4.41s/it] 18%|█▊        | 669/3753 [53:45<3:52:00,  4.51s/it] 18%|█▊        | 670/3753 [53:50<3:55:05,  4.58s/it]{'loss': 57.3885, 'grad_norm': 0.0, 'learning_rate': 9.815403994600958e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.434335708618164, 'weight_rejected': 3.556452989578247, 'kl_term_chosen': 6.362744331359863, 'kl_term_rejected': 3.4794921875, 'epoch': 0.17854763491005995}
                                                    {'loss': 57.3885, 'grad_norm': 0.0, 'learning_rate': 9.815403994600958e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.434335708618164, 'weight_rejected': 3.556452989578247, 'kl_term_chosen': 6.362744331359863, 'kl_term_rejected': 3.4794921875, 'epoch': 0.18}
 18%|█▊        | 670/3753 [53:50<3:55:05,  4.58s/it] 18%|█▊        | 671/3753 [53:54<3:41:59,  4.32s/it] 18%|█▊        | 672/3753 [54:05<5:21:34,  6.26s/it] 18%|█▊        | 673/3753 [54:08<4:44:03,  5.53s/it] 18%|█▊        | 674/3753 [54:16<5:15:22,  6.15s/it] 18%|█▊        | 675/3753 [54:20<4:46:25,  5.58s/it] 18%|█▊        | 676/3753 [54:24<4:23:30,  5.14s/it] 18%|█▊        | 677/3753 [54:29<4:22:08,  5.11s/it] 18%|█▊        | 678/3753 [54:33<4:04:08,  4.76s/it] 18%|█▊        | 679/3753 [54:43<5:16:24,  6.18s/it] 18%|█▊        | 680/3753 [54:47<4:48:53,  5.64s/it]{'loss': 58.2038, 'grad_norm': 195.563232421875, 'learning_rate': 9.80267350577059e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.7258358001708984, 'weight_rejected': 1.1916804313659668, 'kl_term_chosen': 3.4483628273010254, 'kl_term_rejected': 0.9227390289306641, 'epoch': 0.18121252498334445}
                                                    {'loss': 58.2038, 'grad_norm': 195.563232421875, 'learning_rate': 9.80267350577059e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.7258358001708984, 'weight_rejected': 1.1916804313659668, 'kl_term_chosen': 3.4483628273010254, 'kl_term_rejected': 0.9227390289306641, 'epoch': 0.18}
 18%|█▊        | 680/3753 [54:47<4:48:53,  5.64s/it] 18%|█▊        | 681/3753 [54:52<4:37:13,  5.41s/it] 18%|█▊        | 682/3753 [55:00<5:12:23,  6.10s/it] 18%|█▊        | 683/3753 [55:04<4:43:36,  5.54s/it] 18%|█▊        | 684/3753 [55:08<4:19:25,  5.07s/it] 18%|█▊        | 685/3753 [55:13<4:21:43,  5.12s/it] 18%|█▊        | 686/3753 [55:17<4:08:25,  4.86s/it] 18%|█▊        | 687/3753 [55:21<3:48:35,  4.47s/it] 18%|█▊        | 688/3753 [55:28<4:21:18,  5.12s/it] 18%|█▊        | 689/3753 [55:32<4:12:38,  4.95s/it] 18%|█▊        | 690/3753 [55:39<4:36:27,  5.42s/it]{'loss': 50.9512, 'grad_norm': 0.0, 'learning_rate': 9.78952737673028e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.3928992748260498, 'weight_rejected': 2.043266773223877, 'kl_term_chosen': 2.1619794368743896, 'kl_term_rejected': 1.9663059711456299, 'epoch': 0.1838774150566289}
                                                    {'loss': 50.9512, 'grad_norm': 0.0, 'learning_rate': 9.78952737673028e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.3928992748260498, 'weight_rejected': 2.043266773223877, 'kl_term_chosen': 2.1619794368743896, 'kl_term_rejected': 1.9663059711456299, 'epoch': 0.18}
 18%|█▊        | 690/3753 [55:39<4:36:27,  5.42s/it] 18%|█▊        | 691/3753 [55:43<4:19:56,  5.09s/it] 18%|█▊        | 692/3753 [55:46<3:45:12,  4.41s/it] 18%|█▊        | 693/3753 [55:52<4:18:12,  5.06s/it] 18%|█▊        | 694/3753 [55:59<4:44:08,  5.57s/it] 19%|█▊        | 695/3753 [56:04<4:29:34,  5.29s/it] 19%|█▊        | 696/3753 [56:08<4:15:31,  5.02s/it] 19%|█▊        | 697/3753 [56:12<3:57:30,  4.66s/it] 19%|█▊        | 698/3753 [56:17<3:56:58,  4.65s/it] 19%|█▊        | 699/3753 [56:22<4:00:39,  4.73s/it] 19%|█▊        | 700/3753 [56:26<3:51:34,  4.55s/it]{'loss': 39.1202, 'grad_norm': 0.0, 'learning_rate': 9.775966745192144e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 2.5507030487060547, 'weight_rejected': 0.5233383178710938, 'kl_term_chosen': -1.5960556268692017, 'kl_term_rejected': 0.3489280641078949, 'epoch': 0.18654230512991338}
                                                    {'loss': 39.1202, 'grad_norm': 0.0, 'learning_rate': 9.775966745192144e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 2.5507030487060547, 'weight_rejected': 0.5233383178710938, 'kl_term_chosen': -1.5960556268692017, 'kl_term_rejected': 0.3489280641078949, 'epoch': 0.19}
 19%|█▊        | 700/3753 [56:26<3:51:34,  4.55s/it] 19%|█▊        | 701/3753 [56:31<3:55:22,  4.63s/it] 19%|█▊        | 702/3753 [56:34<3:38:48,  4.30s/it] 19%|█▊        | 703/3753 [56:38<3:33:55,  4.21s/it] 19%|█▉        | 704/3753 [56:43<3:43:23,  4.40s/it] 19%|█▉        | 705/3753 [56:48<3:52:07,  4.57s/it] 19%|█▉        | 706/3753 [56:53<4:01:15,  4.75s/it] 19%|█▉        | 707/3753 [56:57<3:51:31,  4.56s/it] 19%|█▉        | 708/3753 [57:02<3:50:26,  4.54s/it] 19%|█▉        | 709/3753 [57:07<3:58:41,  4.70s/it] 19%|█▉        | 710/3753 [57:10<3:38:28,  4.31s/it]{'loss': 40.7442, 'grad_norm': 49.110984802246094, 'learning_rate': 9.761992784740795e-07, 'mean_ratio_chosen': 0.6115489602088928, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.21803294122219086, 'weight_rejected': 5.478689193725586, 'kl_term_chosen': -0.04917602613568306, 'kl_term_rejected': 5.439050197601318, 'epoch': 0.18920719520319787}
                                                    {'loss': 40.7442, 'grad_norm': 49.110984802246094, 'learning_rate': 9.761992784740795e-07, 'mean_ratio_chosen': 0.6115489602088928, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.21803294122219086, 'weight_rejected': 5.478689193725586, 'kl_term_chosen': -0.04917602613568306, 'kl_term_rejected': 5.439050197601318, 'epoch': 0.19}
 19%|█▉        | 710/3753 [57:10<3:38:28,  4.31s/it] 19%|█▉        | 711/3753 [57:14<3:27:27,  4.09s/it] 19%|█▉        | 712/3753 [57:20<3:53:42,  4.61s/it] 19%|█▉        | 713/3753 [57:24<3:53:27,  4.61s/it] 19%|█▉        | 714/3753 [57:28<3:46:55,  4.48s/it] 19%|█▉        | 715/3753 [57:35<4:15:04,  5.04s/it] 19%|█▉        | 716/3753 [57:40<4:11:56,  4.98s/it] 19%|█▉        | 717/3753 [57:45<4:13:56,  5.02s/it] 19%|█▉        | 718/3753 [57:49<4:05:36,  4.86s/it] 19%|█▉        | 719/3753 [57:53<3:51:14,  4.57s/it] 19%|█▉        | 720/3753 [57:57<3:38:17,  4.32s/it]{'loss': 43.1573, 'grad_norm': 2074.8544921875, 'learning_rate': 9.747606704731785e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.933773994445801, 'weight_rejected': 1.6713179349899292, 'kl_term_chosen': 3.7867095470428467, 'kl_term_rejected': 1.426232933998108, 'epoch': 0.19187208527648233}
                                                    {'loss': 43.1573, 'grad_norm': 2074.8544921875, 'learning_rate': 9.747606704731785e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.933773994445801, 'weight_rejected': 1.6713179349899292, 'kl_term_chosen': 3.7867095470428467, 'kl_term_rejected': 1.426232933998108, 'epoch': 0.19}
 19%|█▉        | 720/3753 [57:57<3:38:17,  4.32s/it] 19%|█▉        | 721/3753 [58:00<3:24:40,  4.05s/it] 19%|█▉        | 722/3753 [58:06<3:55:22,  4.66s/it] 19%|█▉        | 723/3753 [58:12<4:07:25,  4.90s/it] 19%|█▉        | 724/3753 [58:16<4:01:11,  4.78s/it] 19%|█▉        | 725/3753 [58:21<4:05:15,  4.86s/it] 19%|█▉        | 726/3753 [58:24<3:32:47,  4.22s/it] 19%|█▉        | 727/3753 [58:29<3:37:43,  4.32s/it] 19%|█▉        | 728/3753 [58:33<3:46:27,  4.49s/it] 19%|█▉        | 729/3753 [58:37<3:38:51,  4.34s/it] 19%|█▉        | 730/3753 [58:42<3:35:08,  4.27s/it]{'loss': 39.5309, 'grad_norm': 0.0, 'learning_rate': 9.732809750186936e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.395887851715088, 'weight_rejected': 1.1796984672546387, 'kl_term_chosen': 7.273364543914795, 'kl_term_rejected': 0.7254684567451477, 'epoch': 0.19453697534976683}
                                                    {'loss': 39.5309, 'grad_norm': 0.0, 'learning_rate': 9.732809750186936e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.395887851715088, 'weight_rejected': 1.1796984672546387, 'kl_term_chosen': 7.273364543914795, 'kl_term_rejected': 0.7254684567451477, 'epoch': 0.19}
 19%|█▉        | 730/3753 [58:42<3:35:08,  4.27s/it] 19%|█▉        | 731/3753 [58:49<4:30:25,  5.37s/it] 20%|█▉        | 732/3753 [58:54<4:17:34,  5.12s/it] 20%|█▉        | 733/3753 [58:58<4:06:47,  4.90s/it] 20%|█▉        | 734/3753 [59:03<4:08:00,  4.93s/it] 20%|█▉        | 735/3753 [59:07<3:41:43,  4.41s/it] 20%|█▉        | 736/3753 [59:11<3:36:36,  4.31s/it] 20%|█▉        | 737/3753 [59:15<3:33:22,  4.24s/it] 20%|█▉        | 738/3753 [59:20<3:42:11,  4.42s/it] 20%|█▉        | 739/3753 [59:24<3:35:47,  4.30s/it] 20%|█▉        | 740/3753 [59:28<3:32:40,  4.24s/it]{'loss': 43.8305, 'grad_norm': 0.0, 'learning_rate': 9.717603201686589e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.491706848144531, 'weight_rejected': -4.318836212158203, 'kl_term_chosen': -5.050274848937988, 'kl_term_rejected': -4.668368816375732, 'epoch': 0.1972018654230513}
                                                    {'loss': 43.8305, 'grad_norm': 0.0, 'learning_rate': 9.717603201686589e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.491706848144531, 'weight_rejected': -4.318836212158203, 'kl_term_chosen': -5.050274848937988, 'kl_term_rejected': -4.668368816375732, 'epoch': 0.2}
 20%|█▉        | 740/3753 [59:28<3:32:40,  4.24s/it] 20%|█▉        | 741/3753 [59:32<3:26:56,  4.12s/it] 20%|█▉        | 742/3753 [59:35<3:24:23,  4.07s/it] 20%|█▉        | 743/3753 [59:39<3:17:29,  3.94s/it] 20%|█▉        | 744/3753 [59:43<3:22:32,  4.04s/it] 20%|█▉        | 745/3753 [59:47<3:10:59,  3.81s/it] 20%|█▉        | 746/3753 [59:51<3:15:12,  3.89s/it] 20%|█▉        | 747/3753 [59:56<3:29:16,  4.18s/it] 20%|█▉        | 748/3753 [1:00:00<3:31:43,  4.23s/it] 20%|█▉        | 749/3753 [1:00:04<3:31:58,  4.23s/it] 20%|█▉        | 750/3753 [1:00:08<3:31:12,  4.22s/it]{'loss': 50.5363, 'grad_norm': 0.0, 'learning_rate': 9.701988375258787e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.726710081100464, 'weight_rejected': 3.574509859085083, 'kl_term_chosen': 3.571631669998169, 'kl_term_rejected': 3.3837857246398926, 'epoch': 0.19986675549633579}
                                                      {'loss': 50.5363, 'grad_norm': 0.0, 'learning_rate': 9.701988375258787e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.726710081100464, 'weight_rejected': 3.574509859085083, 'kl_term_chosen': 3.571631669998169, 'kl_term_rejected': 3.3837857246398926, 'epoch': 0.2}
 20%|█▉        | 750/3753 [1:00:08<3:31:12,  4.22s/it] 20%|██        | 751/3753 [1:00:13<3:30:20,  4.20s/it] 20%|██        | 752/3753 [1:00:17<3:29:44,  4.19s/it] 20%|██        | 753/3753 [1:00:20<3:11:06,  3.82s/it] 20%|██        | 754/3753 [1:00:24<3:20:25,  4.01s/it] 20%|██        | 755/3753 [1:00:28<3:25:26,  4.11s/it] 20%|██        | 756/3753 [1:00:32<3:18:30,  3.97s/it] 20%|██        | 757/3753 [1:00:36<3:13:37,  3.88s/it] 20%|██        | 758/3753 [1:00:40<3:17:15,  3.95s/it] 20%|██        | 759/3753 [1:00:45<3:33:27,  4.28s/it] 20%|██        | 760/3753 [1:00:52<4:20:28,  5.22s/it]{'loss': 53.0054, 'grad_norm': 0.0, 'learning_rate': 9.68596662226538e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.46242618560791, 'weight_rejected': 2.5821690559387207, 'kl_term_chosen': 3.3887298107147217, 'kl_term_rejected': 2.4527664184570312, 'epoch': 0.20253164556962025}
                                                      {'loss': 53.0054, 'grad_norm': 0.0, 'learning_rate': 9.68596662226538e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.46242618560791, 'weight_rejected': 2.5821690559387207, 'kl_term_chosen': 3.3887298107147217, 'kl_term_rejected': 2.4527664184570312, 'epoch': 0.2}
 20%|██        | 760/3753 [1:00:52<4:20:28,  5.22s/it] 20%|██        | 761/3753 [1:00:57<4:08:14,  4.98s/it] 20%|██        | 762/3753 [1:01:02<4:06:17,  4.94s/it] 20%|██        | 763/3753 [1:01:07<4:11:48,  5.05s/it] 20%|██        | 764/3753 [1:01:11<4:04:42,  4.91s/it] 20%|██        | 765/3753 [1:01:17<4:09:25,  5.01s/it] 20%|██        | 766/3753 [1:01:20<3:49:12,  4.60s/it] 20%|██        | 767/3753 [1:01:29<4:45:32,  5.74s/it] 20%|██        | 768/3753 [1:01:34<4:35:10,  5.53s/it] 20%|██        | 769/3753 [1:01:42<5:18:20,  6.40s/it] 21%|██        | 770/3753 [1:01:46<4:34:03,  5.51s/it]{'loss': 45.2503, 'grad_norm': 1284.3099365234375, 'learning_rate': 9.66953932928506e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -11.490705490112305, 'weight_rejected': -1.2803709506988525, 'kl_term_chosen': 12.266650199890137, 'kl_term_rejected': -1.4492279291152954, 'epoch': 0.20519653564290474}
                                                      {'loss': 45.2503, 'grad_norm': 1284.3099365234375, 'learning_rate': 9.66953932928506e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -11.490705490112305, 'weight_rejected': -1.2803709506988525, 'kl_term_chosen': 12.266650199890137, 'kl_term_rejected': -1.4492279291152954, 'epoch': 0.21}
 21%|██        | 770/3753 [1:01:46<4:34:03,  5.51s/it] 21%|██        | 771/3753 [1:01:51<4:25:44,  5.35s/it] 21%|██        | 772/3753 [1:01:54<3:54:05,  4.71s/it] 21%|██        | 773/3753 [1:01:58<3:44:37,  4.52s/it] 21%|██        | 774/3753 [1:02:03<3:51:28,  4.66s/it] 21%|██        | 775/3753 [1:02:07<3:42:37,  4.49s/it] 21%|██        | 776/3753 [1:02:11<3:40:58,  4.45s/it] 21%|██        | 777/3753 [1:02:15<3:31:59,  4.27s/it] 21%|██        | 778/3753 [1:02:19<3:27:52,  4.19s/it] 21%|██        | 779/3753 [1:02:23<3:28:03,  4.20s/it] 21%|██        | 780/3753 [1:02:29<3:48:25,  4.61s/it]{'loss': 48.5373, 'grad_norm': 820.3310546875, 'learning_rate': 9.652707917993383e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.421659469604492, 'weight_rejected': 1.7068455219268799, 'kl_term_chosen': 10.055975914001465, 'kl_term_rejected': 1.368768334388733, 'epoch': 0.2078614257161892}
                                                      {'loss': 48.5373, 'grad_norm': 820.3310546875, 'learning_rate': 9.652707917993383e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.421659469604492, 'weight_rejected': 1.7068455219268799, 'kl_term_chosen': 10.055975914001465, 'kl_term_rejected': 1.368768334388733, 'epoch': 0.21}
 21%|██        | 780/3753 [1:02:29<3:48:25,  4.61s/it] 21%|██        | 781/3753 [1:02:35<4:02:47,  4.90s/it] 21%|██        | 782/3753 [1:02:39<3:49:51,  4.64s/it] 21%|██        | 783/3753 [1:02:44<4:06:03,  4.97s/it] 21%|██        | 784/3753 [1:02:48<3:46:59,  4.59s/it] 21%|██        | 785/3753 [1:02:52<3:30:36,  4.26s/it] 21%|██        | 786/3753 [1:02:55<3:21:10,  4.07s/it] 21%|██        | 787/3753 [1:03:00<3:32:58,  4.31s/it] 21%|██        | 788/3753 [1:03:04<3:26:00,  4.17s/it] 21%|██        | 789/3753 [1:03:08<3:28:25,  4.22s/it] 21%|██        | 790/3753 [1:03:12<3:26:10,  4.17s/it]{'loss': 53.5036, 'grad_norm': 348.2621765136719, 'learning_rate': 9.635473845039716e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.7758917808532715, 'weight_rejected': 3.433741331100464, 'kl_term_chosen': 2.7232728004455566, 'kl_term_rejected': 3.383410692214966, 'epoch': 0.21052631578947367}
                                                      {'loss': 53.5036, 'grad_norm': 348.2621765136719, 'learning_rate': 9.635473845039716e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.7758917808532715, 'weight_rejected': 3.433741331100464, 'kl_term_chosen': 2.7232728004455566, 'kl_term_rejected': 3.383410692214966, 'epoch': 0.21}
 21%|██        | 790/3753 [1:03:12<3:26:10,  4.17s/it] 21%|██        | 791/3753 [1:03:16<3:20:20,  4.06s/it] 21%|██        | 792/3753 [1:03:21<3:29:37,  4.25s/it] 21%|██        | 793/3753 [1:03:25<3:31:31,  4.29s/it] 21%|██        | 794/3753 [1:03:32<4:07:30,  5.02s/it] 21%|██        | 795/3753 [1:03:36<3:58:53,  4.85s/it] 21%|██        | 796/3753 [1:03:41<4:01:14,  4.90s/it] 21%|██        | 797/3753 [1:03:46<4:02:53,  4.93s/it] 21%|██▏       | 798/3753 [1:03:50<3:48:41,  4.64s/it] 21%|██▏       | 799/3753 [1:03:55<3:49:55,  4.67s/it] 21%|██▏       | 800/3753 [1:03:59<3:44:12,  4.56s/it]{'loss': 46.6739, 'grad_norm': 267.47113037109375, 'learning_rate': 9.617838601921176e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.6053287386894226, 'weight_chosen': 6.276602745056152, 'weight_rejected': 0.7820383310317993, 'kl_term_chosen': -5.678760051727295, 'kl_term_rejected': -0.05019836500287056, 'epoch': 0.21319120586275817}
                                                      {'loss': 46.6739, 'grad_norm': 267.47113037109375, 'learning_rate': 9.617838601921176e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.6053287386894226, 'weight_chosen': 6.276602745056152, 'weight_rejected': 0.7820383310317993, 'kl_term_chosen': -5.678760051727295, 'kl_term_rejected': -0.05019836500287056, 'epoch': 0.21}
 21%|██▏       | 800/3753 [1:03:59<3:44:12,  4.56s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 21%|██▏       | 801/3753 [1:04:57<16:47:25, 20.48s/it] 21%|██▏       | 802/3753 [1:05:01<12:49:46, 15.65s/it] 21%|██▏       | 803/3753 [1:05:05<9:51:00, 12.02s/it]  21%|██▏       | 804/3753 [1:05:09<7:50:54,  9.58s/it] 21%|██▏       | 805/3753 [1:05:13<6:34:25,  8.03s/it] 21%|██▏       | 806/3753 [1:05:18<5:42:24,  6.97s/it] 22%|██▏       | 807/3753 [1:05:23<5:12:23,  6.36s/it] 22%|██▏       | 808/3753 [1:05:26<4:34:41,  5.60s/it] 22%|██▏       | 809/3753 [1:05:32<4:31:06,  5.53s/it] 22%|██▏       | 810/3753 [1:05:35<3:53:22,  4.76s/it]{'loss': 39.9924, 'grad_norm': 0.0, 'learning_rate': 9.599803714853558e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.199380874633789, 'weight_rejected': 3.0787341594696045, 'kl_term_chosen': 7.070855617523193, 'kl_term_rejected': 2.987352132797241, 'epoch': 0.21585609593604263}
                                                      {'loss': 39.9924, 'grad_norm': 0.0, 'learning_rate': 9.599803714853558e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.199380874633789, 'weight_rejected': 3.0787341594696045, 'kl_term_chosen': 7.070855617523193, 'kl_term_rejected': 2.987352132797241, 'epoch': 0.22}
 22%|██▏       | 810/3753 [1:05:35<3:53:22,  4.76s/it] 22%|██▏       | 811/3753 [1:05:39<3:51:58,  4.73s/it] 22%|██▏       | 812/3753 [1:05:43<3:37:57,  4.45s/it] 22%|██▏       | 813/3753 [1:05:47<3:30:59,  4.31s/it] 22%|██▏       | 814/3753 [1:05:50<3:13:09,  3.94s/it] 22%|██▏       | 815/3753 [1:05:54<3:14:30,  3.97s/it] 22%|██▏       | 816/3753 [1:06:00<3:37:54,  4.45s/it] 22%|██▏       | 817/3753 [1:06:05<3:41:09,  4.52s/it] 22%|██▏       | 818/3753 [1:06:08<3:29:13,  4.28s/it] 22%|██▏       | 819/3753 [1:06:15<3:59:53,  4.91s/it] 22%|██▏       | 820/3753 [1:06:19<3:44:57,  4.60s/it]{'loss': 38.7056, 'grad_norm': 1304.324951171875, 'learning_rate': 9.581370744639242e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.8048040866851807, 'weight_rejected': -0.5901216864585876, 'kl_term_chosen': 1.5404456853866577, 'kl_term_rejected': -0.7151870727539062, 'epoch': 0.21852098600932712}
                                                      {'loss': 38.7056, 'grad_norm': 1304.324951171875, 'learning_rate': 9.581370744639242e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.8048040866851807, 'weight_rejected': -0.5901216864585876, 'kl_term_chosen': 1.5404456853866577, 'kl_term_rejected': -0.7151870727539062, 'epoch': 0.22}
 22%|██▏       | 820/3753 [1:06:19<3:44:57,  4.60s/it] 22%|██▏       | 821/3753 [1:06:22<3:32:44,  4.35s/it] 22%|██▏       | 822/3753 [1:06:27<3:40:25,  4.51s/it] 22%|██▏       | 823/3753 [1:06:32<3:43:13,  4.57s/it] 22%|██▏       | 824/3753 [1:06:36<3:36:35,  4.44s/it] 22%|██▏       | 825/3753 [1:06:41<3:47:14,  4.66s/it] 22%|██▏       | 826/3753 [1:06:45<3:34:39,  4.40s/it] 22%|██▏       | 827/3753 [1:06:49<3:25:15,  4.21s/it] 22%|██▏       | 828/3753 [1:06:53<3:21:02,  4.12s/it] 22%|██▏       | 829/3753 [1:06:56<3:15:14,  4.01s/it] 22%|██▏       | 830/3753 [1:07:00<3:11:27,  3.93s/it]{'loss': 44.4911, 'grad_norm': 561.1200561523438, 'learning_rate': 9.562541286532122e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.2235080003738403, 'weight_rejected': 1.9150090217590332, 'kl_term_chosen': -0.5494575500488281, 'kl_term_rejected': 1.6167221069335938, 'epoch': 0.2211858760826116}
                                                      {'loss': 44.4911, 'grad_norm': 561.1200561523438, 'learning_rate': 9.562541286532122e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.2235080003738403, 'weight_rejected': 1.9150090217590332, 'kl_term_chosen': -0.5494575500488281, 'kl_term_rejected': 1.6167221069335938, 'epoch': 0.22}
 22%|██▏       | 830/3753 [1:07:00<3:11:27,  3.93s/it] 22%|██▏       | 831/3753 [1:07:05<3:17:56,  4.06s/it] 22%|██▏       | 832/3753 [1:07:09<3:15:47,  4.02s/it] 22%|██▏       | 833/3753 [1:07:13<3:22:42,  4.17s/it] 22%|██▏       | 834/3753 [1:07:17<3:17:37,  4.06s/it] 22%|██▏       | 835/3753 [1:07:21<3:16:12,  4.03s/it] 22%|██▏       | 836/3753 [1:07:25<3:19:59,  4.11s/it] 22%|██▏       | 837/3753 [1:07:30<3:36:54,  4.46s/it] 22%|██▏       | 838/3753 [1:07:35<3:33:01,  4.38s/it] 22%|██▏       | 839/3753 [1:07:38<3:21:41,  4.15s/it] 22%|██▏       | 840/3753 [1:07:42<3:23:11,  4.19s/it]{'loss': 39.47, 'grad_norm': 488.1620788574219, 'learning_rate': 9.543316970099546e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.608572959899902, 'weight_rejected': -0.28443247079849243, 'kl_term_chosen': -4.166418552398682, 'kl_term_rejected': -0.47037965059280396, 'epoch': 0.22385076615589608}
                                                      {'loss': 39.47, 'grad_norm': 488.1620788574219, 'learning_rate': 9.543316970099546e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.608572959899902, 'weight_rejected': -0.28443247079849243, 'kl_term_chosen': -4.166418552398682, 'kl_term_rejected': -0.47037965059280396, 'epoch': 0.22}
 22%|██▏       | 840/3753 [1:07:43<3:23:11,  4.19s/it] 22%|██▏       | 841/3753 [1:07:46<3:13:25,  3.99s/it] 22%|██▏       | 842/3753 [1:07:50<3:19:40,  4.12s/it] 22%|██▏       | 843/3753 [1:07:54<3:17:02,  4.06s/it] 22%|██▏       | 844/3753 [1:07:58<3:07:31,  3.87s/it] 23%|██▎       | 845/3753 [1:08:02<3:09:55,  3.92s/it] 23%|██▎       | 846/3753 [1:08:06<3:10:32,  3.93s/it] 23%|██▎       | 847/3753 [1:08:10<3:09:47,  3.92s/it] 23%|██▎       | 848/3753 [1:08:13<3:03:03,  3.78s/it] 23%|██▎       | 849/3753 [1:08:17<3:10:56,  3.95s/it] 23%|██▎       | 850/3753 [1:08:22<3:14:17,  4.02s/it]{'loss': 32.8147, 'grad_norm': 1379.3876953125, 'learning_rate': 9.523699459081285e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.6795454025268555, 'weight_rejected': 2.1289618015289307, 'kl_term_chosen': 6.617669582366943, 'kl_term_rejected': 2.1203842163085938, 'epoch': 0.22651565622918055}
                                                      {'loss': 32.8147, 'grad_norm': 1379.3876953125, 'learning_rate': 9.523699459081285e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.6795454025268555, 'weight_rejected': 2.1289618015289307, 'kl_term_chosen': 6.617669582366943, 'kl_term_rejected': 2.1203842163085938, 'epoch': 0.23}
 23%|██▎       | 850/3753 [1:08:22<3:14:17,  4.02s/it] 23%|██▎       | 851/3753 [1:08:26<3:22:24,  4.18s/it] 23%|██▎       | 852/3753 [1:08:30<3:19:03,  4.12s/it] 23%|██▎       | 853/3753 [1:08:34<3:18:25,  4.11s/it] 23%|██▎       | 854/3753 [1:08:39<3:28:01,  4.31s/it] 23%|██▎       | 855/3753 [1:08:44<3:33:23,  4.42s/it] 23%|██▎       | 856/3753 [1:08:49<3:40:47,  4.57s/it] 23%|██▎       | 857/3753 [1:08:53<3:32:33,  4.40s/it] 23%|██▎       | 858/3753 [1:08:57<3:38:20,  4.53s/it] 23%|██▎       | 859/3753 [1:09:03<3:47:47,  4.72s/it] 23%|██▎       | 860/3753 [1:09:09<4:07:14,  5.13s/it]{'loss': 38.5539, 'grad_norm': 0.0, 'learning_rate': 9.503690451245545e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.0025441646575928, 'weight_rejected': -2.9671967029571533, 'kl_term_chosen': -1.160718560218811, 'kl_term_rejected': -3.1555206775665283, 'epoch': 0.229180546302465}
                                                      {'loss': 38.5539, 'grad_norm': 0.0, 'learning_rate': 9.503690451245545e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.0025441646575928, 'weight_rejected': -2.9671967029571533, 'kl_term_chosen': -1.160718560218811, 'kl_term_rejected': -3.1555206775665283, 'epoch': 0.23}
 23%|██▎       | 860/3753 [1:09:09<4:07:14,  5.13s/it] 23%|██▎       | 861/3753 [1:09:17<4:49:05,  6.00s/it] 23%|██▎       | 862/3753 [1:09:21<4:30:23,  5.61s/it] 23%|██▎       | 863/3753 [1:09:25<3:57:23,  4.93s/it] 23%|██▎       | 864/3753 [1:09:28<3:39:00,  4.55s/it] 23%|██▎       | 865/3753 [1:09:32<3:30:06,  4.37s/it] 23%|██▎       | 866/3753 [1:09:36<3:21:51,  4.20s/it] 23%|██▎       | 867/3753 [1:09:42<3:43:58,  4.66s/it] 23%|██▎       | 868/3753 [1:09:47<3:49:48,  4.78s/it] 23%|██▎       | 869/3753 [1:09:50<3:28:18,  4.33s/it] 23%|██▎       | 870/3753 [1:09:56<3:47:15,  4.73s/it]{'loss': 33.387, 'grad_norm': 289.3062438964844, 'learning_rate': 9.483291678242047e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.2868289351463318, 'weight_rejected': -0.42794305086135864, 'kl_term_chosen': 1.0132545232772827, 'kl_term_rejected': -1.373744249343872, 'epoch': 0.2318454363757495}
                                                      {'loss': 33.387, 'grad_norm': 289.3062438964844, 'learning_rate': 9.483291678242047e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.2868289351463318, 'weight_rejected': -0.42794305086135864, 'kl_term_chosen': 1.0132545232772827, 'kl_term_rejected': -1.373744249343872, 'epoch': 0.23}
 23%|██▎       | 870/3753 [1:09:56<3:47:15,  4.73s/it] 23%|██▎       | 871/3753 [1:09:59<3:30:33,  4.38s/it] 23%|██▎       | 872/3753 [1:10:04<3:29:00,  4.35s/it] 23%|██▎       | 873/3753 [1:10:07<3:17:08,  4.11s/it] 23%|██▎       | 874/3753 [1:10:11<3:14:37,  4.06s/it] 23%|██▎       | 875/3753 [1:10:15<3:12:47,  4.02s/it] 23%|██▎       | 876/3753 [1:10:19<3:12:53,  4.02s/it] 23%|██▎       | 877/3753 [1:10:23<3:10:28,  3.97s/it] 23%|██▎       | 878/3753 [1:10:27<3:08:36,  3.94s/it] 23%|██▎       | 879/3753 [1:10:31<3:05:10,  3.87s/it] 23%|██▎       | 880/3753 [1:10:35<3:08:03,  3.93s/it]{'loss': 27.223, 'grad_norm': 2687.138916015625, 'learning_rate': 9.462504905452151e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.0023523569107055664, 'weight_rejected': 4.0782012939453125, 'kl_term_chosen': 0.8117004632949829, 'kl_term_rejected': 3.8700225353240967, 'epoch': 0.23451032644903397}
                                                      {'loss': 27.223, 'grad_norm': 2687.138916015625, 'learning_rate': 9.462504905452151e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.0023523569107055664, 'weight_rejected': 4.0782012939453125, 'kl_term_chosen': 0.8117004632949829, 'kl_term_rejected': 3.8700225353240967, 'epoch': 0.23}
 23%|██▎       | 880/3753 [1:10:35<3:08:03,  3.93s/it] 23%|██▎       | 881/3753 [1:10:39<3:07:50,  3.92s/it] 24%|██▎       | 882/3753 [1:10:42<3:03:05,  3.83s/it] 24%|██▎       | 883/3753 [1:10:50<3:53:16,  4.88s/it] 24%|██▎       | 884/3753 [1:10:57<4:32:27,  5.70s/it] 24%|██▎       | 885/3753 [1:11:01<4:12:31,  5.28s/it] 24%|██▎       | 886/3753 [1:11:06<3:57:42,  4.97s/it] 24%|██▎       | 887/3753 [1:11:09<3:36:13,  4.53s/it] 24%|██▎       | 888/3753 [1:11:13<3:32:35,  4.45s/it] 24%|██▎       | 889/3753 [1:11:18<3:28:56,  4.38s/it] 24%|██▎       | 890/3753 [1:11:21<3:16:17,  4.11s/it]{'loss': 32.3171, 'grad_norm': 63.554569244384766, 'learning_rate': 9.441331931836081e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.383699417114258, 'weight_rejected': -4.885115146636963, 'kl_term_chosen': -2.5450196266174316, 'kl_term_rejected': -5.037147521972656, 'epoch': 0.23717521652231846}
                                                      {'loss': 32.3171, 'grad_norm': 63.554569244384766, 'learning_rate': 9.441331931836081e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.383699417114258, 'weight_rejected': -4.885115146636963, 'kl_term_chosen': -2.5450196266174316, 'kl_term_rejected': -5.037147521972656, 'epoch': 0.24}
 24%|██▎       | 890/3753 [1:11:21<3:16:17,  4.11s/it] 24%|██▎       | 891/3753 [1:11:25<3:15:13,  4.09s/it] 24%|██▍       | 892/3753 [1:11:29<3:12:45,  4.04s/it] 24%|██▍       | 893/3753 [1:11:33<3:10:14,  3.99s/it] 24%|██▍       | 894/3753 [1:11:37<3:15:59,  4.11s/it] 24%|██▍       | 895/3753 [1:11:43<3:40:40,  4.63s/it] 24%|██▍       | 896/3753 [1:11:47<3:32:22,  4.46s/it] 24%|██▍       | 897/3753 [1:11:53<3:42:58,  4.68s/it] 24%|██▍       | 898/3753 [1:11:57<3:37:50,  4.58s/it] 24%|██▍       | 899/3753 [1:12:00<3:22:44,  4.26s/it] 24%|██▍       | 900/3753 [1:12:04<3:18:42,  4.18s/it]{'loss': 32.138, 'grad_norm': 347.5302734375, 'learning_rate': 9.419774589777236e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -5.064454078674316, 'weight_rejected': -0.266066312789917, 'kl_term_chosen': 6.009448528289795, 'kl_term_rejected': -0.347586065530777, 'epoch': 0.23984010659560293}
                                                      {'loss': 32.138, 'grad_norm': 347.5302734375, 'learning_rate': 9.419774589777236e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -5.064454078674316, 'weight_rejected': -0.266066312789917, 'kl_term_chosen': 6.009448528289795, 'kl_term_rejected': -0.347586065530777, 'epoch': 0.24}
 24%|██▍       | 900/3753 [1:12:04<3:18:42,  4.18s/it] 24%|██▍       | 901/3753 [1:12:08<3:11:03,  4.02s/it] 24%|██▍       | 902/3753 [1:12:12<3:15:39,  4.12s/it] 24%|██▍       | 903/3753 [1:12:17<3:21:28,  4.24s/it] 24%|██▍       | 904/3753 [1:12:21<3:14:42,  4.10s/it] 24%|██▍       | 905/3753 [1:12:25<3:17:14,  4.16s/it] 24%|██▍       | 906/3753 [1:12:29<3:10:34,  4.02s/it] 24%|██▍       | 907/3753 [1:12:33<3:10:01,  4.01s/it] 24%|██▍       | 908/3753 [1:12:37<3:14:05,  4.09s/it] 24%|██▍       | 909/3753 [1:12:42<3:24:14,  4.31s/it] 24%|██▍       | 910/3753 [1:12:50<4:16:30,  5.41s/it]{'loss': 35.0665, 'grad_norm': 29.553752899169922, 'learning_rate': 9.397834744923606e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.0888668298721313, 'weight_rejected': 5.083759307861328, 'kl_term_chosen': 1.7848252058029175, 'kl_term_rejected': 4.9138031005859375, 'epoch': 0.24250499666888742}
                                                      {'loss': 35.0665, 'grad_norm': 29.553752899169922, 'learning_rate': 9.397834744923606e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.0888668298721313, 'weight_rejected': 5.083759307861328, 'kl_term_chosen': 1.7848252058029175, 'kl_term_rejected': 4.9138031005859375, 'epoch': 0.24}
 24%|██▍       | 910/3753 [1:12:50<4:16:30,  5.41s/it] 24%|██▍       | 911/3753 [1:12:54<4:03:33,  5.14s/it] 24%|██▍       | 912/3753 [1:12:58<3:37:20,  4.59s/it] 24%|██▍       | 913/3753 [1:13:02<3:29:41,  4.43s/it] 24%|██▍       | 914/3753 [1:13:05<3:09:06,  4.00s/it] 24%|██▍       | 915/3753 [1:13:12<4:01:44,  5.11s/it] 24%|██▍       | 916/3753 [1:13:16<3:48:10,  4.83s/it] 24%|██▍       | 917/3753 [1:13:21<3:39:08,  4.64s/it] 24%|██▍       | 918/3753 [1:13:28<4:19:17,  5.49s/it] 24%|██▍       | 919/3753 [1:13:34<4:29:24,  5.70s/it] 25%|██▍       | 920/3753 [1:13:38<4:00:37,  5.10s/it]{'loss': 38.8865, 'grad_norm': 2583.1904296875, 'learning_rate': 9.375514296026317e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.05766141414642334, 'weight_rejected': 1.3925392627716064, 'kl_term_chosen': 0.8545867800712585, 'kl_term_rejected': 1.2225830554962158, 'epoch': 0.24516988674217188}
                                                      {'loss': 38.8865, 'grad_norm': 2583.1904296875, 'learning_rate': 9.375514296026317e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.05766141414642334, 'weight_rejected': 1.3925392627716064, 'kl_term_chosen': 0.8545867800712585, 'kl_term_rejected': 1.2225830554962158, 'epoch': 0.25}
 25%|██▍       | 920/3753 [1:13:38<4:00:37,  5.10s/it] 25%|██▍       | 921/3753 [1:13:42<3:43:58,  4.75s/it] 25%|██▍       | 922/3753 [1:13:48<3:59:57,  5.09s/it] 25%|██▍       | 923/3753 [1:13:52<3:52:33,  4.93s/it] 25%|██▍       | 924/3753 [1:13:58<4:05:56,  5.22s/it] 25%|██▍       | 925/3753 [1:14:03<4:03:21,  5.16s/it] 25%|██▍       | 926/3753 [1:14:07<3:47:10,  4.82s/it] 25%|██▍       | 927/3753 [1:14:12<3:45:53,  4.80s/it] 25%|██▍       | 928/3753 [1:14:16<3:29:03,  4.44s/it] 25%|██▍       | 929/3753 [1:14:22<3:59:04,  5.08s/it] 25%|██▍       | 930/3753 [1:14:26<3:44:03,  4.76s/it]{'loss': 39.6242, 'grad_norm': 19.34285545349121, 'learning_rate': 9.352815174775303e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.3497205972671509, 'weight_rejected': -5.646800994873047, 'kl_term_chosen': 2.15899658203125, 'kl_term_rejected': -5.740811347961426, 'epoch': 0.24783477681545638}
                                                      {'loss': 39.6242, 'grad_norm': 19.34285545349121, 'learning_rate': 9.352815174775303e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.3497205972671509, 'weight_rejected': -5.646800994873047, 'kl_term_chosen': 2.15899658203125, 'kl_term_rejected': -5.740811347961426, 'epoch': 0.25}
 25%|██▍       | 930/3753 [1:14:26<3:44:03,  4.76s/it] 25%|██▍       | 931/3753 [1:14:30<3:28:46,  4.44s/it] 25%|██▍       | 932/3753 [1:14:34<3:27:41,  4.42s/it] 25%|██▍       | 933/3753 [1:14:38<3:11:24,  4.07s/it] 25%|██▍       | 934/3753 [1:14:42<3:09:40,  4.04s/it] 25%|██▍       | 935/3753 [1:14:46<3:13:33,  4.12s/it] 25%|██▍       | 936/3753 [1:14:50<3:16:01,  4.18s/it] 25%|██▍       | 937/3753 [1:14:54<3:12:59,  4.11s/it] 25%|██▍       | 938/3753 [1:14:58<3:10:36,  4.06s/it] 25%|██▌       | 939/3753 [1:15:02<3:03:18,  3.91s/it] 25%|██▌       | 940/3753 [1:15:06<3:12:23,  4.10s/it]{'loss': 33.6062, 'grad_norm': 461.16571044921875, 'learning_rate': 9.329739345632131e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.7145565748214722, 'weight_rejected': -6.2907304763793945, 'kl_term_chosen': 2.584271192550659, 'kl_term_rejected': -6.523040771484375, 'epoch': 0.2504996668887408}
                                                      {'loss': 33.6062, 'grad_norm': 461.16571044921875, 'learning_rate': 9.329739345632131e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.7145565748214722, 'weight_rejected': -6.2907304763793945, 'kl_term_chosen': 2.584271192550659, 'kl_term_rejected': -6.523040771484375, 'epoch': 0.25}
 25%|██▌       | 940/3753 [1:15:06<3:12:23,  4.10s/it] 25%|██▌       | 941/3753 [1:15:12<3:37:29,  4.64s/it] 25%|██▌       | 942/3753 [1:15:16<3:34:18,  4.57s/it] 25%|██▌       | 943/3753 [1:15:20<3:16:22,  4.19s/it] 25%|██▌       | 944/3753 [1:15:24<3:17:43,  4.22s/it] 25%|██▌       | 945/3753 [1:15:27<3:04:38,  3.95s/it] 25%|██▌       | 946/3753 [1:15:31<3:02:49,  3.91s/it] 25%|██▌       | 947/3753 [1:15:36<3:09:24,  4.05s/it] 25%|██▌       | 948/3753 [1:15:41<3:31:02,  4.51s/it] 25%|██▌       | 949/3753 [1:15:45<3:21:39,  4.32s/it] 25%|██▌       | 950/3753 [1:15:49<3:18:04,  4.24s/it]{'loss': 34.7089, 'grad_norm': 59.609100341796875, 'learning_rate': 9.306288805659987e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.904627799987793, 'weight_rejected': 7.278706073760986, 'kl_term_chosen': 3.79941725730896, 'kl_term_rejected': 7.179235935211182, 'epoch': 0.25316455696202533}
                                                      {'loss': 34.7089, 'grad_norm': 59.609100341796875, 'learning_rate': 9.306288805659987e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.904627799987793, 'weight_rejected': 7.278706073760986, 'kl_term_chosen': 3.79941725730896, 'kl_term_rejected': 7.179235935211182, 'epoch': 0.25}
 25%|██▌       | 950/3753 [1:15:49<3:18:04,  4.24s/it] 25%|██▌       | 951/3753 [1:15:53<3:17:07,  4.22s/it] 25%|██▌       | 952/3753 [1:15:57<3:08:56,  4.05s/it] 25%|██▌       | 953/3753 [1:16:00<2:59:47,  3.85s/it] 25%|██▌       | 954/3753 [1:16:05<3:06:16,  3.99s/it] 25%|██▌       | 955/3753 [1:16:09<3:05:53,  3.99s/it] 25%|██▌       | 956/3753 [1:16:16<3:58:45,  5.12s/it] 25%|██▌       | 957/3753 [1:16:25<4:54:11,  6.31s/it] 26%|██▌       | 958/3753 [1:16:29<4:19:40,  5.57s/it] 26%|██▌       | 959/3753 [1:16:33<3:48:26,  4.91s/it] 26%|██▌       | 960/3753 [1:16:38<3:56:59,  5.09s/it]{'loss': 34.0488, 'grad_norm': 16.141746520996094, 'learning_rate': 9.282465584350855e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.545875072479248, 'weight_rejected': 4.717274188995361, 'kl_term_chosen': 2.1810975074768066, 'kl_term_rejected': 4.5922088623046875, 'epoch': 0.2558294470353098}
                                                      {'loss': 34.0488, 'grad_norm': 16.141746520996094, 'learning_rate': 9.282465584350855e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.545875072479248, 'weight_rejected': 4.717274188995361, 'kl_term_chosen': 2.1810975074768066, 'kl_term_rejected': 4.5922088623046875, 'epoch': 0.26}
 26%|██▌       | 960/3753 [1:16:38<3:56:59,  5.09s/it] 26%|██▌       | 961/3753 [1:16:41<3:29:29,  4.50s/it] 26%|██▌       | 962/3753 [1:16:45<3:12:42,  4.14s/it] 26%|██▌       | 963/3753 [1:16:49<3:15:17,  4.20s/it] 26%|██▌       | 964/3753 [1:16:53<3:19:02,  4.28s/it] 26%|██▌       | 965/3753 [1:16:59<3:35:10,  4.63s/it] 26%|██▌       | 966/3753 [1:17:03<3:23:12,  4.37s/it] 26%|██▌       | 967/3753 [1:17:06<3:08:17,  4.06s/it] 26%|██▌       | 968/3753 [1:17:10<3:14:38,  4.19s/it] 26%|██▌       | 969/3753 [1:17:15<3:16:02,  4.23s/it] 26%|██▌       | 970/3753 [1:17:23<4:10:20,  5.40s/it]{'loss': 33.7612, 'grad_norm': 0.0, 'learning_rate': 9.258271743449863e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.7953239679336548, 'weight_rejected': -5.4714789390563965, 'kl_term_chosen': 1.61865234375, 'kl_term_rejected': -5.537083625793457, 'epoch': 0.25849433710859426}
                                                      {'loss': 33.7612, 'grad_norm': 0.0, 'learning_rate': 9.258271743449863e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.7953239679336548, 'weight_rejected': -5.4714789390563965, 'kl_term_chosen': 1.61865234375, 'kl_term_rejected': -5.537083625793457, 'epoch': 0.26}
 26%|██▌       | 970/3753 [1:17:23<4:10:20,  5.40s/it] 26%|██▌       | 971/3753 [1:17:27<3:56:05,  5.09s/it] 26%|██▌       | 972/3753 [1:17:31<3:40:47,  4.76s/it] 26%|██▌       | 973/3753 [1:17:36<3:39:02,  4.73s/it] 26%|██▌       | 974/3753 [1:17:41<3:39:41,  4.74s/it] 26%|██▌       | 975/3753 [1:17:45<3:34:20,  4.63s/it] 26%|██▌       | 976/3753 [1:17:49<3:21:05,  4.34s/it] 26%|██▌       | 977/3753 [1:17:54<3:35:52,  4.67s/it] 26%|██▌       | 978/3753 [1:18:01<4:12:18,  5.46s/it] 26%|██▌       | 979/3753 [1:18:06<4:04:37,  5.29s/it] 26%|██▌       | 980/3753 [1:18:10<3:48:07,  4.94s/it]{'loss': 33.4243, 'grad_norm': 0.0, 'learning_rate': 9.233709376776858e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.5460100173950195, 'weight_rejected': -6.1420745849609375, 'kl_term_chosen': -5.740377902984619, 'kl_term_rejected': -7.10243558883667, 'epoch': 0.26115922718187873}
                                                      {'loss': 33.4243, 'grad_norm': 0.0, 'learning_rate': 9.233709376776858e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.5460100173950195, 'weight_rejected': -6.1420745849609375, 'kl_term_chosen': -5.740377902984619, 'kl_term_rejected': -7.10243558883667, 'epoch': 0.26}
 26%|██▌       | 980/3753 [1:18:11<3:48:07,  4.94s/it] 26%|██▌       | 981/3753 [1:18:15<3:42:42,  4.82s/it] 26%|██▌       | 982/3753 [1:18:19<3:32:38,  4.60s/it] 26%|██▌       | 983/3753 [1:18:24<3:36:44,  4.69s/it] 26%|██▌       | 984/3753 [1:18:29<3:35:50,  4.68s/it] 26%|██▌       | 985/3753 [1:18:33<3:31:12,  4.58s/it] 26%|██▋       | 986/3753 [1:18:37<3:21:04,  4.36s/it] 26%|██▋       | 987/3753 [1:18:41<3:13:33,  4.20s/it] 26%|██▋       | 988/3753 [1:18:46<3:24:45,  4.44s/it] 26%|██▋       | 989/3753 [1:18:50<3:28:51,  4.53s/it] 26%|██▋       | 990/3753 [1:18:55<3:31:35,  4.59s/it]{'loss': 24.6856, 'grad_norm': 2949.55419921875, 'learning_rate': 9.208780610045202e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.343863308429718, 'weight_rejected': 6.674618721008301, 'kl_term_chosen': 1.2196502685546875, 'kl_term_rejected': 6.5832366943359375, 'epoch': 0.26382411725516325}
                                                      {'loss': 24.6856, 'grad_norm': 2949.55419921875, 'learning_rate': 9.208780610045202e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.343863308429718, 'weight_rejected': 6.674618721008301, 'kl_term_chosen': 1.2196502685546875, 'kl_term_rejected': 6.5832366943359375, 'epoch': 0.26}
 26%|██▋       | 990/3753 [1:18:55<3:31:35,  4.59s/it] 26%|██▋       | 991/3753 [1:18:59<3:23:24,  4.42s/it] 26%|██▋       | 992/3753 [1:19:04<3:24:52,  4.45s/it] 26%|██▋       | 993/3753 [1:19:08<3:25:04,  4.46s/it] 26%|██▋       | 994/3753 [1:19:13<3:35:41,  4.69s/it] 27%|██▋       | 995/3753 [1:19:18<3:30:24,  4.58s/it] 27%|██▋       | 996/3753 [1:19:22<3:31:29,  4.60s/it] 27%|██▋       | 997/3753 [1:19:27<3:30:32,  4.58s/it] 27%|██▋       | 998/3753 [1:19:30<3:12:56,  4.20s/it] 27%|██▋       | 999/3753 [1:19:35<3:21:53,  4.40s/it] 27%|██▋       | 1000/3753 [1:19:38<3:00:21,  3.93s/it]{'loss': 32.1043, 'grad_norm': 0.0, 'learning_rate': 9.183487600677799e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.0418763160705566, 'weight_rejected': 4.19796085357666, 'kl_term_chosen': 3.620800733566284, 'kl_term_rejected': 4.144557476043701, 'epoch': 0.2664890073284477}
                                                       {'loss': 32.1043, 'grad_norm': 0.0, 'learning_rate': 9.183487600677799e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.0418763160705566, 'weight_rejected': 4.19796085357666, 'kl_term_chosen': 3.620800733566284, 'kl_term_rejected': 4.144557476043701, 'epoch': 0.27}
 27%|██▋       | 1000/3753 [1:19:38<3:00:21,  3.93s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 27%|██▋       | 1001/3753 [1:20:38<15:53:12, 20.78s/it] 27%|██▋       | 1002/3753 [1:20:42<11:58:10, 15.66s/it] 27%|██▋       | 1003/3753 [1:20:45<9:12:06, 12.05s/it]  27%|██▋       | 1004/3753 [1:20:52<7:55:09, 10.37s/it] 27%|██▋       | 1005/3753 [1:20:56<6:25:51,  8.42s/it] 27%|██▋       | 1006/3753 [1:21:00<5:29:46,  7.20s/it] 27%|██▋       | 1007/3753 [1:21:04<4:43:24,  6.19s/it] 27%|██▋       | 1008/3753 [1:21:09<4:22:31,  5.74s/it] 27%|██▋       | 1009/3753 [1:21:13<3:57:51,  5.20s/it] 27%|██▋       | 1010/3753 [1:21:20<4:33:44,  5.99s/it]{'loss': 32.4442, 'grad_norm': 0.0, 'learning_rate': 9.157832537620397e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.89007568359375, 'weight_rejected': -3.1595938205718994, 'kl_term_chosen': 4.70648193359375, 'kl_term_rejected': -3.1986420154571533, 'epoch': 0.2691538974017322}
                                                       {'loss': 32.4442, 'grad_norm': 0.0, 'learning_rate': 9.157832537620397e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.89007568359375, 'weight_rejected': -3.1595938205718994, 'kl_term_chosen': 4.70648193359375, 'kl_term_rejected': -3.1986420154571533, 'epoch': 0.27}
 27%|██▋       | 1010/3753 [1:21:20<4:33:44,  5.99s/it] 27%|██▋       | 1011/3753 [1:21:24<4:05:43,  5.38s/it] 27%|██▋       | 1012/3753 [1:21:30<4:06:09,  5.39s/it] 27%|██▋       | 1013/3753 [1:21:34<3:48:05,  4.99s/it] 27%|██▋       | 1014/3753 [1:21:39<3:48:51,  5.01s/it] 27%|██▋       | 1015/3753 [1:21:42<3:27:41,  4.55s/it] 27%|██▋       | 1016/3753 [1:21:46<3:17:42,  4.33s/it] 27%|██▋       | 1017/3753 [1:21:51<3:19:49,  4.38s/it] 27%|██▋       | 1018/3753 [1:21:55<3:16:56,  4.32s/it] 27%|██▋       | 1019/3753 [1:22:00<3:22:01,  4.43s/it] 27%|██▋       | 1020/3753 [1:22:04<3:17:05,  4.33s/it]{'loss': 32.0219, 'grad_norm': 0.0, 'learning_rate': 9.131817641152131e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.593201160430908, 'weight_rejected': 0.33435335755348206, 'kl_term_chosen': -2.4254379272460938, 'kl_term_rejected': -0.3439735472202301, 'epoch': 0.27181878747501664}
                                                       {'loss': 32.0219, 'grad_norm': 0.0, 'learning_rate': 9.131817641152131e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.593201160430908, 'weight_rejected': 0.33435335755348206, 'kl_term_chosen': -2.4254379272460938, 'kl_term_rejected': -0.3439735472202301, 'epoch': 0.27}
 27%|██▋       | 1020/3753 [1:22:04<3:17:05,  4.33s/it] 27%|██▋       | 1021/3753 [1:22:07<3:10:19,  4.18s/it] 27%|██▋       | 1022/3753 [1:22:12<3:14:36,  4.28s/it] 27%|██▋       | 1023/3753 [1:22:16<3:10:29,  4.19s/it] 27%|██▋       | 1024/3753 [1:22:20<3:11:15,  4.20s/it] 27%|██▋       | 1025/3753 [1:22:25<3:15:43,  4.30s/it] 27%|██▋       | 1026/3753 [1:22:33<4:09:53,  5.50s/it] 27%|██▋       | 1027/3753 [1:22:37<3:43:13,  4.91s/it] 27%|██▋       | 1028/3753 [1:22:41<3:34:06,  4.71s/it] 27%|██▋       | 1029/3753 [1:22:44<3:15:38,  4.31s/it] 27%|██▋       | 1030/3753 [1:22:49<3:17:50,  4.36s/it]{'loss': 25.079, 'grad_norm': 1894.4130859375, 'learning_rate': 9.105445162693387e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.7113125324249268, 'weight_rejected': -1.9951239824295044, 'kl_term_chosen': -0.8093917965888977, 'kl_term_rejected': -2.171795606613159, 'epoch': 0.2744836775483011}
                                                       {'loss': 25.079, 'grad_norm': 1894.4130859375, 'learning_rate': 9.105445162693387e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.7113125324249268, 'weight_rejected': -1.9951239824295044, 'kl_term_chosen': -0.8093917965888977, 'kl_term_rejected': -2.171795606613159, 'epoch': 0.27}
 27%|██▋       | 1030/3753 [1:22:49<3:17:50,  4.36s/it] 27%|██▋       | 1031/3753 [1:22:53<3:22:12,  4.46s/it] 27%|██▋       | 1032/3753 [1:22:57<3:16:42,  4.34s/it] 28%|██▊       | 1033/3753 [1:23:01<3:09:23,  4.18s/it] 28%|██▊       | 1034/3753 [1:23:06<3:13:37,  4.27s/it] 28%|██▊       | 1035/3753 [1:23:11<3:21:46,  4.45s/it] 28%|██▊       | 1036/3753 [1:23:16<3:39:34,  4.85s/it] 28%|██▊       | 1037/3753 [1:23:27<4:55:57,  6.54s/it] 28%|██▊       | 1038/3753 [1:23:31<4:18:01,  5.70s/it] 28%|██▊       | 1039/3753 [1:23:35<3:57:32,  5.25s/it] 28%|██▊       | 1040/3753 [1:23:39<3:45:20,  4.98s/it]{'loss': 35.6566, 'grad_norm': 0.0, 'learning_rate': 9.078717384610948e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.015906095504760742, 'weight_rejected': 7.755634307861328, 'kl_term_chosen': 0.9205566644668579, 'kl_term_rejected': 7.671743869781494, 'epoch': 0.27714856762158563}
                                                       {'loss': 35.6566, 'grad_norm': 0.0, 'learning_rate': 9.078717384610948e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.015906095504760742, 'weight_rejected': 7.755634307861328, 'kl_term_chosen': 0.9205566644668579, 'kl_term_rejected': 7.671743869781494, 'epoch': 0.28}
 28%|██▊       | 1040/3753 [1:23:39<3:45:20,  4.98s/it] 28%|██▊       | 1041/3753 [1:23:44<3:38:54,  4.84s/it] 28%|██▊       | 1042/3753 [1:23:48<3:36:57,  4.80s/it] 28%|██▊       | 1043/3753 [1:23:54<3:45:17,  4.99s/it] 28%|██▊       | 1044/3753 [1:24:00<4:05:27,  5.44s/it] 28%|██▊       | 1045/3753 [1:24:04<3:39:33,  4.86s/it] 28%|██▊       | 1046/3753 [1:24:07<3:21:50,  4.47s/it] 28%|██▊       | 1047/3753 [1:24:12<3:18:26,  4.40s/it] 28%|██▊       | 1048/3753 [1:24:16<3:13:48,  4.30s/it] 28%|██▊       | 1049/3753 [1:24:21<3:28:11,  4.62s/it] 28%|██▊       | 1050/3753 [1:24:25<3:26:18,  4.58s/it]{'loss': 44.8011, 'grad_norm': 844.5233764648438, 'learning_rate': 9.051636620020473e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.4387428760528564, 'weight_rejected': 4.8120293617248535, 'kl_term_chosen': 2.0454742908477783, 'kl_term_rejected': 4.62489652633667, 'epoch': 0.2798134576948701}
                                                       {'loss': 44.8011, 'grad_norm': 844.5233764648438, 'learning_rate': 9.051636620020473e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.4387428760528564, 'weight_rejected': 4.8120293617248535, 'kl_term_chosen': 2.0454742908477783, 'kl_term_rejected': 4.62489652633667, 'epoch': 0.28}
 28%|██▊       | 1050/3753 [1:24:26<3:26:18,  4.58s/it] 28%|██▊       | 1051/3753 [1:24:30<3:25:03,  4.55s/it] 28%|██▊       | 1052/3753 [1:24:35<3:25:22,  4.56s/it] 28%|██▊       | 1053/3753 [1:24:40<3:32:24,  4.72s/it] 28%|██▊       | 1054/3753 [1:24:44<3:21:30,  4.48s/it] 28%|██▊       | 1055/3753 [1:24:48<3:20:05,  4.45s/it] 28%|██▊       | 1056/3753 [1:24:52<3:15:24,  4.35s/it] 28%|██▊       | 1057/3753 [1:24:56<3:11:01,  4.25s/it] 28%|██▊       | 1058/3753 [1:25:00<3:03:02,  4.08s/it] 28%|██▊       | 1059/3753 [1:25:04<2:58:55,  3.98s/it] 28%|██▊       | 1060/3753 [1:25:07<2:56:03,  3.92s/it]{'loss': 43.9426, 'grad_norm': 0.0, 'learning_rate': 9.024205212586315e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.8717905282974243, 'weight_rejected': 2.414006471633911, 'kl_term_chosen': 1.4473785161972046, 'kl_term_rejected': 1.9953094720840454, 'epoch': 0.28247834776815456}
                                                       {'loss': 43.9426, 'grad_norm': 0.0, 'learning_rate': 9.024205212586315e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.8717905282974243, 'weight_rejected': 2.414006471633911, 'kl_term_chosen': 1.4473785161972046, 'kl_term_rejected': 1.9953094720840454, 'epoch': 0.28}
 28%|██▊       | 1060/3753 [1:25:07<2:56:03,  3.92s/it] 28%|██▊       | 1061/3753 [1:25:12<3:04:49,  4.12s/it] 28%|██▊       | 1062/3753 [1:25:17<3:12:47,  4.30s/it] 28%|██▊       | 1063/3753 [1:25:20<2:58:24,  3.98s/it] 28%|██▊       | 1064/3753 [1:25:27<3:42:40,  4.97s/it] 28%|██▊       | 1065/3753 [1:25:31<3:33:34,  4.77s/it] 28%|██▊       | 1066/3753 [1:25:34<3:09:49,  4.24s/it] 28%|██▊       | 1067/3753 [1:25:38<3:07:10,  4.18s/it] 28%|██▊       | 1068/3753 [1:25:43<3:08:04,  4.20s/it] 28%|██▊       | 1069/3753 [1:25:47<3:15:27,  4.37s/it] 29%|██▊       | 1070/3753 [1:25:52<3:11:06,  4.27s/it]{'loss': 41.0794, 'grad_norm': 2588.85546875, 'learning_rate': 8.996425536318682e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.3970255851745605, 'weight_rejected': 1.6011978387832642, 'kl_term_chosen': 3.2711029052734375, 'kl_term_rejected': 1.3757812976837158, 'epoch': 0.285143237841439}
                                                       {'loss': 41.0794, 'grad_norm': 2588.85546875, 'learning_rate': 8.996425536318682e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.3970255851745605, 'weight_rejected': 1.6011978387832642, 'kl_term_chosen': 3.2711029052734375, 'kl_term_rejected': 1.3757812976837158, 'epoch': 0.29}
 29%|██▊       | 1070/3753 [1:25:52<3:11:06,  4.27s/it] 29%|██▊       | 1071/3753 [1:25:55<3:05:23,  4.15s/it] 29%|██▊       | 1072/3753 [1:25:59<3:03:37,  4.11s/it] 29%|██▊       | 1073/3753 [1:26:04<3:05:06,  4.14s/it] 29%|██▊       | 1074/3753 [1:26:11<3:46:40,  5.08s/it] 29%|██▊       | 1075/3753 [1:26:15<3:28:51,  4.68s/it] 29%|██▊       | 1076/3753 [1:26:18<3:11:34,  4.29s/it] 29%|██▊       | 1077/3753 [1:26:22<3:01:43,  4.07s/it] 29%|██▊       | 1078/3753 [1:26:28<3:37:40,  4.88s/it] 29%|██▉       | 1079/3753 [1:26:32<3:24:23,  4.59s/it] 29%|██▉       | 1080/3753 [1:26:36<3:16:39,  4.41s/it]{'loss': 47.3345, 'grad_norm': 168.9660186767578, 'learning_rate': 8.968299995368191e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.14939162135124207, 'weight_chosen': -4.484524250030518, 'weight_rejected': -0.017946571111679077, 'kl_term_chosen': 5.35335111618042, 'kl_term_rejected': -0.19011841714382172, 'epoch': 0.28780812791472354}
                                                       {'loss': 47.3345, 'grad_norm': 168.9660186767578, 'learning_rate': 8.968299995368191e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.14939162135124207, 'weight_chosen': -4.484524250030518, 'weight_rejected': -0.017946571111679077, 'kl_term_chosen': 5.35335111618042, 'kl_term_rejected': -0.19011841714382172, 'epoch': 0.29}
 29%|██▉       | 1080/3753 [1:26:36<3:16:39,  4.41s/it] 29%|██▉       | 1081/3753 [1:26:41<3:21:02,  4.51s/it] 29%|██▉       | 1082/3753 [1:26:45<3:19:41,  4.49s/it] 29%|██▉       | 1083/3753 [1:26:49<3:13:16,  4.34s/it] 29%|██▉       | 1084/3753 [1:26:53<3:02:53,  4.11s/it] 29%|██▉       | 1085/3753 [1:26:57<3:04:36,  4.15s/it] 29%|██▉       | 1086/3753 [1:27:01<2:56:07,  3.96s/it] 29%|██▉       | 1087/3753 [1:27:05<2:59:30,  4.04s/it] 29%|██▉       | 1088/3753 [1:27:10<3:14:35,  4.38s/it] 29%|██▉       | 1089/3753 [1:27:15<3:22:11,  4.55s/it] 29%|██▉       | 1090/3753 [1:27:20<3:28:23,  4.70s/it]{'loss': 47.0241, 'grad_norm': 0.0, 'learning_rate': 8.939831023817808e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.337731957435608, 'weight_rejected': 6.0558600425720215, 'kl_term_chosen': -0.4594177305698395, 'kl_term_rejected': 5.889184474945068, 'epoch': 0.290473017988008}
                                                       {'loss': 47.0241, 'grad_norm': 0.0, 'learning_rate': 8.939831023817808e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.337731957435608, 'weight_rejected': 6.0558600425720215, 'kl_term_chosen': -0.4594177305698395, 'kl_term_rejected': 5.889184474945068, 'epoch': 0.29}
 29%|██▉       | 1090/3753 [1:27:20<3:28:23,  4.70s/it] 29%|██▉       | 1091/3753 [1:27:28<4:16:02,  5.77s/it] 29%|██▉       | 1092/3753 [1:27:32<3:45:34,  5.09s/it] 29%|██▉       | 1093/3753 [1:27:35<3:24:12,  4.61s/it] 29%|██▉       | 1094/3753 [1:27:38<3:01:40,  4.10s/it] 29%|██▉       | 1095/3753 [1:27:43<3:15:15,  4.41s/it] 29%|██▉       | 1096/3753 [1:27:47<3:05:28,  4.19s/it] 29%|██▉       | 1097/3753 [1:27:51<3:07:40,  4.24s/it] 29%|██▉       | 1098/3753 [1:27:55<2:58:19,  4.03s/it] 29%|██▉       | 1099/3753 [1:27:58<2:49:45,  3.84s/it] 29%|██▉       | 1100/3753 [1:28:02<2:43:33,  3.70s/it]{'loss': 53.9559, 'grad_norm': 0.0, 'learning_rate': 8.911021085472175e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.7381696701049805, 'weight_rejected': 4.085683345794678, 'kl_term_chosen': 2.0291504859924316, 'kl_term_rejected': 3.4369943141937256, 'epoch': 0.2931379080612925}
                                                       {'loss': 53.9559, 'grad_norm': 0.0, 'learning_rate': 8.911021085472175e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.7381696701049805, 'weight_rejected': 4.085683345794678, 'kl_term_chosen': 2.0291504859924316, 'kl_term_rejected': 3.4369943141937256, 'epoch': 0.29}
 29%|██▉       | 1100/3753 [1:28:02<2:43:33,  3.70s/it] 29%|██▉       | 1101/3753 [1:28:06<2:49:05,  3.83s/it] 29%|██▉       | 1102/3753 [1:28:10<2:49:33,  3.84s/it] 29%|██▉       | 1103/3753 [1:28:17<3:28:57,  4.73s/it] 29%|██▉       | 1104/3753 [1:28:25<4:17:07,  5.82s/it] 29%|██▉       | 1105/3753 [1:28:29<3:49:04,  5.19s/it] 29%|██▉       | 1106/3753 [1:28:33<3:42:52,  5.05s/it] 29%|██▉       | 1107/3753 [1:28:38<3:30:54,  4.78s/it] 30%|██▉       | 1108/3753 [1:28:42<3:26:56,  4.69s/it] 30%|██▉       | 1109/3753 [1:28:47<3:33:21,  4.84s/it] 30%|██▉       | 1110/3753 [1:28:51<3:21:18,  4.57s/it]{'loss': 47.8698, 'grad_norm': 239.70230102539062, 'learning_rate': 8.881872673644409e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.008698463439941, 'weight_rejected': 2.2225818634033203, 'kl_term_chosen': 5.958367824554443, 'kl_term_rejected': 2.185812473297119, 'epoch': 0.29580279813457694}
                                                       {'loss': 47.8698, 'grad_norm': 239.70230102539062, 'learning_rate': 8.881872673644409e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.008698463439941, 'weight_rejected': 2.2225818634033203, 'kl_term_chosen': 5.958367824554443, 'kl_term_rejected': 2.185812473297119, 'epoch': 0.3}
 30%|██▉       | 1110/3753 [1:28:51<3:21:18,  4.57s/it] 30%|██▉       | 1111/3753 [1:28:56<3:25:23,  4.66s/it] 30%|██▉       | 1112/3753 [1:29:00<3:19:53,  4.54s/it] 30%|██▉       | 1113/3753 [1:29:04<3:14:20,  4.42s/it] 30%|██▉       | 1114/3753 [1:29:09<3:13:07,  4.39s/it] 30%|██▉       | 1115/3753 [1:29:16<3:55:19,  5.35s/it] 30%|██▉       | 1116/3753 [1:29:21<3:45:12,  5.12s/it] 30%|██▉       | 1117/3753 [1:29:25<3:31:49,  4.82s/it] 30%|██▉       | 1118/3753 [1:29:29<3:19:36,  4.55s/it] 30%|██▉       | 1119/3753 [1:29:32<3:00:59,  4.12s/it] 30%|██▉       | 1120/3753 [1:29:37<3:05:10,  4.22s/it]{'loss': 49.8984, 'grad_norm': 246.9375, 'learning_rate': 8.852388310940302e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 5.1588006019592285, 'weight_rejected': 0.418992280960083, 'kl_term_chosen': -4.325476169586182, 'kl_term_rejected': 0.337472528219223, 'epoch': 0.2984676882078614}
                                                       {'loss': 49.8984, 'grad_norm': 246.9375, 'learning_rate': 8.852388310940302e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 5.1588006019592285, 'weight_rejected': 0.418992280960083, 'kl_term_chosen': -4.325476169586182, 'kl_term_rejected': 0.337472528219223, 'epoch': 0.3}
 30%|██▉       | 1120/3753 [1:29:37<3:05:10,  4.22s/it] 30%|██▉       | 1121/3753 [1:29:42<3:17:10,  4.49s/it] 30%|██▉       | 1122/3753 [1:29:49<3:49:27,  5.23s/it] 30%|██▉       | 1123/3753 [1:29:53<3:35:24,  4.91s/it] 30%|██▉       | 1124/3753 [1:29:58<3:39:54,  5.02s/it] 30%|██▉       | 1125/3753 [1:30:02<3:27:30,  4.74s/it] 30%|███       | 1126/3753 [1:30:06<3:12:02,  4.39s/it] 30%|███       | 1127/3753 [1:30:14<4:00:39,  5.50s/it] 30%|███       | 1128/3753 [1:30:23<4:44:11,  6.50s/it] 30%|███       | 1129/3753 [1:30:26<4:02:58,  5.56s/it] 30%|███       | 1130/3753 [1:30:30<3:46:52,  5.19s/it]{'loss': 45.0731, 'grad_norm': 365.51611328125, 'learning_rate': 8.822570549040016e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.9434919357299805, 'weight_rejected': 0.24561762809753418, 'kl_term_chosen': 3.4924073219299316, 'kl_term_rejected': -0.3232772946357727, 'epoch': 0.3011325782811459}
                                                       {'loss': 45.0731, 'grad_norm': 365.51611328125, 'learning_rate': 8.822570549040016e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.9434919357299805, 'weight_rejected': 0.24561762809753418, 'kl_term_chosen': 3.4924073219299316, 'kl_term_rejected': -0.3232772946357727, 'epoch': 0.3}
 30%|███       | 1130/3753 [1:30:30<3:46:52,  5.19s/it] 30%|███       | 1131/3753 [1:30:35<3:36:54,  4.96s/it] 30%|███       | 1132/3753 [1:30:38<3:10:59,  4.37s/it] 30%|███       | 1133/3753 [1:30:46<3:57:50,  5.45s/it] 30%|███       | 1134/3753 [1:30:49<3:35:39,  4.94s/it] 30%|███       | 1135/3753 [1:30:54<3:29:54,  4.81s/it] 30%|███       | 1136/3753 [1:30:59<3:27:22,  4.75s/it] 30%|███       | 1137/3753 [1:31:02<3:11:03,  4.38s/it] 30%|███       | 1138/3753 [1:31:06<3:01:09,  4.16s/it] 30%|███       | 1139/3753 [1:31:10<3:00:11,  4.14s/it] 30%|███       | 1140/3753 [1:31:14<3:00:13,  4.14s/it]{'loss': 41.0134, 'grad_norm': 2164.1201171875, 'learning_rate': 8.792421968477246e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.250397205352783, 'weight_rejected': 3.7043752670288086, 'kl_term_chosen': 6.224832057952881, 'kl_term_rejected': 3.664137363433838, 'epoch': 0.3037974683544304}
                                                       {'loss': 41.0134, 'grad_norm': 2164.1201171875, 'learning_rate': 8.792421968477246e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.250397205352783, 'weight_rejected': 3.7043752670288086, 'kl_term_chosen': 6.224832057952881, 'kl_term_rejected': 3.664137363433838, 'epoch': 0.3}
 30%|███       | 1140/3753 [1:31:14<3:00:13,  4.14s/it] 30%|███       | 1141/3753 [1:31:20<3:18:56,  4.57s/it] 30%|███       | 1142/3753 [1:31:28<4:04:18,  5.61s/it] 30%|███       | 1143/3753 [1:31:31<3:37:13,  4.99s/it] 30%|███       | 1144/3753 [1:31:35<3:20:32,  4.61s/it] 31%|███       | 1145/3753 [1:31:39<3:19:24,  4.59s/it] 31%|███       | 1146/3753 [1:31:45<3:29:13,  4.82s/it] 31%|███       | 1147/3753 [1:31:48<3:09:29,  4.36s/it] 31%|███       | 1148/3753 [1:31:52<3:00:34,  4.16s/it] 31%|███       | 1149/3753 [1:31:59<3:45:07,  5.19s/it] 31%|███       | 1150/3753 [1:32:03<3:28:22,  4.80s/it]{'loss': 40.0237, 'grad_norm': 0.0, 'learning_rate': 8.761945178415896e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -5.441082954406738, 'weight_rejected': -5.704343795776367, 'kl_term_chosen': 6.329841613769531, 'kl_term_rejected': -5.861480712890625, 'epoch': 0.30646235842771485}
                                                       {'loss': 40.0237, 'grad_norm': 0.0, 'learning_rate': 8.761945178415896e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -5.441082954406738, 'weight_rejected': -5.704343795776367, 'kl_term_chosen': 6.329841613769531, 'kl_term_rejected': -5.861480712890625, 'epoch': 0.31}
 31%|███       | 1150/3753 [1:32:03<3:28:22,  4.80s/it] 31%|███       | 1151/3753 [1:32:08<3:23:15,  4.69s/it] 31%|███       | 1152/3753 [1:32:13<3:33:15,  4.92s/it] 31%|███       | 1153/3753 [1:32:17<3:23:04,  4.69s/it] 31%|███       | 1154/3753 [1:32:22<3:21:24,  4.65s/it] 31%|███       | 1155/3753 [1:32:25<2:58:49,  4.13s/it] 31%|███       | 1156/3753 [1:32:29<3:01:09,  4.19s/it] 31%|███       | 1157/3753 [1:32:34<3:12:55,  4.46s/it] 31%|███       | 1158/3753 [1:32:38<3:00:11,  4.17s/it] 31%|███       | 1159/3753 [1:32:41<2:51:33,  3.97s/it] 31%|███       | 1160/3753 [1:32:45<2:45:39,  3.83s/it]{'loss': 43.0265, 'grad_norm': 222.26937866210938, 'learning_rate': 8.731142816424272e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.861532688140869, 'weight_rejected': -0.6073096990585327, 'kl_term_chosen': 4.636116027832031, 'kl_term_rejected': -0.781719982624054, 'epoch': 0.3091272485009993}
                                                       {'loss': 43.0265, 'grad_norm': 222.26937866210938, 'learning_rate': 8.731142816424272e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.861532688140869, 'weight_rejected': -0.6073096990585327, 'kl_term_chosen': 4.636116027832031, 'kl_term_rejected': -0.781719982624054, 'epoch': 0.31}
 31%|███       | 1160/3753 [1:32:45<2:45:39,  3.83s/it] 31%|███       | 1161/3753 [1:32:49<2:56:03,  4.08s/it] 31%|███       | 1162/3753 [1:32:55<3:15:26,  4.53s/it] 31%|███       | 1163/3753 [1:33:02<3:50:58,  5.35s/it] 31%|███       | 1164/3753 [1:33:11<4:38:29,  6.45s/it] 31%|███       | 1165/3753 [1:33:15<4:03:40,  5.65s/it] 31%|███       | 1166/3753 [1:33:18<3:33:36,  4.95s/it] 31%|███       | 1167/3753 [1:33:22<3:20:40,  4.66s/it] 31%|███       | 1168/3753 [1:33:26<3:05:01,  4.29s/it] 31%|███       | 1169/3753 [1:33:34<3:51:39,  5.38s/it] 31%|███       | 1170/3753 [1:33:37<3:29:19,  4.86s/it]{'loss': 47.3583, 'grad_norm': 0.0, 'learning_rate': 8.700017548246818e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.3157408237457275, 'weight_rejected': -0.8231877088546753, 'kl_term_chosen': 3.110125780105591, 'kl_term_rejected': -0.9692749381065369, 'epoch': 0.3117921385742838}
                                                       {'loss': 47.3583, 'grad_norm': 0.0, 'learning_rate': 8.700017548246818e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.3157408237457275, 'weight_rejected': -0.8231877088546753, 'kl_term_chosen': 3.110125780105591, 'kl_term_rejected': -0.9692749381065369, 'epoch': 0.31}
 31%|███       | 1170/3753 [1:33:37<3:29:19,  4.86s/it] 31%|███       | 1171/3753 [1:33:42<3:29:11,  4.86s/it] 31%|███       | 1172/3753 [1:33:46<3:21:06,  4.67s/it] 31%|███▏      | 1173/3753 [1:33:52<3:36:45,  5.04s/it] 31%|███▏      | 1174/3753 [1:33:56<3:18:05,  4.61s/it] 31%|███▏      | 1175/3753 [1:34:01<3:21:18,  4.69s/it] 31%|███▏      | 1176/3753 [1:34:05<3:16:00,  4.56s/it] 31%|███▏      | 1177/3753 [1:34:09<3:10:57,  4.45s/it] 31%|███▏      | 1178/3753 [1:34:13<3:08:32,  4.39s/it] 31%|███▏      | 1179/3753 [1:34:18<3:08:50,  4.40s/it] 31%|███▏      | 1180/3753 [1:34:22<3:11:30,  4.47s/it]{'loss': 45.1824, 'grad_norm': 780.37109375, 'learning_rate': 8.668572067573407e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.993386149406433, 'weight_rejected': 7.393968105316162, 'kl_term_chosen': 2.749743700027466, 'kl_term_rejected': 7.294497966766357, 'epoch': 0.3144570286475683}
                                                       {'loss': 45.1824, 'grad_norm': 780.37109375, 'learning_rate': 8.668572067573407e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.993386149406433, 'weight_rejected': 7.393968105316162, 'kl_term_chosen': 2.749743700027466, 'kl_term_rejected': 7.294497966766357, 'epoch': 0.31}
 31%|███▏      | 1180/3753 [1:34:23<3:11:30,  4.47s/it] 31%|███▏      | 1181/3753 [1:34:26<3:03:02,  4.27s/it] 31%|███▏      | 1182/3753 [1:34:31<3:06:51,  4.36s/it] 32%|███▏      | 1183/3753 [1:34:36<3:15:46,  4.57s/it] 32%|███▏      | 1184/3753 [1:34:41<3:22:58,  4.74s/it] 32%|███▏      | 1185/3753 [1:34:46<3:20:24,  4.68s/it] 32%|███▏      | 1186/3753 [1:34:49<3:09:12,  4.42s/it] 32%|███▏      | 1187/3753 [1:34:54<3:15:55,  4.58s/it] 32%|███▏      | 1188/3753 [1:34:58<3:03:08,  4.28s/it] 32%|███▏      | 1189/3753 [1:35:02<3:02:48,  4.28s/it] 32%|███▏      | 1190/3753 [1:35:06<3:01:20,  4.25s/it]{'loss': 44.2844, 'grad_norm': 0.0, 'learning_rate': 8.63680909580623e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 7.461194038391113, 'weight_rejected': 4.153058052062988, 'kl_term_chosen': -6.65802001953125, 'kl_term_rejected': 3.636706590652466, 'epoch': 0.31712191872085277}
                                                       {'loss': 44.2844, 'grad_norm': 0.0, 'learning_rate': 8.63680909580623e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 7.461194038391113, 'weight_rejected': 4.153058052062988, 'kl_term_chosen': -6.65802001953125, 'kl_term_rejected': 3.636706590652466, 'epoch': 0.32}
 32%|███▏      | 1190/3753 [1:35:06<3:01:20,  4.25s/it] 32%|███▏      | 1191/3753 [1:35:10<2:59:16,  4.20s/it] 32%|███▏      | 1192/3753 [1:35:14<2:46:57,  3.91s/it] 32%|███▏      | 1193/3753 [1:35:18<2:48:21,  3.95s/it] 32%|███▏      | 1194/3753 [1:35:22<2:55:38,  4.12s/it] 32%|███▏      | 1195/3753 [1:35:28<3:15:31,  4.59s/it] 32%|███▏      | 1196/3753 [1:35:32<3:06:50,  4.38s/it] 32%|███▏      | 1197/3753 [1:35:37<3:11:48,  4.50s/it] 32%|███▏      | 1198/3753 [1:35:41<3:04:28,  4.33s/it] 32%|███▏      | 1199/3753 [1:35:44<2:50:25,  4.00s/it] 32%|███▏      | 1200/3753 [1:35:48<2:49:55,  3.99s/it]{'loss': 43.7105, 'grad_norm': 0.0, 'learning_rate': 8.604731381824266e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.013003349304199, 'weight_rejected': 2.739332914352417, 'kl_term_chosen': 3.9520280361175537, 'kl_term_rejected': 2.689002275466919, 'epoch': 0.31978680879413723}
                                                       {'loss': 43.7105, 'grad_norm': 0.0, 'learning_rate': 8.604731381824266e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.013003349304199, 'weight_rejected': 2.739332914352417, 'kl_term_chosen': 3.9520280361175537, 'kl_term_rejected': 2.689002275466919, 'epoch': 0.32}
 32%|███▏      | 1200/3753 [1:35:48<2:49:55,  3.99s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 32%|███▏      | 1201/3753 [1:37:16<20:41:46, 29.20s/it] 32%|███▏      | 1202/3753 [1:37:20<15:23:51, 21.73s/it] 32%|███▏      | 1203/3753 [1:37:25<11:46:17, 16.62s/it] 32%|███▏      | 1204/3753 [1:37:28<8:55:17, 12.60s/it]  32%|███▏      | 1205/3753 [1:37:33<7:17:12, 10.30s/it] 32%|███▏      | 1206/3753 [1:37:37<6:00:30,  8.49s/it] 32%|███▏      | 1207/3753 [1:37:41<4:59:14,  7.05s/it] 32%|███▏      | 1208/3753 [1:37:45<4:21:32,  6.17s/it] 32%|███▏      | 1209/3753 [1:37:49<3:58:02,  5.61s/it] 32%|███▏      | 1210/3753 [1:37:53<3:34:37,  5.06s/it]{'loss': 34.9282, 'grad_norm': 0.0, 'learning_rate': 8.572341701745392e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -4.887478828430176, 'weight_rejected': -1.8652892112731934, 'kl_term_chosen': 5.439294338226318, 'kl_term_rejected': -2.1554648876190186, 'epoch': 0.3224516988674217}
                                                       {'loss': 34.9282, 'grad_norm': 0.0, 'learning_rate': 8.572341701745392e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -4.887478828430176, 'weight_rejected': -1.8652892112731934, 'kl_term_chosen': 5.439294338226318, 'kl_term_rejected': -2.1554648876190186, 'epoch': 0.32}
 32%|███▏      | 1210/3753 [1:37:53<3:34:37,  5.06s/it] 32%|███▏      | 1211/3753 [1:37:59<3:45:09,  5.31s/it] 32%|███▏      | 1212/3753 [1:38:02<3:21:28,  4.76s/it] 32%|███▏      | 1213/3753 [1:38:06<3:08:25,  4.45s/it] 32%|███▏      | 1214/3753 [1:38:10<2:58:42,  4.22s/it] 32%|███▏      | 1215/3753 [1:38:15<3:08:11,  4.45s/it] 32%|███▏      | 1216/3753 [1:38:20<3:11:07,  4.52s/it] 32%|███▏      | 1217/3753 [1:38:24<3:12:56,  4.56s/it] 32%|███▏      | 1218/3753 [1:38:29<3:11:33,  4.53s/it] 32%|███▏      | 1219/3753 [1:38:33<3:04:47,  4.38s/it] 33%|███▎      | 1220/3753 [1:38:36<2:54:14,  4.13s/it]{'loss': 42.84, 'grad_norm': 0.0, 'learning_rate': 8.539642858686124e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.594337522983551, 'weight_rejected': 1.225042700767517, 'kl_term_chosen': 1.055596947669983, 'kl_term_rejected': 0.764996349811554, 'epoch': 0.3251165889407062}
                                                       {'loss': 42.84, 'grad_norm': 0.0, 'learning_rate': 8.539642858686124e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.594337522983551, 'weight_rejected': 1.225042700767517, 'kl_term_chosen': 1.055596947669983, 'kl_term_rejected': 0.764996349811554, 'epoch': 0.33}
 33%|███▎      | 1220/3753 [1:38:36<2:54:14,  4.13s/it] 33%|███▎      | 1221/3753 [1:38:43<3:33:36,  5.06s/it] 33%|███▎      | 1222/3753 [1:38:48<3:26:00,  4.88s/it] 33%|███▎      | 1223/3753 [1:38:52<3:14:44,  4.62s/it] 33%|███▎      | 1224/3753 [1:38:56<3:05:08,  4.39s/it] 33%|███▎      | 1225/3753 [1:39:00<2:58:08,  4.23s/it] 33%|███▎      | 1226/3753 [1:39:05<3:13:10,  4.59s/it] 33%|███▎      | 1227/3753 [1:39:10<3:11:58,  4.56s/it] 33%|███▎      | 1228/3753 [1:39:13<3:02:39,  4.34s/it] 33%|███▎      | 1229/3753 [1:39:18<3:02:16,  4.33s/it] 33%|███▎      | 1230/3753 [1:39:22<2:58:40,  4.25s/it]{'loss': 49.6186, 'grad_norm': 394.6021728515625, 'learning_rate': 8.506637682519029e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.7334414124488831, 'weight_rejected': -0.027878880500793457, 'kl_term_chosen': -0.6495510339736938, 'kl_term_rejected': -0.8707420229911804, 'epoch': 0.3277814790139907}
                                                       {'loss': 49.6186, 'grad_norm': 394.6021728515625, 'learning_rate': 8.506637682519029e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.7334414124488831, 'weight_rejected': -0.027878880500793457, 'kl_term_chosen': -0.6495510339736938, 'kl_term_rejected': -0.8707420229911804, 'epoch': 0.33}
 33%|███▎      | 1230/3753 [1:39:22<2:58:40,  4.25s/it] 33%|███▎      | 1231/3753 [1:39:27<3:05:14,  4.41s/it] 33%|███▎      | 1232/3753 [1:39:31<3:02:30,  4.34s/it] 33%|███▎      | 1233/3753 [1:39:40<4:01:57,  5.76s/it] 33%|███▎      | 1234/3753 [1:39:44<3:45:20,  5.37s/it] 33%|███▎      | 1235/3753 [1:39:50<3:52:20,  5.54s/it] 33%|███▎      | 1236/3753 [1:39:54<3:34:20,  5.11s/it] 33%|███▎      | 1237/3753 [1:39:59<3:24:32,  4.88s/it] 33%|███▎      | 1238/3753 [1:40:03<3:23:04,  4.84s/it] 33%|███▎      | 1239/3753 [1:40:07<3:10:56,  4.56s/it] 33%|███▎      | 1240/3753 [1:40:11<3:00:11,  4.30s/it]{'loss': 45.0436, 'grad_norm': 658.4522094726562, 'learning_rate': 8.473329029627813e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.1303133964538574, 'weight_rejected': 3.3628320693969727, 'kl_term_chosen': 2.7582645416259766, 'kl_term_rejected': 2.539503812789917, 'epoch': 0.33044636908727515}
                                                       {'loss': 45.0436, 'grad_norm': 658.4522094726562, 'learning_rate': 8.473329029627813e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.1303133964538574, 'weight_rejected': 3.3628320693969727, 'kl_term_chosen': 2.7582645416259766, 'kl_term_rejected': 2.539503812789917, 'epoch': 0.33}
 33%|███▎      | 1240/3753 [1:40:11<3:00:11,  4.30s/it] 33%|███▎      | 1241/3753 [1:40:15<2:58:46,  4.27s/it] 33%|███▎      | 1242/3753 [1:40:19<2:55:52,  4.20s/it] 33%|███▎      | 1243/3753 [1:40:24<2:57:36,  4.25s/it] 33%|███▎      | 1244/3753 [1:40:29<3:08:27,  4.51s/it] 33%|███▎      | 1245/3753 [1:40:34<3:12:58,  4.62s/it] 33%|███▎      | 1246/3753 [1:40:41<3:51:33,  5.54s/it] 33%|███▎      | 1247/3753 [1:40:45<3:29:09,  5.01s/it] 33%|███▎      | 1248/3753 [1:40:49<3:19:02,  4.77s/it] 33%|███▎      | 1249/3753 [1:40:53<3:06:20,  4.47s/it] 33%|███▎      | 1250/3753 [1:40:57<3:00:35,  4.33s/it]{'loss': 48.3005, 'grad_norm': 0.0, 'learning_rate': 8.439719782660123e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.6999680995941162, 'weight_rejected': 1.5891426801681519, 'kl_term_chosen': 2.215466022491455, 'kl_term_rejected': 1.3455002307891846, 'epoch': 0.3331112591605596}
                                                       {'loss': 48.3005, 'grad_norm': 0.0, 'learning_rate': 8.439719782660123e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.6999680995941162, 'weight_rejected': 1.5891426801681519, 'kl_term_chosen': 2.215466022491455, 'kl_term_rejected': 1.3455002307891846, 'epoch': 0.33}
 33%|███▎      | 1250/3753 [1:40:57<3:00:35,  4.33s/it] 33%|███▎      | 1251/3753 [1:41:01<2:55:24,  4.21s/it] 33%|███▎      | 1252/3753 [1:41:04<2:41:13,  3.87s/it] 33%|███▎      | 1253/3753 [1:41:13<3:41:05,  5.31s/it] 33%|███▎      | 1254/3753 [1:41:18<3:40:32,  5.30s/it] 33%|███▎      | 1255/3753 [1:41:22<3:19:44,  4.80s/it] 33%|███▎      | 1256/3753 [1:41:25<3:01:14,  4.35s/it] 33%|███▎      | 1257/3753 [1:41:29<2:59:21,  4.31s/it] 34%|███▎      | 1258/3753 [1:41:33<2:49:40,  4.08s/it] 34%|███▎      | 1259/3753 [1:41:36<2:46:08,  4.00s/it] 34%|███▎      | 1260/3753 [1:41:40<2:43:02,  3.92s/it]{'loss': 48.8315, 'grad_norm': 1062.601806640625, 'learning_rate': 8.405812850278072e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.28858450055122375, 'weight_chosen': 4.321513652801514, 'weight_rejected': 0.4019443094730377, 'kl_term_chosen': -4.276161193847656, 'kl_term_rejected': -0.12427673488855362, 'epoch': 0.3357761492338441}
                                                       {'loss': 48.8315, 'grad_norm': 1062.601806640625, 'learning_rate': 8.405812850278072e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.28858450055122375, 'weight_chosen': 4.321513652801514, 'weight_rejected': 0.4019443094730377, 'kl_term_chosen': -4.276161193847656, 'kl_term_rejected': -0.12427673488855362, 'epoch': 0.34}
 34%|███▎      | 1260/3753 [1:41:40<2:43:02,  3.92s/it] 34%|███▎      | 1261/3753 [1:41:44<2:44:58,  3.97s/it] 34%|███▎      | 1262/3753 [1:41:48<2:46:10,  4.00s/it] 34%|███▎      | 1263/3753 [1:41:52<2:42:32,  3.92s/it] 34%|███▎      | 1264/3753 [1:41:58<3:01:59,  4.39s/it] 34%|███▎      | 1265/3753 [1:42:03<3:18:35,  4.79s/it] 34%|███▎      | 1266/3753 [1:42:07<3:06:00,  4.49s/it] 34%|███▍      | 1267/3753 [1:42:14<3:38:04,  5.26s/it] 34%|███▍      | 1268/3753 [1:42:21<3:53:19,  5.63s/it] 34%|███▍      | 1269/3753 [1:42:24<3:30:09,  5.08s/it] 34%|███▍      | 1270/3753 [1:42:29<3:18:37,  4.80s/it]{'loss': 59.1459, 'grad_norm': 0.3083340525627136, 'learning_rate': 8.371611166906512e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.4851883053779602, 'weight_rejected': 3.1117708683013916, 'kl_term_chosen': 0.9091232419013977, 'kl_term_rejected': 2.635434865951538, 'epoch': 0.3384410393071286}
                                                       {'loss': 59.1459, 'grad_norm': 0.3083340525627136, 'learning_rate': 8.371611166906512e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.4851883053779602, 'weight_rejected': 3.1117708683013916, 'kl_term_chosen': 0.9091232419013977, 'kl_term_rejected': 2.635434865951538, 'epoch': 0.34}
 34%|███▍      | 1270/3753 [1:42:29<3:18:37,  4.80s/it] 34%|███▍      | 1271/3753 [1:42:32<3:05:29,  4.48s/it] 34%|███▍      | 1272/3753 [1:42:36<2:59:21,  4.34s/it] 34%|███▍      | 1273/3753 [1:42:40<2:46:52,  4.04s/it] 34%|███▍      | 1274/3753 [1:42:44<2:45:24,  4.00s/it] 34%|███▍      | 1275/3753 [1:42:48<2:46:59,  4.04s/it] 34%|███▍      | 1276/3753 [1:42:53<3:02:48,  4.43s/it] 34%|███▍      | 1277/3753 [1:42:58<3:12:23,  4.66s/it] 34%|███▍      | 1278/3753 [1:43:02<2:59:45,  4.36s/it] 34%|███▍      | 1279/3753 [1:43:08<3:20:19,  4.86s/it] 34%|███▍      | 1280/3753 [1:43:12<3:10:27,  4.62s/it]{'loss': 57.9525, 'grad_norm': 79.541259765625, 'learning_rate': 8.337117692479079e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.9847522974014282, 'weight_rejected': 2.276601552963257, 'kl_term_chosen': 2.733839511871338, 'kl_term_rejected': 2.1622331142425537, 'epoch': 0.34110592938041306}
                                                       {'loss': 57.9525, 'grad_norm': 79.541259765625, 'learning_rate': 8.337117692479079e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.9847522974014282, 'weight_rejected': 2.276601552963257, 'kl_term_chosen': 2.733839511871338, 'kl_term_rejected': 2.1622331142425537, 'epoch': 0.34}
 34%|███▍      | 1280/3753 [1:43:12<3:10:27,  4.62s/it] 34%|███▍      | 1281/3753 [1:43:15<2:56:07,  4.28s/it] 34%|███▍      | 1282/3753 [1:43:21<3:06:37,  4.53s/it] 34%|███▍      | 1283/3753 [1:43:26<3:12:53,  4.69s/it] 34%|███▍      | 1284/3753 [1:43:29<2:55:55,  4.28s/it] 34%|███▍      | 1285/3753 [1:43:34<3:01:43,  4.42s/it] 34%|███▍      | 1286/3753 [1:43:38<2:54:03,  4.23s/it] 34%|███▍      | 1287/3753 [1:43:43<3:03:27,  4.46s/it] 34%|███▍      | 1288/3753 [1:43:47<3:04:05,  4.48s/it] 34%|███▍      | 1289/3753 [1:43:51<3:00:48,  4.40s/it] 34%|███▍      | 1290/3753 [1:43:56<2:59:19,  4.37s/it]{'loss': 51.4737, 'grad_norm': 0.0, 'learning_rate': 8.302335412182033e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.792707443237305, 'weight_rejected': 2.5644140243530273, 'kl_term_chosen': 8.74008846282959, 'kl_term_rejected': 2.519061326980591, 'epoch': 0.34377081945369753}
                                                       {'loss': 51.4737, 'grad_norm': 0.0, 'learning_rate': 8.302335412182033e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.792707443237305, 'weight_rejected': 2.5644140243530273, 'kl_term_chosen': 8.74008846282959, 'kl_term_rejected': 2.519061326980591, 'epoch': 0.34}
 34%|███▍      | 1290/3753 [1:43:56<2:59:19,  4.37s/it] 34%|███▍      | 1291/3753 [1:44:01<3:12:30,  4.69s/it] 34%|███▍      | 1292/3753 [1:44:05<3:03:55,  4.48s/it] 34%|███▍      | 1293/3753 [1:44:09<2:57:54,  4.34s/it] 34%|███▍      | 1294/3753 [1:44:14<3:06:25,  4.55s/it] 35%|███▍      | 1295/3753 [1:44:18<2:56:21,  4.30s/it] 35%|███▍      | 1296/3753 [1:44:22<3:00:45,  4.41s/it] 35%|███▍      | 1297/3753 [1:44:30<3:44:03,  5.47s/it] 35%|███▍      | 1298/3753 [1:44:35<3:33:30,  5.22s/it] 35%|███▍      | 1299/3753 [1:44:43<4:04:55,  5.99s/it] 35%|███▍      | 1300/3753 [1:44:47<3:39:35,  5.37s/it]{'loss': 54.3175, 'grad_norm': 57.34508514404297, 'learning_rate': 8.267267336195905e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.27245807647705, 'weight_rejected': 3.253885507583618, 'kl_term_chosen': 9.241782188415527, 'kl_term_rejected': 3.2379791736602783, 'epoch': 0.346435709526982}
                                                       {'loss': 54.3175, 'grad_norm': 57.34508514404297, 'learning_rate': 8.267267336195905e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.27245807647705, 'weight_rejected': 3.253885507583618, 'kl_term_chosen': 9.241782188415527, 'kl_term_rejected': 3.2379791736602783, 'epoch': 0.35}
 35%|███▍      | 1300/3753 [1:44:47<3:39:35,  5.37s/it] 35%|███▍      | 1301/3753 [1:44:51<3:27:52,  5.09s/it] 35%|███▍      | 1302/3753 [1:44:55<3:15:42,  4.79s/it] 35%|███▍      | 1303/3753 [1:44:59<3:08:22,  4.61s/it] 35%|███▍      | 1304/3753 [1:45:04<3:04:03,  4.51s/it] 35%|███▍      | 1305/3753 [1:45:08<3:02:06,  4.46s/it] 35%|███▍      | 1306/3753 [1:45:12<2:59:56,  4.41s/it] 35%|███▍      | 1307/3753 [1:45:16<2:53:34,  4.26s/it] 35%|███▍      | 1308/3753 [1:45:22<3:14:26,  4.77s/it] 35%|███▍      | 1309/3753 [1:45:27<3:11:55,  4.71s/it] 35%|███▍      | 1310/3753 [1:45:31<3:08:22,  4.63s/it]{'loss': 51.2719, 'grad_norm': 22.544357299804688, 'learning_rate': 8.231916499434987e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.2992158532142639, 'weight_rejected': -0.9162644147872925, 'kl_term_chosen': 1.2188583612442017, 'kl_term_rejected': -0.9868240356445312, 'epoch': 0.3491005996002665}
                                                       {'loss': 51.2719, 'grad_norm': 22.544357299804688, 'learning_rate': 8.231916499434987e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.2992158532142639, 'weight_rejected': -0.9162644147872925, 'kl_term_chosen': 1.2188583612442017, 'kl_term_rejected': -0.9868240356445312, 'epoch': 0.35}
 35%|███▍      | 1310/3753 [1:45:31<3:08:22,  4.63s/it] 35%|███▍      | 1311/3753 [1:45:36<3:10:19,  4.68s/it] 35%|███▍      | 1312/3753 [1:45:40<3:04:04,  4.52s/it] 35%|███▍      | 1313/3753 [1:45:47<3:37:25,  5.35s/it] 35%|███▌      | 1314/3753 [1:45:51<3:18:49,  4.89s/it] 35%|███▌      | 1315/3753 [1:45:55<3:02:41,  4.50s/it] 35%|███▌      | 1316/3753 [1:45:59<2:56:36,  4.35s/it] 35%|███▌      | 1317/3753 [1:46:03<2:54:48,  4.31s/it] 35%|███▌      | 1318/3753 [1:46:08<3:02:57,  4.51s/it] 35%|███▌      | 1319/3753 [1:46:11<2:48:47,  4.16s/it] 35%|███▌      | 1320/3753 [1:46:16<2:56:33,  4.35s/it]{'loss': 45.7986, 'grad_norm': 0.0, 'learning_rate': 8.19628596128468e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.4119043350219727, 'weight_rejected': 9.905167579650879, 'kl_term_chosen': 2.2484588623046875, 'kl_term_rejected': 9.798477172851562, 'epoch': 0.351765489673551}
                                                       {'loss': 45.7986, 'grad_norm': 0.0, 'learning_rate': 8.19628596128468e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.4119043350219727, 'weight_rejected': 9.905167579650879, 'kl_term_chosen': 2.2484588623046875, 'kl_term_rejected': 9.798477172851562, 'epoch': 0.35}
 35%|███▌      | 1320/3753 [1:46:16<2:56:33,  4.35s/it] 35%|███▌      | 1321/3753 [1:46:20<2:51:35,  4.23s/it] 35%|███▌      | 1322/3753 [1:46:24<2:47:28,  4.13s/it] 35%|███▌      | 1323/3753 [1:46:28<2:43:44,  4.04s/it] 35%|███▌      | 1324/3753 [1:46:32<2:45:30,  4.09s/it] 35%|███▌      | 1325/3753 [1:46:38<3:10:38,  4.71s/it] 35%|███▌      | 1326/3753 [1:46:43<3:06:37,  4.61s/it] 35%|███▌      | 1327/3753 [1:46:46<2:54:07,  4.31s/it] 35%|███▌      | 1328/3753 [1:46:52<3:16:01,  4.85s/it] 35%|███▌      | 1329/3753 [1:46:56<3:04:24,  4.56s/it] 35%|███▌      | 1330/3753 [1:47:00<2:56:29,  4.37s/it]{'loss': 47.1653, 'grad_norm': 26.407394409179688, 'learning_rate': 8.160378805336728e-07, 'mean_ratio_chosen': 0.5116001963615417, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.158403217792511, 'weight_rejected': -1.2864857912063599, 'kl_term_chosen': -0.06702118366956711, 'kl_term_rejected': -1.8223129510879517, 'epoch': 0.35443037974683544}
                                                       {'loss': 47.1653, 'grad_norm': 26.407394409179688, 'learning_rate': 8.160378805336728e-07, 'mean_ratio_chosen': 0.5116001963615417, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.158403217792511, 'weight_rejected': -1.2864857912063599, 'kl_term_chosen': -0.06702118366956711, 'kl_term_rejected': -1.8223129510879517, 'epoch': 0.35}
 35%|███▌      | 1330/3753 [1:47:00<2:56:29,  4.37s/it] 35%|███▌      | 1331/3753 [1:47:05<3:01:14,  4.49s/it] 35%|███▌      | 1332/3753 [1:47:10<3:03:52,  4.56s/it] 36%|███▌      | 1333/3753 [1:47:13<2:44:37,  4.08s/it] 36%|███▌      | 1334/3753 [1:47:18<2:57:57,  4.41s/it] 36%|███▌      | 1335/3753 [1:47:23<3:03:59,  4.57s/it] 36%|███▌      | 1336/3753 [1:47:27<3:00:41,  4.49s/it] 36%|███▌      | 1337/3753 [1:47:31<2:58:27,  4.43s/it] 36%|███▌      | 1338/3753 [1:47:35<2:45:11,  4.10s/it] 36%|███▌      | 1339/3753 [1:47:39<2:44:48,  4.10s/it] 36%|███▌      | 1340/3753 [1:47:43<2:48:49,  4.20s/it]{'loss': 43.5231, 'grad_norm': 125.06311798095703, 'learning_rate': 8.124198139122342e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.09778380393981934, 'weight_rejected': 9.509432792663574, 'kl_term_chosen': 1.0240875482559204, 'kl_term_rejected': 9.41674518585205, 'epoch': 0.3570952698201199}
                                                       {'loss': 43.5231, 'grad_norm': 125.06311798095703, 'learning_rate': 8.124198139122342e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.09778380393981934, 'weight_rejected': 9.509432792663574, 'kl_term_chosen': 1.0240875482559204, 'kl_term_rejected': 9.41674518585205, 'epoch': 0.36}
 36%|███▌      | 1340/3753 [1:47:43<2:48:49,  4.20s/it] 36%|███▌      | 1341/3753 [1:47:48<2:54:54,  4.35s/it] 36%|███▌      | 1342/3753 [1:47:52<2:54:40,  4.35s/it] 36%|███▌      | 1343/3753 [1:47:57<2:55:17,  4.36s/it] 36%|███▌      | 1344/3753 [1:48:00<2:41:39,  4.03s/it] 36%|███▌      | 1345/3753 [1:48:04<2:42:09,  4.04s/it] 36%|███▌      | 1346/3753 [1:48:09<2:52:41,  4.30s/it] 36%|███▌      | 1347/3753 [1:48:12<2:41:45,  4.03s/it] 36%|███▌      | 1348/3753 [1:48:16<2:39:09,  3.97s/it] 36%|███▌      | 1349/3753 [1:48:20<2:38:47,  3.96s/it] 36%|███▌      | 1350/3753 [1:48:24<2:32:56,  3.82s/it]{'loss': 46.1172, 'grad_norm': 12.878167152404785, 'learning_rate': 8.087747093843278e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.2555624842643738, 'weight_chosen': -8.025014877319336, 'weight_rejected': 0.09588131308555603, 'kl_term_chosen': 8.802314758300781, 'kl_term_rejected': -0.1364288330078125, 'epoch': 0.3597601598934044}
                                                       {'loss': 46.1172, 'grad_norm': 12.878167152404785, 'learning_rate': 8.087747093843278e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.2555624842643738, 'weight_chosen': -8.025014877319336, 'weight_rejected': 0.09588131308555603, 'kl_term_chosen': 8.802314758300781, 'kl_term_rejected': -0.1364288330078125, 'epoch': 0.36}
 36%|███▌      | 1350/3753 [1:48:24<2:32:56,  3.82s/it] 36%|███▌      | 1351/3753 [1:48:28<2:39:13,  3.98s/it] 36%|███▌      | 1352/3753 [1:48:32<2:42:54,  4.07s/it] 36%|███▌      | 1353/3753 [1:48:37<2:47:19,  4.18s/it] 36%|███▌      | 1354/3753 [1:48:41<2:49:29,  4.24s/it] 36%|███▌      | 1355/3753 [1:48:46<2:57:31,  4.44s/it] 36%|███▌      | 1356/3753 [1:48:50<2:53:56,  4.35s/it] 36%|███▌      | 1357/3753 [1:48:53<2:39:01,  3.98s/it] 36%|███▌      | 1358/3753 [1:49:03<3:44:11,  5.62s/it] 36%|███▌      | 1359/3753 [1:49:06<3:21:43,  5.06s/it] 36%|███▌      | 1360/3753 [1:49:13<3:40:19,  5.52s/it]{'loss': 48.5516, 'grad_norm': 0.0, 'learning_rate': 8.051028824100841e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.34987211227417, 'weight_rejected': 2.037353277206421, 'kl_term_chosen': 6.278280735015869, 'kl_term_rejected': 1.9558334350585938, 'epoch': 0.3624250499666889}
                                                       {'loss': 48.5516, 'grad_norm': 0.0, 'learning_rate': 8.051028824100841e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.34987211227417, 'weight_rejected': 2.037353277206421, 'kl_term_chosen': 6.278280735015869, 'kl_term_rejected': 1.9558334350585938, 'epoch': 0.36}
 36%|███▌      | 1360/3753 [1:49:13<3:40:19,  5.52s/it] 36%|███▋      | 1361/3753 [1:49:18<3:29:45,  5.26s/it] 36%|███▋      | 1362/3753 [1:49:21<3:11:27,  4.80s/it] 36%|███▋      | 1363/3753 [1:49:25<2:55:09,  4.40s/it] 36%|███▋      | 1364/3753 [1:49:30<3:03:12,  4.60s/it] 36%|███▋      | 1365/3753 [1:49:34<2:58:41,  4.49s/it] 36%|███▋      | 1366/3753 [1:49:38<2:50:23,  4.28s/it] 36%|███▋      | 1367/3753 [1:49:42<2:52:13,  4.33s/it] 36%|███▋      | 1368/3753 [1:49:46<2:42:06,  4.08s/it] 36%|███▋      | 1369/3753 [1:49:53<3:18:00,  4.98s/it] 37%|███▋      | 1370/3753 [1:49:58<3:22:27,  5.10s/it]{'loss': 48.7579, 'grad_norm': 7.30046272277832, 'learning_rate': 8.01404650762288e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -4.688839435577393, 'weight_rejected': -4.9330153465271, 'kl_term_chosen': 5.450909614562988, 'kl_term_rejected': -5.044256687164307, 'epoch': 0.36508994003997336}
                                                       {'loss': 48.7579, 'grad_norm': 7.30046272277832, 'learning_rate': 8.01404650762288e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -4.688839435577393, 'weight_rejected': -4.9330153465271, 'kl_term_chosen': 5.450909614562988, 'kl_term_rejected': -5.044256687164307, 'epoch': 0.37}
 37%|███▋      | 1370/3753 [1:49:58<3:22:27,  5.10s/it] 37%|███▋      | 1371/3753 [1:50:02<3:10:51,  4.81s/it] 37%|███▋      | 1372/3753 [1:50:06<3:00:18,  4.54s/it] 37%|███▋      | 1373/3753 [1:50:11<2:57:07,  4.47s/it] 37%|███▋      | 1374/3753 [1:50:15<2:52:03,  4.34s/it] 37%|███▋      | 1375/3753 [1:50:19<2:50:02,  4.29s/it] 37%|███▋      | 1376/3753 [1:50:24<2:55:10,  4.42s/it] 37%|███▋      | 1377/3753 [1:50:30<3:18:02,  5.00s/it] 37%|███▋      | 1378/3753 [1:50:34<3:04:25,  4.66s/it] 37%|███▋      | 1379/3753 [1:50:38<3:04:27,  4.66s/it] 37%|███▋      | 1380/3753 [1:50:43<2:57:13,  4.48s/it]{'loss': 44.6352, 'grad_norm': 826.0244140625, 'learning_rate': 7.976803344988774e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.1129274368286133, 'weight_rejected': 1.8396399021148682, 'kl_term_chosen': 3.389617919921875, 'kl_term_rejected': 1.7495468854904175, 'epoch': 0.3677548301132578}
                                                       {'loss': 44.6352, 'grad_norm': 826.0244140625, 'learning_rate': 7.976803344988774e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.1129274368286133, 'weight_rejected': 1.8396399021148682, 'kl_term_chosen': 3.389617919921875, 'kl_term_rejected': 1.7495468854904175, 'epoch': 0.37}
 37%|███▋      | 1380/3753 [1:50:43<2:57:13,  4.48s/it] 37%|███▋      | 1381/3753 [1:50:47<2:56:41,  4.47s/it] 37%|███▋      | 1382/3753 [1:50:51<2:49:15,  4.28s/it] 37%|███▋      | 1383/3753 [1:50:55<2:43:15,  4.13s/it] 37%|███▋      | 1384/3753 [1:50:59<2:46:28,  4.22s/it] 37%|███▋      | 1385/3753 [1:51:03<2:43:25,  4.14s/it] 37%|███▋      | 1386/3753 [1:51:07<2:44:12,  4.16s/it] 37%|███▋      | 1387/3753 [1:51:11<2:39:47,  4.05s/it] 37%|███▋      | 1388/3753 [1:51:15<2:38:07,  4.01s/it] 37%|███▋      | 1389/3753 [1:51:22<3:11:05,  4.85s/it] 37%|███▋      | 1390/3753 [1:51:27<3:19:24,  5.06s/it]{'loss': 51.0866, 'grad_norm': 0.0, 'learning_rate': 7.939302559352441e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -10.494950294494629, 'weight_rejected': -2.9163739681243896, 'kl_term_chosen': 11.295641899108887, 'kl_term_rejected': -3.7769775390625, 'epoch': 0.3704197201865423}
                                                       {'loss': 51.0866, 'grad_norm': 0.0, 'learning_rate': 7.939302559352441e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -10.494950294494629, 'weight_rejected': -2.9163739681243896, 'kl_term_chosen': 11.295641899108887, 'kl_term_rejected': -3.7769775390625, 'epoch': 0.37}
 37%|███▋      | 1390/3753 [1:51:27<3:19:24,  5.06s/it] 37%|███▋      | 1391/3753 [1:51:32<3:21:18,  5.11s/it] 37%|███▋      | 1392/3753 [1:51:38<3:21:11,  5.11s/it] 37%|███▋      | 1393/3753 [1:51:43<3:20:40,  5.10s/it] 37%|███▋      | 1394/3753 [1:51:46<3:02:51,  4.65s/it] 37%|███▋      | 1395/3753 [1:51:51<2:59:13,  4.56s/it] 37%|███▋      | 1396/3753 [1:51:56<3:08:52,  4.81s/it] 37%|███▋      | 1397/3753 [1:52:01<3:11:05,  4.87s/it] 37%|███▋      | 1398/3753 [1:52:04<2:54:00,  4.43s/it] 37%|███▋      | 1399/3753 [1:52:09<2:51:21,  4.37s/it] 37%|███▋      | 1400/3753 [1:52:12<2:40:56,  4.10s/it]{'loss': 57.1722, 'grad_norm': 837.7545776367188, 'learning_rate': 7.901547396163399e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.8623170852661133, 'weight_rejected': 4.318780422210693, 'kl_term_chosen': 3.9486405849456787, 'kl_term_rejected': 3.3518664836883545, 'epoch': 0.37308461025982675}
                                                       {'loss': 57.1722, 'grad_norm': 837.7545776367188, 'learning_rate': 7.901547396163399e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.8623170852661133, 'weight_rejected': 4.318780422210693, 'kl_term_chosen': 3.9486405849456787, 'kl_term_rejected': 3.3518664836883545, 'epoch': 0.37}
 37%|███▋      | 1400/3753 [1:52:12<2:40:56,  4.10s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 37%|███▋      | 1401/3753 [1:53:09<13:01:18, 19.93s/it] 37%|███▋      | 1402/3753 [1:53:14<10:05:08, 15.44s/it] 37%|███▋      | 1403/3753 [1:53:17<7:44:14, 11.85s/it]  37%|███▋      | 1404/3753 [1:53:21<6:06:21,  9.36s/it] 37%|███▋      | 1405/3753 [1:53:26<5:10:59,  7.95s/it] 37%|███▋      | 1406/3753 [1:53:31<4:35:57,  7.05s/it] 37%|███▋      | 1407/3753 [1:53:34<3:55:00,  6.01s/it] 38%|███▊      | 1408/3753 [1:53:38<3:31:06,  5.40s/it] 38%|███▊      | 1409/3753 [1:53:43<3:18:43,  5.09s/it] 38%|███▊      | 1410/3753 [1:53:46<3:04:10,  4.72s/it]{'loss': 53.951, 'grad_norm': 302.3123474121094, 'learning_rate': 7.863541122885895e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.047764480113983154, 'weight_rejected': -3.084937334060669, 'kl_term_chosen': 0.7042480707168579, 'kl_term_rejected': -3.38077712059021, 'epoch': 0.3757495003331113}
                                                       {'loss': 53.951, 'grad_norm': 302.3123474121094, 'learning_rate': 7.863541122885895e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.047764480113983154, 'weight_rejected': -3.084937334060669, 'kl_term_chosen': 0.7042480707168579, 'kl_term_rejected': -3.38077712059021, 'epoch': 0.38}
 38%|███▊      | 1410/3753 [1:53:46<3:04:10,  4.72s/it] 38%|███▊      | 1411/3753 [1:53:50<2:48:45,  4.32s/it] 38%|███▊      | 1412/3753 [1:53:55<2:58:12,  4.57s/it] 38%|███▊      | 1413/3753 [1:54:02<3:22:29,  5.19s/it] 38%|███▊      | 1414/3753 [1:54:07<3:25:03,  5.26s/it] 38%|███▊      | 1415/3753 [1:54:15<3:51:57,  5.95s/it] 38%|███▊      | 1416/3753 [1:54:20<3:43:25,  5.74s/it] 38%|███▊      | 1417/3753 [1:54:24<3:20:41,  5.15s/it] 38%|███▊      | 1418/3753 [1:54:30<3:30:45,  5.42s/it] 38%|███▊      | 1419/3753 [1:54:34<3:18:28,  5.10s/it] 38%|███▊      | 1420/3753 [1:54:39<3:14:04,  4.99s/it]{'loss': 50.7207, 'grad_norm': 383.1571350097656, 'learning_rate': 7.825287028716117e-07, 'mean_ratio_chosen': 0.3509901463985443, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.046353816986084, 'weight_rejected': 0.9956324696540833, 'kl_term_chosen': -0.10469970852136612, 'kl_term_rejected': 0.9489074945449829, 'epoch': 0.37841439040639574}
                                                       {'loss': 50.7207, 'grad_norm': 383.1571350097656, 'learning_rate': 7.825287028716117e-07, 'mean_ratio_chosen': 0.3509901463985443, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.046353816986084, 'weight_rejected': 0.9956324696540833, 'kl_term_chosen': -0.10469970852136612, 'kl_term_rejected': 0.9489074945449829, 'epoch': 0.38}
 38%|███▊      | 1420/3753 [1:54:39<3:14:04,  4.99s/it] 38%|███▊      | 1421/3753 [1:54:43<3:00:26,  4.64s/it] 38%|███▊      | 1422/3753 [1:54:45<2:40:46,  4.14s/it] 38%|███▊      | 1423/3753 [1:54:50<2:43:47,  4.22s/it] 38%|███▊      | 1424/3753 [1:54:54<2:42:22,  4.18s/it] 38%|███▊      | 1425/3753 [1:54:59<2:54:55,  4.51s/it] 38%|███▊      | 1426/3753 [1:55:05<3:07:35,  4.84s/it] 38%|███▊      | 1427/3753 [1:55:14<3:53:53,  6.03s/it] 38%|███▊      | 1428/3753 [1:55:17<3:26:09,  5.32s/it] 38%|███▊      | 1429/3753 [1:55:22<3:17:25,  5.10s/it] 38%|███▊      | 1430/3753 [1:55:28<3:22:54,  5.24s/it]{'loss': 49.7053, 'grad_norm': 4391.85498046875, 'learning_rate': 7.786788424297547e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.062151908874512, 'weight_rejected': 1.2251251935958862, 'kl_term_chosen': 8.027007102966309, 'kl_term_rejected': 1.1091644763946533, 'epoch': 0.3810792804796802}
                                                       {'loss': 49.7053, 'grad_norm': 4391.85498046875, 'learning_rate': 7.786788424297547e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.062151908874512, 'weight_rejected': 1.2251251935958862, 'kl_term_chosen': 8.027007102966309, 'kl_term_rejected': 1.1091644763946533, 'epoch': 0.38}
 38%|███▊      | 1430/3753 [1:55:28<3:22:54,  5.24s/it] 38%|███▊      | 1431/3753 [1:55:31<3:05:58,  4.81s/it] 38%|███▊      | 1432/3753 [1:55:35<2:56:05,  4.55s/it] 38%|███▊      | 1433/3753 [1:55:40<2:56:42,  4.57s/it] 38%|███▊      | 1434/3753 [1:55:44<2:48:35,  4.36s/it] 38%|███▊      | 1435/3753 [1:55:51<3:25:37,  5.32s/it] 38%|███▊      | 1436/3753 [1:55:57<3:32:02,  5.49s/it] 38%|███▊      | 1437/3753 [1:56:01<3:07:57,  4.87s/it] 38%|███▊      | 1438/3753 [1:56:05<3:07:03,  4.85s/it] 38%|███▊      | 1439/3753 [1:56:10<3:07:10,  4.85s/it] 38%|███▊      | 1440/3753 [1:56:15<3:06:21,  4.83s/it]{'loss': 50.2491, 'grad_norm': 0.0, 'learning_rate': 7.748048641434439e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 8.323234558105469, 'weight_rejected': 12.983271598815918, 'kl_term_chosen': -7.8496994972229, 'kl_term_rejected': 12.360812187194824, 'epoch': 0.38374417055296467}
                                                       {'loss': 50.2491, 'grad_norm': 0.0, 'learning_rate': 7.748048641434439e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 8.323234558105469, 'weight_rejected': 12.983271598815918, 'kl_term_chosen': -7.8496994972229, 'kl_term_rejected': 12.360812187194824, 'epoch': 0.38}
 38%|███▊      | 1440/3753 [1:56:15<3:06:21,  4.83s/it] 38%|███▊      | 1441/3753 [1:56:19<2:58:57,  4.64s/it] 38%|███▊      | 1442/3753 [1:56:23<2:52:55,  4.49s/it] 38%|███▊      | 1443/3753 [1:56:28<2:57:48,  4.62s/it] 38%|███▊      | 1444/3753 [1:56:32<2:42:53,  4.23s/it] 39%|███▊      | 1445/3753 [1:56:36<2:48:23,  4.38s/it] 39%|███▊      | 1446/3753 [1:56:41<2:50:59,  4.45s/it] 39%|███▊      | 1447/3753 [1:56:45<2:43:21,  4.25s/it] 39%|███▊      | 1448/3753 [1:56:50<2:51:17,  4.46s/it] 39%|███▊      | 1449/3753 [1:56:54<2:48:11,  4.38s/it] 39%|███▊      | 1450/3753 [1:56:59<2:54:32,  4.55s/it]{'loss': 47.8043, 'grad_norm': 902.79541015625, 'learning_rate': 7.70907103280348e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.8865982294082642, 'weight_rejected': -1.2639957666397095, 'kl_term_chosen': 2.8598389625549316, 'kl_term_rejected': -1.3036346435546875, 'epoch': 0.3864090606262492}
                                                       {'loss': 47.8043, 'grad_norm': 902.79541015625, 'learning_rate': 7.70907103280348e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.8865982294082642, 'weight_rejected': -1.2639957666397095, 'kl_term_chosen': 2.8598389625549316, 'kl_term_rejected': -1.3036346435546875, 'epoch': 0.39}
 39%|███▊      | 1450/3753 [1:56:59<2:54:32,  4.55s/it] 39%|███▊      | 1451/3753 [1:57:07<3:32:55,  5.55s/it] 39%|███▊      | 1452/3753 [1:57:11<3:16:57,  5.14s/it] 39%|███▊      | 1453/3753 [1:57:15<3:00:57,  4.72s/it] 39%|███▊      | 1454/3753 [1:57:19<2:54:44,  4.56s/it] 39%|███▉      | 1455/3753 [1:57:23<2:55:06,  4.57s/it] 39%|███▉      | 1456/3753 [1:57:30<3:14:36,  5.08s/it] 39%|███▉      | 1457/3753 [1:57:34<3:00:31,  4.72s/it] 39%|███▉      | 1458/3753 [1:57:37<2:50:49,  4.47s/it] 39%|███▉      | 1459/3753 [1:57:42<2:48:13,  4.40s/it] 39%|███▉      | 1460/3753 [1:57:47<2:56:04,  4.61s/it]{'loss': 56.7044, 'grad_norm': 0.0, 'learning_rate': 7.669858971663626e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 2.950373888015747, 'weight_rejected': 4.902531623840332, 'kl_term_chosen': -2.2294158935546875, 'kl_term_rejected': 4.79732084274292, 'epoch': 0.38907395069953365}
                                                       {'loss': 56.7044, 'grad_norm': 0.0, 'learning_rate': 7.669858971663626e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 2.950373888015747, 'weight_rejected': 4.902531623840332, 'kl_term_chosen': -2.2294158935546875, 'kl_term_rejected': 4.79732084274292, 'epoch': 0.39}
 39%|███▉      | 1460/3753 [1:57:47<2:56:04,  4.61s/it] 39%|███▉      | 1461/3753 [1:57:51<2:50:12,  4.46s/it] 39%|███▉      | 1462/3753 [1:57:56<2:52:35,  4.52s/it] 39%|███▉      | 1463/3753 [1:58:00<2:48:10,  4.41s/it] 39%|███▉      | 1464/3753 [1:58:03<2:32:57,  4.01s/it] 39%|███▉      | 1465/3753 [1:58:06<2:22:17,  3.73s/it] 39%|███▉      | 1466/3753 [1:58:10<2:26:27,  3.84s/it] 39%|███▉      | 1467/3753 [1:58:13<2:21:41,  3.72s/it] 39%|███▉      | 1468/3753 [1:58:18<2:35:35,  4.09s/it] 39%|███▉      | 1469/3753 [1:58:23<2:38:52,  4.17s/it] 39%|███▉      | 1470/3753 [1:58:27<2:41:25,  4.24s/it]{'loss': 60.2833, 'grad_norm': 0.0, 'learning_rate': 7.630415851564183e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.863285541534424, 'weight_rejected': 3.2798666954040527, 'kl_term_chosen': 3.6689178943634033, 'kl_term_rejected': 3.1131913661956787, 'epoch': 0.3917388407728181}
                                                       {'loss': 60.2833, 'grad_norm': 0.0, 'learning_rate': 7.630415851564183e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.863285541534424, 'weight_rejected': 3.2798666954040527, 'kl_term_chosen': 3.6689178943634033, 'kl_term_rejected': 3.1131913661956787, 'epoch': 0.39}
 39%|███▉      | 1470/3753 [1:58:27<2:41:25,  4.24s/it] 39%|███▉      | 1471/3753 [1:58:31<2:41:15,  4.24s/it] 39%|███▉      | 1472/3753 [1:58:36<2:50:34,  4.49s/it] 39%|███▉      | 1473/3753 [1:58:41<2:54:16,  4.59s/it] 39%|███▉      | 1474/3753 [1:58:45<2:46:08,  4.37s/it] 39%|███▉      | 1475/3753 [1:58:49<2:44:32,  4.33s/it] 39%|███▉      | 1476/3753 [1:58:53<2:37:06,  4.14s/it] 39%|███▉      | 1477/3753 [1:58:58<2:45:51,  4.37s/it] 39%|███▉      | 1478/3753 [1:59:06<3:22:26,  5.34s/it] 39%|███▉      | 1479/3753 [1:59:10<3:16:52,  5.19s/it] 39%|███▉      | 1480/3753 [1:59:15<3:04:12,  4.86s/it]{'loss': 55.4933, 'grad_norm': 0.0, 'learning_rate': 7.590745086051101e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.097661256790161, 'weight_rejected': 1.7512786388397217, 'kl_term_chosen': 2.9725959300994873, 'kl_term_rejected': 1.6649551391601562, 'epoch': 0.3944037308461026}
                                                       {'loss': 55.4933, 'grad_norm': 0.0, 'learning_rate': 7.590745086051101e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.097661256790161, 'weight_rejected': 1.7512786388397217, 'kl_term_chosen': 2.9725959300994873, 'kl_term_rejected': 1.6649551391601562, 'epoch': 0.39}
 39%|███▉      | 1480/3753 [1:59:15<3:04:12,  4.86s/it] 39%|███▉      | 1481/3753 [1:59:20<3:13:55,  5.12s/it] 39%|███▉      | 1482/3753 [1:59:24<3:03:07,  4.84s/it] 40%|███▉      | 1483/3753 [1:59:28<2:48:22,  4.45s/it] 40%|███▉      | 1484/3753 [1:59:32<2:46:06,  4.39s/it] 40%|███▉      | 1485/3753 [1:59:36<2:36:54,  4.15s/it] 40%|███▉      | 1486/3753 [1:59:40<2:36:39,  4.15s/it] 40%|███▉      | 1487/3753 [1:59:48<3:16:49,  5.21s/it] 40%|███▉      | 1488/3753 [1:59:51<3:00:14,  4.77s/it] 40%|███▉      | 1489/3753 [1:59:56<3:00:03,  4.77s/it] 40%|███▉      | 1490/3753 [2:00:00<2:51:56,  4.56s/it]{'loss': 56.9203, 'grad_norm': 2732.266357421875, 'learning_rate': 7.550850108371574e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.1702797412872314, 'weight_rejected': 1.104888677597046, 'kl_term_chosen': 2.0270919799804688, 'kl_term_rejected': 0.9435684084892273, 'epoch': 0.39706862091938705}
                                                       {'loss': 56.9203, 'grad_norm': 2732.266357421875, 'learning_rate': 7.550850108371574e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.1702797412872314, 'weight_rejected': 1.104888677597046, 'kl_term_chosen': 2.0270919799804688, 'kl_term_rejected': 0.9435684084892273, 'epoch': 0.4}
 40%|███▉      | 1490/3753 [2:00:00<2:51:56,  4.56s/it] 40%|███▉      | 1491/3753 [2:00:04<2:43:25,  4.33s/it] 40%|███▉      | 1492/3753 [2:00:10<3:02:23,  4.84s/it] 40%|███▉      | 1493/3753 [2:00:16<3:16:22,  5.21s/it] 40%|███▉      | 1494/3753 [2:00:21<3:13:27,  5.14s/it] 40%|███▉      | 1495/3753 [2:00:28<3:31:50,  5.63s/it] 40%|███▉      | 1496/3753 [2:00:34<3:35:11,  5.72s/it] 40%|███▉      | 1497/3753 [2:00:38<3:12:36,  5.12s/it] 40%|███▉      | 1498/3753 [2:00:41<2:59:21,  4.77s/it] 40%|███▉      | 1499/3753 [2:00:44<2:38:26,  4.22s/it] 40%|███▉      | 1500/3753 [2:00:49<2:43:09,  4.35s/it]{'loss': 59.5873, 'grad_norm': 0.0, 'learning_rate': 7.51073437117689e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.94828200340271, 'weight_rejected': 2.796090602874756, 'kl_term_chosen': 2.7439401149749756, 'kl_term_rejected': 1.8105942010879517, 'epoch': 0.39973351099267157}
                                                       {'loss': 59.5873, 'grad_norm': 0.0, 'learning_rate': 7.51073437117689e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.94828200340271, 'weight_rejected': 2.796090602874756, 'kl_term_chosen': 2.7439401149749756, 'kl_term_rejected': 1.8105942010879517, 'epoch': 0.4}
 40%|███▉      | 1500/3753 [2:00:49<2:43:09,  4.35s/it] 40%|███▉      | 1501/3753 [2:00:54<2:46:16,  4.43s/it] 40%|████      | 1502/3753 [2:00:56<2:27:57,  3.94s/it] 40%|████      | 1503/3753 [2:01:01<2:33:20,  4.09s/it] 40%|████      | 1504/3753 [2:01:05<2:34:23,  4.12s/it] 40%|████      | 1505/3753 [2:01:10<2:39:26,  4.26s/it] 40%|████      | 1506/3753 [2:01:14<2:37:21,  4.20s/it] 40%|████      | 1507/3753 [2:01:22<3:22:57,  5.42s/it] 40%|████      | 1508/3753 [2:01:26<3:08:10,  5.03s/it] 40%|████      | 1509/3753 [2:01:31<3:03:00,  4.89s/it] 40%|████      | 1510/3753 [2:01:35<2:53:27,  4.64s/it]{'loss': 59.5931, 'grad_norm': 430.3112487792969, 'learning_rate': 7.470401346223653e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.7340953350067139, 'weight_rejected': 3.2496023178100586, 'kl_term_chosen': 1.8922697305679321, 'kl_term_rejected': 2.3956897258758545, 'epoch': 0.40239840106595604}
                                                       {'loss': 59.5931, 'grad_norm': 430.3112487792969, 'learning_rate': 7.470401346223653e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.7340953350067139, 'weight_rejected': 3.2496023178100586, 'kl_term_chosen': 1.8922697305679321, 'kl_term_rejected': 2.3956897258758545, 'epoch': 0.4}
 40%|████      | 1510/3753 [2:01:35<2:53:27,  4.64s/it] 40%|████      | 1511/3753 [2:01:40<2:56:55,  4.74s/it] 40%|████      | 1512/3753 [2:01:44<2:52:18,  4.61s/it] 40%|████      | 1513/3753 [2:01:48<2:43:08,  4.37s/it] 40%|████      | 1514/3753 [2:01:53<2:47:07,  4.48s/it] 40%|████      | 1515/3753 [2:01:56<2:37:37,  4.23s/it] 40%|████      | 1516/3753 [2:02:01<2:46:01,  4.45s/it] 40%|████      | 1517/3753 [2:02:05<2:34:21,  4.14s/it] 40%|████      | 1518/3753 [2:02:09<2:32:22,  4.09s/it] 40%|████      | 1519/3753 [2:02:17<3:19:07,  5.35s/it] 41%|████      | 1520/3753 [2:02:23<3:22:33,  5.44s/it]{'loss': 65.1437, 'grad_norm': 1384.5943603515625, 'learning_rate': 7.4298545240733e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.7414990067481995, 'weight_rejected': 9.87879753112793, 'kl_term_chosen': 1.659979224205017, 'kl_term_rejected': 9.826178550720215, 'epoch': 0.4050632911392405}
                                                       {'loss': 65.1437, 'grad_norm': 1384.5943603515625, 'learning_rate': 7.4298545240733e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.7414990067481995, 'weight_rejected': 9.87879753112793, 'kl_term_chosen': 1.659979224205017, 'kl_term_rejected': 9.826178550720215, 'epoch': 0.41}
 41%|████      | 1520/3753 [2:02:23<3:22:33,  5.44s/it] 41%|████      | 1521/3753 [2:02:26<3:03:16,  4.93s/it] 41%|████      | 1522/3753 [2:02:31<3:06:21,  5.01s/it] 41%|████      | 1523/3753 [2:02:36<2:58:33,  4.80s/it] 41%|████      | 1524/3753 [2:02:41<3:04:12,  4.96s/it] 41%|████      | 1525/3753 [2:02:46<2:59:37,  4.84s/it] 41%|████      | 1526/3753 [2:02:54<3:39:24,  5.91s/it] 41%|████      | 1527/3753 [2:03:02<4:00:23,  6.48s/it] 41%|████      | 1528/3753 [2:03:07<3:39:42,  5.92s/it] 41%|████      | 1529/3753 [2:03:11<3:23:47,  5.50s/it] 41%|████      | 1530/3753 [2:03:15<3:08:38,  5.09s/it]{'loss': 52.7559, 'grad_norm': 0.0, 'learning_rate': 7.389097413790035e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.5558915734291077, 'weight_rejected': -1.2219947576522827, 'kl_term_chosen': 1.0987548828125, 'kl_term_rejected': -1.4175888299942017, 'epoch': 0.40772818121252496}
                                                       {'loss': 52.7559, 'grad_norm': 0.0, 'learning_rate': 7.389097413790035e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.5558915734291077, 'weight_rejected': -1.2219947576522827, 'kl_term_chosen': 1.0987548828125, 'kl_term_rejected': -1.4175888299942017, 'epoch': 0.41}
 41%|████      | 1530/3753 [2:03:15<3:08:38,  5.09s/it] 41%|████      | 1531/3753 [2:03:20<3:01:48,  4.91s/it] 41%|████      | 1532/3753 [2:03:25<3:02:35,  4.93s/it] 41%|████      | 1533/3753 [2:03:28<2:48:41,  4.56s/it] 41%|████      | 1534/3753 [2:03:32<2:40:16,  4.33s/it] 41%|████      | 1535/3753 [2:03:38<3:01:04,  4.90s/it] 41%|████      | 1536/3753 [2:03:43<2:57:56,  4.82s/it] 41%|████      | 1537/3753 [2:03:49<3:06:23,  5.05s/it] 41%|████      | 1538/3753 [2:03:53<3:00:37,  4.89s/it] 41%|████      | 1539/3753 [2:03:57<2:50:10,  4.61s/it] 41%|████      | 1540/3753 [2:04:01<2:48:24,  4.57s/it]{'loss': 55.2788, 'grad_norm': 0.0, 'learning_rate': 7.348133542637131e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.8464632034301758, 'weight_rejected': -0.677406907081604, 'kl_term_chosen': 2.498704671859741, 'kl_term_rejected': -1.0674179792404175, 'epoch': 0.4103930712858095}
                                                       {'loss': 55.2788, 'grad_norm': 0.0, 'learning_rate': 7.348133542637131e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.8464632034301758, 'weight_rejected': -0.677406907081604, 'kl_term_chosen': 2.498704671859741, 'kl_term_rejected': -1.0674179792404175, 'epoch': 0.41}
 41%|████      | 1540/3753 [2:04:02<2:48:24,  4.57s/it] 41%|████      | 1541/3753 [2:04:06<2:46:01,  4.50s/it] 41%|████      | 1542/3753 [2:04:11<2:48:24,  4.57s/it] 41%|████      | 1543/3753 [2:04:15<2:45:20,  4.49s/it] 41%|████      | 1544/3753 [2:04:19<2:38:03,  4.29s/it] 41%|████      | 1545/3753 [2:04:22<2:32:25,  4.14s/it] 41%|████      | 1546/3753 [2:04:27<2:32:34,  4.15s/it] 41%|████      | 1547/3753 [2:04:31<2:34:12,  4.19s/it] 41%|████      | 1548/3753 [2:04:36<2:39:39,  4.34s/it] 41%|████▏     | 1549/3753 [2:04:39<2:32:16,  4.15s/it] 41%|████▏     | 1550/3753 [2:04:44<2:35:44,  4.24s/it]{'loss': 54.3253, 'grad_norm': 1201.726806640625, 'learning_rate': 7.306966455771677e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.15234042704105377, 'weight_chosen': -11.06801986694336, 'weight_rejected': 0.0815463662147522, 'kl_term_chosen': 11.808194160461426, 'kl_term_rejected': -0.18816375732421875, 'epoch': 0.41305796135909395}
                                                       {'loss': 54.3253, 'grad_norm': 1201.726806640625, 'learning_rate': 7.306966455771677e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.15234042704105377, 'weight_chosen': -11.06801986694336, 'weight_rejected': 0.0815463662147522, 'kl_term_chosen': 11.808194160461426, 'kl_term_rejected': -0.18816375732421875, 'epoch': 0.41}
 41%|████▏     | 1550/3753 [2:04:44<2:35:44,  4.24s/it] 41%|████▏     | 1551/3753 [2:04:50<2:53:20,  4.72s/it] 41%|████▏     | 1552/3753 [2:04:54<2:52:49,  4.71s/it] 41%|████▏     | 1553/3753 [2:04:58<2:44:41,  4.49s/it] 41%|████▏     | 1554/3753 [2:05:02<2:36:14,  4.26s/it] 41%|████▏     | 1555/3753 [2:05:06<2:36:39,  4.28s/it] 41%|████▏     | 1556/3753 [2:05:10<2:34:41,  4.22s/it] 41%|████▏     | 1557/3753 [2:05:14<2:23:56,  3.93s/it] 42%|████▏     | 1558/3753 [2:05:18<2:24:59,  3.96s/it] 42%|████▏     | 1559/3753 [2:05:22<2:26:28,  4.01s/it] 42%|████▏     | 1560/3753 [2:05:26<2:24:00,  3.94s/it]{'loss': 58.5577, 'grad_norm': 2521.469482421875, 'learning_rate': 7.265599715937754e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.2142128944396973, 'weight_rejected': 7.667755126953125, 'kl_term_chosen': 2.1830689907073975, 'kl_term_rejected': 7.642956733703613, 'epoch': 0.4157228514323784}
                                                       {'loss': 58.5577, 'grad_norm': 2521.469482421875, 'learning_rate': 7.265599715937754e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.2142128944396973, 'weight_rejected': 7.667755126953125, 'kl_term_chosen': 2.1830689907073975, 'kl_term_rejected': 7.642956733703613, 'epoch': 0.42}
 42%|████▏     | 1560/3753 [2:05:26<2:24:00,  3.94s/it] 42%|████▏     | 1561/3753 [2:05:29<2:19:32,  3.82s/it] 42%|████▏     | 1562/3753 [2:05:33<2:19:13,  3.81s/it] 42%|████▏     | 1563/3753 [2:05:38<2:31:39,  4.16s/it] 42%|████▏     | 1564/3753 [2:05:46<3:12:35,  5.28s/it] 42%|████▏     | 1565/3753 [2:05:50<3:04:07,  5.05s/it] 42%|████▏     | 1566/3753 [2:05:55<2:57:23,  4.87s/it] 42%|████▏     | 1567/3753 [2:05:59<2:49:43,  4.66s/it] 42%|████▏     | 1568/3753 [2:06:03<2:45:40,  4.55s/it] 42%|████▏     | 1569/3753 [2:06:07<2:41:07,  4.43s/it] 42%|████▏     | 1570/3753 [2:06:11<2:29:17,  4.10s/it]{'loss': 52.1551, 'grad_norm': 2979.157958984375, 'learning_rate': 7.224036903158118e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.292333602905273, 'weight_rejected': 0.8041118383407593, 'kl_term_chosen': 10.23813533782959, 'kl_term_rejected': 0.7793136835098267, 'epoch': 0.4183877415056629}
                                                       {'loss': 52.1551, 'grad_norm': 2979.157958984375, 'learning_rate': 7.224036903158118e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.292333602905273, 'weight_rejected': 0.8041118383407593, 'kl_term_chosen': 10.23813533782959, 'kl_term_rejected': 0.7793136835098267, 'epoch': 0.42}
 42%|████▏     | 1570/3753 [2:06:11<2:29:17,  4.10s/it] 42%|████▏     | 1571/3753 [2:06:16<2:38:30,  4.36s/it] 42%|████▏     | 1572/3753 [2:06:21<2:48:24,  4.63s/it] 42%|████▏     | 1573/3753 [2:06:24<2:34:43,  4.26s/it] 42%|████▏     | 1574/3753 [2:06:29<2:36:51,  4.32s/it] 42%|████▏     | 1575/3753 [2:06:34<2:49:52,  4.68s/it] 42%|████▏     | 1576/3753 [2:06:39<2:44:35,  4.54s/it] 42%|████▏     | 1577/3753 [2:06:42<2:36:28,  4.31s/it] 42%|████▏     | 1578/3753 [2:06:47<2:38:52,  4.38s/it] 42%|████▏     | 1579/3753 [2:06:51<2:35:13,  4.28s/it] 42%|████▏     | 1580/3753 [2:06:56<2:42:21,  4.48s/it]{'loss': 53.2945, 'grad_norm': 1771.4307861328125, 'learning_rate': 7.182281614424362e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 6.044406890869141, 'weight_chosen': 9.353729248046875, 'weight_rejected': 0.5153729915618896, 'kl_term_chosen': -8.550555229187012, 'kl_term_rejected': 0.17991332709789276, 'epoch': 0.42105263157894735}
                                                       {'loss': 53.2945, 'grad_norm': 1771.4307861328125, 'learning_rate': 7.182281614424362e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 6.044406890869141, 'weight_chosen': 9.353729248046875, 'weight_rejected': 0.5153729915618896, 'kl_term_chosen': -8.550555229187012, 'kl_term_rejected': 0.17991332709789276, 'epoch': 0.42}
 42%|████▏     | 1580/3753 [2:06:56<2:42:21,  4.48s/it] 42%|████▏     | 1581/3753 [2:07:00<2:37:45,  4.36s/it] 42%|████▏     | 1582/3753 [2:07:04<2:37:27,  4.35s/it] 42%|████▏     | 1583/3753 [2:07:08<2:27:51,  4.09s/it] 42%|████▏     | 1584/3753 [2:07:12<2:28:15,  4.10s/it] 42%|████▏     | 1585/3753 [2:07:17<2:34:02,  4.26s/it] 42%|████▏     | 1586/3753 [2:07:23<2:56:55,  4.90s/it] 42%|████▏     | 1587/3753 [2:07:27<2:45:15,  4.58s/it] 42%|████▏     | 1588/3753 [2:07:31<2:43:35,  4.53s/it] 42%|████▏     | 1589/3753 [2:07:35<2:39:54,  4.43s/it] 42%|████▏     | 1590/3753 [2:07:40<2:44:10,  4.55s/it]{'loss': 41.8258, 'grad_norm': 0.0, 'learning_rate': 7.140337463385624e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.0311279296875, 'weight_rejected': 2.7606914043426514, 'kl_term_chosen': 2.8151164054870605, 'kl_term_rejected': 2.4591236114501953, 'epoch': 0.42371752165223187}
                                                       {'loss': 41.8258, 'grad_norm': 0.0, 'learning_rate': 7.140337463385624e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.0311279296875, 'weight_rejected': 2.7606914043426514, 'kl_term_chosen': 2.8151164054870605, 'kl_term_rejected': 2.4591236114501953, 'epoch': 0.42}
 42%|████▏     | 1590/3753 [2:07:40<2:44:10,  4.55s/it] 42%|████▏     | 1591/3753 [2:07:46<2:52:14,  4.78s/it] 42%|████▏     | 1592/3753 [2:07:53<3:18:36,  5.51s/it] 42%|████▏     | 1593/3753 [2:07:56<2:54:47,  4.86s/it] 42%|████▏     | 1594/3753 [2:07:59<2:34:55,  4.31s/it] 42%|████▏     | 1595/3753 [2:08:04<2:39:39,  4.44s/it] 43%|████▎     | 1596/3753 [2:08:11<3:04:32,  5.13s/it] 43%|████▎     | 1597/3753 [2:08:15<2:58:16,  4.96s/it] 43%|████▎     | 1598/3753 [2:08:18<2:40:34,  4.47s/it] 43%|████▎     | 1599/3753 [2:08:26<3:14:56,  5.43s/it] 43%|████▎     | 1600/3753 [2:08:30<2:53:44,  4.84s/it]{'loss': 43.5383, 'grad_norm': 11.548223495483398, 'learning_rate': 7.09820808003585e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.25480842590332, 'weight_rejected': 0.9840019345283508, 'kl_term_chosen': 6.120941162109375, 'kl_term_rejected': 0.8680412173271179, 'epoch': 0.42638241172551633}
                                                       {'loss': 43.5383, 'grad_norm': 11.548223495483398, 'learning_rate': 7.09820808003585e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.25480842590332, 'weight_rejected': 0.9840019345283508, 'kl_term_chosen': 6.120941162109375, 'kl_term_rejected': 0.8680412173271179, 'epoch': 0.43}
 43%|████▎     | 1600/3753 [2:08:30<2:53:44,  4.84s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 43%|████▎     | 1601/3753 [2:09:27<12:19:39, 20.62s/it] 43%|████▎     | 1602/3753 [2:09:31<9:19:06, 15.60s/it]  43%|████▎     | 1603/3753 [2:09:34<7:01:08, 11.75s/it] 43%|████▎     | 1604/3753 [2:09:38<5:42:01,  9.55s/it] 43%|████▎     | 1605/3753 [2:09:42<4:41:13,  7.86s/it] 43%|████▎     | 1606/3753 [2:09:50<4:40:46,  7.85s/it] 43%|████▎     | 1607/3753 [2:09:53<3:54:11,  6.55s/it] 43%|████▎     | 1608/3753 [2:09:57<3:22:55,  5.68s/it] 43%|████▎     | 1609/3753 [2:10:02<3:11:23,  5.36s/it] 43%|████▎     | 1610/3753 [2:10:06<3:04:30,  5.17s/it]{'loss': 50.3587, 'grad_norm': 1915.714599609375, 'learning_rate': 7.055897110399637e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.7968096733093262, 'weight_rejected': -5.972928524017334, 'kl_term_chosen': -1.4835999011993408, 'kl_term_rejected': -6.8890380859375, 'epoch': 0.4290473017988008}
                                                       {'loss': 50.3587, 'grad_norm': 1915.714599609375, 'learning_rate': 7.055897110399637e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.7968096733093262, 'weight_rejected': -5.972928524017334, 'kl_term_chosen': -1.4835999011993408, 'kl_term_rejected': -6.8890380859375, 'epoch': 0.43}
 43%|████▎     | 1610/3753 [2:10:06<3:04:30,  5.17s/it] 43%|████▎     | 1611/3753 [2:10:10<2:50:57,  4.79s/it] 43%|████▎     | 1612/3753 [2:10:15<2:47:50,  4.70s/it] 43%|████▎     | 1613/3753 [2:10:20<2:52:26,  4.83s/it] 43%|████▎     | 1614/3753 [2:10:24<2:45:53,  4.65s/it] 43%|████▎     | 1615/3753 [2:10:28<2:39:02,  4.46s/it] 43%|████▎     | 1616/3753 [2:10:32<2:37:30,  4.42s/it] 43%|████▎     | 1617/3753 [2:10:36<2:28:07,  4.16s/it] 43%|████▎     | 1618/3753 [2:10:40<2:27:26,  4.14s/it] 43%|████▎     | 1619/3753 [2:10:44<2:27:12,  4.14s/it] 43%|████▎     | 1620/3753 [2:10:50<2:42:06,  4.56s/it]{'loss': 48.7531, 'grad_norm': 1137.0548095703125, 'learning_rate': 7.013408216216699e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.17361342906951904, 'weight_rejected': 0.7950226068496704, 'kl_term_chosen': 0.7867477536201477, 'kl_term_rejected': 0.6749969720840454, 'epoch': 0.43171219187208526}
                                                       {'loss': 48.7531, 'grad_norm': 1137.0548095703125, 'learning_rate': 7.013408216216699e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.17361342906951904, 'weight_rejected': 0.7950226068496704, 'kl_term_chosen': 0.7867477536201477, 'kl_term_rejected': 0.6749969720840454, 'epoch': 0.43}
 43%|████▎     | 1620/3753 [2:10:50<2:42:06,  4.56s/it] 43%|████▎     | 1621/3753 [2:10:53<2:29:24,  4.20s/it] 43%|████▎     | 1622/3753 [2:10:59<2:47:39,  4.72s/it] 43%|████▎     | 1623/3753 [2:11:04<2:46:10,  4.68s/it] 43%|████▎     | 1624/3753 [2:11:08<2:37:45,  4.45s/it] 43%|████▎     | 1625/3753 [2:11:13<2:45:13,  4.66s/it] 43%|████▎     | 1626/3753 [2:11:21<3:27:15,  5.85s/it] 43%|████▎     | 1627/3753 [2:11:25<3:01:06,  5.11s/it] 43%|████▎     | 1628/3753 [2:11:29<2:53:48,  4.91s/it] 43%|████▎     | 1629/3753 [2:11:33<2:43:40,  4.62s/it] 43%|████▎     | 1630/3753 [2:11:37<2:35:21,  4.39s/it]{'loss': 50.898, 'grad_norm': 20.058073043823242, 'learning_rate': 6.970745074624961e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.8920312523841858, 'weight_rejected': 1.5207197666168213, 'kl_term_chosen': 1.815070390701294, 'kl_term_rejected': 1.453173041343689, 'epoch': 0.4343770819453698}
                                                       {'loss': 50.898, 'grad_norm': 20.058073043823242, 'learning_rate': 6.970745074624961e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.8920312523841858, 'weight_rejected': 1.5207197666168213, 'kl_term_chosen': 1.815070390701294, 'kl_term_rejected': 1.453173041343689, 'epoch': 0.43}
 43%|████▎     | 1630/3753 [2:11:37<2:35:21,  4.39s/it] 43%|████▎     | 1631/3753 [2:11:43<2:49:00,  4.78s/it] 43%|████▎     | 1632/3753 [2:11:48<2:52:52,  4.89s/it] 44%|████▎     | 1633/3753 [2:11:52<2:46:03,  4.70s/it] 44%|████▎     | 1634/3753 [2:11:56<2:39:46,  4.52s/it] 44%|████▎     | 1635/3753 [2:12:01<2:40:49,  4.56s/it] 44%|████▎     | 1636/3753 [2:12:04<2:27:03,  4.17s/it] 44%|████▎     | 1637/3753 [2:12:08<2:24:03,  4.08s/it] 44%|████▎     | 1638/3753 [2:12:12<2:24:23,  4.10s/it] 44%|████▎     | 1639/3753 [2:12:16<2:24:07,  4.09s/it] 44%|████▎     | 1640/3753 [2:12:21<2:29:24,  4.24s/it]{'loss': 52.5103, 'grad_norm': 1833.2987060546875, 'learning_rate': 6.927911377842334e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.13492701947689056, 'weight_chosen': -11.496990203857422, 'weight_rejected': -0.15494954586029053, 'kl_term_chosen': 12.385748863220215, 'kl_term_rejected': -0.2003021240234375, 'epoch': 0.43704197201865425}
                                                       {'loss': 52.5103, 'grad_norm': 1833.2987060546875, 'learning_rate': 6.927911377842334e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.13492701947689056, 'weight_chosen': -11.496990203857422, 'weight_rejected': -0.15494954586029053, 'kl_term_chosen': 12.385748863220215, 'kl_term_rejected': -0.2003021240234375, 'epoch': 0.44}
 44%|████▎     | 1640/3753 [2:12:21<2:29:24,  4.24s/it] 44%|████▎     | 1641/3753 [2:12:24<2:21:55,  4.03s/it] 44%|████▍     | 1642/3753 [2:12:29<2:30:08,  4.27s/it] 44%|████▍     | 1643/3753 [2:12:33<2:27:31,  4.20s/it] 44%|████▍     | 1644/3753 [2:12:41<3:06:01,  5.29s/it] 44%|████▍     | 1645/3753 [2:12:45<2:54:20,  4.96s/it] 44%|████▍     | 1646/3753 [2:12:50<2:47:38,  4.77s/it] 44%|████▍     | 1647/3753 [2:12:54<2:45:53,  4.73s/it] 44%|████▍     | 1648/3753 [2:12:57<2:29:21,  4.26s/it] 44%|████▍     | 1649/3753 [2:13:01<2:19:50,  3.99s/it] 44%|████▍     | 1650/3753 [2:13:06<2:30:11,  4.29s/it]{'loss': 56.5868, 'grad_norm': 561.9972534179688, 'learning_rate': 6.884910832847167e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.766665935516357, 'weight_rejected': -6.8014068603515625, 'kl_term_chosen': -5.4285888671875, 'kl_term_rejected': -7.594512939453125, 'epoch': 0.4397068620919387}
                                                       {'loss': 56.5868, 'grad_norm': 561.9972534179688, 'learning_rate': 6.884910832847167e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.766665935516357, 'weight_rejected': -6.8014068603515625, 'kl_term_chosen': -5.4285888671875, 'kl_term_rejected': -7.594512939453125, 'epoch': 0.44}
 44%|████▍     | 1650/3753 [2:13:06<2:30:11,  4.29s/it] 44%|████▍     | 1651/3753 [2:13:09<2:22:57,  4.08s/it] 44%|████▍     | 1652/3753 [2:13:14<2:29:47,  4.28s/it] 44%|████▍     | 1653/3753 [2:13:18<2:21:53,  4.05s/it] 44%|████▍     | 1654/3753 [2:13:21<2:10:40,  3.74s/it] 44%|████▍     | 1655/3753 [2:13:25<2:18:23,  3.96s/it] 44%|████▍     | 1656/3753 [2:13:30<2:29:13,  4.27s/it] 44%|████▍     | 1657/3753 [2:13:34<2:26:40,  4.20s/it] 44%|████▍     | 1658/3753 [2:13:41<2:56:28,  5.05s/it] 44%|████▍     | 1659/3753 [2:13:45<2:47:56,  4.81s/it] 44%|████▍     | 1660/3753 [2:13:49<2:36:13,  4.48s/it]{'loss': 49.4168, 'grad_norm': 1136.9368896484375, 'learning_rate': 6.84174716105745e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.6929037570953369, 'weight_rejected': 1.9590508937835693, 'kl_term_chosen': 1.4146469831466675, 'kl_term_rejected': 1.8786934614181519, 'epoch': 0.4423717521652232}
                                                       {'loss': 49.4168, 'grad_norm': 1136.9368896484375, 'learning_rate': 6.84174716105745e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.6929037570953369, 'weight_rejected': 1.9590508937835693, 'kl_term_chosen': 1.4146469831466675, 'kl_term_rejected': 1.8786934614181519, 'epoch': 0.44}
 44%|████▍     | 1660/3753 [2:13:49<2:36:13,  4.48s/it] 44%|████▍     | 1661/3753 [2:13:54<2:43:32,  4.69s/it] 44%|████▍     | 1662/3753 [2:13:58<2:39:25,  4.57s/it] 44%|████▍     | 1663/3753 [2:14:03<2:34:20,  4.43s/it] 44%|████▍     | 1664/3753 [2:14:07<2:38:19,  4.55s/it] 44%|████▍     | 1665/3753 [2:14:13<2:44:30,  4.73s/it] 44%|████▍     | 1666/3753 [2:14:17<2:38:05,  4.55s/it] 44%|████▍     | 1667/3753 [2:14:21<2:36:21,  4.50s/it] 44%|████▍     | 1668/3753 [2:14:25<2:25:26,  4.19s/it] 44%|████▍     | 1669/3753 [2:14:28<2:18:43,  3.99s/it] 44%|████▍     | 1670/3753 [2:14:32<2:14:05,  3.86s/it]{'loss': 49.0169, 'grad_norm': 95.52729034423828, 'learning_rate': 6.798424098008722e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -5.1748552322387695, 'weight_rejected': -4.468920707702637, 'kl_term_chosen': 5.98048734664917, 'kl_term_rejected': -4.67073392868042, 'epoch': 0.44503664223850764}
                                                       {'loss': 49.0169, 'grad_norm': 95.52729034423828, 'learning_rate': 6.798424098008722e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -5.1748552322387695, 'weight_rejected': -4.468920707702637, 'kl_term_chosen': 5.98048734664917, 'kl_term_rejected': -4.67073392868042, 'epoch': 0.45}
 44%|████▍     | 1670/3753 [2:14:32<2:14:05,  3.86s/it] 45%|████▍     | 1671/3753 [2:14:36<2:18:54,  4.00s/it] 45%|████▍     | 1672/3753 [2:14:40<2:22:38,  4.11s/it] 45%|████▍     | 1673/3753 [2:14:46<2:35:55,  4.50s/it] 45%|████▍     | 1674/3753 [2:14:50<2:28:40,  4.29s/it] 45%|████▍     | 1675/3753 [2:14:53<2:17:43,  3.98s/it] 45%|████▍     | 1676/3753 [2:14:56<2:15:01,  3.90s/it] 45%|████▍     | 1677/3753 [2:15:01<2:20:52,  4.07s/it] 45%|████▍     | 1678/3753 [2:15:06<2:30:45,  4.36s/it] 45%|████▍     | 1679/3753 [2:15:10<2:24:43,  4.19s/it] 45%|████▍     | 1680/3753 [2:15:13<2:14:13,  3.88s/it]{'loss': 51.6188, 'grad_norm': 342.0506286621094, 'learning_rate': 6.754945393030818e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.4949288368225098, 'weight_rejected': 2.9181606769561768, 'kl_term_chosen': 3.466921329498291, 'kl_term_rejected': 2.833061695098877, 'epoch': 0.44770153231179216}
                                                       {'loss': 51.6188, 'grad_norm': 342.0506286621094, 'learning_rate': 6.754945393030818e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.4949288368225098, 'weight_rejected': 2.9181606769561768, 'kl_term_chosen': 3.466921329498291, 'kl_term_rejected': 2.833061695098877, 'epoch': 0.45}
 45%|████▍     | 1680/3753 [2:15:13<2:14:13,  3.88s/it] 45%|████▍     | 1681/3753 [2:15:17<2:16:15,  3.95s/it] 45%|████▍     | 1682/3753 [2:15:23<2:37:41,  4.57s/it] 45%|████▍     | 1683/3753 [2:15:27<2:26:48,  4.26s/it] 45%|████▍     | 1684/3753 [2:15:32<2:34:29,  4.48s/it] 45%|████▍     | 1685/3753 [2:15:36<2:29:40,  4.34s/it] 45%|████▍     | 1686/3753 [2:15:39<2:19:23,  4.05s/it] 45%|████▍     | 1687/3753 [2:15:43<2:18:06,  4.01s/it] 45%|████▍     | 1688/3753 [2:15:50<2:47:37,  4.87s/it] 45%|████▌     | 1689/3753 [2:15:54<2:43:45,  4.76s/it] 45%|████▌     | 1690/3753 [2:16:02<3:14:20,  5.65s/it]{'loss': 50.2901, 'grad_norm': 0.0, 'learning_rate': 6.711314808923356e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -11.89465618133545, 'weight_rejected': -7.906253337860107, 'kl_term_chosen': 12.1041259765625, 'kl_term_rejected': -8.515777587890625, 'epoch': 0.4503664223850766}
                                                       {'loss': 50.2901, 'grad_norm': 0.0, 'learning_rate': 6.711314808923356e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -11.89465618133545, 'weight_rejected': -7.906253337860107, 'kl_term_chosen': 12.1041259765625, 'kl_term_rejected': -8.515777587890625, 'epoch': 0.45}
 45%|████▌     | 1690/3753 [2:16:02<3:14:20,  5.65s/it] 45%|████▌     | 1691/3753 [2:16:06<2:56:33,  5.14s/it] 45%|████▌     | 1692/3753 [2:16:11<2:58:17,  5.19s/it] 45%|████▌     | 1693/3753 [2:16:17<3:07:57,  5.47s/it] 45%|████▌     | 1694/3753 [2:16:21<2:45:47,  4.83s/it] 45%|████▌     | 1695/3753 [2:16:24<2:34:04,  4.49s/it] 45%|████▌     | 1696/3753 [2:16:28<2:25:51,  4.25s/it] 45%|████▌     | 1697/3753 [2:16:32<2:21:21,  4.13s/it] 45%|████▌     | 1698/3753 [2:16:35<2:15:00,  3.94s/it] 45%|████▌     | 1699/3753 [2:16:40<2:24:53,  4.23s/it] 45%|████▌     | 1700/3753 [2:16:45<2:27:47,  4.32s/it]{'loss': 56.6328, 'grad_norm': 579.388671875, 'learning_rate': 6.667536121630115e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.11618310213088989, 'weight_chosen': 0.28038835525512695, 'weight_rejected': -0.14469918608665466, 'kl_term_chosen': 0.615863025188446, 'kl_term_rejected': -0.21525879204273224, 'epoch': 0.4530313124583611}
                                                       {'loss': 56.6328, 'grad_norm': 579.388671875, 'learning_rate': 6.667536121630115e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.11618310213088989, 'weight_chosen': 0.28038835525512695, 'weight_rejected': -0.14469918608665466, 'kl_term_chosen': 0.615863025188446, 'kl_term_rejected': -0.21525879204273224, 'epoch': 0.45}
 45%|████▌     | 1700/3753 [2:16:45<2:27:47,  4.32s/it] 45%|████▌     | 1701/3753 [2:16:48<2:20:02,  4.09s/it] 45%|████▌     | 1702/3753 [2:16:52<2:13:56,  3.92s/it] 45%|████▌     | 1703/3753 [2:16:56<2:17:06,  4.01s/it] 45%|████▌     | 1704/3753 [2:17:00<2:15:09,  3.96s/it] 45%|████▌     | 1705/3753 [2:17:04<2:13:48,  3.92s/it] 45%|████▌     | 1706/3753 [2:17:08<2:15:49,  3.98s/it] 45%|████▌     | 1707/3753 [2:17:12<2:14:14,  3.94s/it] 46%|████▌     | 1708/3753 [2:17:18<2:36:08,  4.58s/it] 46%|████▌     | 1709/3753 [2:17:22<2:32:09,  4.47s/it] 46%|████▌     | 1710/3753 [2:17:26<2:25:23,  4.27s/it]{'loss': 52.4728, 'grad_norm': 28.84522247314453, 'learning_rate': 6.623613119912244e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.0640748739242554, 'weight_rejected': 9.201726913452148, 'kl_term_chosen': 2.0200562477111816, 'kl_term_rejected': 9.112906455993652, 'epoch': 0.45569620253164556}
                                                       {'loss': 52.4728, 'grad_norm': 28.84522247314453, 'learning_rate': 6.623613119912244e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.0640748739242554, 'weight_rejected': 9.201726913452148, 'kl_term_chosen': 2.0200562477111816, 'kl_term_rejected': 9.112906455993652, 'epoch': 0.46}
 46%|████▌     | 1710/3753 [2:17:26<2:25:23,  4.27s/it] 46%|████▌     | 1711/3753 [2:17:31<2:36:05,  4.59s/it] 46%|████▌     | 1712/3753 [2:17:34<2:19:16,  4.09s/it] 46%|████▌     | 1713/3753 [2:17:38<2:16:02,  4.00s/it] 46%|████▌     | 1714/3753 [2:17:42<2:13:43,  3.93s/it] 46%|████▌     | 1715/3753 [2:17:46<2:12:22,  3.90s/it] 46%|████▌     | 1716/3753 [2:17:50<2:19:19,  4.10s/it] 46%|████▌     | 1717/3753 [2:17:54<2:16:59,  4.04s/it] 46%|████▌     | 1718/3753 [2:17:58<2:16:57,  4.04s/it] 46%|████▌     | 1719/3753 [2:18:02<2:16:34,  4.03s/it] 46%|████▌     | 1720/3753 [2:18:11<3:06:49,  5.51s/it]{'loss': 56.7647, 'grad_norm': 0.0, 'learning_rate': 6.57954960502036e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -10.091659545898438, 'weight_rejected': 0.9004107713699341, 'kl_term_chosen': 10.923895835876465, 'kl_term_rejected': 0.8050613403320312, 'epoch': 0.45836109260493}
                                                       {'loss': 56.7647, 'grad_norm': 0.0, 'learning_rate': 6.57954960502036e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -10.091659545898438, 'weight_rejected': 0.9004107713699341, 'kl_term_chosen': 10.923895835876465, 'kl_term_rejected': 0.8050613403320312, 'epoch': 0.46}
 46%|████▌     | 1720/3753 [2:18:11<3:06:49,  5.51s/it] 46%|████▌     | 1721/3753 [2:18:14<2:45:11,  4.88s/it] 46%|████▌     | 1722/3753 [2:18:19<2:45:19,  4.88s/it] 46%|████▌     | 1723/3753 [2:18:23<2:33:02,  4.52s/it] 46%|████▌     | 1724/3753 [2:18:31<3:05:52,  5.50s/it] 46%|████▌     | 1725/3753 [2:18:39<3:35:24,  6.37s/it] 46%|████▌     | 1726/3753 [2:18:43<3:07:12,  5.54s/it] 46%|████▌     | 1727/3753 [2:18:46<2:47:39,  4.97s/it] 46%|████▌     | 1728/3753 [2:18:50<2:33:19,  4.54s/it] 46%|████▌     | 1729/3753 [2:18:53<2:22:29,  4.22s/it] 46%|████▌     | 1730/3753 [2:18:58<2:23:19,  4.25s/it]{'loss': 52.0605, 'grad_norm': 0.0, 'learning_rate': 6.535349390365596e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.1050297021865845, 'weight_rejected': -0.8838248252868652, 'kl_term_chosen': -0.23980560898780823, 'kl_term_rejected': -0.9981933832168579, 'epoch': 0.46102598267821454}
                                                       {'loss': 52.0605, 'grad_norm': 0.0, 'learning_rate': 6.535349390365596e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.1050297021865845, 'weight_rejected': -0.8838248252868652, 'kl_term_chosen': -0.23980560898780823, 'kl_term_rejected': -0.9981933832168579, 'epoch': 0.46}
 46%|████▌     | 1730/3753 [2:18:58<2:23:19,  4.25s/it] 46%|████▌     | 1731/3753 [2:19:03<2:35:01,  4.60s/it] 46%|████▌     | 1732/3753 [2:19:09<2:42:25,  4.82s/it] 46%|████▌     | 1733/3753 [2:19:13<2:37:20,  4.67s/it] 46%|████▌     | 1734/3753 [2:19:16<2:17:53,  4.10s/it] 46%|████▌     | 1735/3753 [2:19:19<2:11:23,  3.91s/it] 46%|████▋     | 1736/3753 [2:19:23<2:06:52,  3.77s/it] 46%|████▋     | 1737/3753 [2:19:28<2:19:22,  4.15s/it] 46%|████▋     | 1738/3753 [2:19:33<2:28:15,  4.41s/it] 46%|████▋     | 1739/3753 [2:19:38<2:40:33,  4.78s/it] 46%|████▋     | 1740/3753 [2:19:42<2:33:41,  4.58s/it]{'loss': 44.3139, 'grad_norm': 3491.926513671875, 'learning_rate': 6.491016301189551e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.2323029041290283, 'weight_rejected': 4.143961429595947, 'kl_term_chosen': 4.160711765289307, 'kl_term_rejected': 4.016308784484863, 'epoch': 0.463690872751499}
                                                       {'loss': 44.3139, 'grad_norm': 3491.926513671875, 'learning_rate': 6.491016301189551e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.2323029041290283, 'weight_rejected': 4.143961429595947, 'kl_term_chosen': 4.160711765289307, 'kl_term_rejected': 4.016308784484863, 'epoch': 0.46}
 46%|████▋     | 1740/3753 [2:19:42<2:33:41,  4.58s/it] 46%|████▋     | 1741/3753 [2:19:47<2:29:28,  4.46s/it] 46%|████▋     | 1742/3753 [2:19:50<2:18:43,  4.14s/it] 46%|████▋     | 1743/3753 [2:19:54<2:17:47,  4.11s/it] 46%|████▋     | 1744/3753 [2:20:00<2:37:38,  4.71s/it] 46%|████▋     | 1745/3753 [2:20:04<2:30:22,  4.49s/it] 47%|████▋     | 1746/3753 [2:20:08<2:25:35,  4.35s/it] 47%|████▋     | 1747/3753 [2:20:11<2:08:33,  3.85s/it] 47%|████▋     | 1748/3753 [2:20:17<2:28:39,  4.45s/it] 47%|████▋     | 1749/3753 [2:20:21<2:23:36,  4.30s/it] 47%|████▋     | 1750/3753 [2:20:24<2:18:35,  4.15s/it]{'loss': 52.383, 'grad_norm': 0.0, 'learning_rate': 6.446554174233255e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.9077707529067993, 'weight_rejected': 4.220447063446045, 'kl_term_chosen': 1.4757072925567627, 'kl_term_rejected': 3.6770989894866943, 'epoch': 0.46635576282478347}
                                                       {'loss': 52.383, 'grad_norm': 0.0, 'learning_rate': 6.446554174233255e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.9077707529067993, 'weight_rejected': 4.220447063446045, 'kl_term_chosen': 1.4757072925567627, 'kl_term_rejected': 3.6770989894866943, 'epoch': 0.47}
 47%|████▋     | 1750/3753 [2:20:24<2:18:35,  4.15s/it] 47%|████▋     | 1751/3753 [2:20:28<2:11:47,  3.95s/it] 47%|████▋     | 1752/3753 [2:20:32<2:11:22,  3.94s/it] 47%|████▋     | 1753/3753 [2:20:36<2:11:42,  3.95s/it] 47%|████▋     | 1754/3753 [2:20:39<2:05:38,  3.77s/it] 47%|████▋     | 1755/3753 [2:20:45<2:22:11,  4.27s/it] 47%|████▋     | 1756/3753 [2:20:48<2:16:59,  4.12s/it] 47%|████▋     | 1757/3753 [2:20:53<2:19:35,  4.20s/it] 47%|████▋     | 1758/3753 [2:20:57<2:22:37,  4.29s/it] 47%|████▋     | 1759/3753 [2:21:02<2:26:17,  4.40s/it] 47%|████▋     | 1760/3753 [2:21:06<2:26:08,  4.40s/it]{'loss': 55.9107, 'grad_norm': 50.32435607910156, 'learning_rate': 6.401966857405119e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 4.12540340423584, 'weight_rejected': 8.935286521911621, 'kl_term_chosen': -3.206923007965088, 'kl_term_rejected': 8.857208251953125, 'epoch': 0.46902065289806794}
                                                       {'loss': 55.9107, 'grad_norm': 50.32435607910156, 'learning_rate': 6.401966857405119e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 4.12540340423584, 'weight_rejected': 8.935286521911621, 'kl_term_chosen': -3.206923007965088, 'kl_term_rejected': 8.857208251953125, 'epoch': 0.47}
 47%|████▋     | 1760/3753 [2:21:06<2:26:08,  4.40s/it] 47%|████▋     | 1761/3753 [2:21:10<2:16:25,  4.11s/it] 47%|████▋     | 1762/3753 [2:21:14<2:21:29,  4.26s/it] 47%|████▋     | 1763/3753 [2:21:18<2:15:53,  4.10s/it] 47%|████▋     | 1764/3753 [2:21:22<2:17:22,  4.14s/it] 47%|████▋     | 1765/3753 [2:21:26<2:08:54,  3.89s/it] 47%|████▋     | 1766/3753 [2:21:30<2:13:25,  4.03s/it] 47%|████▋     | 1767/3753 [2:21:36<2:29:14,  4.51s/it] 47%|████▋     | 1768/3753 [2:21:39<2:23:16,  4.33s/it] 47%|████▋     | 1769/3753 [2:21:43<2:17:19,  4.15s/it] 47%|████▋     | 1770/3753 [2:21:48<2:18:51,  4.20s/it]{'loss': 49.4616, 'grad_norm': 128.54161071777344, 'learning_rate': 6.357258209447929e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.5011165142059326, 'weight_rejected': 1.7510515451431274, 'kl_term_chosen': 3.3645081520080566, 'kl_term_rejected': 1.6097701787948608, 'epoch': 0.47168554297135246}
                                                       {'loss': 49.4616, 'grad_norm': 128.54161071777344, 'learning_rate': 6.357258209447929e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.5011165142059326, 'weight_rejected': 1.7510515451431274, 'kl_term_chosen': 3.3645081520080566, 'kl_term_rejected': 1.6097701787948608, 'epoch': 0.47}
 47%|████▋     | 1770/3753 [2:21:48<2:18:51,  4.20s/it] 47%|████▋     | 1771/3753 [2:21:51<2:15:11,  4.09s/it] 47%|████▋     | 1772/3753 [2:21:55<2:13:29,  4.04s/it] 47%|████▋     | 1773/3753 [2:22:00<2:19:52,  4.24s/it] 47%|████▋     | 1774/3753 [2:22:04<2:13:59,  4.06s/it] 47%|████▋     | 1775/3753 [2:22:07<2:11:25,  3.99s/it] 47%|████▋     | 1776/3753 [2:22:11<2:07:17,  3.86s/it] 47%|████▋     | 1777/3753 [2:22:15<2:08:13,  3.89s/it] 47%|████▋     | 1778/3753 [2:22:19<2:07:03,  3.86s/it] 47%|████▋     | 1779/3753 [2:22:23<2:07:34,  3.88s/it] 47%|████▋     | 1780/3753 [2:22:26<2:04:11,  3.78s/it]{'loss': 51.6202, 'grad_norm': 391.1537780761719, 'learning_rate': 6.312432099604884e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.42156267166137695, 'weight_rejected': 11.712311744689941, 'kl_term_chosen': 0.528106689453125, 'kl_term_rejected': 11.659692764282227, 'epoch': 0.4743504330446369}
                                                       {'loss': 51.6202, 'grad_norm': 391.1537780761719, 'learning_rate': 6.312432099604884e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.42156267166137695, 'weight_rejected': 11.712311744689941, 'kl_term_chosen': 0.528106689453125, 'kl_term_rejected': 11.659692764282227, 'epoch': 0.47}
 47%|████▋     | 1780/3753 [2:22:26<2:04:11,  3.78s/it] 47%|████▋     | 1781/3753 [2:22:31<2:16:34,  4.16s/it] 47%|████▋     | 1782/3753 [2:22:36<2:21:04,  4.29s/it] 48%|████▊     | 1783/3753 [2:22:45<3:07:47,  5.72s/it] 48%|████▊     | 1784/3753 [2:22:48<2:45:32,  5.04s/it] 48%|████▊     | 1785/3753 [2:22:52<2:28:38,  4.53s/it] 48%|████▊     | 1786/3753 [2:22:56<2:25:37,  4.44s/it] 48%|████▊     | 1787/3753 [2:23:00<2:24:10,  4.40s/it] 48%|████▊     | 1788/3753 [2:23:05<2:25:56,  4.46s/it] 48%|████▊     | 1789/3753 [2:23:10<2:37:08,  4.80s/it] 48%|████▊     | 1790/3753 [2:23:16<2:48:53,  5.16s/it]{'loss': 42.7956, 'grad_norm': 668.06005859375, 'learning_rate': 6.267492407284756e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -4.141696453094482, 'weight_rejected': -4.998955726623535, 'kl_term_chosen': 4.857914924621582, 'kl_term_rejected': -5.278784275054932, 'epoch': 0.4770153231179214}
                                                       {'loss': 42.7956, 'grad_norm': 668.06005859375, 'learning_rate': 6.267492407284756e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -4.141696453094482, 'weight_rejected': -4.998955726623535, 'kl_term_chosen': 4.857914924621582, 'kl_term_rejected': -5.278784275054932, 'epoch': 0.48}
 48%|████▊     | 1790/3753 [2:23:17<2:48:53,  5.16s/it] 48%|████▊     | 1791/3753 [2:23:20<2:35:55,  4.77s/it] 48%|████▊     | 1792/3753 [2:23:24<2:28:50,  4.55s/it] 48%|████▊     | 1793/3753 [2:23:28<2:17:07,  4.20s/it] 48%|████▊     | 1794/3753 [2:23:35<2:51:22,  5.25s/it] 48%|████▊     | 1795/3753 [2:23:39<2:32:44,  4.68s/it] 48%|████▊     | 1796/3753 [2:23:46<2:58:02,  5.46s/it] 48%|████▊     | 1797/3753 [2:23:51<2:48:36,  5.17s/it] 48%|████▊     | 1798/3753 [2:23:55<2:38:14,  4.86s/it] 48%|████▊     | 1799/3753 [2:23:59<2:37:11,  4.83s/it] 48%|████▊     | 1800/3753 [2:24:03<2:28:15,  4.55s/it]{'loss': 44.7268, 'grad_norm': 0.0, 'learning_rate': 6.222443021726136e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.354033470153809, 'weight_rejected': -1.2295109033584595, 'kl_term_chosen': -5.3113112449646, 'kl_term_rejected': -1.5245376825332642, 'epoch': 0.47968021319120585}
                                                       {'loss': 44.7268, 'grad_norm': 0.0, 'learning_rate': 6.222443021726136e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.354033470153809, 'weight_rejected': -1.2295109033584595, 'kl_term_chosen': -5.3113112449646, 'kl_term_rejected': -1.5245376825332642, 'epoch': 0.48}
 48%|████▊     | 1800/3753 [2:24:03<2:28:15,  4.55s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 48%|████▊     | 1801/3753 [2:25:02<11:15:54, 20.78s/it] 48%|████▊     | 1802/3753 [2:25:06<8:33:14, 15.78s/it]  48%|████▊     | 1803/3753 [2:25:11<6:45:17, 12.47s/it] 48%|████▊     | 1804/3753 [2:25:14<5:18:35,  9.81s/it] 48%|████▊     | 1805/3753 [2:25:19<4:24:02,  8.13s/it] 48%|████▊     | 1806/3753 [2:25:23<3:44:23,  6.92s/it] 48%|████▊     | 1807/3753 [2:25:27<3:15:05,  6.02s/it] 48%|████▊     | 1808/3753 [2:25:32<3:07:57,  5.80s/it] 48%|████▊     | 1809/3753 [2:25:36<2:51:40,  5.30s/it] 48%|████▊     | 1810/3753 [2:25:39<2:33:07,  4.73s/it]{'loss': 46.6027, 'grad_norm': 2005.0294189453125, 'learning_rate': 6.177287841660855e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -6.094499588012695, 'weight_rejected': -8.132577896118164, 'kl_term_chosen': 6.70912504196167, 'kl_term_rejected': -8.370508193969727, 'epoch': 0.4823451032644903}
                                                       {'loss': 46.6027, 'grad_norm': 2005.0294189453125, 'learning_rate': 6.177287841660855e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -6.094499588012695, 'weight_rejected': -8.132577896118164, 'kl_term_chosen': 6.70912504196167, 'kl_term_rejected': -8.370508193969727, 'epoch': 0.48}
 48%|████▊     | 1810/3753 [2:25:40<2:33:07,  4.73s/it] 48%|████▊     | 1811/3753 [2:25:43<2:24:33,  4.47s/it] 48%|████▊     | 1812/3753 [2:25:48<2:22:32,  4.41s/it] 48%|████▊     | 1813/3753 [2:25:51<2:13:51,  4.14s/it] 48%|████▊     | 1814/3753 [2:25:55<2:07:48,  3.95s/it] 48%|████▊     | 1815/3753 [2:25:58<2:05:41,  3.89s/it] 48%|████▊     | 1816/3753 [2:26:02<2:06:53,  3.93s/it] 48%|████▊     | 1817/3753 [2:26:07<2:13:16,  4.13s/it] 48%|████▊     | 1818/3753 [2:26:12<2:19:56,  4.34s/it] 48%|████▊     | 1819/3753 [2:26:16<2:18:25,  4.29s/it] 48%|████▊     | 1820/3753 [2:26:20<2:10:41,  4.06s/it]{'loss': 47.0928, 'grad_norm': 139.74871826171875, 'learning_rate': 6.132030774976575e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.9702012538909912, 'weight_rejected': -2.001298666000366, 'kl_term_chosen': -1.09356689453125, 'kl_term_rejected': -2.1315841674804688, 'epoch': 0.48500999333777484}
                                                       {'loss': 47.0928, 'grad_norm': 139.74871826171875, 'learning_rate': 6.132030774976575e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.9702012538909912, 'weight_rejected': -2.001298666000366, 'kl_term_chosen': -1.09356689453125, 'kl_term_rejected': -2.1315841674804688, 'epoch': 0.49}
 48%|████▊     | 1820/3753 [2:26:20<2:10:41,  4.06s/it] 49%|████▊     | 1821/3753 [2:26:24<2:16:08,  4.23s/it] 49%|████▊     | 1822/3753 [2:26:29<2:22:03,  4.41s/it] 49%|████▊     | 1823/3753 [2:26:34<2:23:17,  4.45s/it] 49%|████▊     | 1824/3753 [2:26:37<2:17:12,  4.27s/it] 49%|████▊     | 1825/3753 [2:26:43<2:32:43,  4.75s/it] 49%|████▊     | 1826/3753 [2:26:47<2:24:58,  4.51s/it] 49%|████▊     | 1827/3753 [2:26:53<2:34:57,  4.83s/it] 49%|████▊     | 1828/3753 [2:26:58<2:40:56,  5.02s/it] 49%|████▊     | 1829/3753 [2:27:02<2:33:05,  4.77s/it] 49%|████▉     | 1830/3753 [2:27:07<2:30:51,  4.71s/it]{'loss': 48.4118, 'grad_norm': 0.0, 'learning_rate': 6.086675738378576e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 10.830157279968262, 'weight_rejected': -6.655394554138184, 'kl_term_chosen': -10.820744514465332, 'kl_term_rejected': -7.51220703125, 'epoch': 0.4876748834110593}
                                                       {'loss': 48.4118, 'grad_norm': 0.0, 'learning_rate': 6.086675738378576e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 10.830157279968262, 'weight_rejected': -6.655394554138184, 'kl_term_chosen': -10.820744514465332, 'kl_term_rejected': -7.51220703125, 'epoch': 0.49}
 49%|████▉     | 1830/3753 [2:27:07<2:30:51,  4.71s/it] 49%|████▉     | 1831/3753 [2:27:11<2:23:21,  4.48s/it] 49%|████▉     | 1832/3753 [2:27:15<2:18:33,  4.33s/it] 49%|████▉     | 1833/3753 [2:27:19<2:19:30,  4.36s/it] 49%|████▉     | 1834/3753 [2:27:24<2:17:56,  4.31s/it] 49%|████▉     | 1835/3753 [2:27:28<2:14:20,  4.20s/it] 49%|████▉     | 1836/3753 [2:27:31<2:06:28,  3.96s/it] 49%|████▉     | 1837/3753 [2:27:34<2:00:10,  3.76s/it] 49%|████▉     | 1838/3753 [2:27:38<2:05:03,  3.92s/it] 49%|████▉     | 1839/3753 [2:27:43<2:11:46,  4.13s/it] 49%|████▉     | 1840/3753 [2:27:48<2:22:39,  4.47s/it]{'loss': 49.5513, 'grad_norm': 156.3123016357422, 'learning_rate': 6.041226657050803e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.0272483825683594, 'weight_rejected': -5.13052225112915, 'kl_term_chosen': 2.4559600353240967, 'kl_term_rejected': -5.32489013671875, 'epoch': 0.49033977348434377}
                                                       {'loss': 49.5513, 'grad_norm': 156.3123016357422, 'learning_rate': 6.041226657050803e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.0272483825683594, 'weight_rejected': -5.13052225112915, 'kl_term_chosen': 2.4559600353240967, 'kl_term_rejected': -5.32489013671875, 'epoch': 0.49}
 49%|████▉     | 1840/3753 [2:27:48<2:22:39,  4.47s/it] 49%|████▉     | 1841/3753 [2:27:52<2:17:36,  4.32s/it] 49%|████▉     | 1842/3753 [2:27:56<2:12:01,  4.15s/it] 49%|████▉     | 1843/3753 [2:28:00<2:07:06,  3.99s/it] 49%|████▉     | 1844/3753 [2:28:04<2:11:53,  4.15s/it] 49%|████▉     | 1845/3753 [2:28:09<2:13:10,  4.19s/it] 49%|████▉     | 1846/3753 [2:28:12<2:08:58,  4.06s/it] 49%|████▉     | 1847/3753 [2:28:16<2:03:46,  3.90s/it] 49%|████▉     | 1848/3753 [2:28:20<2:05:50,  3.96s/it] 49%|████▉     | 1849/3753 [2:28:24<2:06:07,  3.97s/it] 49%|████▉     | 1850/3753 [2:28:29<2:12:59,  4.19s/it]{'loss': 55.8867, 'grad_norm': 301.7406005859375, 'learning_rate': 5.995687464316163e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.7974743843078613, 'weight_rejected': -2.195906162261963, 'kl_term_chosen': -2.0884552001953125, 'kl_term_rejected': -2.409283399581909, 'epoch': 0.49300466355762823}
                                                       {'loss': 55.8867, 'grad_norm': 301.7406005859375, 'learning_rate': 5.995687464316163e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.7974743843078613, 'weight_rejected': -2.195906162261963, 'kl_term_chosen': -2.0884552001953125, 'kl_term_rejected': -2.409283399581909, 'epoch': 0.49}
 49%|████▉     | 1850/3753 [2:28:29<2:12:59,  4.19s/it] 49%|████▉     | 1851/3753 [2:28:33<2:12:39,  4.18s/it] 49%|████▉     | 1852/3753 [2:28:37<2:10:27,  4.12s/it] 49%|████▉     | 1853/3753 [2:28:41<2:08:30,  4.06s/it] 49%|████▉     | 1854/3753 [2:28:45<2:10:00,  4.11s/it] 49%|████▉     | 1855/3753 [2:28:49<2:08:38,  4.07s/it] 49%|████▉     | 1856/3753 [2:28:55<2:26:21,  4.63s/it] 49%|████▉     | 1857/3753 [2:29:00<2:29:34,  4.73s/it] 50%|████▉     | 1858/3753 [2:29:03<2:19:31,  4.42s/it] 50%|████▉     | 1859/3753 [2:29:07<2:09:00,  4.09s/it] 50%|████▉     | 1860/3753 [2:29:12<2:22:14,  4.51s/it]{'loss': 45.4563, 'grad_norm': 590.6791381835938, 'learning_rate': 5.950062101296117e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -6.246423244476318, 'weight_rejected': -4.25008487701416, 'kl_term_chosen': 6.6958160400390625, 'kl_term_rejected': -4.4325103759765625, 'epoch': 0.49566955363091275}
                                                       {'loss': 45.4563, 'grad_norm': 590.6791381835938, 'learning_rate': 5.950062101296117e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -6.246423244476318, 'weight_rejected': -4.25008487701416, 'kl_term_chosen': 6.6958160400390625, 'kl_term_rejected': -4.4325103759765625, 'epoch': 0.5}
 50%|████▉     | 1860/3753 [2:29:12<2:22:14,  4.51s/it] 50%|████▉     | 1861/3753 [2:29:21<3:02:46,  5.80s/it] 50%|████▉     | 1862/3753 [2:29:29<3:19:08,  6.32s/it] 50%|████▉     | 1863/3753 [2:29:33<3:01:08,  5.75s/it] 50%|████▉     | 1864/3753 [2:29:37<2:40:46,  5.11s/it] 50%|████▉     | 1865/3753 [2:29:41<2:31:35,  4.82s/it] 50%|████▉     | 1866/3753 [2:29:46<2:32:23,  4.85s/it] 50%|████▉     | 1867/3753 [2:29:51<2:41:22,  5.13s/it] 50%|████▉     | 1868/3753 [2:29:54<2:21:18,  4.50s/it] 50%|████▉     | 1869/3753 [2:29:58<2:13:30,  4.25s/it] 50%|████▉     | 1870/3753 [2:30:02<2:10:06,  4.15s/it]{'loss': 49.7474, 'grad_norm': 20.905324935913086, 'learning_rate': 5.904354516569605e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.973926544189453, 'weight_rejected': 3.8962249755859375, 'kl_term_chosen': 4.3332905769348145, 'kl_term_rejected': 3.3579697608947754, 'epoch': 0.4983344437041972}
                                                       {'loss': 49.7474, 'grad_norm': 20.905324935913086, 'learning_rate': 5.904354516569605e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.973926544189453, 'weight_rejected': 3.8962249755859375, 'kl_term_chosen': 4.3332905769348145, 'kl_term_rejected': 3.3579697608947754, 'epoch': 0.5}
 50%|████▉     | 1870/3753 [2:30:02<2:10:06,  4.15s/it] 50%|████▉     | 1871/3753 [2:30:06<2:09:41,  4.13s/it] 50%|████▉     | 1872/3753 [2:30:12<2:29:24,  4.77s/it] 50%|████▉     | 1873/3753 [2:30:16<2:13:59,  4.28s/it] 50%|████▉     | 1874/3753 [2:30:19<2:05:27,  4.01s/it] 50%|████▉     | 1875/3753 [2:30:24<2:15:06,  4.32s/it] 50%|████▉     | 1876/3753 [2:30:28<2:13:52,  4.28s/it] 50%|█████     | 1877/3753 [2:30:33<2:16:24,  4.36s/it] 50%|█████     | 1878/3753 [2:30:38<2:21:05,  4.51s/it] 50%|█████     | 1879/3753 [2:30:42<2:16:18,  4.36s/it] 50%|█████     | 1880/3753 [2:30:46<2:15:22,  4.34s/it]{'loss': 50.1753, 'grad_norm': 5463.50830078125, 'learning_rate': 5.858568665831324e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.8467795848846436, 'weight_chosen': 0.2354615330696106, 'weight_rejected': 0.23314398527145386, 'kl_term_chosen': 0.6084335446357727, 'kl_term_rejected': 0.10461883991956711, 'epoch': 0.5009993337774816}
                                                       {'loss': 50.1753, 'grad_norm': 5463.50830078125, 'learning_rate': 5.858568665831324e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.8467795848846436, 'weight_chosen': 0.2354615330696106, 'weight_rejected': 0.23314398527145386, 'kl_term_chosen': 0.6084335446357727, 'kl_term_rejected': 0.10461883991956711, 'epoch': 0.5}
 50%|█████     | 1880/3753 [2:30:46<2:15:22,  4.34s/it] 50%|█████     | 1881/3753 [2:30:52<2:32:19,  4.88s/it] 50%|█████     | 1882/3753 [2:30:55<2:16:51,  4.39s/it] 50%|█████     | 1883/3753 [2:31:00<2:18:11,  4.43s/it] 50%|█████     | 1884/3753 [2:31:05<2:24:07,  4.63s/it] 50%|█████     | 1885/3753 [2:31:09<2:20:15,  4.50s/it] 50%|█████     | 1886/3753 [2:31:13<2:13:39,  4.30s/it] 50%|█████     | 1887/3753 [2:31:17<2:07:52,  4.11s/it] 50%|█████     | 1888/3753 [2:31:20<2:05:56,  4.05s/it] 50%|█████     | 1889/3753 [2:31:24<2:03:55,  3.99s/it] 50%|█████     | 1890/3753 [2:31:28<2:04:43,  4.02s/it]{'loss': 56.3845, 'grad_norm': 921.3347778320312, 'learning_rate': 5.812708511549382e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.717429161071777, 'weight_rejected': 1.4288884401321411, 'kl_term_chosen': 6.400002956390381, 'kl_term_rejected': 1.19237220287323, 'epoch': 0.5036642238507661}
                                                       {'loss': 56.3845, 'grad_norm': 921.3347778320312, 'learning_rate': 5.812708511549382e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.717429161071777, 'weight_rejected': 1.4288884401321411, 'kl_term_chosen': 6.400002956390381, 'kl_term_rejected': 1.19237220287323, 'epoch': 0.5}
 50%|█████     | 1890/3753 [2:31:29<2:04:43,  4.02s/it] 50%|█████     | 1891/3753 [2:31:33<2:14:07,  4.32s/it] 50%|█████     | 1892/3753 [2:31:39<2:24:36,  4.66s/it] 50%|█████     | 1893/3753 [2:31:42<2:07:37,  4.12s/it] 50%|█████     | 1894/3753 [2:31:49<2:37:01,  5.07s/it] 50%|█████     | 1895/3753 [2:31:53<2:29:59,  4.84s/it] 51%|█████     | 1896/3753 [2:31:58<2:28:14,  4.79s/it] 51%|█████     | 1897/3753 [2:32:02<2:22:04,  4.59s/it] 51%|█████     | 1898/3753 [2:32:10<2:51:38,  5.55s/it] 51%|█████     | 1899/3753 [2:32:14<2:35:51,  5.04s/it] 51%|█████     | 1900/3753 [2:32:19<2:32:45,  4.95s/it]{'loss': 50.145, 'grad_norm': 6179.78955078125, 'learning_rate': 5.766778022622383e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.5624496936798096, 'weight_rejected': -2.590272903442383, 'kl_term_chosen': -1.8017990589141846, 'kl_term_rejected': -3.432098388671875, 'epoch': 0.5063291139240507}
                                                       {'loss': 50.145, 'grad_norm': 6179.78955078125, 'learning_rate': 5.766778022622383e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.5624496936798096, 'weight_rejected': -2.590272903442383, 'kl_term_chosen': -1.8017990589141846, 'kl_term_rejected': -3.432098388671875, 'epoch': 0.51}
 51%|█████     | 1900/3753 [2:32:19<2:32:45,  4.95s/it] 51%|█████     | 1901/3753 [2:32:22<2:19:44,  4.53s/it] 51%|█████     | 1902/3753 [2:32:26<2:11:38,  4.27s/it] 51%|█████     | 1903/3753 [2:32:29<2:05:50,  4.08s/it] 51%|█████     | 1904/3753 [2:32:33<1:59:39,  3.88s/it] 51%|█████     | 1905/3753 [2:32:36<1:54:01,  3.70s/it] 51%|█████     | 1906/3753 [2:32:41<2:01:44,  3.95s/it] 51%|█████     | 1907/3753 [2:32:45<2:02:20,  3.98s/it] 51%|█████     | 1908/3753 [2:32:48<1:58:12,  3.84s/it] 51%|█████     | 1909/3753 [2:32:52<1:59:19,  3.88s/it] 51%|█████     | 1910/3753 [2:32:57<2:07:22,  4.15s/it]{'loss': 49.0032, 'grad_norm': 169.30421447753906, 'learning_rate': 5.720781174035931e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -7.903149604797363, 'weight_rejected': -1.3316656351089478, 'kl_term_chosen': 8.458584785461426, 'kl_term_rejected': -1.8120224475860596, 'epoch': 0.5089940039973351}
                                                       {'loss': 49.0032, 'grad_norm': 169.30421447753906, 'learning_rate': 5.720781174035931e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -7.903149604797363, 'weight_rejected': -1.3316656351089478, 'kl_term_chosen': 8.458584785461426, 'kl_term_rejected': -1.8120224475860596, 'epoch': 0.51}
 51%|█████     | 1910/3753 [2:32:57<2:07:22,  4.15s/it] 51%|█████     | 1911/3753 [2:33:01<2:03:30,  4.02s/it] 51%|█████     | 1912/3753 [2:33:06<2:19:03,  4.53s/it] 51%|█████     | 1913/3753 [2:33:11<2:19:05,  4.54s/it] 51%|█████     | 1914/3753 [2:33:16<2:19:26,  4.55s/it] 51%|█████     | 1915/3753 [2:33:20<2:16:11,  4.45s/it] 51%|█████     | 1916/3753 [2:33:24<2:14:31,  4.39s/it] 51%|█████     | 1917/3753 [2:33:28<2:12:35,  4.33s/it] 51%|█████     | 1918/3753 [2:33:32<2:04:52,  4.08s/it] 51%|█████     | 1919/3753 [2:33:37<2:15:34,  4.44s/it] 51%|█████     | 1920/3753 [2:33:41<2:10:45,  4.28s/it]{'loss': 43.3892, 'grad_norm': 327.6064758300781, 'learning_rate': 5.674721946518631e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.478679358959198, 'weight_rejected': 1.1854759454727173, 'kl_term_chosen': 0.7355114221572876, 'kl_term_rejected': 0.46688157320022583, 'epoch': 0.5116588940706196}
                                                       {'loss': 43.3892, 'grad_norm': 327.6064758300781, 'learning_rate': 5.674721946518631e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.478679358959198, 'weight_rejected': 1.1854759454727173, 'kl_term_chosen': 0.7355114221572876, 'kl_term_rejected': 0.46688157320022583, 'epoch': 0.51}
 51%|█████     | 1920/3753 [2:33:41<2:10:45,  4.28s/it] 51%|█████     | 1921/3753 [2:33:45<2:12:33,  4.34s/it] 51%|█████     | 1922/3753 [2:33:49<2:08:51,  4.22s/it] 51%|█████     | 1923/3753 [2:33:54<2:09:22,  4.24s/it] 51%|█████▏    | 1924/3753 [2:33:58<2:14:13,  4.40s/it] 51%|█████▏    | 1925/3753 [2:34:03<2:18:25,  4.54s/it] 51%|█████▏    | 1926/3753 [2:34:08<2:17:32,  4.52s/it] 51%|█████▏    | 1927/3753 [2:34:12<2:14:19,  4.41s/it] 51%|█████▏    | 1928/3753 [2:34:17<2:24:51,  4.76s/it] 51%|█████▏    | 1929/3753 [2:34:22<2:19:06,  4.58s/it] 51%|█████▏    | 1930/3753 [2:34:25<2:12:51,  4.37s/it]{'loss': 44.6494, 'grad_norm': 0.0, 'learning_rate': 5.628604326197582e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -6.326519966125488, 'weight_rejected': -0.4203782081604004, 'kl_term_chosen': 7.129693508148193, 'kl_term_rejected': -0.7540985345840454, 'epoch': 0.5143237841439041}
                                                       {'loss': 44.6494, 'grad_norm': 0.0, 'learning_rate': 5.628604326197582e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -6.326519966125488, 'weight_rejected': -0.4203782081604004, 'kl_term_chosen': 7.129693508148193, 'kl_term_rejected': -0.7540985345840454, 'epoch': 0.51}
 51%|█████▏    | 1930/3753 [2:34:26<2:12:51,  4.37s/it] 51%|█████▏    | 1931/3753 [2:34:31<2:19:01,  4.58s/it] 51%|█████▏    | 1932/3753 [2:34:35<2:19:28,  4.60s/it] 52%|█████▏    | 1933/3753 [2:34:39<2:14:42,  4.44s/it] 52%|█████▏    | 1934/3753 [2:34:44<2:15:37,  4.47s/it] 52%|█████▏    | 1935/3753 [2:34:49<2:19:42,  4.61s/it] 52%|█████▏    | 1936/3753 [2:34:53<2:20:20,  4.63s/it] 52%|█████▏    | 1937/3753 [2:34:58<2:20:51,  4.65s/it] 52%|█████▏    | 1938/3753 [2:35:03<2:21:36,  4.68s/it] 52%|█████▏    | 1939/3753 [2:35:08<2:23:45,  4.76s/it] 52%|█████▏    | 1940/3753 [2:35:11<2:10:16,  4.31s/it]{'loss': 42.6659, 'grad_norm': 8.727914810180664, 'learning_rate': 5.582432304253394e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.0231716632843018, 'weight_rejected': -1.0701297521591187, 'kl_term_chosen': -0.252706915140152, 'kl_term_rejected': -1.2808960676193237, 'epoch': 0.5169886742171885}
                                                       {'loss': 42.6659, 'grad_norm': 8.727914810180664, 'learning_rate': 5.582432304253394e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.0231716632843018, 'weight_rejected': -1.0701297521591187, 'kl_term_chosen': -0.252706915140152, 'kl_term_rejected': -1.2808960676193237, 'epoch': 0.52}
 52%|█████▏    | 1940/3753 [2:35:11<2:10:16,  4.31s/it] 52%|█████▏    | 1941/3753 [2:35:15<2:06:04,  4.17s/it] 52%|█████▏    | 1942/3753 [2:35:20<2:12:55,  4.40s/it] 52%|█████▏    | 1943/3753 [2:35:25<2:16:42,  4.53s/it] 52%|█████▏    | 1944/3753 [2:35:28<2:06:52,  4.21s/it] 52%|█████▏    | 1945/3753 [2:35:33<2:14:30,  4.46s/it] 52%|█████▏    | 1946/3753 [2:35:38<2:16:59,  4.55s/it] 52%|█████▏    | 1947/3753 [2:35:42<2:12:09,  4.39s/it] 52%|█████▏    | 1948/3753 [2:35:46<2:04:33,  4.14s/it] 52%|█████▏    | 1949/3753 [2:35:50<2:05:38,  4.18s/it] 52%|█████▏    | 1950/3753 [2:35:54<2:06:07,  4.20s/it]{'loss': 43.2105, 'grad_norm': 146.18917846679688, 'learning_rate': 5.536209876574792e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.7181130051612854, 'weight_rejected': -3.875545024871826, 'kl_term_chosen': 1.6354156732559204, 'kl_term_rejected': -4.035810947418213, 'epoch': 0.519653564290473}
                                                       {'loss': 43.2105, 'grad_norm': 146.18917846679688, 'learning_rate': 5.536209876574792e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.7181130051612854, 'weight_rejected': -3.875545024871826, 'kl_term_chosen': 1.6354156732559204, 'kl_term_rejected': -4.035810947418213, 'epoch': 0.52}
 52%|█████▏    | 1950/3753 [2:35:54<2:06:07,  4.20s/it] 52%|█████▏    | 1951/3753 [2:35:58<2:01:58,  4.06s/it] 52%|█████▏    | 1952/3753 [2:36:01<1:56:51,  3.89s/it] 52%|█████▏    | 1953/3753 [2:36:06<2:07:06,  4.24s/it] 52%|█████▏    | 1954/3753 [2:36:11<2:08:08,  4.27s/it] 52%|█████▏    | 1955/3753 [2:36:15<2:12:19,  4.42s/it] 52%|█████▏    | 1956/3753 [2:36:20<2:10:08,  4.35s/it] 52%|█████▏    | 1957/3753 [2:36:24<2:09:33,  4.33s/it] 52%|█████▏    | 1958/3753 [2:36:28<2:11:30,  4.40s/it] 52%|█████▏    | 1959/3753 [2:36:33<2:15:03,  4.52s/it] 52%|█████▏    | 1960/3753 [2:36:37<2:05:55,  4.21s/it]{'loss': 49.286, 'grad_norm': 0.0, 'learning_rate': 5.489941043412783e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.148087501525879, 'weight_rejected': 1.1435010433197021, 'kl_term_chosen': 9.112408638000488, 'kl_term_rejected': 1.0860077142715454, 'epoch': 0.5223184543637575}
                                                       {'loss': 49.286, 'grad_norm': 0.0, 'learning_rate': 5.489941043412783e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.148087501525879, 'weight_rejected': 1.1435010433197021, 'kl_term_chosen': 9.112408638000488, 'kl_term_rejected': 1.0860077142715454, 'epoch': 0.52}
 52%|█████▏    | 1960/3753 [2:36:37<2:05:55,  4.21s/it] 52%|█████▏    | 1961/3753 [2:36:41<2:04:36,  4.17s/it] 52%|█████▏    | 1962/3753 [2:36:46<2:16:26,  4.57s/it] 52%|█████▏    | 1963/3753 [2:36:49<2:01:58,  4.09s/it] 52%|█████▏    | 1964/3753 [2:36:53<2:02:17,  4.10s/it] 52%|█████▏    | 1965/3753 [2:36:58<2:06:11,  4.23s/it] 52%|█████▏    | 1966/3753 [2:37:02<2:01:46,  4.09s/it] 52%|█████▏    | 1967/3753 [2:37:06<1:59:26,  4.01s/it] 52%|█████▏    | 1968/3753 [2:37:09<1:58:44,  3.99s/it] 52%|█████▏    | 1969/3753 [2:37:13<1:55:33,  3.89s/it] 52%|█████▏    | 1970/3753 [2:37:18<2:07:04,  4.28s/it]{'loss': 43.9497, 'grad_norm': 1725.05126953125, 'learning_rate': 5.443629809034473e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -7.31428861618042, 'weight_rejected': -1.2828943729400635, 'kl_term_chosen': 8.198328018188477, 'kl_term_rejected': -1.3587524890899658, 'epoch': 0.524983344437042}
                                                       {'loss': 43.9497, 'grad_norm': 1725.05126953125, 'learning_rate': 5.443629809034473e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -7.31428861618042, 'weight_rejected': -1.2828943729400635, 'kl_term_chosen': 8.198328018188477, 'kl_term_rejected': -1.3587524890899658, 'epoch': 0.52}
 52%|█████▏    | 1970/3753 [2:37:18<2:07:04,  4.28s/it] 53%|█████▎    | 1971/3753 [2:37:25<2:25:16,  4.89s/it] 53%|█████▎    | 1972/3753 [2:37:29<2:20:28,  4.73s/it] 53%|█████▎    | 1973/3753 [2:37:35<2:27:28,  4.97s/it] 53%|█████▎    | 1974/3753 [2:37:39<2:25:33,  4.91s/it] 53%|█████▎    | 1975/3753 [2:37:44<2:19:32,  4.71s/it] 53%|█████▎    | 1976/3753 [2:37:48<2:21:14,  4.77s/it] 53%|█████▎    | 1977/3753 [2:37:52<2:13:00,  4.49s/it] 53%|█████▎    | 1978/3753 [2:37:56<2:03:52,  4.19s/it] 53%|█████▎    | 1979/3753 [2:38:00<2:08:25,  4.34s/it] 53%|█████▎    | 1980/3753 [2:38:04<1:58:41,  4.02s/it]{'loss': 44.294, 'grad_norm': 3293.05712890625, 'learning_rate': 5.397280181376514e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.018200576305389404, 'weight_rejected': 1.0387873649597168, 'kl_term_chosen': 0.5124008059501648, 'kl_term_rejected': 0.5591617822647095, 'epoch': 0.5276482345103265}
                                                       {'loss': 44.294, 'grad_norm': 3293.05712890625, 'learning_rate': 5.397280181376514e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.018200576305389404, 'weight_rejected': 1.0387873649597168, 'kl_term_chosen': 0.5124008059501648, 'kl_term_rejected': 0.5591617822647095, 'epoch': 0.53}
 53%|█████▎    | 1980/3753 [2:38:04<1:58:41,  4.02s/it] 53%|█████▎    | 1981/3753 [2:38:09<2:09:01,  4.37s/it] 53%|█████▎    | 1982/3753 [2:38:13<2:06:05,  4.27s/it] 53%|█████▎    | 1983/3753 [2:38:17<2:07:47,  4.33s/it] 53%|█████▎    | 1984/3753 [2:38:22<2:06:37,  4.30s/it] 53%|█████▎    | 1985/3753 [2:38:26<2:04:21,  4.22s/it] 53%|█████▎    | 1986/3753 [2:38:30<2:01:10,  4.11s/it] 53%|█████▎    | 1987/3753 [2:38:34<2:03:41,  4.20s/it] 53%|█████▎    | 1988/3753 [2:38:37<1:55:42,  3.93s/it] 53%|█████▎    | 1989/3753 [2:38:42<2:05:11,  4.26s/it] 53%|█████▎    | 1990/3753 [2:38:46<1:59:58,  4.08s/it]{'loss': 46.2622, 'grad_norm': 0.0, 'learning_rate': 5.350896171698253e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.720920085906982, 'weight_rejected': 3.0891785621643066, 'kl_term_chosen': 8.382843017578125, 'kl_term_rejected': 2.9779374599456787, 'epoch': 0.5303131245836109}
                                                       {'loss': 46.2622, 'grad_norm': 0.0, 'learning_rate': 5.350896171698253e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.720920085906982, 'weight_rejected': 3.0891785621643066, 'kl_term_chosen': 8.382843017578125, 'kl_term_rejected': 2.9779374599456787, 'epoch': 0.53}
 53%|█████▎    | 1990/3753 [2:38:46<1:59:58,  4.08s/it] 53%|█████▎    | 1991/3753 [2:38:50<1:58:17,  4.03s/it] 53%|█████▎    | 1992/3753 [2:38:55<2:04:52,  4.25s/it] 53%|█████▎    | 1993/3753 [2:38:59<2:07:18,  4.34s/it] 53%|█████▎    | 1994/3753 [2:39:04<2:10:10,  4.44s/it] 53%|█████▎    | 1995/3753 [2:39:08<2:04:03,  4.23s/it] 53%|█████▎    | 1996/3753 [2:39:16<2:39:47,  5.46s/it] 53%|█████▎    | 1997/3753 [2:39:20<2:27:49,  5.05s/it] 53%|█████▎    | 1998/3753 [2:39:23<2:09:52,  4.44s/it] 53%|█████▎    | 1999/3753 [2:39:26<2:00:47,  4.13s/it] 53%|█████▎    | 2000/3753 [2:39:34<2:30:45,  5.16s/it]{'loss': 45.5112, 'grad_norm': 680.2344970703125, 'learning_rate': 5.304481794234569e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.095691442489624, 'weight_rejected': -4.250179767608643, 'kl_term_chosen': 3.0319764614105225, 'kl_term_rejected': -4.302798748016357, 'epoch': 0.5329780146568954}
                                                       {'loss': 45.5112, 'grad_norm': 680.2344970703125, 'learning_rate': 5.304481794234569e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.095691442489624, 'weight_rejected': -4.250179767608643, 'kl_term_chosen': 3.0319764614105225, 'kl_term_rejected': -4.302798748016357, 'epoch': 0.53}
 53%|█████▎    | 2000/3753 [2:39:34<2:30:45,  5.16s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 53%|█████▎    | 2001/3753 [2:40:33<10:24:57, 21.40s/it] 53%|█████▎    | 2002/3753 [2:40:37<7:51:57, 16.17s/it]  53%|█████▎    | 2003/3753 [2:40:41<5:58:25, 12.29s/it] 53%|█████▎    | 2004/3753 [2:40:44<4:43:32,  9.73s/it] 53%|█████▎    | 2005/3753 [2:40:48<3:55:12,  8.07s/it] 53%|█████▎    | 2006/3753 [2:40:53<3:19:57,  6.87s/it] 53%|█████▎    | 2007/3753 [2:40:57<2:56:22,  6.06s/it] 54%|█████▎    | 2008/3753 [2:41:00<2:29:30,  5.14s/it] 54%|█████▎    | 2009/3753 [2:41:05<2:28:18,  5.10s/it] 54%|█████▎    | 2010/3753 [2:41:09<2:21:05,  4.86s/it]{'loss': 36.1065, 'grad_norm': 1524.6549072265625, 'learning_rate': 5.258041065848482e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.4046792685985565, 'weight_rejected': -1.5279574394226074, 'kl_term_chosen': 0.43294069170951843, 'kl_term_rejected': -1.6769927740097046, 'epoch': 0.5356429047301798}
                                                       {'loss': 36.1065, 'grad_norm': 1524.6549072265625, 'learning_rate': 5.258041065848482e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.4046792685985565, 'weight_rejected': -1.5279574394226074, 'kl_term_chosen': 0.43294069170951843, 'kl_term_rejected': -1.6769927740097046, 'epoch': 0.54}
 54%|█████▎    | 2010/3753 [2:41:09<2:21:05,  4.86s/it] 54%|█████▎    | 2011/3753 [2:41:14<2:22:13,  4.90s/it] 54%|█████▎    | 2012/3753 [2:41:18<2:12:31,  4.57s/it] 54%|█████▎    | 2013/3753 [2:41:22<2:11:50,  4.55s/it] 54%|█████▎    | 2014/3753 [2:41:27<2:17:21,  4.74s/it] 54%|█████▎    | 2015/3753 [2:41:32<2:11:45,  4.55s/it] 54%|█████▎    | 2016/3753 [2:41:35<2:01:47,  4.21s/it] 54%|█████▎    | 2017/3753 [2:41:39<2:03:01,  4.25s/it] 54%|█████▍    | 2018/3753 [2:41:43<1:56:28,  4.03s/it] 54%|█████▍    | 2019/3753 [2:41:50<2:27:41,  5.11s/it] 54%|█████▍    | 2020/3753 [2:41:54<2:13:33,  4.62s/it]{'loss': 40.2155, 'grad_norm': 1397.7794189453125, 'learning_rate': 5.211578005683511e-07, 'mean_ratio_chosen': 0.3631056547164917, 'mean_ratio_rejected': 8.630776405334473, 'weight_chosen': 1.050223469734192, 'weight_rejected': 0.2643912434577942, 'kl_term_chosen': -0.10130615532398224, 'kl_term_rejected': 0.21553345024585724, 'epoch': 0.5383077948034644}
                                                       {'loss': 40.2155, 'grad_norm': 1397.7794189453125, 'learning_rate': 5.211578005683511e-07, 'mean_ratio_chosen': 0.3631056547164917, 'mean_ratio_rejected': 8.630776405334473, 'weight_chosen': 1.050223469734192, 'weight_rejected': 0.2643912434577942, 'kl_term_chosen': -0.10130615532398224, 'kl_term_rejected': 0.21553345024585724, 'epoch': 0.54}
 54%|█████▍    | 2020/3753 [2:41:54<2:13:33,  4.62s/it] 54%|█████▍    | 2021/3753 [2:41:59<2:20:35,  4.87s/it] 54%|█████▍    | 2022/3753 [2:42:03<2:08:32,  4.46s/it] 54%|█████▍    | 2023/3753 [2:42:07<2:03:53,  4.30s/it] 54%|█████▍    | 2024/3753 [2:42:12<2:09:51,  4.51s/it] 54%|█████▍    | 2025/3753 [2:42:16<2:04:19,  4.32s/it] 54%|█████▍    | 2026/3753 [2:42:19<1:58:10,  4.11s/it] 54%|█████▍    | 2027/3753 [2:42:23<1:52:21,  3.91s/it] 54%|█████▍    | 2028/3753 [2:42:27<1:57:49,  4.10s/it] 54%|█████▍    | 2029/3753 [2:42:32<2:06:57,  4.42s/it] 54%|█████▍    | 2030/3753 [2:42:36<1:56:43,  4.06s/it]{'loss': 32.4471, 'grad_norm': 472.4791564941406, 'learning_rate': 5.165096634815846e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.5697027444839478, 'weight_rejected': 8.04914665222168, 'kl_term_chosen': 1.348352074623108, 'kl_term_rejected': 7.964047431945801, 'epoch': 0.5409726848767489}
                                                       {'loss': 32.4471, 'grad_norm': 472.4791564941406, 'learning_rate': 5.165096634815846e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.5697027444839478, 'weight_rejected': 8.04914665222168, 'kl_term_chosen': 1.348352074623108, 'kl_term_rejected': 7.964047431945801, 'epoch': 0.54}
 54%|█████▍    | 2030/3753 [2:42:36<1:56:43,  4.06s/it] 54%|█████▍    | 2031/3753 [2:42:40<2:01:53,  4.25s/it] 54%|█████▍    | 2032/3753 [2:42:45<2:03:02,  4.29s/it] 54%|█████▍    | 2033/3753 [2:42:51<2:17:40,  4.80s/it] 54%|█████▍    | 2034/3753 [2:42:56<2:18:41,  4.84s/it] 54%|█████▍    | 2035/3753 [2:43:01<2:19:14,  4.86s/it] 54%|█████▍    | 2036/3753 [2:43:10<2:58:00,  6.22s/it] 54%|█████▍    | 2037/3753 [2:43:15<2:43:58,  5.73s/it] 54%|█████▍    | 2038/3753 [2:43:19<2:36:34,  5.48s/it] 54%|█████▍    | 2039/3753 [2:43:24<2:28:22,  5.19s/it] 54%|█████▍    | 2040/3753 [2:43:29<2:23:23,  5.02s/it]{'loss': 41.9622, 'grad_norm': 424.3674011230469, 'learning_rate': 5.118600975906348e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.357816219329834, 'weight_rejected': 7.325066566467285, 'kl_term_chosen': -0.9481231570243835, 'kl_term_rejected': 6.753777980804443, 'epoch': 0.5436375749500333}
                                                       {'loss': 41.9622, 'grad_norm': 424.3674011230469, 'learning_rate': 5.118600975906348e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.357816219329834, 'weight_rejected': 7.325066566467285, 'kl_term_chosen': -0.9481231570243835, 'kl_term_rejected': 6.753777980804443, 'epoch': 0.54}
 54%|█████▍    | 2040/3753 [2:43:29<2:23:23,  5.02s/it] 54%|█████▍    | 2041/3753 [2:43:34<2:28:11,  5.19s/it] 54%|█████▍    | 2042/3753 [2:43:38<2:13:50,  4.69s/it] 54%|█████▍    | 2043/3753 [2:43:46<2:45:04,  5.79s/it] 54%|█████▍    | 2044/3753 [2:43:51<2:34:39,  5.43s/it] 54%|█████▍    | 2045/3753 [2:43:55<2:28:44,  5.23s/it] 55%|█████▍    | 2046/3753 [2:44:05<3:03:30,  6.45s/it] 55%|█████▍    | 2047/3753 [2:44:09<2:44:02,  5.77s/it] 55%|█████▍    | 2048/3753 [2:44:13<2:27:34,  5.19s/it] 55%|█████▍    | 2049/3753 [2:44:18<2:24:14,  5.08s/it] 55%|█████▍    | 2050/3753 [2:44:22<2:16:29,  4.81s/it]{'loss': 40.7127, 'grad_norm': 901.325927734375, 'learning_rate': 5.072095052852418e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.7740610241889954, 'weight_rejected': -1.0597070455551147, 'kl_term_chosen': 1.7319732904434204, 'kl_term_rejected': -1.1024292707443237, 'epoch': 0.5463024650233178}
                                                       {'loss': 40.7127, 'grad_norm': 901.325927734375, 'learning_rate': 5.072095052852418e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.7740610241889954, 'weight_rejected': -1.0597070455551147, 'kl_term_chosen': 1.7319732904434204, 'kl_term_rejected': -1.1024292707443237, 'epoch': 0.55}
 55%|█████▍    | 2050/3753 [2:44:22<2:16:29,  4.81s/it] 55%|█████▍    | 2051/3753 [2:44:26<2:07:31,  4.50s/it] 55%|█████▍    | 2052/3753 [2:44:31<2:13:59,  4.73s/it] 55%|█████▍    | 2053/3753 [2:44:38<2:36:32,  5.53s/it] 55%|█████▍    | 2054/3753 [2:44:41<2:17:31,  4.86s/it] 55%|█████▍    | 2055/3753 [2:44:45<2:06:46,  4.48s/it] 55%|█████▍    | 2056/3753 [2:44:50<2:07:44,  4.52s/it] 55%|█████▍    | 2057/3753 [2:44:53<2:00:40,  4.27s/it] 55%|█████▍    | 2058/3753 [2:44:56<1:50:08,  3.90s/it] 55%|█████▍    | 2059/3753 [2:45:01<1:56:35,  4.13s/it] 55%|█████▍    | 2060/3753 [2:45:07<2:13:30,  4.73s/it]{'loss': 40.0378, 'grad_norm': 312.54071044921875, 'learning_rate': 5.025582890439752e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.7482002377510071, 'weight_rejected': 2.739445686340332, 'kl_term_chosen': -0.256500244140625, 'kl_term_rejected': 1.8594712018966675, 'epoch': 0.5489673550966022}
                                                       {'loss': 40.0378, 'grad_norm': 312.54071044921875, 'learning_rate': 5.025582890439752e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.7482002377510071, 'weight_rejected': 2.739445686340332, 'kl_term_chosen': -0.256500244140625, 'kl_term_rejected': 1.8594712018966675, 'epoch': 0.55}
 55%|█████▍    | 2060/3753 [2:45:07<2:13:30,  4.73s/it] 55%|█████▍    | 2061/3753 [2:45:11<2:09:22,  4.59s/it] 55%|█████▍    | 2062/3753 [2:45:16<2:06:54,  4.50s/it] 55%|█████▍    | 2063/3753 [2:45:20<2:02:43,  4.36s/it] 55%|█████▍    | 2064/3753 [2:45:24<2:05:21,  4.45s/it] 55%|█████▌    | 2065/3753 [2:45:28<1:54:40,  4.08s/it] 55%|█████▌    | 2066/3753 [2:45:32<1:53:10,  4.03s/it] 55%|█████▌    | 2067/3753 [2:45:37<2:02:26,  4.36s/it] 55%|█████▌    | 2068/3753 [2:45:40<1:53:29,  4.04s/it] 55%|█████▌    | 2069/3753 [2:45:49<2:34:29,  5.50s/it] 55%|█████▌    | 2070/3753 [2:45:54<2:28:45,  5.30s/it]{'loss': 42.0728, 'grad_norm': 242.6260528564453, 'learning_rate': 4.979068513994016e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 3.3611788749694824, 'weight_rejected': 7.72831392288208, 'kl_term_chosen': -2.5948853492736816, 'kl_term_rejected': 7.193701267242432, 'epoch': 0.5516322451698867}
                                                       {'loss': 42.0728, 'grad_norm': 242.6260528564453, 'learning_rate': 4.979068513994016e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 3.3611788749694824, 'weight_rejected': 7.72831392288208, 'kl_term_chosen': -2.5948853492736816, 'kl_term_rejected': 7.193701267242432, 'epoch': 0.55}
 55%|█████▌    | 2070/3753 [2:45:54<2:28:45,  5.30s/it] 55%|█████▌    | 2071/3753 [2:45:57<2:13:03,  4.75s/it] 55%|█████▌    | 2072/3753 [2:46:03<2:19:59,  5.00s/it] 55%|█████▌    | 2073/3753 [2:46:07<2:11:19,  4.69s/it] 55%|█████▌    | 2074/3753 [2:46:10<2:01:41,  4.35s/it] 55%|█████▌    | 2075/3753 [2:46:15<2:03:14,  4.41s/it] 55%|█████▌    | 2076/3753 [2:46:19<1:58:02,  4.22s/it] 55%|█████▌    | 2077/3753 [2:46:22<1:47:08,  3.84s/it] 55%|█████▌    | 2078/3753 [2:46:25<1:47:17,  3.84s/it] 55%|█████▌    | 2079/3753 [2:46:30<1:49:49,  3.94s/it] 55%|█████▌    | 2080/3753 [2:46:39<2:33:24,  5.50s/it]{'loss': 47.5687, 'grad_norm': 799.1834106445312, 'learning_rate': 4.932555949032494e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.4078528881072998, 'weight_rejected': 2.4599106311798096, 'kl_term_chosen': 1.6071609258651733, 'kl_term_rejected': 1.6222906112670898, 'epoch': 0.5542971352431713}
                                                       {'loss': 47.5687, 'grad_norm': 799.1834106445312, 'learning_rate': 4.932555949032494e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.4078528881072998, 'weight_rejected': 2.4599106311798096, 'kl_term_chosen': 1.6071609258651733, 'kl_term_rejected': 1.6222906112670898, 'epoch': 0.55}
 55%|█████▌    | 2080/3753 [2:46:39<2:33:24,  5.50s/it] 55%|█████▌    | 2081/3753 [2:46:44<2:27:47,  5.30s/it] 55%|█████▌    | 2082/3753 [2:46:47<2:13:47,  4.80s/it] 56%|█████▌    | 2083/3753 [2:46:53<2:22:55,  5.14s/it] 56%|█████▌    | 2084/3753 [2:46:58<2:18:45,  4.99s/it] 56%|█████▌    | 2085/3753 [2:47:03<2:18:45,  4.99s/it] 56%|█████▌    | 2086/3753 [2:47:07<2:10:11,  4.69s/it] 56%|█████▌    | 2087/3753 [2:47:11<2:02:19,  4.41s/it] 56%|█████▌    | 2088/3753 [2:47:17<2:16:03,  4.90s/it] 56%|█████▌    | 2089/3753 [2:47:22<2:19:24,  5.03s/it] 56%|█████▌    | 2090/3753 [2:47:28<2:30:58,  5.45s/it]{'loss': 45.7596, 'grad_norm': 1600.655517578125, 'learning_rate': 4.886049220915695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.429997205734253, 'weight_rejected': -4.143309116363525, 'kl_term_chosen': -1.7645866870880127, 'kl_term_rejected': -4.39129638671875, 'epoch': 0.5569620253164557}
                                                       {'loss': 45.7596, 'grad_norm': 1600.655517578125, 'learning_rate': 4.886049220915695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.429997205734253, 'weight_rejected': -4.143309116363525, 'kl_term_chosen': -1.7645866870880127, 'kl_term_rejected': -4.39129638671875, 'epoch': 0.56}
 56%|█████▌    | 2090/3753 [2:47:28<2:30:58,  5.45s/it] 56%|█████▌    | 2091/3753 [2:47:33<2:25:48,  5.26s/it] 56%|█████▌    | 2092/3753 [2:47:37<2:17:10,  4.96s/it] 56%|█████▌    | 2093/3753 [2:47:44<2:26:56,  5.31s/it] 56%|█████▌    | 2094/3753 [2:47:48<2:19:08,  5.03s/it] 56%|█████▌    | 2095/3753 [2:47:52<2:12:14,  4.79s/it] 56%|█████▌    | 2096/3753 [2:47:56<2:07:32,  4.62s/it] 56%|█████▌    | 2097/3753 [2:48:01<2:06:52,  4.60s/it] 56%|█████▌    | 2098/3753 [2:48:06<2:11:15,  4.76s/it] 56%|█████▌    | 2099/3753 [2:48:10<2:03:02,  4.46s/it] 56%|█████▌    | 2100/3753 [2:48:15<2:07:26,  4.63s/it]{'loss': 52.589, 'grad_norm': 126.66941833496094, 'learning_rate': 4.839552354498985e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.835405349731445, 'weight_rejected': 2.504694938659668, 'kl_term_chosen': 8.62071418762207, 'kl_term_rejected': 2.414602041244507, 'epoch': 0.5596269153897402}
                                                       {'loss': 52.589, 'grad_norm': 126.66941833496094, 'learning_rate': 4.839552354498985e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.835405349731445, 'weight_rejected': 2.504694938659668, 'kl_term_chosen': 8.62071418762207, 'kl_term_rejected': 2.414602041244507, 'epoch': 0.56}
 56%|█████▌    | 2100/3753 [2:48:15<2:07:26,  4.63s/it] 56%|█████▌    | 2101/3753 [2:48:20<2:13:16,  4.84s/it] 56%|█████▌    | 2102/3753 [2:48:25<2:11:57,  4.80s/it] 56%|█████▌    | 2103/3753 [2:48:28<1:55:31,  4.20s/it] 56%|█████▌    | 2104/3753 [2:48:31<1:48:41,  3.95s/it] 56%|█████▌    | 2105/3753 [2:48:35<1:50:01,  4.01s/it] 56%|█████▌    | 2106/3753 [2:48:43<2:20:17,  5.11s/it] 56%|█████▌    | 2107/3753 [2:48:47<2:15:35,  4.94s/it] 56%|█████▌    | 2108/3753 [2:48:54<2:27:13,  5.37s/it] 56%|█████▌    | 2109/3753 [2:48:57<2:13:11,  4.86s/it] 56%|█████▌    | 2110/3753 [2:49:05<2:34:53,  5.66s/it]{'loss': 47.6801, 'grad_norm': 0.0, 'learning_rate': 4.793069373784266e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.425130844116211, 'weight_rejected': -3.921929359436035, 'kl_term_chosen': -4.607556343078613, 'kl_term_rejected': -4.282193183898926, 'epoch': 0.5622918054630246}
                                                       {'loss': 47.6801, 'grad_norm': 0.0, 'learning_rate': 4.793069373784266e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.425130844116211, 'weight_rejected': -3.921929359436035, 'kl_term_chosen': -4.607556343078613, 'kl_term_rejected': -4.282193183898926, 'epoch': 0.56}
 56%|█████▌    | 2110/3753 [2:49:05<2:34:53,  5.66s/it] 56%|█████▌    | 2111/3753 [2:49:10<2:26:25,  5.35s/it] 56%|█████▋    | 2112/3753 [2:49:14<2:16:54,  5.01s/it] 56%|█████▋    | 2113/3753 [2:49:18<2:11:10,  4.80s/it] 56%|█████▋    | 2114/3753 [2:49:23<2:07:59,  4.69s/it] 56%|█████▋    | 2115/3753 [2:49:27<2:09:46,  4.75s/it] 56%|█████▋    | 2116/3753 [2:49:31<1:58:31,  4.34s/it] 56%|█████▋    | 2117/3753 [2:49:36<2:01:17,  4.45s/it] 56%|█████▋    | 2118/3753 [2:49:40<1:57:37,  4.32s/it] 56%|█████▋    | 2119/3753 [2:49:44<2:00:12,  4.41s/it] 56%|█████▋    | 2120/3753 [2:49:47<1:50:32,  4.06s/it]{'loss': 45.0761, 'grad_norm': 0.0, 'learning_rate': 4.7466043015717217e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.5409343242645264, 'weight_rejected': 0.408328652381897, 'kl_term_chosen': 1.4913452863693237, 'kl_term_rejected': 0.36297607421875, 'epoch': 0.5649566955363091}
                                                       {'loss': 45.0761, 'grad_norm': 0.0, 'learning_rate': 4.7466043015717217e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.5409343242645264, 'weight_rejected': 0.408328652381897, 'kl_term_chosen': 1.4913452863693237, 'kl_term_rejected': 0.36297607421875, 'epoch': 0.56}
 56%|█████▋    | 2120/3753 [2:49:48<1:50:32,  4.06s/it] 57%|█████▋    | 2121/3753 [2:49:51<1:43:28,  3.80s/it] 57%|█████▋    | 2122/3753 [2:49:55<1:49:55,  4.04s/it] 57%|█████▋    | 2123/3753 [2:49:59<1:45:58,  3.90s/it] 57%|█████▋    | 2124/3753 [2:50:03<1:46:43,  3.93s/it] 57%|█████▋    | 2125/3753 [2:50:07<1:47:11,  3.95s/it] 57%|█████▋    | 2126/3753 [2:50:11<1:49:11,  4.03s/it] 57%|█████▋    | 2127/3753 [2:50:14<1:44:51,  3.87s/it] 57%|█████▋    | 2128/3753 [2:50:20<1:59:01,  4.39s/it] 57%|█████▋    | 2129/3753 [2:50:26<2:13:06,  4.92s/it] 57%|█████▋    | 2130/3753 [2:50:30<2:03:50,  4.58s/it]{'loss': 49.4319, 'grad_norm': 0.0, 'learning_rate': 4.70016115911167e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.926025629043579, 'weight_rejected': -0.3620269298553467, 'kl_term_chosen': -2.2243125438690186, 'kl_term_rejected': -0.9710861444473267, 'epoch': 0.5676215856095936}
                                                       {'loss': 49.4319, 'grad_norm': 0.0, 'learning_rate': 4.70016115911167e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.926025629043579, 'weight_rejected': -0.3620269298553467, 'kl_term_chosen': -2.2243125438690186, 'kl_term_rejected': -0.9710861444473267, 'epoch': 0.57}
 57%|█████▋    | 2130/3753 [2:50:30<2:03:50,  4.58s/it] 57%|█████▋    | 2131/3753 [2:50:35<2:04:15,  4.60s/it] 57%|█████▋    | 2132/3753 [2:50:38<1:57:07,  4.34s/it] 57%|█████▋    | 2133/3753 [2:50:42<1:52:22,  4.16s/it] 57%|█████▋    | 2134/3753 [2:50:46<1:47:30,  3.98s/it] 57%|█████▋    | 2135/3753 [2:50:51<1:57:36,  4.36s/it] 57%|█████▋    | 2136/3753 [2:50:56<2:01:13,  4.50s/it] 57%|█████▋    | 2137/3753 [2:51:00<2:01:54,  4.53s/it] 57%|█████▋    | 2138/3753 [2:51:04<1:57:11,  4.35s/it] 57%|█████▋    | 2139/3753 [2:51:11<2:19:38,  5.19s/it] 57%|█████▋    | 2140/3753 [2:51:17<2:21:11,  5.25s/it]{'loss': 49.1737, 'grad_norm': 913.1941528320312, 'learning_rate': 4.653743965756556e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.5094857215881348, 'weight_rejected': 2.493546485900879, 'kl_term_chosen': 2.7294929027557373, 'kl_term_rejected': 2.1718735694885254, 'epoch': 0.570286475682878}
                                                       {'loss': 49.1737, 'grad_norm': 913.1941528320312, 'learning_rate': 4.653743965756556e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.5094857215881348, 'weight_rejected': 2.493546485900879, 'kl_term_chosen': 2.7294929027557373, 'kl_term_rejected': 2.1718735694885254, 'epoch': 0.57}
 57%|█████▋    | 2140/3753 [2:51:17<2:21:11,  5.25s/it] 57%|█████▋    | 2141/3753 [2:51:21<2:09:38,  4.83s/it] 57%|█████▋    | 2142/3753 [2:51:24<1:57:09,  4.36s/it] 57%|█████▋    | 2143/3753 [2:51:29<2:01:38,  4.53s/it] 57%|█████▋    | 2144/3753 [2:51:32<1:52:09,  4.18s/it] 57%|█████▋    | 2145/3753 [2:51:36<1:49:13,  4.08s/it] 57%|█████▋    | 2146/3753 [2:51:41<1:51:42,  4.17s/it] 57%|█████▋    | 2147/3753 [2:51:46<2:01:43,  4.55s/it] 57%|█████▋    | 2148/3753 [2:51:50<1:57:47,  4.40s/it] 57%|█████▋    | 2149/3753 [2:51:55<1:59:27,  4.47s/it] 57%|█████▋    | 2150/3753 [2:51:58<1:50:02,  4.12s/it]{'loss': 52.5179, 'grad_norm': 0.0, 'learning_rate': 4.607356738613095e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.9785758256912231, 'weight_rejected': 11.122016906738281, 'kl_term_chosen': 1.847402572631836, 'kl_term_rejected': 10.92764949798584, 'epoch': 0.5729513657561626}
                                                       {'loss': 52.5179, 'grad_norm': 0.0, 'learning_rate': 4.607356738613095e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.9785758256912231, 'weight_rejected': 11.122016906738281, 'kl_term_chosen': 1.847402572631836, 'kl_term_rejected': 10.92764949798584, 'epoch': 0.57}
 57%|█████▋    | 2150/3753 [2:51:58<1:50:02,  4.12s/it] 57%|█████▋    | 2151/3753 [2:52:01<1:44:55,  3.93s/it] 57%|█████▋    | 2152/3753 [2:52:07<1:54:12,  4.28s/it] 57%|█████▋    | 2153/3753 [2:52:10<1:45:15,  3.95s/it] 57%|█████▋    | 2154/3753 [2:52:14<1:47:01,  4.02s/it] 57%|█████▋    | 2155/3753 [2:52:18<1:45:53,  3.98s/it] 57%|█████▋    | 2156/3753 [2:52:22<1:45:20,  3.96s/it] 57%|█████▋    | 2157/3753 [2:52:25<1:43:59,  3.91s/it] 58%|█████▊    | 2158/3753 [2:52:31<1:59:06,  4.48s/it] 58%|█████▊    | 2159/3753 [2:52:40<2:34:52,  5.83s/it] 58%|█████▊    | 2160/3753 [2:52:44<2:19:09,  5.24s/it]{'loss': 50.684, 'grad_norm': 227.60317993164062, 'learning_rate': 4.561003492194618e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.6535683274269104, 'weight_chosen': -1.1503074169158936, 'weight_rejected': 0.6332337856292725, 'kl_term_chosen': 1.5922211408615112, 'kl_term_rejected': -0.04253082349896431, 'epoch': 0.5756162558294471}
                                                       {'loss': 50.684, 'grad_norm': 227.60317993164062, 'learning_rate': 4.561003492194618e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.6535683274269104, 'weight_chosen': -1.1503074169158936, 'weight_rejected': 0.6332337856292725, 'kl_term_chosen': 1.5922211408615112, 'kl_term_rejected': -0.04253082349896431, 'epoch': 0.58}
 58%|█████▊    | 2160/3753 [2:52:44<2:19:09,  5.24s/it] 58%|█████▊    | 2161/3753 [2:52:48<2:11:43,  4.96s/it] 58%|█████▊    | 2162/3753 [2:52:53<2:07:53,  4.82s/it] 58%|█████▊    | 2163/3753 [2:52:57<2:04:08,  4.68s/it] 58%|█████▊    | 2164/3753 [2:53:01<1:57:11,  4.43s/it] 58%|█████▊    | 2165/3753 [2:53:06<2:03:46,  4.68s/it] 58%|█████▊    | 2166/3753 [2:53:11<2:06:09,  4.77s/it] 58%|█████▊    | 2167/3753 [2:53:15<1:54:35,  4.33s/it] 58%|█████▊    | 2168/3753 [2:53:20<2:06:07,  4.77s/it] 58%|█████▊    | 2169/3753 [2:53:24<1:58:14,  4.48s/it] 58%|█████▊    | 2170/3753 [2:53:28<1:54:56,  4.36s/it]{'loss': 51.096, 'grad_norm': 679.3115844726562, 'learning_rate': 4.5146882380736504e-07, 'mean_ratio_chosen': 2.967984199523926, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.831125020980835, 'weight_rejected': 1.4434324502944946, 'kl_term_chosen': 0.10878830403089523, 'kl_term_rejected': 1.3411277532577515, 'epoch': 0.5782811459027315}
                                                       {'loss': 51.096, 'grad_norm': 679.3115844726562, 'learning_rate': 4.5146882380736504e-07, 'mean_ratio_chosen': 2.967984199523926, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.831125020980835, 'weight_rejected': 1.4434324502944946, 'kl_term_chosen': 0.10878830403089523, 'kl_term_rejected': 1.3411277532577515, 'epoch': 0.58}
 58%|█████▊    | 2170/3753 [2:53:28<1:54:56,  4.36s/it] 58%|█████▊    | 2171/3753 [2:53:32<1:47:54,  4.09s/it] 58%|█████▊    | 2172/3753 [2:53:36<1:47:46,  4.09s/it] 58%|█████▊    | 2173/3753 [2:53:40<1:49:18,  4.15s/it] 58%|█████▊    | 2174/3753 [2:53:45<1:57:34,  4.47s/it] 58%|█████▊    | 2175/3753 [2:53:51<2:03:24,  4.69s/it] 58%|█████▊    | 2176/3753 [2:53:55<1:57:18,  4.46s/it] 58%|█████▊    | 2177/3753 [2:53:59<1:54:20,  4.35s/it] 58%|█████▊    | 2178/3753 [2:54:07<2:27:38,  5.62s/it] 58%|█████▊    | 2179/3753 [2:54:12<2:23:53,  5.49s/it] 58%|█████▊    | 2180/3753 [2:54:16<2:12:24,  5.05s/it]{'loss': 46.6501, 'grad_norm': 27.50867462158203, 'learning_rate': 4.468414984534727e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.39911651611328125, 'weight_rejected': 2.95810604095459, 'kl_term_chosen': 0.5728759765625, 'kl_term_rejected': 2.927891492843628, 'epoch': 0.580946035976016}
                                                       {'loss': 46.6501, 'grad_norm': 27.50867462158203, 'learning_rate': 4.468414984534727e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.39911651611328125, 'weight_rejected': 2.95810604095459, 'kl_term_chosen': 0.5728759765625, 'kl_term_rejected': 2.927891492843628, 'epoch': 0.58}
 58%|█████▊    | 2180/3753 [2:54:17<2:12:24,  5.05s/it] 58%|█████▊    | 2181/3753 [2:54:20<1:58:37,  4.53s/it] 58%|█████▊    | 2182/3753 [2:54:24<1:59:38,  4.57s/it] 58%|█████▊    | 2183/3753 [2:54:28<1:54:31,  4.38s/it] 58%|█████▊    | 2184/3753 [2:54:36<2:21:35,  5.41s/it] 58%|█████▊    | 2185/3753 [2:54:41<2:13:13,  5.10s/it] 58%|█████▊    | 2186/3753 [2:54:46<2:16:00,  5.21s/it] 58%|█████▊    | 2187/3753 [2:54:49<2:01:04,  4.64s/it] 58%|█████▊    | 2188/3753 [2:54:53<1:50:02,  4.22s/it] 58%|█████▊    | 2189/3753 [2:54:57<1:49:00,  4.18s/it] 58%|█████▊    | 2190/3753 [2:55:01<1:50:30,  4.24s/it]{'loss': 49.1126, 'grad_norm': 2062.69482421875, 'learning_rate': 4.422187736227509e-07, 'mean_ratio_chosen': 2.8009769916534424, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.793254554271698, 'weight_rejected': 6.8882246017456055, 'kl_term_chosen': 0.102996826171875, 'kl_term_rejected': 6.838635444641113, 'epoch': 0.5836109260493004}
                                                       {'loss': 49.1126, 'grad_norm': 2062.69482421875, 'learning_rate': 4.422187736227509e-07, 'mean_ratio_chosen': 2.8009769916534424, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.793254554271698, 'weight_rejected': 6.8882246017456055, 'kl_term_chosen': 0.102996826171875, 'kl_term_rejected': 6.838635444641113, 'epoch': 0.58}
 58%|█████▊    | 2190/3753 [2:55:01<1:50:30,  4.24s/it] 58%|█████▊    | 2191/3753 [2:55:06<1:57:44,  4.52s/it] 58%|█████▊    | 2192/3753 [2:55:12<2:11:23,  5.05s/it] 58%|█████▊    | 2193/3753 [2:55:17<2:07:29,  4.90s/it] 58%|█████▊    | 2194/3753 [2:55:21<1:58:35,  4.56s/it] 58%|█████▊    | 2195/3753 [2:55:27<2:12:08,  5.09s/it] 59%|█████▊    | 2196/3753 [2:55:31<2:04:54,  4.81s/it] 59%|█████▊    | 2197/3753 [2:55:36<2:02:47,  4.73s/it] 59%|█████▊    | 2198/3753 [2:55:40<1:56:08,  4.48s/it] 59%|█████▊    | 2199/3753 [2:55:44<1:57:44,  4.55s/it] 59%|█████▊    | 2200/3753 [2:55:48<1:52:50,  4.36s/it]{'loss': 42.7746, 'grad_norm': 1181.549560546875, 'learning_rate': 4.376010493820198e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.0078978538513184, 'weight_rejected': -3.2679271697998047, 'kl_term_chosen': -2.40958571434021, 'kl_term_rejected': -3.363276720046997, 'epoch': 0.586275816122585}
                                                       {'loss': 42.7746, 'grad_norm': 1181.549560546875, 'learning_rate': 4.376010493820198e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.0078978538513184, 'weight_rejected': -3.2679271697998047, 'kl_term_chosen': -2.40958571434021, 'kl_term_rejected': -3.363276720046997, 'epoch': 0.59}
 59%|█████▊    | 2200/3753 [2:55:48<1:52:50,  4.36s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 59%|█████▊    | 2201/3753 [2:56:47<8:50:56, 20.53s/it] 59%|█████▊    | 2202/3753 [2:56:53<6:59:29, 16.23s/it] 59%|█████▊    | 2203/3753 [2:57:01<5:55:41, 13.77s/it] 59%|█████▊    | 2204/3753 [2:57:06<4:45:38, 11.06s/it] 59%|█████▉    | 2205/3753 [2:57:10<3:53:21,  9.04s/it] 59%|█████▉    | 2206/3753 [2:57:14<3:12:54,  7.48s/it] 59%|█████▉    | 2207/3753 [2:57:18<2:44:42,  6.39s/it] 59%|█████▉    | 2208/3753 [2:57:22<2:27:05,  5.71s/it] 59%|█████▉    | 2209/3753 [2:57:26<2:14:05,  5.21s/it] 59%|█████▉    | 2210/3753 [2:57:30<2:06:42,  4.93s/it]{'loss': 44.6137, 'grad_norm': 374.89544677734375, 'learning_rate': 4.329887253653315e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.9010639190673828, 'weight_rejected': 7.951552391052246, 'kl_term_chosen': -1.0385963916778564, 'kl_term_rejected': 7.783789157867432, 'epoch': 0.5889407061958695}
                                                       {'loss': 44.6137, 'grad_norm': 374.89544677734375, 'learning_rate': 4.329887253653315e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.9010639190673828, 'weight_rejected': 7.951552391052246, 'kl_term_chosen': -1.0385963916778564, 'kl_term_rejected': 7.783789157867432, 'epoch': 0.59}
 59%|█████▉    | 2210/3753 [2:57:30<2:06:42,  4.93s/it] 59%|█████▉    | 2211/3753 [2:57:38<2:31:58,  5.91s/it] 59%|█████▉    | 2212/3753 [2:57:43<2:22:50,  5.56s/it] 59%|█████▉    | 2213/3753 [2:57:47<2:10:18,  5.08s/it] 59%|█████▉    | 2214/3753 [2:57:51<2:06:07,  4.92s/it] 59%|█████▉    | 2215/3753 [2:57:56<2:00:09,  4.69s/it] 59%|█████▉    | 2216/3753 [2:58:00<1:59:54,  4.68s/it] 59%|█████▉    | 2217/3753 [2:58:05<2:01:11,  4.73s/it] 59%|█████▉    | 2218/3753 [2:58:10<2:01:29,  4.75s/it] 59%|█████▉    | 2219/3753 [2:58:14<1:53:29,  4.44s/it] 59%|█████▉    | 2220/3753 [2:58:19<1:57:35,  4.60s/it]{'loss': 47.183, 'grad_norm': 518.8101196289062, 'learning_rate': 4.2838220073938323e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.2915260791778564, 'weight_rejected': -1.2491443157196045, 'kl_term_chosen': -1.4560425281524658, 'kl_term_rejected': -1.3558349609375, 'epoch': 0.5916055962691539}
                                                       {'loss': 47.183, 'grad_norm': 518.8101196289062, 'learning_rate': 4.2838220073938323e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.2915260791778564, 'weight_rejected': -1.2491443157196045, 'kl_term_chosen': -1.4560425281524658, 'kl_term_rejected': -1.3558349609375, 'epoch': 0.59}
 59%|█████▉    | 2220/3753 [2:58:19<1:57:35,  4.60s/it] 59%|█████▉    | 2221/3753 [2:58:23<1:56:08,  4.55s/it] 59%|█████▉    | 2222/3753 [2:58:28<1:56:52,  4.58s/it] 59%|█████▉    | 2223/3753 [2:58:32<1:51:58,  4.39s/it] 59%|█████▉    | 2224/3753 [2:58:35<1:41:30,  3.98s/it] 59%|█████▉    | 2225/3753 [2:58:38<1:37:53,  3.84s/it] 59%|█████▉    | 2226/3753 [2:58:43<1:47:35,  4.23s/it] 59%|█████▉    | 2227/3753 [2:58:47<1:43:13,  4.06s/it] 59%|█████▉    | 2228/3753 [2:58:51<1:41:01,  3.98s/it] 59%|█████▉    | 2229/3753 [2:58:55<1:43:41,  4.08s/it] 59%|█████▉    | 2230/3753 [2:59:01<1:54:48,  4.52s/it]{'loss': 41.0647, 'grad_norm': 202.3640594482422, 'learning_rate': 4.2378187416897325e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.17471283674240112, 'weight_rejected': 1.111539363861084, 'kl_term_chosen': 0.35467225313186646, 'kl_term_rejected': 0.5788711905479431, 'epoch': 0.5942704863424384}
                                                       {'loss': 41.0647, 'grad_norm': 202.3640594482422, 'learning_rate': 4.2378187416897325e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.17471283674240112, 'weight_rejected': 1.111539363861084, 'kl_term_chosen': 0.35467225313186646, 'kl_term_rejected': 0.5788711905479431, 'epoch': 0.59}
 59%|█████▉    | 2230/3753 [2:59:01<1:54:48,  4.52s/it] 59%|█████▉    | 2231/3753 [2:59:05<1:52:29,  4.43s/it] 59%|█████▉    | 2232/3753 [2:59:08<1:43:48,  4.10s/it] 59%|█████▉    | 2233/3753 [2:59:12<1:39:02,  3.91s/it] 60%|█████▉    | 2234/3753 [2:59:15<1:38:05,  3.87s/it] 60%|█████▉    | 2235/3753 [2:59:19<1:35:08,  3.76s/it] 60%|█████▉    | 2236/3753 [2:59:23<1:38:02,  3.88s/it] 60%|█████▉    | 2237/3753 [2:59:27<1:36:42,  3.83s/it] 60%|█████▉    | 2238/3753 [2:59:31<1:39:29,  3.94s/it] 60%|█████▉    | 2239/3753 [2:59:35<1:38:07,  3.89s/it] 60%|█████▉    | 2240/3753 [2:59:40<1:48:08,  4.29s/it]{'loss': 40.6706, 'grad_norm': 95.63660430908203, 'learning_rate': 4.191881437824978e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.19523507356643677, 'weight_rejected': 7.45850944519043, 'kl_term_chosen': 0.6980743408203125, 'kl_term_rejected': 7.351819038391113, 'epoch': 0.5969353764157228}
                                                       {'loss': 40.6706, 'grad_norm': 95.63660430908203, 'learning_rate': 4.191881437824978e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.19523507356643677, 'weight_rejected': 7.45850944519043, 'kl_term_chosen': 0.6980743408203125, 'kl_term_rejected': 7.351819038391113, 'epoch': 0.6}
 60%|█████▉    | 2240/3753 [2:59:40<1:48:08,  4.29s/it] 60%|█████▉    | 2241/3753 [2:59:44<1:45:53,  4.20s/it] 60%|█████▉    | 2242/3753 [2:59:47<1:39:24,  3.95s/it] 60%|█████▉    | 2243/3753 [2:59:51<1:38:58,  3.93s/it] 60%|█████▉    | 2244/3753 [2:59:56<1:46:19,  4.23s/it] 60%|█████▉    | 2245/3753 [3:00:01<1:52:13,  4.47s/it] 60%|█████▉    | 2246/3753 [3:00:05<1:43:31,  4.12s/it] 60%|█████▉    | 2247/3753 [3:00:09<1:43:15,  4.11s/it] 60%|█████▉    | 2248/3753 [3:00:14<1:53:59,  4.54s/it] 60%|█████▉    | 2249/3753 [3:00:19<1:55:29,  4.61s/it] 60%|█████▉    | 2250/3753 [3:00:23<1:52:25,  4.49s/it]{'loss': 45.9494, 'grad_norm': 0.0, 'learning_rate': 4.146014071374963e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.653873443603516, 'weight_rejected': -1.9956176280975342, 'kl_term_chosen': -4.769834041595459, 'kl_term_rejected': -2.165573835372925, 'epoch': 0.5996002664890073}
                                                       {'loss': 45.9494, 'grad_norm': 0.0, 'learning_rate': 4.146014071374963e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.653873443603516, 'weight_rejected': -1.9956176280975342, 'kl_term_chosen': -4.769834041595459, 'kl_term_rejected': -2.165573835372925, 'epoch': 0.6}
 60%|█████▉    | 2250/3753 [3:00:23<1:52:25,  4.49s/it] 60%|█████▉    | 2251/3753 [3:00:27<1:47:54,  4.31s/it] 60%|██████    | 2252/3753 [3:00:30<1:40:36,  4.02s/it] 60%|██████    | 2253/3753 [3:00:36<1:50:47,  4.43s/it] 60%|██████    | 2254/3753 [3:00:40<1:49:08,  4.37s/it] 60%|██████    | 2255/3753 [3:00:43<1:38:24,  3.94s/it] 60%|██████    | 2256/3753 [3:00:47<1:38:32,  3.95s/it] 60%|██████    | 2257/3753 [3:00:51<1:36:32,  3.87s/it] 60%|██████    | 2258/3753 [3:00:54<1:36:16,  3.86s/it] 60%|██████    | 2259/3753 [3:00:58<1:35:11,  3.82s/it] 60%|██████    | 2260/3753 [3:01:02<1:34:21,  3.79s/it]{'loss': 42.5889, 'grad_norm': 8.913995742797852, 'learning_rate': 4.1002206118624584e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -5.237987995147705, 'weight_rejected': -7.757188320159912, 'kl_term_chosen': 5.861364841461182, 'kl_term_rejected': -8.049783706665039, 'epoch': 0.6022651565622918}
                                                       {'loss': 42.5889, 'grad_norm': 8.913995742797852, 'learning_rate': 4.1002206118624584e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -5.237987995147705, 'weight_rejected': -7.757188320159912, 'kl_term_chosen': 5.861364841461182, 'kl_term_rejected': -8.049783706665039, 'epoch': 0.6}
 60%|██████    | 2260/3753 [3:01:02<1:34:21,  3.79s/it] 60%|██████    | 2261/3753 [3:01:06<1:33:15,  3.75s/it] 60%|██████    | 2262/3753 [3:01:10<1:40:25,  4.04s/it] 60%|██████    | 2263/3753 [3:01:15<1:46:06,  4.27s/it] 60%|██████    | 2264/3753 [3:01:19<1:41:56,  4.11s/it] 60%|██████    | 2265/3753 [3:01:23<1:46:19,  4.29s/it] 60%|██████    | 2266/3753 [3:01:27<1:42:58,  4.15s/it] 60%|██████    | 2267/3753 [3:01:32<1:46:34,  4.30s/it] 60%|██████    | 2268/3753 [3:01:36<1:46:01,  4.28s/it] 60%|██████    | 2269/3753 [3:01:40<1:42:08,  4.13s/it] 60%|██████    | 2270/3753 [3:01:44<1:41:27,  4.10s/it]{'loss': 41.7919, 'grad_norm': 3313.188720703125, 'learning_rate': 4.054505022414061e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.89898681640625, 'weight_rejected': -5.763071537017822, 'kl_term_chosen': -3.225795030593872, 'kl_term_rejected': -6.350541591644287, 'epoch': 0.6049300466355763}
                                                       {'loss': 41.7919, 'grad_norm': 3313.188720703125, 'learning_rate': 4.054505022414061e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.89898681640625, 'weight_rejected': -5.763071537017822, 'kl_term_chosen': -3.225795030593872, 'kl_term_rejected': -6.350541591644287, 'epoch': 0.6}
 60%|██████    | 2270/3753 [3:01:44<1:41:27,  4.10s/it] 61%|██████    | 2271/3753 [3:01:48<1:42:51,  4.16s/it] 61%|██████    | 2272/3753 [3:01:53<1:44:06,  4.22s/it] 61%|██████    | 2273/3753 [3:01:57<1:43:36,  4.20s/it] 61%|██████    | 2274/3753 [3:02:01<1:41:38,  4.12s/it] 61%|██████    | 2275/3753 [3:02:05<1:41:49,  4.13s/it] 61%|██████    | 2276/3753 [3:02:12<2:05:04,  5.08s/it] 61%|██████    | 2277/3753 [3:02:16<1:53:42,  4.62s/it] 61%|██████    | 2278/3753 [3:02:21<1:54:17,  4.65s/it] 61%|██████    | 2279/3753 [3:02:27<2:10:17,  5.30s/it] 61%|██████    | 2280/3753 [3:02:32<2:02:42,  5.00s/it]{'loss': 41.227, 'grad_norm': 0.0, 'learning_rate': 4.0088712594172264e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.4147051274776459, 'weight_rejected': 9.099595069885254, 'kl_term_chosen': 0.4602294862270355, 'kl_term_rejected': 8.913647651672363, 'epoch': 0.6075949367088608}
                                                       {'loss': 41.227, 'grad_norm': 0.0, 'learning_rate': 4.0088712594172264e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.4147051274776459, 'weight_rejected': 9.099595069885254, 'kl_term_chosen': 0.4602294862270355, 'kl_term_rejected': 8.913647651672363, 'epoch': 0.61}
 61%|██████    | 2280/3753 [3:02:32<2:02:42,  5.00s/it] 61%|██████    | 2281/3753 [3:02:36<1:56:18,  4.74s/it] 61%|██████    | 2282/3753 [3:02:40<1:49:26,  4.46s/it] 61%|██████    | 2283/3753 [3:02:44<1:49:32,  4.47s/it] 61%|██████    | 2284/3753 [3:02:49<1:52:45,  4.61s/it] 61%|██████    | 2285/3753 [3:02:53<1:46:25,  4.35s/it] 61%|██████    | 2286/3753 [3:02:56<1:39:34,  4.07s/it] 61%|██████    | 2287/3753 [3:03:00<1:36:07,  3.93s/it] 61%|██████    | 2288/3753 [3:03:03<1:30:08,  3.69s/it] 61%|██████    | 2289/3753 [3:03:07<1:30:54,  3.73s/it] 61%|██████    | 2290/3753 [3:03:10<1:30:30,  3.71s/it]{'loss': 39.9866, 'grad_norm': 911.6397705078125, 'learning_rate': 3.9633232721778554e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.395438194274902, 'weight_rejected': 1.3315703868865967, 'kl_term_chosen': 8.055610656738281, 'kl_term_rejected': 1.059545874595642, 'epoch': 0.6102598267821452}
                                                       {'loss': 39.9866, 'grad_norm': 911.6397705078125, 'learning_rate': 3.9633232721778554e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.395438194274902, 'weight_rejected': 1.3315703868865967, 'kl_term_chosen': 8.055610656738281, 'kl_term_rejected': 1.059545874595642, 'epoch': 0.61}
 61%|██████    | 2290/3753 [3:03:10<1:30:30,  3.71s/it] 61%|██████    | 2291/3753 [3:03:18<2:01:21,  4.98s/it] 61%|██████    | 2292/3753 [3:03:23<1:56:39,  4.79s/it] 61%|██████    | 2293/3753 [3:03:27<1:49:46,  4.51s/it] 61%|██████    | 2294/3753 [3:03:31<1:48:10,  4.45s/it] 61%|██████    | 2295/3753 [3:03:35<1:48:07,  4.45s/it] 61%|██████    | 2296/3753 [3:03:40<1:48:02,  4.45s/it] 61%|██████    | 2297/3753 [3:03:43<1:38:36,  4.06s/it] 61%|██████    | 2298/3753 [3:03:47<1:41:37,  4.19s/it] 61%|██████▏   | 2299/3753 [3:03:52<1:45:34,  4.36s/it] 61%|██████▏   | 2300/3753 [3:03:56<1:39:39,  4.12s/it]{'loss': 37.2175, 'grad_norm': 1122.5819091796875, 'learning_rate': 3.91786500257852e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.776604175567627, 'weight_rejected': -3.1353089809417725, 'kl_term_chosen': -4.90252685546875, 'kl_term_rejected': -3.3236329555511475, 'epoch': 0.6129247168554297}
                                                       {'loss': 37.2175, 'grad_norm': 1122.5819091796875, 'learning_rate': 3.91786500257852e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.776604175567627, 'weight_rejected': -3.1353089809417725, 'kl_term_chosen': -4.90252685546875, 'kl_term_rejected': -3.3236329555511475, 'epoch': 0.61}
 61%|██████▏   | 2300/3753 [3:03:56<1:39:39,  4.12s/it] 61%|██████▏   | 2301/3753 [3:04:02<1:54:33,  4.73s/it] 61%|██████▏   | 2302/3753 [3:04:07<1:59:40,  4.95s/it] 61%|██████▏   | 2303/3753 [3:04:14<2:10:11,  5.39s/it] 61%|██████▏   | 2304/3753 [3:04:17<1:55:14,  4.77s/it] 61%|██████▏   | 2305/3753 [3:04:21<1:50:10,  4.57s/it] 61%|██████▏   | 2306/3753 [3:04:25<1:42:45,  4.26s/it] 61%|██████▏   | 2307/3753 [3:04:29<1:44:22,  4.33s/it] 61%|██████▏   | 2308/3753 [3:04:33<1:41:37,  4.22s/it] 62%|██████▏   | 2309/3753 [3:04:39<1:50:47,  4.60s/it] 62%|██████▏   | 2310/3753 [3:04:44<1:53:59,  4.74s/it]{'loss': 43.584, 'grad_norm': 19.38088607788086, 'learning_rate': 3.8725003847373087e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.1809217929840088, 'weight_rejected': -2.3320648670196533, 'kl_term_chosen': -1.094598412513733, 'kl_term_rejected': -3.2120392322540283, 'epoch': 0.6155896069287142}
                                                       {'loss': 43.584, 'grad_norm': 19.38088607788086, 'learning_rate': 3.8725003847373087e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.1809217929840088, 'weight_rejected': -2.3320648670196533, 'kl_term_chosen': -1.094598412513733, 'kl_term_rejected': -3.2120392322540283, 'epoch': 0.62}
 62%|██████▏   | 2310/3753 [3:04:44<1:53:59,  4.74s/it] 62%|██████▏   | 2311/3753 [3:04:48<1:48:16,  4.51s/it] 62%|██████▏   | 2312/3753 [3:04:55<2:06:08,  5.25s/it] 62%|██████▏   | 2313/3753 [3:04:59<2:00:35,  5.02s/it] 62%|██████▏   | 2314/3753 [3:05:04<2:02:14,  5.10s/it] 62%|██████▏   | 2315/3753 [3:05:08<1:51:36,  4.66s/it] 62%|██████▏   | 2316/3753 [3:05:12<1:49:30,  4.57s/it] 62%|██████▏   | 2317/3753 [3:05:17<1:46:03,  4.43s/it] 62%|██████▏   | 2318/3753 [3:05:20<1:39:34,  4.16s/it] 62%|██████▏   | 2319/3753 [3:05:29<2:13:09,  5.57s/it] 62%|██████▏   | 2320/3753 [3:05:34<2:07:43,  5.35s/it]{'loss': 35.4116, 'grad_norm': 0.0, 'learning_rate': 3.8272333446673617e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.5496633052825928, 'weight_rejected': -3.251183271408081, 'kl_term_chosen': 4.3872833251953125, 'kl_term_rejected': -4.039114475250244, 'epoch': 0.6182544970019986}
                                                       {'loss': 35.4116, 'grad_norm': 0.0, 'learning_rate': 3.8272333446673617e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.5496633052825928, 'weight_rejected': -3.251183271408081, 'kl_term_chosen': 4.3872833251953125, 'kl_term_rejected': -4.039114475250244, 'epoch': 0.62}
 62%|██████▏   | 2320/3753 [3:05:34<2:07:43,  5.35s/it] 62%|██████▏   | 2321/3753 [3:05:38<2:02:13,  5.12s/it] 62%|██████▏   | 2322/3753 [3:05:42<1:51:10,  4.66s/it] 62%|██████▏   | 2323/3753 [3:05:47<1:55:48,  4.86s/it] 62%|██████▏   | 2324/3753 [3:05:52<1:57:00,  4.91s/it] 62%|██████▏   | 2325/3753 [3:05:56<1:49:38,  4.61s/it] 62%|██████▏   | 2326/3753 [3:06:01<1:52:49,  4.74s/it] 62%|██████▏   | 2327/3753 [3:06:05<1:45:10,  4.43s/it] 62%|██████▏   | 2328/3753 [3:06:09<1:44:01,  4.38s/it] 62%|██████▏   | 2329/3753 [3:06:13<1:40:28,  4.23s/it] 62%|██████▏   | 2330/3753 [3:06:17<1:39:59,  4.22s/it]{'loss': 40.4668, 'grad_norm': 781.8963623046875, 'learning_rate': 3.782067799937092e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.08662277460098267, 'weight_rejected': 0.29556071758270264, 'kl_term_chosen': 0.8438354730606079, 'kl_term_rejected': 0.24136200547218323, 'epoch': 0.6209193870752832}
                                                       {'loss': 40.4668, 'grad_norm': 781.8963623046875, 'learning_rate': 3.782067799937092e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.08662277460098267, 'weight_rejected': 0.29556071758270264, 'kl_term_chosen': 0.8438354730606079, 'kl_term_rejected': 0.24136200547218323, 'epoch': 0.62}
 62%|██████▏   | 2330/3753 [3:06:17<1:39:59,  4.22s/it] 62%|██████▏   | 2331/3753 [3:06:22<1:40:20,  4.23s/it] 62%|██████▏   | 2332/3753 [3:06:26<1:39:12,  4.19s/it] 62%|██████▏   | 2333/3753 [3:06:30<1:39:10,  4.19s/it] 62%|██████▏   | 2334/3753 [3:06:34<1:40:40,  4.26s/it] 62%|██████▏   | 2335/3753 [3:06:38<1:37:17,  4.12s/it] 62%|██████▏   | 2336/3753 [3:06:42<1:36:08,  4.07s/it] 62%|██████▏   | 2337/3753 [3:06:46<1:37:31,  4.13s/it] 62%|██████▏   | 2338/3753 [3:06:50<1:37:52,  4.15s/it] 62%|██████▏   | 2339/3753 [3:06:56<1:46:20,  4.51s/it] 62%|██████▏   | 2340/3753 [3:07:00<1:44:09,  4.42s/it]{'loss': 36.9222, 'grad_norm': 0.0, 'learning_rate': 3.737007659331156e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.9953658580780029, 'weight_rejected': 4.840753078460693, 'kl_term_chosen': 1.8392609357833862, 'kl_term_rejected': 4.652429103851318, 'epoch': 0.6235842771485676}
                                                       {'loss': 36.9222, 'grad_norm': 0.0, 'learning_rate': 3.737007659331156e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.9953658580780029, 'weight_rejected': 4.840753078460693, 'kl_term_chosen': 1.8392609357833862, 'kl_term_rejected': 4.652429103851318, 'epoch': 0.62}
 62%|██████▏   | 2340/3753 [3:07:00<1:44:09,  4.42s/it] 62%|██████▏   | 2341/3753 [3:07:07<2:04:37,  5.30s/it] 62%|██████▏   | 2342/3753 [3:07:11<1:54:24,  4.87s/it] 62%|██████▏   | 2343/3753 [3:07:15<1:45:09,  4.47s/it] 62%|██████▏   | 2344/3753 [3:07:20<1:53:05,  4.82s/it] 62%|██████▏   | 2345/3753 [3:07:24<1:47:10,  4.57s/it] 63%|██████▎   | 2346/3753 [3:07:28<1:43:11,  4.40s/it] 63%|██████▎   | 2347/3753 [3:07:33<1:41:25,  4.33s/it] 63%|██████▎   | 2348/3753 [3:07:39<1:56:26,  4.97s/it] 63%|██████▎   | 2349/3753 [3:07:44<1:53:35,  4.85s/it] 63%|██████▎   | 2350/3753 [3:07:48<1:46:48,  4.57s/it]{'loss': 41.0174, 'grad_norm': 1758.6097412109375, 'learning_rate': 3.692056822512162e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.202108383178711, 'weight_rejected': 2.1201064586639404, 'kl_term_chosen': 4.070935249328613, 'kl_term_rejected': 2.0000808238983154, 'epoch': 0.6262491672218521}
                                                       {'loss': 41.0174, 'grad_norm': 1758.6097412109375, 'learning_rate': 3.692056822512162e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.202108383178711, 'weight_rejected': 2.1201064586639404, 'kl_term_chosen': 4.070935249328613, 'kl_term_rejected': 2.0000808238983154, 'epoch': 0.63}
 63%|██████▎   | 2350/3753 [3:07:48<1:46:48,  4.57s/it] 63%|██████▎   | 2351/3753 [3:07:51<1:42:02,  4.37s/it] 63%|██████▎   | 2352/3753 [3:07:57<1:50:15,  4.72s/it] 63%|██████▎   | 2353/3753 [3:08:01<1:46:56,  4.58s/it] 63%|██████▎   | 2354/3753 [3:08:05<1:39:32,  4.27s/it] 63%|██████▎   | 2355/3753 [3:08:09<1:36:50,  4.16s/it] 63%|██████▎   | 2356/3753 [3:08:13<1:39:16,  4.26s/it] 63%|██████▎   | 2357/3753 [3:08:18<1:40:38,  4.33s/it] 63%|██████▎   | 2358/3753 [3:08:21<1:35:09,  4.09s/it] 63%|██████▎   | 2359/3753 [3:08:26<1:40:59,  4.35s/it] 63%|██████▎   | 2360/3753 [3:08:31<1:44:14,  4.49s/it]{'loss': 46.514, 'grad_norm': 0.0, 'learning_rate': 3.64721917968319e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.27283117175102234, 'weight_rejected': -9.269279479980469, 'kl_term_chosen': 0.257040411233902, 'kl_term_rejected': -9.617037773132324, 'epoch': 0.6289140572951366}
                                                       {'loss': 46.514, 'grad_norm': 0.0, 'learning_rate': 3.64721917968319e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.27283117175102234, 'weight_rejected': -9.269279479980469, 'kl_term_chosen': 0.257040411233902, 'kl_term_rejected': -9.617037773132324, 'epoch': 0.63}
 63%|██████▎   | 2360/3753 [3:08:31<1:44:14,  4.49s/it] 63%|██████▎   | 2361/3753 [3:08:34<1:37:12,  4.19s/it] 63%|██████▎   | 2362/3753 [3:08:41<1:50:18,  4.76s/it] 63%|██████▎   | 2363/3753 [3:08:48<2:07:30,  5.50s/it] 63%|██████▎   | 2364/3753 [3:08:52<2:00:39,  5.21s/it] 63%|██████▎   | 2365/3753 [3:08:57<1:54:55,  4.97s/it] 63%|██████▎   | 2366/3753 [3:09:01<1:47:22,  4.64s/it] 63%|██████▎   | 2367/3753 [3:09:05<1:43:01,  4.46s/it] 63%|██████▎   | 2368/3753 [3:09:08<1:37:49,  4.24s/it] 63%|██████▎   | 2369/3753 [3:09:14<1:47:12,  4.65s/it] 63%|██████▎   | 2370/3753 [3:09:17<1:39:34,  4.32s/it]{'loss': 43.2216, 'grad_norm': 0.0, 'learning_rate': 3.6024986112511093e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.722297191619873, 'weight_rejected': -4.746042728424072, 'kl_term_chosen': -2.8900604248046875, 'kl_term_rejected': -5.005868434906006, 'epoch': 0.631578947368421}
                                                       {'loss': 43.2216, 'grad_norm': 0.0, 'learning_rate': 3.6024986112511093e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.722297191619873, 'weight_rejected': -4.746042728424072, 'kl_term_chosen': -2.8900604248046875, 'kl_term_rejected': -5.005868434906006, 'epoch': 0.63}
 63%|██████▎   | 2370/3753 [3:09:18<1:39:34,  4.32s/it] 63%|██████▎   | 2371/3753 [3:09:22<1:37:32,  4.23s/it] 63%|██████▎   | 2372/3753 [3:09:25<1:33:02,  4.04s/it] 63%|██████▎   | 2373/3753 [3:09:28<1:27:55,  3.82s/it] 63%|██████▎   | 2374/3753 [3:09:32<1:26:33,  3.77s/it] 63%|██████▎   | 2375/3753 [3:09:36<1:29:58,  3.92s/it] 63%|██████▎   | 2376/3753 [3:09:44<1:55:23,  5.03s/it] 63%|██████▎   | 2377/3753 [3:09:48<1:47:28,  4.69s/it] 63%|██████▎   | 2378/3753 [3:09:52<1:42:00,  4.45s/it] 63%|██████▎   | 2379/3753 [3:09:56<1:40:27,  4.39s/it] 63%|██████▎   | 2380/3753 [3:10:00<1:41:02,  4.42s/it]{'loss': 49.2942, 'grad_norm': 2149.49560546875, 'learning_rate': 3.5578989874907643e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.654573440551758, 'weight_rejected': 1.086702823638916, 'kl_term_chosen': 10.52160930633545, 'kl_term_rejected': 1.0040054321289062, 'epoch': 0.6342438374417055}
                                                       {'loss': 49.2942, 'grad_norm': 2149.49560546875, 'learning_rate': 3.5578989874907643e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.654573440551758, 'weight_rejected': 1.086702823638916, 'kl_term_chosen': 10.52160930633545, 'kl_term_rejected': 1.0040054321289062, 'epoch': 0.63}
 63%|██████▎   | 2380/3753 [3:10:01<1:41:02,  4.42s/it] 63%|██████▎   | 2381/3753 [3:10:04<1:37:59,  4.29s/it] 63%|██████▎   | 2382/3753 [3:10:12<2:02:12,  5.35s/it] 63%|██████▎   | 2383/3753 [3:10:17<1:56:43,  5.11s/it] 64%|██████▎   | 2384/3753 [3:10:22<1:53:57,  4.99s/it] 64%|██████▎   | 2385/3753 [3:10:26<1:51:12,  4.88s/it] 64%|██████▎   | 2386/3753 [3:10:30<1:42:33,  4.50s/it] 64%|██████▎   | 2387/3753 [3:10:34<1:43:55,  4.57s/it] 64%|██████▎   | 2388/3753 [3:10:37<1:32:24,  4.06s/it] 64%|██████▎   | 2389/3753 [3:10:42<1:36:06,  4.23s/it] 64%|██████▎   | 2390/3753 [3:10:47<1:38:47,  4.35s/it]{'loss': 47.8518, 'grad_norm': 863.0457763671875, 'learning_rate': 3.513424168210026e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.0196855068206787, 'weight_rejected': -11.767579078674316, 'kl_term_chosen': 2.8313615322113037, 'kl_term_rejected': -11.911727905273438, 'epoch': 0.6369087275149901}
                                                       {'loss': 47.8518, 'grad_norm': 863.0457763671875, 'learning_rate': 3.513424168210026e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.0196855068206787, 'weight_rejected': -11.767579078674316, 'kl_term_chosen': 2.8313615322113037, 'kl_term_rejected': -11.911727905273438, 'epoch': 0.64}
 64%|██████▎   | 2390/3753 [3:10:47<1:38:47,  4.35s/it] 64%|██████▎   | 2391/3753 [3:10:52<1:43:56,  4.58s/it] 64%|██████▎   | 2392/3753 [3:10:56<1:39:48,  4.40s/it] 64%|██████▍   | 2393/3753 [3:11:01<1:47:54,  4.76s/it] 64%|██████▍   | 2394/3753 [3:11:06<1:49:40,  4.84s/it] 64%|██████▍   | 2395/3753 [3:11:11<1:49:25,  4.83s/it] 64%|██████▍   | 2396/3753 [3:11:15<1:40:53,  4.46s/it] 64%|██████▍   | 2397/3753 [3:11:18<1:31:23,  4.04s/it] 64%|██████▍   | 2398/3753 [3:11:26<1:58:48,  5.26s/it] 64%|██████▍   | 2399/3753 [3:11:30<1:52:23,  4.98s/it] 64%|██████▍   | 2400/3753 [3:11:36<1:55:43,  5.13s/it]{'loss': 47.5803, 'grad_norm': 130.84921264648438, 'learning_rate': 3.469078002415741e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.8520210385322571, 'weight_rejected': 6.501856327056885, 'kl_term_chosen': 1.8001755475997925, 'kl_term_rejected': 6.284518718719482, 'epoch': 0.6395736175882745}
                                                       {'loss': 47.5803, 'grad_norm': 130.84921264648438, 'learning_rate': 3.469078002415741e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.8520210385322571, 'weight_rejected': 6.501856327056885, 'kl_term_chosen': 1.8001755475997925, 'kl_term_rejected': 6.284518718719482, 'epoch': 0.64}
 64%|██████▍   | 2400/3753 [3:11:36<1:55:43,  5.13s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 64%|██████▍   | 2401/3753 [3:12:40<8:32:31, 22.75s/it] 64%|██████▍   | 2402/3753 [3:12:49<7:02:28, 18.76s/it] 64%|██████▍   | 2403/3753 [3:12:55<5:33:02, 14.80s/it] 64%|██████▍   | 2404/3753 [3:12:58<4:15:29, 11.36s/it] 64%|██████▍   | 2405/3753 [3:13:02<3:24:04,  9.08s/it] 64%|██████▍   | 2406/3753 [3:13:07<2:59:24,  7.99s/it] 64%|██████▍   | 2407/3753 [3:13:11<2:32:55,  6.82s/it] 64%|██████▍   | 2408/3753 [3:13:15<2:11:03,  5.85s/it] 64%|██████▍   | 2409/3753 [3:13:19<1:57:30,  5.25s/it] 64%|██████▍   | 2410/3753 [3:13:24<1:56:34,  5.21s/it]{'loss': 44.8705, 'grad_norm': 1628.4991455078125, 'learning_rate': 3.424864327980639e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.48772668838501, 'weight_rejected': -3.2632641792297363, 'kl_term_chosen': -4.398906230926514, 'kl_term_rejected': -4.1550750732421875, 'epoch': 0.642238507661559}
                                                       {'loss': 44.8705, 'grad_norm': 1628.4991455078125, 'learning_rate': 3.424864327980639e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.48772668838501, 'weight_rejected': -3.2632641792297363, 'kl_term_chosen': -4.398906230926514, 'kl_term_rejected': -4.1550750732421875, 'epoch': 0.64}
 64%|██████▍   | 2410/3753 [3:13:24<1:56:34,  5.21s/it] 64%|██████▍   | 2411/3753 [3:13:28<1:46:59,  4.78s/it] 64%|██████▍   | 2412/3753 [3:13:36<2:08:34,  5.75s/it] 64%|██████▍   | 2413/3753 [3:13:40<1:58:13,  5.29s/it] 64%|██████▍   | 2414/3753 [3:13:44<1:53:03,  5.07s/it] 64%|██████▍   | 2415/3753 [3:13:49<1:52:31,  5.05s/it] 64%|██████▍   | 2416/3753 [3:13:53<1:45:28,  4.73s/it] 64%|██████▍   | 2417/3753 [3:13:59<1:54:09,  5.13s/it] 64%|██████▍   | 2418/3753 [3:14:04<1:47:24,  4.83s/it] 64%|██████▍   | 2419/3753 [3:14:07<1:40:45,  4.53s/it] 64%|██████▍   | 2420/3753 [3:14:12<1:43:47,  4.67s/it]{'loss': 54.9656, 'grad_norm': 6.351866245269775, 'learning_rate': 3.380786971311175e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.682176351547241, 'weight_rejected': 2.7950615882873535, 'kl_term_chosen': 3.353646993637085, 'kl_term_rejected': 2.4918458461761475, 'epoch': 0.6449033977348434}
                                                       {'loss': 54.9656, 'grad_norm': 6.351866245269775, 'learning_rate': 3.380786971311175e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.682176351547241, 'weight_rejected': 2.7950615882873535, 'kl_term_chosen': 3.353646993637085, 'kl_term_rejected': 2.4918458461761475, 'epoch': 0.64}
 64%|██████▍   | 2420/3753 [3:14:12<1:43:47,  4.67s/it] 65%|██████▍   | 2421/3753 [3:14:17<1:43:32,  4.66s/it] 65%|██████▍   | 2422/3753 [3:14:20<1:35:30,  4.31s/it] 65%|██████▍   | 2423/3753 [3:14:28<1:57:53,  5.32s/it] 65%|██████▍   | 2424/3753 [3:14:33<1:52:14,  5.07s/it] 65%|██████▍   | 2425/3753 [3:14:38<1:53:20,  5.12s/it] 65%|██████▍   | 2426/3753 [3:14:42<1:45:26,  4.77s/it] 65%|██████▍   | 2427/3753 [3:14:46<1:40:24,  4.54s/it] 65%|██████▍   | 2428/3753 [3:14:50<1:35:49,  4.34s/it] 65%|██████▍   | 2429/3753 [3:14:53<1:30:27,  4.10s/it] 65%|██████▍   | 2430/3753 [3:14:56<1:23:56,  3.81s/it]{'loss': 47.386, 'grad_norm': 9.79989242553711, 'learning_rate': 3.3368497470163937e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.38656896352767944, 'weight_rejected': 0.5355703234672546, 'kl_term_chosen': 1.3576980829238892, 'kl_term_rejected': 0.5186554193496704, 'epoch': 0.6475682878081279}
                                                       {'loss': 47.386, 'grad_norm': 9.79989242553711, 'learning_rate': 3.3368497470163937e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.38656896352767944, 'weight_rejected': 0.5355703234672546, 'kl_term_chosen': 1.3576980829238892, 'kl_term_rejected': 0.5186554193496704, 'epoch': 0.65}
 65%|██████▍   | 2430/3753 [3:14:56<1:23:56,  3.81s/it] 65%|██████▍   | 2431/3753 [3:15:00<1:25:17,  3.87s/it] 65%|██████▍   | 2432/3753 [3:15:04<1:25:28,  3.88s/it] 65%|██████▍   | 2433/3753 [3:15:08<1:25:08,  3.87s/it] 65%|██████▍   | 2434/3753 [3:15:14<1:38:30,  4.48s/it] 65%|██████▍   | 2435/3753 [3:15:18<1:37:06,  4.42s/it] 65%|██████▍   | 2436/3753 [3:15:23<1:38:55,  4.51s/it] 65%|██████▍   | 2437/3753 [3:15:27<1:34:33,  4.31s/it] 65%|██████▍   | 2438/3753 [3:15:32<1:40:41,  4.59s/it] 65%|██████▍   | 2439/3753 [3:15:38<1:50:58,  5.07s/it] 65%|██████▌   | 2440/3753 [3:15:43<1:48:10,  4.94s/it]{'loss': 47.876, 'grad_norm': 429.9376525878906, 'learning_rate': 3.2930564575777887e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.45832633972168, 'weight_rejected': 0.8052569031715393, 'kl_term_chosen': 8.328041076660156, 'kl_term_rejected': 0.5865875482559204, 'epoch': 0.6502331778814124}
                                                       {'loss': 47.876, 'grad_norm': 429.9376525878906, 'learning_rate': 3.2930564575777887e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.45832633972168, 'weight_rejected': 0.8052569031715393, 'kl_term_chosen': 8.328041076660156, 'kl_term_rejected': 0.5865875482559204, 'epoch': 0.65}
 65%|██████▌   | 2440/3753 [3:15:43<1:48:10,  4.94s/it] 65%|██████▌   | 2441/3753 [3:15:47<1:45:09,  4.81s/it] 65%|██████▌   | 2442/3753 [3:15:52<1:42:38,  4.70s/it] 65%|██████▌   | 2443/3753 [3:15:56<1:37:05,  4.45s/it] 65%|██████▌   | 2444/3753 [3:15:59<1:31:18,  4.19s/it] 65%|██████▌   | 2445/3753 [3:16:03<1:26:31,  3.97s/it] 65%|██████▌   | 2446/3753 [3:16:06<1:23:39,  3.84s/it] 65%|██████▌   | 2447/3753 [3:16:12<1:34:19,  4.33s/it] 65%|██████▌   | 2448/3753 [3:16:17<1:41:05,  4.65s/it] 65%|██████▌   | 2449/3753 [3:16:22<1:40:07,  4.61s/it] 65%|██████▌   | 2450/3753 [3:16:26<1:38:41,  4.54s/it]{'loss': 52.4641, 'grad_norm': 517.7282104492188, 'learning_rate': 3.249410893020228e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.795604228973389, 'weight_rejected': 3.4634077548980713, 'kl_term_chosen': 5.4956793785095215, 'kl_term_rejected': 3.1944663524627686, 'epoch': 0.6528980679546968}
                                                       {'loss': 52.4641, 'grad_norm': 517.7282104492188, 'learning_rate': 3.249410893020228e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.795604228973389, 'weight_rejected': 3.4634077548980713, 'kl_term_chosen': 5.4956793785095215, 'kl_term_rejected': 3.1944663524627686, 'epoch': 0.65}
 65%|██████▌   | 2450/3753 [3:16:26<1:38:41,  4.54s/it] 65%|██████▌   | 2451/3753 [3:16:31<1:39:05,  4.57s/it] 65%|██████▌   | 2452/3753 [3:16:36<1:41:29,  4.68s/it] 65%|██████▌   | 2453/3753 [3:16:40<1:36:12,  4.44s/it] 65%|██████▌   | 2454/3753 [3:16:44<1:33:29,  4.32s/it] 65%|██████▌   | 2455/3753 [3:16:48<1:32:54,  4.29s/it] 65%|██████▌   | 2456/3753 [3:16:53<1:37:04,  4.49s/it] 65%|██████▌   | 2457/3753 [3:16:58<1:39:27,  4.60s/it] 65%|██████▌   | 2458/3753 [3:17:02<1:39:52,  4.63s/it] 66%|██████▌   | 2459/3753 [3:17:05<1:30:03,  4.18s/it] 66%|██████▌   | 2460/3753 [3:17:09<1:27:48,  4.07s/it]{'loss': 49.78, 'grad_norm': 150.7779083251953, 'learning_rate': 3.205916830583948e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.5434914827346802, 'weight_chosen': -6.264036655426025, 'weight_rejected': 0.0027408748865127563, 'kl_term_chosen': 7.183679103851318, 'kl_term_rejected': -0.06097412109375, 'epoch': 0.6555629580279814}
                                                       {'loss': 49.78, 'grad_norm': 150.7779083251953, 'learning_rate': 3.205916830583948e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.5434914827346802, 'weight_chosen': -6.264036655426025, 'weight_rejected': 0.0027408748865127563, 'kl_term_chosen': 7.183679103851318, 'kl_term_rejected': -0.06097412109375, 'epoch': 0.66}
 66%|██████▌   | 2460/3753 [3:17:09<1:27:48,  4.07s/it] 66%|██████▌   | 2461/3753 [3:17:14<1:29:09,  4.14s/it] 66%|██████▌   | 2462/3753 [3:17:17<1:24:40,  3.94s/it] 66%|██████▌   | 2463/3753 [3:17:22<1:31:00,  4.23s/it] 66%|██████▌   | 2464/3753 [3:17:26<1:32:34,  4.31s/it] 66%|██████▌   | 2465/3753 [3:17:30<1:28:52,  4.14s/it] 66%|██████▌   | 2466/3753 [3:17:35<1:29:50,  4.19s/it] 66%|██████▌   | 2467/3753 [3:17:40<1:39:15,  4.63s/it] 66%|██████▌   | 2468/3753 [3:17:45<1:39:57,  4.67s/it] 66%|██████▌   | 2469/3753 [3:17:49<1:34:10,  4.40s/it] 66%|██████▌   | 2470/3753 [3:17:53<1:34:47,  4.43s/it]{'loss': 53.7054, 'grad_norm': 0.0, 'learning_rate': 3.1625780343976646e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.897590160369873, 'weight_rejected': 2.4434852600097656, 'kl_term_chosen': 2.77166748046875, 'kl_term_rejected': 2.349475145339966, 'epoch': 0.6582278481012658}
                                                       {'loss': 53.7054, 'grad_norm': 0.0, 'learning_rate': 3.1625780343976646e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.897590160369873, 'weight_rejected': 2.4434852600097656, 'kl_term_chosen': 2.77166748046875, 'kl_term_rejected': 2.349475145339966, 'epoch': 0.66}
 66%|██████▌   | 2470/3753 [3:17:53<1:34:47,  4.43s/it] 66%|██████▌   | 2471/3753 [3:17:57<1:29:14,  4.18s/it] 66%|██████▌   | 2472/3753 [3:18:01<1:28:01,  4.12s/it] 66%|██████▌   | 2473/3753 [3:18:05<1:30:44,  4.25s/it] 66%|██████▌   | 2474/3753 [3:18:09<1:29:24,  4.19s/it] 66%|██████▌   | 2475/3753 [3:18:14<1:31:12,  4.28s/it] 66%|██████▌   | 2476/3753 [3:18:18<1:32:03,  4.33s/it] 66%|██████▌   | 2477/3753 [3:18:23<1:33:15,  4.39s/it] 66%|██████▌   | 2478/3753 [3:18:26<1:27:29,  4.12s/it] 66%|██████▌   | 2479/3753 [3:18:30<1:26:19,  4.07s/it] 66%|██████▌   | 2480/3753 [3:18:34<1:25:24,  4.03s/it]{'loss': 57.2332, 'grad_norm': 129.46714782714844, 'learning_rate': 3.119398255152801e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.1390748023986816, 'weight_rejected': -6.7516937255859375, 'kl_term_chosen': -1.641851782798767, 'kl_term_rejected': -7.468705654144287, 'epoch': 0.6608927381745503}
                                                       {'loss': 57.2332, 'grad_norm': 129.46714782714844, 'learning_rate': 3.119398255152801e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.1390748023986816, 'weight_rejected': -6.7516937255859375, 'kl_term_chosen': -1.641851782798767, 'kl_term_rejected': -7.468705654144287, 'epoch': 0.66}
 66%|██████▌   | 2480/3753 [3:18:34<1:25:24,  4.03s/it] 66%|██████▌   | 2481/3753 [3:18:39<1:32:24,  4.36s/it] 66%|██████▌   | 2482/3753 [3:18:43<1:26:42,  4.09s/it] 66%|██████▌   | 2483/3753 [3:18:47<1:26:06,  4.07s/it] 66%|██████▌   | 2484/3753 [3:18:51<1:28:26,  4.18s/it] 66%|██████▌   | 2485/3753 [3:18:55<1:23:39,  3.96s/it] 66%|██████▌   | 2486/3753 [3:18:59<1:23:39,  3.96s/it] 66%|██████▋   | 2487/3753 [3:19:03<1:25:34,  4.06s/it] 66%|██████▋   | 2488/3753 [3:19:08<1:29:16,  4.23s/it] 66%|██████▋   | 2489/3753 [3:19:12<1:30:50,  4.31s/it] 66%|██████▋   | 2490/3753 [3:19:18<1:38:28,  4.68s/it]{'loss': 56.2039, 'grad_norm': 372.67584228515625, 'learning_rate': 3.076381229778904e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.5436023473739624, 'weight_rejected': -0.49390336871147156, 'kl_term_chosen': 0.7989460229873657, 'kl_term_rejected': -0.7659279108047485, 'epoch': 0.6635576282478348}
                                                       {'loss': 56.2039, 'grad_norm': 372.67584228515625, 'learning_rate': 3.076381229778904e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.5436023473739624, 'weight_rejected': -0.49390336871147156, 'kl_term_chosen': 0.7989460229873657, 'kl_term_rejected': -0.7659279108047485, 'epoch': 0.66}
 66%|██████▋   | 2490/3753 [3:19:18<1:38:28,  4.68s/it] 66%|██████▋   | 2491/3753 [3:19:22<1:38:17,  4.67s/it] 66%|██████▋   | 2492/3753 [3:19:26<1:29:55,  4.28s/it] 66%|██████▋   | 2493/3753 [3:19:30<1:28:26,  4.21s/it] 66%|██████▋   | 2494/3753 [3:19:34<1:31:54,  4.38s/it] 66%|██████▋   | 2495/3753 [3:19:39<1:29:54,  4.29s/it] 67%|██████▋   | 2496/3753 [3:19:42<1:25:16,  4.07s/it] 67%|██████▋   | 2497/3753 [3:19:47<1:28:53,  4.25s/it] 67%|██████▋   | 2498/3753 [3:19:51<1:26:56,  4.16s/it] 67%|██████▋   | 2499/3753 [3:19:55<1:29:41,  4.29s/it] 67%|██████▋   | 2500/3753 [3:20:00<1:31:39,  4.39s/it]{'loss': 47.2726, 'grad_norm': 1535.345947265625, 'learning_rate': 3.033530681120224e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -7.341975212097168, 'weight_rejected': -3.2839536666870117, 'kl_term_chosen': 8.019449234008789, 'kl_term_rejected': -3.4081666469573975, 'epoch': 0.6662225183211192}
                                                       {'loss': 47.2726, 'grad_norm': 1535.345947265625, 'learning_rate': 3.033530681120224e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -7.341975212097168, 'weight_rejected': -3.2839536666870117, 'kl_term_chosen': 8.019449234008789, 'kl_term_rejected': -3.4081666469573975, 'epoch': 0.67}
 67%|██████▋   | 2500/3753 [3:20:00<1:31:39,  4.39s/it] 67%|██████▋   | 2501/3753 [3:20:05<1:37:28,  4.67s/it] 67%|██████▋   | 2502/3753 [3:20:09<1:29:07,  4.27s/it] 67%|██████▋   | 2503/3753 [3:20:12<1:22:55,  3.98s/it] 67%|██████▋   | 2504/3753 [3:20:15<1:19:19,  3.81s/it] 67%|██████▋   | 2505/3753 [3:20:20<1:21:48,  3.93s/it] 67%|██████▋   | 2506/3753 [3:20:24<1:26:10,  4.15s/it] 67%|██████▋   | 2507/3753 [3:20:28<1:23:34,  4.02s/it] 67%|██████▋   | 2508/3753 [3:20:32<1:22:03,  3.95s/it] 67%|██████▋   | 2509/3753 [3:20:37<1:32:12,  4.45s/it] 67%|██████▋   | 2510/3753 [3:20:41<1:27:33,  4.23s/it]{'loss': 47.9903, 'grad_norm': 165.16357421875, 'learning_rate': 2.990850317613535e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.598464250564575, 'weight_rejected': 3.9869985580444336, 'kl_term_chosen': 3.6754250526428223, 'kl_term_rejected': 3.0878772735595703, 'epoch': 0.6688874083944037}
                                                       {'loss': 47.9903, 'grad_norm': 165.16357421875, 'learning_rate': 2.990850317613535e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.598464250564575, 'weight_rejected': 3.9869985580444336, 'kl_term_chosen': 3.6754250526428223, 'kl_term_rejected': 3.0878772735595703, 'epoch': 0.67}
 67%|██████▋   | 2510/3753 [3:20:41<1:27:33,  4.23s/it] 67%|██████▋   | 2511/3753 [3:20:46<1:30:25,  4.37s/it] 67%|██████▋   | 2512/3753 [3:20:51<1:32:51,  4.49s/it] 67%|██████▋   | 2513/3753 [3:20:55<1:30:21,  4.37s/it] 67%|██████▋   | 2514/3753 [3:20:59<1:30:39,  4.39s/it] 67%|██████▋   | 2515/3753 [3:21:03<1:30:34,  4.39s/it] 67%|██████▋   | 2516/3753 [3:21:08<1:29:58,  4.36s/it] 67%|██████▋   | 2517/3753 [3:21:12<1:28:37,  4.30s/it] 67%|██████▋   | 2518/3753 [3:21:17<1:31:56,  4.47s/it] 67%|██████▋   | 2519/3753 [3:21:21<1:32:58,  4.52s/it] 67%|██████▋   | 2520/3753 [3:21:29<1:52:42,  5.48s/it]{'loss': 52.3551, 'grad_norm': 527.25048828125, 'learning_rate': 2.9483438329671915e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.155701160430908, 'weight_rejected': 0.8197131156921387, 'kl_term_chosen': 8.112335205078125, 'kl_term_rejected': 0.7834930419921875, 'epoch': 0.6715522984676882}
                                                       {'loss': 52.3551, 'grad_norm': 527.25048828125, 'learning_rate': 2.9483438329671915e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.155701160430908, 'weight_rejected': 0.8197131156921387, 'kl_term_chosen': 8.112335205078125, 'kl_term_rejected': 0.7834930419921875, 'epoch': 0.67}
 67%|██████▋   | 2520/3753 [3:21:29<1:52:42,  5.48s/it] 67%|██████▋   | 2521/3753 [3:21:33<1:45:23,  5.13s/it] 67%|██████▋   | 2522/3753 [3:21:38<1:38:58,  4.82s/it] 67%|██████▋   | 2523/3753 [3:21:41<1:31:15,  4.45s/it] 67%|██████▋   | 2524/3753 [3:21:45<1:29:14,  4.36s/it] 67%|██████▋   | 2525/3753 [3:21:50<1:34:30,  4.62s/it] 67%|██████▋   | 2526/3753 [3:21:54<1:27:47,  4.29s/it] 67%|██████▋   | 2527/3753 [3:21:58<1:23:39,  4.09s/it] 67%|██████▋   | 2528/3753 [3:22:03<1:33:21,  4.57s/it] 67%|██████▋   | 2529/3753 [3:22:07<1:28:12,  4.32s/it] 67%|██████▋   | 2530/3753 [3:22:11<1:28:27,  4.34s/it]{'loss': 54.7063, 'grad_norm': 11.252431869506836, 'learning_rate': 2.9060149058414613e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.429656982421875, 'weight_rejected': 2.9819953441619873, 'kl_term_chosen': 10.374651908874512, 'kl_term_rejected': 2.9285919666290283, 'epoch': 0.6742171885409727}
                                                       {'loss': 54.7063, 'grad_norm': 11.252431869506836, 'learning_rate': 2.9060149058414613e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.429656982421875, 'weight_rejected': 2.9819953441619873, 'kl_term_chosen': 10.374651908874512, 'kl_term_rejected': 2.9285919666290283, 'epoch': 0.67}
 67%|██████▋   | 2530/3753 [3:22:12<1:28:27,  4.34s/it] 67%|██████▋   | 2531/3753 [3:22:16<1:29:11,  4.38s/it] 67%|██████▋   | 2532/3753 [3:22:24<1:48:30,  5.33s/it] 67%|██████▋   | 2533/3753 [3:22:28<1:42:02,  5.02s/it] 68%|██████▊   | 2534/3753 [3:22:32<1:38:57,  4.87s/it] 68%|██████▊   | 2535/3753 [3:22:37<1:40:08,  4.93s/it] 68%|██████▊   | 2536/3753 [3:22:41<1:31:06,  4.49s/it] 68%|██████▊   | 2537/3753 [3:22:45<1:27:08,  4.30s/it] 68%|██████▊   | 2538/3753 [3:22:48<1:18:27,  3.87s/it] 68%|██████▊   | 2539/3753 [3:22:53<1:29:09,  4.41s/it] 68%|██████▊   | 2540/3753 [3:22:58<1:29:34,  4.43s/it]{'loss': 52.331, 'grad_norm': 126.95337677001953, 'learning_rate': 2.863867199530159e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.389607429504395, 'weight_rejected': 3.245563268661499, 'kl_term_chosen': 9.932955741882324, 'kl_term_rejected': 2.905735731124878, 'epoch': 0.6768820786142572}
                                                       {'loss': 52.331, 'grad_norm': 126.95337677001953, 'learning_rate': 2.863867199530159e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.389607429504395, 'weight_rejected': 3.245563268661499, 'kl_term_chosen': 9.932955741882324, 'kl_term_rejected': 2.905735731124878, 'epoch': 0.68}
 68%|██████▊   | 2540/3753 [3:22:58<1:29:34,  4.43s/it] 68%|██████▊   | 2541/3753 [3:23:01<1:20:22,  3.98s/it] 68%|██████▊   | 2542/3753 [3:23:04<1:18:19,  3.88s/it] 68%|██████▊   | 2543/3753 [3:23:09<1:24:54,  4.21s/it] 68%|██████▊   | 2544/3753 [3:23:14<1:25:51,  4.26s/it] 68%|██████▊   | 2545/3753 [3:23:17<1:22:24,  4.09s/it] 68%|██████▊   | 2546/3753 [3:23:22<1:28:38,  4.41s/it] 68%|██████▊   | 2547/3753 [3:23:27<1:29:34,  4.46s/it] 68%|██████▊   | 2548/3753 [3:23:31<1:24:14,  4.19s/it] 68%|██████▊   | 2549/3753 [3:23:35<1:24:57,  4.23s/it] 68%|██████▊   | 2550/3753 [3:23:41<1:33:56,  4.69s/it]{'loss': 55.5186, 'grad_norm': 0.0, 'learning_rate': 2.8219043616436167e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.708073139190674, 'weight_rejected': 4.020271301269531, 'kl_term_chosen': 4.392337322235107, 'kl_term_rejected': 3.6977450847625732, 'epoch': 0.6795469686875416}
                                                       {'loss': 55.5186, 'grad_norm': 0.0, 'learning_rate': 2.8219043616436167e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.708073139190674, 'weight_rejected': 4.020271301269531, 'kl_term_chosen': 4.392337322235107, 'kl_term_rejected': 3.6977450847625732, 'epoch': 0.68}
 68%|██████▊   | 2550/3753 [3:23:41<1:33:56,  4.69s/it] 68%|██████▊   | 2551/3753 [3:23:44<1:27:26,  4.36s/it] 68%|██████▊   | 2552/3753 [3:23:48<1:24:44,  4.23s/it] 68%|██████▊   | 2553/3753 [3:23:52<1:24:08,  4.21s/it] 68%|██████▊   | 2554/3753 [3:23:56<1:23:11,  4.16s/it] 68%|██████▊   | 2555/3753 [3:24:00<1:19:35,  3.99s/it] 68%|██████▊   | 2556/3753 [3:24:04<1:21:56,  4.11s/it] 68%|██████▊   | 2557/3753 [3:24:09<1:23:12,  4.17s/it] 68%|██████▊   | 2558/3753 [3:24:12<1:19:14,  3.98s/it] 68%|██████▊   | 2559/3753 [3:24:17<1:22:18,  4.14s/it] 68%|██████▊   | 2560/3753 [3:24:20<1:14:11,  3.73s/it]{'loss': 54.8982, 'grad_norm': 0.0, 'learning_rate': 2.780130023793006e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.9522916078567505, 'weight_rejected': -4.375649452209473, 'kl_term_chosen': 2.820225477218628, 'kl_term_rejected': -4.818045139312744, 'epoch': 0.6822118587608261}
                                                       {'loss': 54.8982, 'grad_norm': 0.0, 'learning_rate': 2.780130023793006e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.9522916078567505, 'weight_rejected': -4.375649452209473, 'kl_term_chosen': 2.820225477218628, 'kl_term_rejected': -4.818045139312744, 'epoch': 0.68}
 68%|██████▊   | 2560/3753 [3:24:20<1:14:11,  3.73s/it] 68%|██████▊   | 2561/3753 [3:24:24<1:15:40,  3.81s/it] 68%|██████▊   | 2562/3753 [3:24:27<1:13:26,  3.70s/it] 68%|██████▊   | 2563/3753 [3:24:32<1:20:39,  4.07s/it] 68%|██████▊   | 2564/3753 [3:24:36<1:19:25,  4.01s/it] 68%|██████▊   | 2565/3753 [3:24:40<1:21:23,  4.11s/it] 68%|██████▊   | 2566/3753 [3:24:44<1:22:16,  4.16s/it] 68%|██████▊   | 2567/3753 [3:24:50<1:28:15,  4.47s/it] 68%|██████▊   | 2568/3753 [3:24:54<1:29:34,  4.54s/it] 68%|██████▊   | 2569/3753 [3:24:59<1:31:13,  4.62s/it] 68%|██████▊   | 2570/3753 [3:25:03<1:28:18,  4.48s/it]{'loss': 58.1208, 'grad_norm': 962.4135131835938, 'learning_rate': 2.738547801276043e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.0795793533325195, 'weight_rejected': 19.804380416870117, 'kl_term_chosen': 1.8315918445587158, 'kl_term_rejected': 19.635522842407227, 'epoch': 0.6848767488341105}
                                                       {'loss': 58.1208, 'grad_norm': 962.4135131835938, 'learning_rate': 2.738547801276043e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.0795793533325195, 'weight_rejected': 19.804380416870117, 'kl_term_chosen': 1.8315918445587158, 'kl_term_rejected': 19.635522842407227, 'epoch': 0.68}
 68%|██████▊   | 2570/3753 [3:25:03<1:28:18,  4.48s/it] 69%|██████▊   | 2571/3753 [3:25:08<1:27:47,  4.46s/it] 69%|██████▊   | 2572/3753 [3:25:12<1:29:16,  4.54s/it] 69%|██████▊   | 2573/3753 [3:25:17<1:27:49,  4.47s/it] 69%|██████▊   | 2574/3753 [3:25:20<1:22:26,  4.20s/it] 69%|██████▊   | 2575/3753 [3:25:27<1:37:33,  4.97s/it] 69%|██████▊   | 2576/3753 [3:25:35<1:53:40,  5.79s/it] 69%|██████▊   | 2577/3753 [3:25:39<1:43:10,  5.26s/it] 69%|██████▊   | 2578/3753 [3:25:47<2:02:31,  6.26s/it] 69%|██████▊   | 2579/3753 [3:25:51<1:47:51,  5.51s/it] 69%|██████▊   | 2580/3753 [3:25:55<1:38:13,  5.02s/it]{'loss': 55.8612, 'grad_norm': 766.8556518554688, 'learning_rate': 2.6971612927641056e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -12.358662605285645, 'weight_rejected': -1.157124638557434, 'kl_term_chosen': 13.165514945983887, 'kl_term_rejected': -1.2796478271484375, 'epoch': 0.6875416389073951}
                                                       {'loss': 55.8612, 'grad_norm': 766.8556518554688, 'learning_rate': 2.6971612927641056e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -12.358662605285645, 'weight_rejected': -1.157124638557434, 'kl_term_chosen': 13.165514945983887, 'kl_term_rejected': -1.2796478271484375, 'epoch': 0.69}
 69%|██████▊   | 2580/3753 [3:25:55<1:38:13,  5.02s/it] 69%|██████▉   | 2581/3753 [3:25:59<1:34:36,  4.84s/it] 69%|██████▉   | 2582/3753 [3:26:04<1:34:58,  4.87s/it] 69%|██████▉   | 2583/3753 [3:26:09<1:33:51,  4.81s/it] 69%|██████▉   | 2584/3753 [3:26:13<1:28:17,  4.53s/it] 69%|██████▉   | 2585/3753 [3:26:16<1:21:19,  4.18s/it] 69%|██████▉   | 2586/3753 [3:26:21<1:26:27,  4.44s/it] 69%|██████▉   | 2587/3753 [3:26:26<1:25:32,  4.40s/it] 69%|██████▉   | 2588/3753 [3:26:31<1:29:25,  4.61s/it] 69%|██████▉   | 2589/3753 [3:26:39<1:48:05,  5.57s/it] 69%|██████▉   | 2590/3753 [3:26:43<1:43:48,  5.36s/it]{'loss': 56.1058, 'grad_norm': 79.28929901123047, 'learning_rate': 2.6559740799908e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.7729408740997314, 'weight_rejected': 1.879329800605774, 'kl_term_chosen': 1.6029846668243408, 'kl_term_rejected': 1.68980872631073, 'epoch': 0.6902065289806796}
                                                       {'loss': 56.1058, 'grad_norm': 79.28929901123047, 'learning_rate': 2.6559740799908e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.7729408740997314, 'weight_rejected': 1.879329800605774, 'kl_term_chosen': 1.6029846668243408, 'kl_term_rejected': 1.68980872631073, 'epoch': 0.69}
 69%|██████▉   | 2590/3753 [3:26:44<1:43:48,  5.36s/it] 69%|██████▉   | 2591/3753 [3:26:48<1:39:46,  5.15s/it] 69%|██████▉   | 2592/3753 [3:26:53<1:40:07,  5.17s/it] 69%|██████▉   | 2593/3753 [3:27:00<1:51:27,  5.77s/it] 69%|██████▉   | 2594/3753 [3:27:05<1:43:37,  5.36s/it] 69%|██████▉   | 2595/3753 [3:27:09<1:37:41,  5.06s/it] 69%|██████▉   | 2596/3753 [3:27:14<1:38:03,  5.08s/it] 69%|██████▉   | 2597/3753 [3:27:19<1:34:26,  4.90s/it] 69%|██████▉   | 2598/3753 [3:27:22<1:26:22,  4.49s/it] 69%|██████▉   | 2599/3753 [3:27:26<1:22:35,  4.29s/it] 69%|██████▉   | 2600/3753 [3:27:32<1:28:22,  4.60s/it]{'loss': 51.3201, 'grad_norm': 0.0, 'learning_rate': 2.6149897274419794e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.1677913665771484, 'weight_rejected': 4.285656452178955, 'kl_term_chosen': 3.061100721359253, 'kl_term_rejected': 4.125390529632568, 'epoch': 0.692871419053964}
                                                       {'loss': 51.3201, 'grad_norm': 0.0, 'learning_rate': 2.6149897274419794e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.1677913665771484, 'weight_rejected': 4.285656452178955, 'kl_term_chosen': 3.061100721359253, 'kl_term_rejected': 4.125390529632568, 'epoch': 0.69}
 69%|██████▉   | 2600/3753 [3:27:32<1:28:22,  4.60s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 69%|██████▉   | 2601/3753 [3:28:33<6:54:34, 21.59s/it] 69%|██████▉   | 2602/3753 [3:28:38<5:18:44, 16.62s/it] 69%|██████▉   | 2603/3753 [3:28:42<4:08:41, 12.98s/it] 69%|██████▉   | 2604/3753 [3:28:46<3:16:13, 10.25s/it] 69%|██████▉   | 2605/3753 [3:28:51<2:42:31,  8.49s/it] 69%|██████▉   | 2606/3753 [3:28:56<2:23:58,  7.53s/it] 69%|██████▉   | 2607/3753 [3:28:59<2:00:48,  6.32s/it] 69%|██████▉   | 2608/3753 [3:29:02<1:41:37,  5.33s/it] 70%|██████▉   | 2609/3753 [3:29:06<1:32:01,  4.83s/it] 70%|██████▉   | 2610/3753 [3:29:10<1:29:09,  4.68s/it]{'loss': 50.1475, 'grad_norm': 0.0, 'learning_rate': 2.574211782047258e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.940582752227783, 'weight_rejected': -2.5198748111724854, 'kl_term_chosen': -2.0926148891448975, 'kl_term_rejected': -2.6423981189727783, 'epoch': 0.6955363091272485}
                                                       {'loss': 50.1475, 'grad_norm': 0.0, 'learning_rate': 2.574211782047258e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.940582752227783, 'weight_rejected': -2.5198748111724854, 'kl_term_chosen': -2.0926148891448975, 'kl_term_rejected': -2.6423981189727783, 'epoch': 0.7}
 70%|██████▉   | 2610/3753 [3:29:10<1:29:09,  4.68s/it] 70%|██████▉   | 2611/3753 [3:29:15<1:27:10,  4.58s/it] 70%|██████▉   | 2612/3753 [3:29:19<1:28:08,  4.63s/it] 70%|██████▉   | 2613/3753 [3:29:25<1:30:47,  4.78s/it] 70%|██████▉   | 2614/3753 [3:29:28<1:25:44,  4.52s/it] 70%|██████▉   | 2615/3753 [3:29:32<1:21:29,  4.30s/it] 70%|██████▉   | 2616/3753 [3:29:36<1:20:00,  4.22s/it] 70%|██████▉   | 2617/3753 [3:29:41<1:20:25,  4.25s/it] 70%|██████▉   | 2618/3753 [3:29:44<1:16:58,  4.07s/it] 70%|██████▉   | 2619/3753 [3:29:50<1:24:12,  4.46s/it] 70%|██████▉   | 2620/3753 [3:29:53<1:20:42,  4.27s/it]{'loss': 51.3643, 'grad_norm': 0.0, 'learning_rate': 2.533643772873055e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.2324682474136353, 'weight_rejected': 3.831156015396118, 'kl_term_chosen': 2.1543900966644287, 'kl_term_rejected': 3.747265577316284, 'epoch': 0.698201199200533}
                                                       {'loss': 51.3643, 'grad_norm': 0.0, 'learning_rate': 2.533643772873055e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.2324682474136353, 'weight_rejected': 3.831156015396118, 'kl_term_chosen': 2.1543900966644287, 'kl_term_rejected': 3.747265577316284, 'epoch': 0.7}
 70%|██████▉   | 2620/3753 [3:29:54<1:20:42,  4.27s/it] 70%|██████▉   | 2621/3753 [3:29:59<1:29:51,  4.76s/it] 70%|██████▉   | 2622/3753 [3:30:04<1:26:54,  4.61s/it] 70%|██████▉   | 2623/3753 [3:30:07<1:22:02,  4.36s/it] 70%|██████▉   | 2624/3753 [3:30:11<1:19:43,  4.24s/it] 70%|██████▉   | 2625/3753 [3:30:15<1:18:01,  4.15s/it] 70%|██████▉   | 2626/3753 [3:30:20<1:19:27,  4.23s/it] 70%|██████▉   | 2627/3753 [3:30:26<1:30:56,  4.85s/it] 70%|███████   | 2628/3753 [3:30:30<1:27:01,  4.64s/it] 70%|███████   | 2629/3753 [3:30:35<1:29:09,  4.76s/it] 70%|███████   | 2630/3753 [3:30:39<1:25:13,  4.55s/it]{'loss': 50.2591, 'grad_norm': 1118.5426025390625, 'learning_rate': 2.4932892108171695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 2.4542672634124756, 'weight_rejected': 0.7945682406425476, 'kl_term_chosen': -1.8154319524765015, 'kl_term_rejected': 0.308297723531723, 'epoch': 0.7008660892738174}
                                                       {'loss': 50.2591, 'grad_norm': 1118.5426025390625, 'learning_rate': 2.4932892108171695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 2.4542672634124756, 'weight_rejected': 0.7945682406425476, 'kl_term_chosen': -1.8154319524765015, 'kl_term_rejected': 0.308297723531723, 'epoch': 0.7}
 70%|███████   | 2630/3753 [3:30:39<1:25:13,  4.55s/it] 70%|███████   | 2631/3753 [3:30:43<1:19:07,  4.23s/it] 70%|███████   | 2632/3753 [3:30:49<1:29:10,  4.77s/it] 70%|███████   | 2633/3753 [3:30:54<1:31:32,  4.90s/it] 70%|███████   | 2634/3753 [3:30:59<1:31:17,  4.89s/it] 70%|███████   | 2635/3753 [3:31:06<1:44:57,  5.63s/it] 70%|███████   | 2636/3753 [3:31:10<1:36:03,  5.16s/it] 70%|███████   | 2637/3753 [3:31:13<1:23:30,  4.49s/it] 70%|███████   | 2638/3753 [3:31:17<1:17:37,  4.18s/it] 70%|███████   | 2639/3753 [3:31:21<1:18:33,  4.23s/it] 70%|███████   | 2640/3753 [3:31:26<1:20:23,  4.33s/it]{'loss': 50.1568, 'grad_norm': 2031.0714111328125, 'learning_rate': 2.4531515883049456e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.4633774757385254, 'weight_rejected': 3.568578004837036, 'kl_term_chosen': 3.272653341293335, 'kl_term_rejected': 3.4938080310821533, 'epoch': 0.703530979347102}
                                                       {'loss': 50.1568, 'grad_norm': 2031.0714111328125, 'learning_rate': 2.4531515883049456e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.4633774757385254, 'weight_rejected': 3.568578004837036, 'kl_term_chosen': 3.272653341293335, 'kl_term_rejected': 3.4938080310821533, 'epoch': 0.7}
 70%|███████   | 2640/3753 [3:31:26<1:20:23,  4.33s/it] 70%|███████   | 2641/3753 [3:31:30<1:20:46,  4.36s/it] 70%|███████   | 2642/3753 [3:31:34<1:17:46,  4.20s/it] 70%|███████   | 2643/3753 [3:31:38<1:15:20,  4.07s/it] 70%|███████   | 2644/3753 [3:31:43<1:23:44,  4.53s/it] 70%|███████   | 2645/3753 [3:31:48<1:25:16,  4.62s/it] 71%|███████   | 2646/3753 [3:31:53<1:29:17,  4.84s/it] 71%|███████   | 2647/3753 [3:31:57<1:22:22,  4.47s/it] 71%|███████   | 2648/3753 [3:32:06<1:45:37,  5.74s/it] 71%|███████   | 2649/3753 [3:32:11<1:42:33,  5.57s/it] 71%|███████   | 2650/3753 [3:32:16<1:39:33,  5.42s/it]{'loss': 51.6997, 'grad_norm': 552.4876098632812, 'learning_rate': 2.413234378987008e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.0820306539535522, 'weight_rejected': -2.7814247608184814, 'kl_term_chosen': 1.5179321765899658, 'kl_term_rejected': -3.0716004371643066, 'epoch': 0.7061958694203864}
                                                       {'loss': 51.6997, 'grad_norm': 552.4876098632812, 'learning_rate': 2.413234378987008e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.0820306539535522, 'weight_rejected': -2.7814247608184814, 'kl_term_chosen': 1.5179321765899658, 'kl_term_rejected': -3.0716004371643066, 'epoch': 0.71}
 71%|███████   | 2650/3753 [3:32:16<1:39:33,  5.42s/it] 71%|███████   | 2651/3753 [3:32:21<1:35:55,  5.22s/it] 71%|███████   | 2652/3753 [3:32:25<1:31:12,  4.97s/it] 71%|███████   | 2653/3753 [3:32:29<1:26:49,  4.74s/it] 71%|███████   | 2654/3753 [3:32:33<1:20:40,  4.40s/it] 71%|███████   | 2655/3753 [3:32:38<1:25:50,  4.69s/it] 71%|███████   | 2656/3753 [3:32:42<1:22:35,  4.52s/it] 71%|███████   | 2657/3753 [3:32:47<1:22:34,  4.52s/it] 71%|███████   | 2658/3753 [3:32:51<1:17:55,  4.27s/it] 71%|███████   | 2659/3753 [3:32:54<1:13:25,  4.03s/it] 71%|███████   | 2660/3753 [3:32:58<1:12:56,  4.00s/it]{'loss': 52.2007, 'grad_norm': 0.0, 'learning_rate': 2.373541037438657e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -8.344128608703613, 'weight_rejected': -1.7496365308761597, 'kl_term_chosen': 9.175271987915039, 'kl_term_rejected': -1.8449859619140625, 'epoch': 0.7088607594936709}
                                                       {'loss': 52.2007, 'grad_norm': 0.0, 'learning_rate': 2.373541037438657e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -8.344128608703613, 'weight_rejected': -1.7496365308761597, 'kl_term_chosen': 9.175271987915039, 'kl_term_rejected': -1.8449859619140625, 'epoch': 0.71}
 71%|███████   | 2660/3753 [3:32:58<1:12:56,  4.00s/it] 71%|███████   | 2661/3753 [3:33:02<1:12:37,  3.99s/it] 71%|███████   | 2662/3753 [3:33:06<1:11:07,  3.91s/it] 71%|███████   | 2663/3753 [3:33:11<1:16:24,  4.21s/it] 71%|███████   | 2664/3753 [3:33:15<1:15:18,  4.15s/it] 71%|███████   | 2665/3753 [3:33:22<1:31:33,  5.05s/it] 71%|███████   | 2666/3753 [3:33:26<1:29:38,  4.95s/it] 71%|███████   | 2667/3753 [3:33:30<1:23:31,  4.61s/it] 71%|███████   | 2668/3753 [3:33:34<1:21:15,  4.49s/it] 71%|███████   | 2669/3753 [3:33:39<1:19:02,  4.38s/it] 71%|███████   | 2670/3753 [3:33:42<1:14:40,  4.14s/it]{'loss': 47.4673, 'grad_norm': 1872.513916015625, 'learning_rate': 2.3340749988608916e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 6.004968643188477, 'weight_chosen': 2.937295436859131, 'weight_rejected': 1.1721373796463013, 'kl_term_chosen': -2.3852386474609375, 'kl_term_rejected': 0.17925873398780823, 'epoch': 0.7115256495669554}
                                                       {'loss': 47.4673, 'grad_norm': 1872.513916015625, 'learning_rate': 2.3340749988608916e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 6.004968643188477, 'weight_chosen': 2.937295436859131, 'weight_rejected': 1.1721373796463013, 'kl_term_chosen': -2.3852386474609375, 'kl_term_rejected': 0.17925873398780823, 'epoch': 0.71}
 71%|███████   | 2670/3753 [3:33:42<1:14:40,  4.14s/it] 71%|███████   | 2671/3753 [3:33:46<1:15:34,  4.19s/it] 71%|███████   | 2672/3753 [3:33:52<1:22:58,  4.61s/it] 71%|███████   | 2673/3753 [3:33:57<1:23:30,  4.64s/it] 71%|███████   | 2674/3753 [3:34:02<1:24:52,  4.72s/it] 71%|███████▏  | 2675/3753 [3:34:06<1:22:02,  4.57s/it] 71%|███████▏  | 2676/3753 [3:34:10<1:20:06,  4.46s/it] 71%|███████▏  | 2677/3753 [3:34:15<1:22:11,  4.58s/it] 71%|███████▏  | 2678/3753 [3:34:23<1:39:28,  5.55s/it] 71%|███████▏  | 2679/3753 [3:34:29<1:40:36,  5.62s/it] 71%|███████▏  | 2680/3753 [3:34:33<1:33:23,  5.22s/it]{'loss': 54.9284, 'grad_norm': 142.69625854492188, 'learning_rate': 2.2948396787831076e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.873218536376953, 'weight_rejected': 0.5765620470046997, 'kl_term_chosen': 10.789328575134277, 'kl_term_rejected': 0.5449432730674744, 'epoch': 0.7141905396402398}
                                                       {'loss': 54.9284, 'grad_norm': 142.69625854492188, 'learning_rate': 2.2948396787831076e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.873218536376953, 'weight_rejected': 0.5765620470046997, 'kl_term_chosen': 10.789328575134277, 'kl_term_rejected': 0.5449432730674744, 'epoch': 0.71}
 71%|███████▏  | 2680/3753 [3:34:33<1:33:23,  5.22s/it] 71%|███████▏  | 2681/3753 [3:34:38<1:32:32,  5.18s/it] 71%|███████▏  | 2682/3753 [3:34:42<1:28:04,  4.93s/it] 71%|███████▏  | 2683/3753 [3:34:46<1:20:41,  4.52s/it] 72%|███████▏  | 2684/3753 [3:34:51<1:25:48,  4.82s/it] 72%|███████▏  | 2685/3753 [3:34:56<1:22:40,  4.64s/it] 72%|███████▏  | 2686/3753 [3:35:00<1:21:58,  4.61s/it] 72%|███████▏  | 2687/3753 [3:35:03<1:15:03,  4.22s/it] 72%|███████▏  | 2688/3753 [3:35:11<1:34:28,  5.32s/it] 72%|███████▏  | 2689/3753 [3:35:15<1:27:04,  4.91s/it] 72%|███████▏  | 2690/3753 [3:35:21<1:31:03,  5.14s/it]{'loss': 59.4357, 'grad_norm': 786.7720947265625, 'learning_rate': 2.25583847276752e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.5469512939453125, 'weight_rejected': 1.650712251663208, 'kl_term_chosen': 1.4763916730880737, 'kl_term_rejected': 1.585107445716858, 'epoch': 0.7168554297135243}
                                                       {'loss': 59.4357, 'grad_norm': 786.7720947265625, 'learning_rate': 2.25583847276752e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.5469512939453125, 'weight_rejected': 1.650712251663208, 'kl_term_chosen': 1.4763916730880737, 'kl_term_rejected': 1.585107445716858, 'epoch': 0.72}
 72%|███████▏  | 2690/3753 [3:35:21<1:31:03,  5.14s/it] 72%|███████▏  | 2691/3753 [3:35:30<1:49:44,  6.20s/it] 72%|███████▏  | 2692/3753 [3:35:41<2:18:31,  7.83s/it] 72%|███████▏  | 2693/3753 [3:35:45<1:53:56,  6.45s/it] 72%|███████▏  | 2694/3753 [3:35:48<1:40:08,  5.67s/it] 72%|███████▏  | 2695/3753 [3:35:52<1:30:38,  5.14s/it] 72%|███████▏  | 2696/3753 [3:35:56<1:23:02,  4.71s/it] 72%|███████▏  | 2697/3753 [3:35:59<1:15:29,  4.29s/it] 72%|███████▏  | 2698/3753 [3:36:03<1:12:47,  4.14s/it] 72%|███████▏  | 2699/3753 [3:36:08<1:16:08,  4.33s/it] 72%|███████▏  | 2700/3753 [3:36:11<1:10:32,  4.02s/it]{'loss': 50.4401, 'grad_norm': 0.0, 'learning_rate': 2.2170747561152893e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.5693461894989014, 'weight_rejected': 1.4532395601272583, 'kl_term_chosen': 1.5197571516036987, 'kl_term_rejected': 1.3940292596817017, 'epoch': 0.7195203197868087}
                                                       {'loss': 50.4401, 'grad_norm': 0.0, 'learning_rate': 2.2170747561152893e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.5693461894989014, 'weight_rejected': 1.4532395601272583, 'kl_term_chosen': 1.5197571516036987, 'kl_term_rejected': 1.3940292596817017, 'epoch': 0.72}
 72%|███████▏  | 2700/3753 [3:36:11<1:10:32,  4.02s/it] 72%|███████▏  | 2701/3753 [3:36:18<1:23:38,  4.77s/it] 72%|███████▏  | 2702/3753 [3:36:22<1:20:09,  4.58s/it] 72%|███████▏  | 2703/3753 [3:36:25<1:11:56,  4.11s/it] 72%|███████▏  | 2704/3753 [3:36:29<1:11:09,  4.07s/it] 72%|███████▏  | 2705/3753 [3:36:33<1:09:33,  3.98s/it] 72%|███████▏  | 2706/3753 [3:36:36<1:06:11,  3.79s/it] 72%|███████▏  | 2707/3753 [3:36:41<1:14:41,  4.28s/it] 72%|███████▏  | 2708/3753 [3:36:46<1:18:33,  4.51s/it] 72%|███████▏  | 2709/3753 [3:36:50<1:13:17,  4.21s/it] 72%|███████▏  | 2710/3753 [3:36:55<1:15:31,  4.34s/it]{'loss': 55.445, 'grad_norm': 1569.239501953125, 'learning_rate': 2.1785518835744148e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.8892500400543213, 'weight_rejected': 1.5659383535385132, 'kl_term_chosen': 2.7615973949432373, 'kl_term_rejected': 1.4732506275177002, 'epoch': 0.7221852098600933}
                                                       {'loss': 55.445, 'grad_norm': 1569.239501953125, 'learning_rate': 2.1785518835744148e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.8892500400543213, 'weight_rejected': 1.5659383535385132, 'kl_term_chosen': 2.7615973949432373, 'kl_term_rejected': 1.4732506275177002, 'epoch': 0.72}
 72%|███████▏  | 2710/3753 [3:36:55<1:15:31,  4.34s/it] 72%|███████▏  | 2711/3753 [3:36:59<1:16:49,  4.42s/it] 72%|███████▏  | 2712/3753 [3:37:03<1:14:03,  4.27s/it] 72%|███████▏  | 2713/3753 [3:37:07<1:10:11,  4.05s/it] 72%|███████▏  | 2714/3753 [3:37:10<1:08:07,  3.93s/it] 72%|███████▏  | 2715/3753 [3:37:13<1:02:27,  3.61s/it] 72%|███████▏  | 2716/3753 [3:37:17<1:05:41,  3.80s/it] 72%|███████▏  | 2717/3753 [3:37:23<1:14:06,  4.29s/it] 72%|███████▏  | 2718/3753 [3:37:27<1:11:41,  4.16s/it] 72%|███████▏  | 2719/3753 [3:37:31<1:11:54,  4.17s/it] 72%|███████▏  | 2720/3753 [3:37:35<1:13:26,  4.27s/it]{'loss': 52.909, 'grad_norm': 943.7669677734375, 'learning_rate': 2.140273189049396e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.884497880935669, 'weight_rejected': -1.4880512952804565, 'kl_term_chosen': -2.799398899078369, 'kl_term_rejected': -2.39923095703125, 'epoch': 0.7248500999333778}
                                                       {'loss': 52.909, 'grad_norm': 943.7669677734375, 'learning_rate': 2.140273189049396e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.884497880935669, 'weight_rejected': -1.4880512952804565, 'kl_term_chosen': -2.799398899078369, 'kl_term_rejected': -2.39923095703125, 'epoch': 0.72}
 72%|███████▏  | 2720/3753 [3:37:35<1:13:26,  4.27s/it] 73%|███████▎  | 2721/3753 [3:37:39<1:10:54,  4.12s/it] 73%|███████▎  | 2722/3753 [3:37:43<1:08:54,  4.01s/it] 73%|███████▎  | 2723/3753 [3:37:47<1:11:25,  4.16s/it] 73%|███████▎  | 2724/3753 [3:37:51<1:10:02,  4.08s/it] 73%|███████▎  | 2725/3753 [3:37:59<1:30:30,  5.28s/it] 73%|███████▎  | 2726/3753 [3:38:03<1:24:19,  4.93s/it] 73%|███████▎  | 2727/3753 [3:38:11<1:39:11,  5.80s/it] 73%|███████▎  | 2728/3753 [3:38:17<1:39:08,  5.80s/it] 73%|███████▎  | 2729/3753 [3:38:21<1:31:26,  5.36s/it] 73%|███████▎  | 2730/3753 [3:38:25<1:22:19,  4.83s/it]{'loss': 53.7509, 'grad_norm': 0.0, 'learning_rate': 2.102241985312717e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.9369022846221924, 'weight_rejected': 3.7066404819488525, 'kl_term_chosen': 3.625370740890503, 'kl_term_rejected': 3.389214277267456, 'epoch': 0.7275149900066622}
                                                       {'loss': 53.7509, 'grad_norm': 0.0, 'learning_rate': 2.102241985312717e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.9369022846221924, 'weight_rejected': 3.7066404819488525, 'kl_term_chosen': 3.625370740890503, 'kl_term_rejected': 3.389214277267456, 'epoch': 0.73}
 73%|███████▎  | 2730/3753 [3:38:25<1:22:19,  4.83s/it] 73%|███████▎  | 2731/3753 [3:38:30<1:22:10,  4.82s/it] 73%|███████▎  | 2732/3753 [3:38:34<1:18:45,  4.63s/it] 73%|███████▎  | 2733/3753 [3:38:37<1:11:06,  4.18s/it] 73%|███████▎  | 2734/3753 [3:38:41<1:09:57,  4.12s/it] 73%|███████▎  | 2735/3753 [3:38:45<1:10:48,  4.17s/it] 73%|███████▎  | 2736/3753 [3:38:49<1:09:26,  4.10s/it] 73%|███████▎  | 2737/3753 [3:38:54<1:14:24,  4.39s/it] 73%|███████▎  | 2738/3753 [3:38:59<1:13:10,  4.33s/it] 73%|███████▎  | 2739/3753 [3:39:03<1:13:07,  4.33s/it] 73%|███████▎  | 2740/3753 [3:39:06<1:09:07,  4.09s/it]{'loss': 52.574, 'grad_norm': 275.6929626464844, 'learning_rate': 2.064461563718139e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.45407193899154663, 'weight_rejected': 2.0066261291503906, 'kl_term_chosen': 0.8694450259208679, 'kl_term_rejected': 1.4177368879318237, 'epoch': 0.7301798800799467}
                                                       {'loss': 52.574, 'grad_norm': 275.6929626464844, 'learning_rate': 2.064461563718139e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.45407193899154663, 'weight_rejected': 2.0066261291503906, 'kl_term_chosen': 0.8694450259208679, 'kl_term_rejected': 1.4177368879318237, 'epoch': 0.73}
 73%|███████▎  | 2740/3753 [3:39:07<1:09:07,  4.09s/it] 73%|███████▎  | 2741/3753 [3:39:11<1:12:44,  4.31s/it] 73%|███████▎  | 2742/3753 [3:39:15<1:09:01,  4.10s/it] 73%|███████▎  | 2743/3753 [3:39:22<1:25:14,  5.06s/it] 73%|███████▎  | 2744/3753 [3:39:26<1:20:49,  4.81s/it] 73%|███████▎  | 2745/3753 [3:39:30<1:16:27,  4.55s/it] 73%|███████▎  | 2746/3753 [3:39:36<1:23:38,  4.98s/it] 73%|███████▎  | 2747/3753 [3:39:44<1:39:17,  5.92s/it] 73%|███████▎  | 2748/3753 [3:39:49<1:31:00,  5.43s/it] 73%|███████▎  | 2749/3753 [3:39:52<1:21:38,  4.88s/it] 73%|███████▎  | 2750/3753 [3:39:56<1:15:24,  4.51s/it]{'loss': 53.6173, 'grad_norm': 96.21133422851562, 'learning_rate': 2.0269351939158574e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.51253342628479, 'weight_rejected': -6.349945068359375, 'kl_term_chosen': -2.441973924636841, 'kl_term_rejected': -7.199916362762451, 'epoch': 0.7328447701532311}
                                                       {'loss': 53.6173, 'grad_norm': 96.21133422851562, 'learning_rate': 2.0269351939158574e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.51253342628479, 'weight_rejected': -6.349945068359375, 'kl_term_chosen': -2.441973924636841, 'kl_term_rejected': -7.199916362762451, 'epoch': 0.73}
 73%|███████▎  | 2750/3753 [3:39:56<1:15:24,  4.51s/it] 73%|███████▎  | 2751/3753 [3:40:00<1:14:54,  4.49s/it] 73%|███████▎  | 2752/3753 [3:40:05<1:15:48,  4.54s/it] 73%|███████▎  | 2753/3753 [3:40:10<1:15:17,  4.52s/it] 73%|███████▎  | 2754/3753 [3:40:13<1:10:53,  4.26s/it] 73%|███████▎  | 2755/3753 [3:40:19<1:18:48,  4.74s/it] 73%|███████▎  | 2756/3753 [3:40:24<1:17:04,  4.64s/it] 73%|███████▎  | 2757/3753 [3:40:28<1:14:21,  4.48s/it] 73%|███████▎  | 2758/3753 [3:40:32<1:12:37,  4.38s/it] 74%|███████▎  | 2759/3753 [3:40:35<1:07:13,  4.06s/it] 74%|███████▎  | 2760/3753 [3:40:40<1:12:09,  4.36s/it]{'loss': 58.8468, 'grad_norm': 895.5578002929688, 'learning_rate': 1.9896661235695295e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 2.4348154067993164, 'weight_rejected': 1.3005313873291016, 'kl_term_chosen': -1.9567737579345703, 'kl_term_rejected': 0.35887718200683594, 'epoch': 0.7355096602265156}
                                                       {'loss': 58.8468, 'grad_norm': 895.5578002929688, 'learning_rate': 1.9896661235695295e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 2.4348154067993164, 'weight_rejected': 1.3005313873291016, 'kl_term_chosen': -1.9567737579345703, 'kl_term_rejected': 0.35887718200683594, 'epoch': 0.74}
 74%|███████▎  | 2760/3753 [3:40:40<1:12:09,  4.36s/it] 74%|███████▎  | 2761/3753 [3:40:48<1:28:54,  5.38s/it] 74%|███████▎  | 2762/3753 [3:40:52<1:24:44,  5.13s/it] 74%|███████▎  | 2763/3753 [3:40:57<1:20:03,  4.85s/it] 74%|███████▎  | 2764/3753 [3:41:02<1:22:10,  4.98s/it] 74%|███████▎  | 2765/3753 [3:41:06<1:15:25,  4.58s/it] 74%|███████▎  | 2766/3753 [3:41:10<1:12:32,  4.41s/it] 74%|███████▎  | 2767/3753 [3:41:14<1:10:09,  4.27s/it] 74%|███████▍  | 2768/3753 [3:41:18<1:10:26,  4.29s/it] 74%|███████▍  | 2769/3753 [3:41:23<1:12:34,  4.43s/it] 74%|███████▍  | 2770/3753 [3:41:26<1:09:46,  4.26s/it]{'loss': 52.5786, 'grad_norm': 16.641447067260742, 'learning_rate': 1.9526575780752242e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.505718231201172, 'weight_rejected': 0.3887939751148224, 'kl_term_chosen': 9.419394493103027, 'kl_term_rejected': 0.31720277667045593, 'epoch': 0.7381745502998002}
                                                       {'loss': 52.5786, 'grad_norm': 16.641447067260742, 'learning_rate': 1.9526575780752242e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.505718231201172, 'weight_rejected': 0.3887939751148224, 'kl_term_chosen': 9.419394493103027, 'kl_term_rejected': 0.31720277667045593, 'epoch': 0.74}
 74%|███████▍  | 2770/3753 [3:41:27<1:09:46,  4.26s/it] 74%|███████▍  | 2771/3753 [3:41:30<1:05:45,  4.02s/it] 74%|███████▍  | 2772/3753 [3:41:37<1:18:27,  4.80s/it] 74%|███████▍  | 2773/3753 [3:41:41<1:15:27,  4.62s/it] 74%|███████▍  | 2774/3753 [3:41:45<1:12:48,  4.46s/it] 74%|███████▍  | 2775/3753 [3:41:49<1:10:50,  4.35s/it] 74%|███████▍  | 2776/3753 [3:41:53<1:09:36,  4.27s/it] 74%|███████▍  | 2777/3753 [3:41:58<1:12:19,  4.45s/it] 74%|███████▍  | 2778/3753 [3:42:01<1:08:04,  4.19s/it] 74%|███████▍  | 2779/3753 [3:42:05<1:06:24,  4.09s/it] 74%|███████▍  | 2780/3753 [3:42:09<1:05:58,  4.07s/it]{'loss': 54.0683, 'grad_norm': 24.859819412231445, 'learning_rate': 1.9159127602822717e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.228002071380615, 'weight_rejected': -5.688587665557861, 'kl_term_chosen': -3.771350145339966, 'kl_term_rejected': -6.321998119354248, 'epoch': 0.7408394403730846}
                                                       {'loss': 54.0683, 'grad_norm': 24.859819412231445, 'learning_rate': 1.9159127602822717e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.228002071380615, 'weight_rejected': -5.688587665557861, 'kl_term_chosen': -3.771350145339966, 'kl_term_rejected': -6.321998119354248, 'epoch': 0.74}
 74%|███████▍  | 2780/3753 [3:42:09<1:05:58,  4.07s/it] 74%|███████▍  | 2781/3753 [3:42:14<1:07:22,  4.16s/it] 74%|███████▍  | 2782/3753 [3:42:18<1:05:42,  4.06s/it] 74%|███████▍  | 2783/3753 [3:42:21<1:04:24,  3.98s/it] 74%|███████▍  | 2784/3753 [3:42:29<1:20:24,  4.98s/it] 74%|███████▍  | 2785/3753 [3:42:34<1:20:53,  5.01s/it] 74%|███████▍  | 2786/3753 [3:42:38<1:15:43,  4.70s/it] 74%|███████▍  | 2787/3753 [3:42:41<1:11:02,  4.41s/it] 74%|███████▍  | 2788/3753 [3:42:46<1:12:52,  4.53s/it] 74%|███████▍  | 2789/3753 [3:42:50<1:08:26,  4.26s/it] 74%|███████▍  | 2790/3753 [3:42:53<1:03:53,  3.98s/it]{'loss': 52.4299, 'grad_norm': 99.01274108886719, 'learning_rate': 1.8794348502160772e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.06764531135559082, 'weight_rejected': 0.4988226890563965, 'kl_term_chosen': 0.8268707394599915, 'kl_term_rejected': 0.3385566771030426, 'epoch': 0.7435043304463691}
                                                       {'loss': 52.4299, 'grad_norm': 99.01274108886719, 'learning_rate': 1.8794348502160772e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.06764531135559082, 'weight_rejected': 0.4988226890563965, 'kl_term_chosen': 0.8268707394599915, 'kl_term_rejected': 0.3385566771030426, 'epoch': 0.74}
 74%|███████▍  | 2790/3753 [3:42:53<1:03:53,  3.98s/it] 74%|███████▍  | 2791/3753 [3:42:59<1:13:26,  4.58s/it] 74%|███████▍  | 2792/3753 [3:43:04<1:16:32,  4.78s/it] 74%|███████▍  | 2793/3753 [3:43:09<1:15:06,  4.69s/it] 74%|███████▍  | 2794/3753 [3:43:13<1:12:49,  4.56s/it] 74%|███████▍  | 2795/3753 [3:43:17<1:10:15,  4.40s/it] 75%|███████▍  | 2796/3753 [3:43:22<1:11:20,  4.47s/it] 75%|███████▍  | 2797/3753 [3:43:26<1:11:38,  4.50s/it] 75%|███████▍  | 2798/3753 [3:43:30<1:08:18,  4.29s/it] 75%|███████▍  | 2799/3753 [3:43:35<1:08:18,  4.30s/it] 75%|███████▍  | 2800/3753 [3:43:38<1:04:56,  4.09s/it]{'loss': 55.2869, 'grad_norm': 67.36006164550781, 'learning_rate': 1.843227004802922e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.229136943817139, 'weight_rejected': 2.6393659114837646, 'kl_term_chosen': 4.821331977844238, 'kl_term_rejected': 2.41666579246521, 'epoch': 0.7461692205196535}
                                                       {'loss': 55.2869, 'grad_norm': 67.36006164550781, 'learning_rate': 1.843227004802922e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.229136943817139, 'weight_rejected': 2.6393659114837646, 'kl_term_chosen': 4.821331977844238, 'kl_term_rejected': 2.41666579246521, 'epoch': 0.75}
 75%|███████▍  | 2800/3753 [3:43:38<1:04:56,  4.09s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 75%|███████▍  | 2801/3753 [3:44:37<5:27:45, 20.66s/it] 75%|███████▍  | 2802/3753 [3:44:42<4:10:35, 15.81s/it] 75%|███████▍  | 2803/3753 [3:44:46<3:16:37, 12.42s/it] 75%|███████▍  | 2804/3753 [3:44:53<2:48:39, 10.66s/it] 75%|███████▍  | 2805/3753 [3:44:56<2:13:33,  8.45s/it] 75%|███████▍  | 2806/3753 [3:45:01<1:56:20,  7.37s/it] 75%|███████▍  | 2807/3753 [3:45:06<1:44:12,  6.61s/it] 75%|███████▍  | 2808/3753 [3:45:10<1:33:14,  5.92s/it] 75%|███████▍  | 2809/3753 [3:45:15<1:25:45,  5.45s/it] 75%|███████▍  | 2810/3753 [3:45:18<1:16:06,  4.84s/it]{'loss': 52.4456, 'grad_norm': 846.3848266601562, 'learning_rate': 1.8072923575967419e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.697216749191284, 'weight_rejected': 3.8006033897399902, 'kl_term_chosen': 3.2238030433654785, 'kl_term_rejected': 3.3190276622772217, 'epoch': 0.748834110592938}
                                                       {'loss': 52.4456, 'grad_norm': 846.3848266601562, 'learning_rate': 1.8072923575967419e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.697216749191284, 'weight_rejected': 3.8006033897399902, 'kl_term_chosen': 3.2238030433654785, 'kl_term_rejected': 3.3190276622772217, 'epoch': 0.75}
 75%|███████▍  | 2810/3753 [3:45:18<1:16:06,  4.84s/it] 75%|███████▍  | 2811/3753 [3:45:22<1:11:24,  4.55s/it] 75%|███████▍  | 2812/3753 [3:45:29<1:24:34,  5.39s/it] 75%|███████▍  | 2813/3753 [3:45:33<1:17:49,  4.97s/it] 75%|███████▍  | 2814/3753 [3:45:39<1:21:18,  5.20s/it] 75%|███████▌  | 2815/3753 [3:45:46<1:27:31,  5.60s/it] 75%|███████▌  | 2816/3753 [3:45:49<1:15:32,  4.84s/it] 75%|███████▌  | 2817/3753 [3:45:52<1:08:00,  4.36s/it] 75%|███████▌  | 2818/3753 [3:45:55<1:04:22,  4.13s/it] 75%|███████▌  | 2819/3753 [3:46:00<1:06:39,  4.28s/it] 75%|███████▌  | 2820/3753 [3:46:04<1:06:46,  4.29s/it]{'loss': 45.0926, 'grad_norm': 970.58251953125, 'learning_rate': 1.7716340185079442e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.937439918518066, 'weight_rejected': 3.5606396198272705, 'kl_term_chosen': 7.83074951171875, 'kl_term_rejected': 3.441436767578125, 'epoch': 0.7514990006662225}
                                                       {'loss': 45.0926, 'grad_norm': 970.58251953125, 'learning_rate': 1.7716340185079442e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.937439918518066, 'weight_rejected': 3.5606396198272705, 'kl_term_chosen': 7.83074951171875, 'kl_term_rejected': 3.441436767578125, 'epoch': 0.75}
 75%|███████▌  | 2820/3753 [3:46:05<1:06:46,  4.29s/it] 75%|███████▌  | 2821/3753 [3:46:08<1:03:38,  4.10s/it] 75%|███████▌  | 2822/3753 [3:46:16<1:20:13,  5.17s/it] 75%|███████▌  | 2823/3753 [3:46:19<1:11:38,  4.62s/it] 75%|███████▌  | 2824/3753 [3:46:23<1:09:50,  4.51s/it] 75%|███████▌  | 2825/3753 [3:46:28<1:11:21,  4.61s/it] 75%|███████▌  | 2826/3753 [3:46:33<1:12:18,  4.68s/it] 75%|███████▌  | 2827/3753 [3:46:38<1:12:10,  4.68s/it] 75%|███████▌  | 2828/3753 [3:46:45<1:25:30,  5.55s/it] 75%|███████▌  | 2829/3753 [3:46:49<1:18:07,  5.07s/it] 75%|███████▌  | 2830/3753 [3:46:53<1:10:22,  4.58s/it]{'loss': 48.6865, 'grad_norm': 1846.9326171875, 'learning_rate': 1.7362550735342575e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.335137128829956, 'weight_rejected': 8.830016136169434, 'kl_term_chosen': -0.524658203125, 'kl_term_rejected': 8.743692398071289, 'epoch': 0.754163890739507}
                                                       {'loss': 48.6865, 'grad_norm': 1846.9326171875, 'learning_rate': 1.7362550735342575e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.335137128829956, 'weight_rejected': 8.830016136169434, 'kl_term_chosen': -0.524658203125, 'kl_term_rejected': 8.743692398071289, 'epoch': 0.75}
 75%|███████▌  | 2830/3753 [3:46:53<1:10:22,  4.58s/it] 75%|███████▌  | 2831/3753 [3:46:57<1:10:09,  4.57s/it] 75%|███████▌  | 2832/3753 [3:47:02<1:10:52,  4.62s/it] 75%|███████▌  | 2833/3753 [3:47:06<1:09:27,  4.53s/it] 76%|███████▌  | 2834/3753 [3:47:10<1:07:16,  4.39s/it] 76%|███████▌  | 2835/3753 [3:47:14<1:05:24,  4.28s/it] 76%|███████▌  | 2836/3753 [3:47:20<1:11:47,  4.70s/it] 76%|███████▌  | 2837/3753 [3:47:24<1:08:18,  4.47s/it] 76%|███████▌  | 2838/3753 [3:47:27<1:03:15,  4.15s/it] 76%|███████▌  | 2839/3753 [3:47:33<1:10:55,  4.66s/it] 76%|███████▌  | 2840/3753 [3:47:41<1:27:17,  5.74s/it]{'loss': 47.8182, 'grad_norm': 1269.077880859375, 'learning_rate': 1.7011585844936675e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.490823268890381, 'weight_rejected': 2.6289772987365723, 'kl_term_chosen': 3.117861270904541, 'kl_term_rejected': 2.14849853515625, 'epoch': 0.7568287808127915}
                                                       {'loss': 47.8182, 'grad_norm': 1269.077880859375, 'learning_rate': 1.7011585844936675e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.490823268890381, 'weight_rejected': 2.6289772987365723, 'kl_term_chosen': 3.117861270904541, 'kl_term_rejected': 2.14849853515625, 'epoch': 0.76}
 76%|███████▌  | 2840/3753 [3:47:42<1:27:17,  5.74s/it] 76%|███████▌  | 2841/3753 [3:47:45<1:18:38,  5.17s/it] 76%|███████▌  | 2842/3753 [3:47:50<1:15:32,  4.98s/it] 76%|███████▌  | 2843/3753 [3:47:53<1:08:16,  4.50s/it] 76%|███████▌  | 2844/3753 [3:47:57<1:06:03,  4.36s/it] 76%|███████▌  | 2845/3753 [3:48:01<1:04:36,  4.27s/it] 76%|███████▌  | 2846/3753 [3:48:09<1:21:42,  5.40s/it] 76%|███████▌  | 2847/3753 [3:48:12<1:10:58,  4.70s/it] 76%|███████▌  | 2848/3753 [3:48:16<1:06:09,  4.39s/it] 76%|███████▌  | 2849/3753 [3:48:20<1:05:46,  4.37s/it] 76%|███████▌  | 2850/3753 [3:48:25<1:07:21,  4.48s/it]{'loss': 51.1957, 'grad_norm': 1093.43701171875, 'learning_rate': 1.666347588759433e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.5771491527557373, 'weight_rejected': 9.465872764587402, 'kl_term_chosen': 2.5398223400115967, 'kl_term_rejected': 9.430193901062012, 'epoch': 0.759493670886076}
                                                       {'loss': 51.1957, 'grad_norm': 1093.43701171875, 'learning_rate': 1.666347588759433e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.5771491527557373, 'weight_rejected': 9.465872764587402, 'kl_term_chosen': 2.5398223400115967, 'kl_term_rejected': 9.430193901062012, 'epoch': 0.76}
 76%|███████▌  | 2850/3753 [3:48:25<1:07:21,  4.48s/it] 76%|███████▌  | 2851/3753 [3:48:28<1:01:27,  4.09s/it] 76%|███████▌  | 2852/3753 [3:48:32<1:01:31,  4.10s/it] 76%|███████▌  | 2853/3753 [3:48:37<1:04:11,  4.28s/it] 76%|███████▌  | 2854/3753 [3:48:41<1:02:08,  4.15s/it] 76%|███████▌  | 2855/3753 [3:48:46<1:05:22,  4.37s/it] 76%|███████▌  | 2856/3753 [3:48:49<1:01:56,  4.14s/it] 76%|███████▌  | 2857/3753 [3:48:53<1:00:54,  4.08s/it] 76%|███████▌  | 2858/3753 [3:49:01<1:15:38,  5.07s/it] 76%|███████▌  | 2859/3753 [3:49:05<1:09:40,  4.68s/it] 76%|███████▌  | 2860/3753 [3:49:09<1:07:55,  4.56s/it]{'loss': 52.9485, 'grad_norm': 0.0, 'learning_rate': 1.6318250989972216e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.5429083704948425, 'weight_rejected': 1.1444765329360962, 'kl_term_chosen': 1.5117645263671875, 'kl_term_rejected': 1.0477707386016846, 'epoch': 0.7621585609593604}
                                                       {'loss': 52.9485, 'grad_norm': 0.0, 'learning_rate': 1.6318250989972216e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.5429083704948425, 'weight_rejected': 1.1444765329360962, 'kl_term_chosen': 1.5117645263671875, 'kl_term_rejected': 1.0477707386016846, 'epoch': 0.76}
 76%|███████▌  | 2860/3753 [3:49:09<1:07:55,  4.56s/it] 76%|███████▌  | 2861/3753 [3:49:12<1:03:07,  4.25s/it] 76%|███████▋  | 2862/3753 [3:49:16<1:02:23,  4.20s/it] 76%|███████▋  | 2863/3753 [3:49:21<1:02:14,  4.20s/it] 76%|███████▋  | 2864/3753 [3:49:24<57:47,  3.90s/it]   76%|███████▋  | 2865/3753 [3:49:28<59:37,  4.03s/it] 76%|███████▋  | 2866/3753 [3:49:32<59:12,  4.01s/it] 76%|███████▋  | 2867/3753 [3:49:36<57:51,  3.92s/it] 76%|███████▋  | 2868/3753 [3:49:41<1:04:57,  4.40s/it] 76%|███████▋  | 2869/3753 [3:49:45<1:00:34,  4.11s/it] 76%|███████▋  | 2870/3753 [3:49:49<1:00:44,  4.13s/it]{'loss': 44.2572, 'grad_norm': 1375.059326171875, 'learning_rate': 1.5975941029043772e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.7547900676727295, 'weight_rejected': 1.3802305459976196, 'kl_term_chosen': 3.675579786300659, 'kl_term_rejected': 1.310688853263855, 'epoch': 0.7648234510326449}
                                                       {'loss': 44.2572, 'grad_norm': 1375.059326171875, 'learning_rate': 1.5975941029043772e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.7547900676727295, 'weight_rejected': 1.3802305459976196, 'kl_term_chosen': 3.675579786300659, 'kl_term_rejected': 1.310688853263855, 'epoch': 0.76}
 76%|███████▋  | 2870/3753 [3:49:49<1:00:44,  4.13s/it] 76%|███████▋  | 2871/3753 [3:49:54<1:03:05,  4.29s/it] 77%|███████▋  | 2872/3753 [3:49:58<1:04:12,  4.37s/it] 77%|███████▋  | 2873/3753 [3:50:02<1:02:06,  4.23s/it] 77%|███████▋  | 2874/3753 [3:50:06<1:01:34,  4.20s/it] 77%|███████▋  | 2875/3753 [3:50:10<58:29,  4.00s/it]   77%|███████▋  | 2876/3753 [3:50:13<56:27,  3.86s/it] 77%|███████▋  | 2877/3753 [3:50:17<56:38,  3.88s/it] 77%|███████▋  | 2878/3753 [3:50:22<59:17,  4.07s/it] 77%|███████▋  | 2879/3753 [3:50:28<1:07:24,  4.63s/it] 77%|███████▋  | 2880/3753 [3:50:33<1:08:44,  4.72s/it]{'loss': 54.682, 'grad_norm': 0.0, 'learning_rate': 1.5636575629513632e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.6035492420196533, 'weight_rejected': -4.782968521118164, 'kl_term_chosen': -1.8794586658477783, 'kl_term_rejected': -5.661283016204834, 'epoch': 0.7674883411059293}
                                                       {'loss': 54.682, 'grad_norm': 0.0, 'learning_rate': 1.5636575629513632e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.6035492420196533, 'weight_rejected': -4.782968521118164, 'kl_term_chosen': -1.8794586658477783, 'kl_term_rejected': -5.661283016204834, 'epoch': 0.77}
 77%|███████▋  | 2880/3753 [3:50:33<1:08:44,  4.72s/it] 77%|███████▋  | 2881/3753 [3:50:37<1:06:40,  4.59s/it] 77%|███████▋  | 2882/3753 [3:50:42<1:07:43,  4.66s/it] 77%|███████▋  | 2883/3753 [3:50:47<1:08:56,  4.76s/it] 77%|███████▋  | 2884/3753 [3:50:51<1:06:51,  4.62s/it] 77%|███████▋  | 2885/3753 [3:50:55<1:04:55,  4.49s/it] 77%|███████▋  | 2886/3753 [3:51:00<1:05:21,  4.52s/it] 77%|███████▋  | 2887/3753 [3:51:04<1:05:48,  4.56s/it] 77%|███████▋  | 2888/3753 [3:51:09<1:04:15,  4.46s/it] 77%|███████▋  | 2889/3753 [3:51:13<1:03:19,  4.40s/it] 77%|███████▋  | 2890/3753 [3:51:16<59:45,  4.15s/it]  {'loss': 53.0993, 'grad_norm': 1915.8914794921875, 'learning_rate': 1.5300184161253766e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.5113391876220703, 'weight_rejected': 2.313286781311035, 'kl_term_chosen': -0.6195282340049744, 'kl_term_rejected': 2.2622039318084717, 'epoch': 0.7701532311792139}
                                                     {'loss': 53.0993, 'grad_norm': 1915.8914794921875, 'learning_rate': 1.5300184161253766e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.5113391876220703, 'weight_rejected': 2.313286781311035, 'kl_term_chosen': -0.6195282340049744, 'kl_term_rejected': 2.2622039318084717, 'epoch': 0.77}
 77%|███████▋  | 2890/3753 [3:51:17<59:45,  4.15s/it] 77%|███████▋  | 2891/3753 [3:51:21<1:02:00,  4.32s/it] 77%|███████▋  | 2892/3753 [3:51:26<1:04:13,  4.48s/it] 77%|███████▋  | 2893/3753 [3:51:31<1:05:40,  4.58s/it] 77%|███████▋  | 2894/3753 [3:51:34<59:24,  4.15s/it]   77%|███████▋  | 2895/3753 [3:51:38<58:58,  4.12s/it] 77%|███████▋  | 2896/3753 [3:51:43<1:00:43,  4.25s/it] 77%|███████▋  | 2897/3753 [3:51:46<58:57,  4.13s/it]   77%|███████▋  | 2898/3753 [3:51:52<1:03:15,  4.44s/it] 77%|███████▋  | 2899/3753 [3:51:58<1:12:39,  5.10s/it] 77%|███████▋  | 2900/3753 [3:52:02<1:06:14,  4.66s/it]{'loss': 53.2435, 'grad_norm': 355.41754150390625, 'learning_rate': 1.4966795736761668e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.003178834915161133, 'weight_rejected': 1.1483895778656006, 'kl_term_chosen': 0.9577728509902954, 'kl_term_rejected': 1.1063019037246704, 'epoch': 0.7728181212524984}
                                                       {'loss': 53.2435, 'grad_norm': 355.41754150390625, 'learning_rate': 1.4966795736761668e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.003178834915161133, 'weight_rejected': 1.1483895778656006, 'kl_term_chosen': 0.9577728509902954, 'kl_term_rejected': 1.1063019037246704, 'epoch': 0.77}
 77%|███████▋  | 2900/3753 [3:52:02<1:06:14,  4.66s/it] 77%|███████▋  | 2901/3753 [3:52:07<1:07:48,  4.78s/it] 77%|███████▋  | 2902/3753 [3:52:11<1:05:03,  4.59s/it] 77%|███████▋  | 2903/3753 [3:52:15<1:03:12,  4.46s/it] 77%|███████▋  | 2904/3753 [3:52:20<1:04:26,  4.55s/it] 77%|███████▋  | 2905/3753 [3:52:24<1:00:57,  4.31s/it] 77%|███████▋  | 2906/3753 [3:52:28<59:12,  4.19s/it]   77%|███████▋  | 2907/3753 [3:52:31<57:33,  4.08s/it] 77%|███████▋  | 2908/3753 [3:52:37<1:02:10,  4.42s/it] 78%|███████▊  | 2909/3753 [3:52:41<1:02:42,  4.46s/it] 78%|███████▊  | 2910/3753 [3:52:45<1:01:11,  4.36s/it]{'loss': 44.8013, 'grad_norm': 651.0288696289062, 'learning_rate': 1.4636439208640926e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.3852977752685547, 'weight_rejected': 1.2388126850128174, 'kl_term_chosen': 3.266094923019409, 'kl_term_rejected': 1.183807373046875, 'epoch': 0.7754830113257828}
                                                       {'loss': 44.8013, 'grad_norm': 651.0288696289062, 'learning_rate': 1.4636439208640926e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.3852977752685547, 'weight_rejected': 1.2388126850128174, 'kl_term_chosen': 3.266094923019409, 'kl_term_rejected': 1.183807373046875, 'epoch': 0.78}
 78%|███████▊  | 2910/3753 [3:52:45<1:01:11,  4.36s/it] 78%|███████▊  | 2911/3753 [3:52:49<59:22,  4.23s/it]   78%|███████▊  | 2912/3753 [3:52:53<56:27,  4.03s/it] 78%|███████▊  | 2913/3753 [3:52:57<55:44,  3.98s/it] 78%|███████▊  | 2914/3753 [3:53:02<59:33,  4.26s/it] 78%|███████▊  | 2915/3753 [3:53:05<55:49,  4.00s/it] 78%|███████▊  | 2916/3753 [3:53:13<1:11:38,  5.14s/it] 78%|███████▊  | 2917/3753 [3:53:17<1:09:02,  4.95s/it] 78%|███████▊  | 2918/3753 [3:53:21<1:04:55,  4.67s/it] 78%|███████▊  | 2919/3753 [3:53:27<1:08:57,  4.96s/it] 78%|███████▊  | 2920/3753 [3:53:30<1:02:37,  4.51s/it]{'loss': 58.2475, 'grad_norm': 323.9303894042969, 'learning_rate': 1.430914316710416e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.75057053565979, 'weight_rejected': 6.951639652252197, 'kl_term_chosen': 0.23492585122585297, 'kl_term_rejected': 6.932806491851807, 'epoch': 0.7781479013990673}
                                                       {'loss': 58.2475, 'grad_norm': 323.9303894042969, 'learning_rate': 1.430914316710416e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.75057053565979, 'weight_rejected': 6.951639652252197, 'kl_term_chosen': 0.23492585122585297, 'kl_term_rejected': 6.932806491851807, 'epoch': 0.78}
 78%|███████▊  | 2920/3753 [3:53:31<1:02:37,  4.51s/it] 78%|███████▊  | 2921/3753 [3:53:35<1:03:09,  4.55s/it] 78%|███████▊  | 2922/3753 [3:53:39<1:00:36,  4.38s/it] 78%|███████▊  | 2923/3753 [3:53:43<59:10,  4.28s/it]   78%|███████▊  | 2924/3753 [3:53:48<1:02:57,  4.56s/it] 78%|███████▊  | 2925/3753 [3:53:53<1:04:10,  4.65s/it] 78%|███████▊  | 2926/3753 [3:53:58<1:02:50,  4.56s/it] 78%|███████▊  | 2927/3753 [3:54:05<1:15:33,  5.49s/it] 78%|███████▊  | 2928/3753 [3:54:08<1:04:12,  4.67s/it] 78%|███████▊  | 2929/3753 [3:54:12<1:01:22,  4.47s/it] 78%|███████▊  | 2930/3753 [3:54:16<59:31,  4.34s/it]  {'loss': 55.3925, 'grad_norm': 0.0, 'learning_rate': 1.398493593749877e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.358115196228027, 'weight_rejected': 1.9309781789779663, 'kl_term_chosen': 10.255810737609863, 'kl_term_rejected': 1.843414306640625, 'epoch': 0.7808127914723517}
                                                     {'loss': 55.3925, 'grad_norm': 0.0, 'learning_rate': 1.398493593749877e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.358115196228027, 'weight_rejected': 1.9309781789779663, 'kl_term_chosen': 10.255810737609863, 'kl_term_rejected': 1.843414306640625, 'epoch': 0.78}
 78%|███████▊  | 2930/3753 [3:54:16<59:31,  4.34s/it] 78%|███████▊  | 2931/3753 [3:54:20<57:53,  4.23s/it] 78%|███████▊  | 2932/3753 [3:54:24<56:56,  4.16s/it] 78%|███████▊  | 2933/3753 [3:54:28<56:27,  4.13s/it] 78%|███████▊  | 2934/3753 [3:54:33<59:03,  4.33s/it] 78%|███████▊  | 2935/3753 [3:54:37<57:09,  4.19s/it] 78%|███████▊  | 2936/3753 [3:54:41<57:15,  4.20s/it] 78%|███████▊  | 2937/3753 [3:54:45<58:01,  4.27s/it] 78%|███████▊  | 2938/3753 [3:54:49<54:56,  4.04s/it] 78%|███████▊  | 2939/3753 [3:54:53<55:40,  4.10s/it] 78%|███████▊  | 2940/3753 [3:54:58<58:03,  4.29s/it]{'loss': 56.5955, 'grad_norm': 1881.36962890625, 'learning_rate': 1.3663845577855488e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.1158432960510254, 'weight_rejected': 11.259367942810059, 'kl_term_chosen': 2.9958176612854004, 'kl_term_rejected': 11.151179313659668, 'epoch': 0.7834776815456362}
                                                     {'loss': 56.5955, 'grad_norm': 1881.36962890625, 'learning_rate': 1.3663845577855488e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.1158432960510254, 'weight_rejected': 11.259367942810059, 'kl_term_chosen': 2.9958176612854004, 'kl_term_rejected': 11.151179313659668, 'epoch': 0.78}
 78%|███████▊  | 2940/3753 [3:54:58<58:03,  4.29s/it] 78%|███████▊  | 2941/3753 [3:55:02<56:20,  4.16s/it] 78%|███████▊  | 2942/3753 [3:55:06<54:55,  4.06s/it] 78%|███████▊  | 2943/3753 [3:55:12<1:04:41,  4.79s/it] 78%|███████▊  | 2944/3753 [3:55:18<1:10:43,  5.25s/it] 78%|███████▊  | 2945/3753 [3:55:23<1:06:32,  4.94s/it] 78%|███████▊  | 2946/3753 [3:55:28<1:06:33,  4.95s/it] 79%|███████▊  | 2947/3753 [3:55:31<1:01:05,  4.55s/it] 79%|███████▊  | 2948/3753 [3:55:35<58:42,  4.38s/it]   79%|███████▊  | 2949/3753 [3:55:40<58:53,  4.39s/it] 79%|███████▊  | 2950/3753 [3:55:43<56:35,  4.23s/it]{'loss': 50.8816, 'grad_norm': 228.889404296875, 'learning_rate': 1.3345899876460237e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.3119850754737854, 'weight_rejected': -0.5323852300643921, 'kl_term_chosen': 0.34818726778030396, 'kl_term_rejected': -0.862640380859375, 'epoch': 0.7861425716189208}
                                                     {'loss': 50.8816, 'grad_norm': 228.889404296875, 'learning_rate': 1.3345899876460237e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.3119850754737854, 'weight_rejected': -0.5323852300643921, 'kl_term_chosen': 0.34818726778030396, 'kl_term_rejected': -0.862640380859375, 'epoch': 0.79}
 79%|███████▊  | 2950/3753 [3:55:43<56:35,  4.23s/it] 79%|███████▊  | 2951/3753 [3:55:48<57:59,  4.34s/it] 79%|███████▊  | 2952/3753 [3:55:52<58:19,  4.37s/it] 79%|███████▊  | 2953/3753 [3:55:57<58:59,  4.42s/it] 79%|███████▊  | 2954/3753 [3:56:01<57:39,  4.33s/it] 79%|███████▊  | 2955/3753 [3:56:04<53:02,  3.99s/it] 79%|███████▉  | 2956/3753 [3:56:09<55:32,  4.18s/it] 79%|███████▉  | 2957/3753 [3:56:12<52:30,  3.96s/it] 79%|███████▉  | 2958/3753 [3:56:18<1:00:33,  4.57s/it] 79%|███████▉  | 2959/3753 [3:56:26<1:14:09,  5.60s/it] 79%|███████▉  | 2960/3753 [3:56:31<1:12:09,  5.46s/it]{'loss': 46.363, 'grad_norm': 0.0, 'learning_rate': 1.3031126349449168e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.0916780233383179, 'weight_rejected': 1.7476295232772827, 'kl_term_chosen': 1.922821044921875, 'kl_term_rejected': 1.6942261457443237, 'epoch': 0.7888074616922052}
                                                       {'loss': 46.363, 'grad_norm': 0.0, 'learning_rate': 1.3031126349449168e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.0916780233383179, 'weight_rejected': 1.7476295232772827, 'kl_term_chosen': 1.922821044921875, 'kl_term_rejected': 1.6942261457443237, 'epoch': 0.79}
 79%|███████▉  | 2960/3753 [3:56:32<1:12:09,  5.46s/it] 79%|███████▉  | 2961/3753 [3:56:36<1:09:16,  5.25s/it] 79%|███████▉  | 2962/3753 [3:56:39<1:00:28,  4.59s/it] 79%|███████▉  | 2963/3753 [3:56:43<58:23,  4.44s/it]   79%|███████▉  | 2964/3753 [3:56:47<56:28,  4.30s/it] 79%|███████▉  | 2965/3753 [3:56:52<56:49,  4.33s/it] 79%|███████▉  | 2966/3753 [3:56:57<1:01:10,  4.66s/it] 79%|███████▉  | 2967/3753 [3:57:02<1:02:14,  4.75s/it] 79%|███████▉  | 2968/3753 [3:57:06<57:39,  4.41s/it]   79%|███████▉  | 2969/3753 [3:57:09<54:56,  4.20s/it] 79%|███████▉  | 2970/3753 [3:57:15<58:42,  4.50s/it]{'loss': 53.8508, 'grad_norm': 2318.63623046875, 'learning_rate': 1.271955223842735e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.3076283931732178, 'weight_rejected': 10.777460098266602, 'kl_term_chosen': 2.28244948387146, 'kl_term_rejected': 10.743359565734863, 'epoch': 0.7914723517654897}
                                                     {'loss': 53.8508, 'grad_norm': 2318.63623046875, 'learning_rate': 1.271955223842735e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.3076283931732178, 'weight_rejected': 10.777460098266602, 'kl_term_chosen': 2.28244948387146, 'kl_term_rejected': 10.743359565734863, 'epoch': 0.79}
 79%|███████▉  | 2970/3753 [3:57:15<58:42,  4.50s/it] 79%|███████▉  | 2971/3753 [3:57:21<1:07:47,  5.20s/it] 79%|███████▉  | 2972/3753 [3:57:26<1:05:03,  5.00s/it] 79%|███████▉  | 2973/3753 [3:57:30<1:00:16,  4.64s/it] 79%|███████▉  | 2974/3753 [3:57:36<1:04:57,  5.00s/it] 79%|███████▉  | 2975/3753 [3:57:40<1:00:57,  4.70s/it] 79%|███████▉  | 2976/3753 [3:57:43<56:20,  4.35s/it]   79%|███████▉  | 2977/3753 [3:57:47<55:24,  4.28s/it] 79%|███████▉  | 2978/3753 [3:57:51<52:40,  4.08s/it] 79%|███████▉  | 2979/3753 [3:57:57<1:00:41,  4.71s/it] 79%|███████▉  | 2980/3753 [3:58:01<58:51,  4.57s/it]  {'loss': 47.1571, 'grad_norm': 3419.158935546875, 'learning_rate': 1.241120450811113e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.4488966464996338, 'weight_rejected': -1.1986089944839478, 'kl_term_chosen': 2.3673768043518066, 'kl_term_rejected': -1.2302277088165283, 'epoch': 0.7941372418387741}
                                                     {'loss': 47.1571, 'grad_norm': 3419.158935546875, 'learning_rate': 1.241120450811113e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -1.4488966464996338, 'weight_rejected': -1.1986089944839478, 'kl_term_chosen': 2.3673768043518066, 'kl_term_rejected': -1.2302277088165283, 'epoch': 0.79}
 79%|███████▉  | 2980/3753 [3:58:01<58:51,  4.57s/it] 79%|███████▉  | 2981/3753 [3:58:05<57:01,  4.43s/it] 79%|███████▉  | 2982/3753 [3:58:14<1:12:51,  5.67s/it] 79%|███████▉  | 2983/3753 [3:58:19<1:11:01,  5.53s/it] 80%|███████▉  | 2984/3753 [3:58:23<1:03:59,  4.99s/it] 80%|███████▉  | 2985/3753 [3:58:29<1:09:42,  5.45s/it] 80%|███████▉  | 2986/3753 [3:58:34<1:05:23,  5.12s/it] 80%|███████▉  | 2987/3753 [3:58:38<1:01:23,  4.81s/it] 80%|███████▉  | 2988/3753 [3:58:42<1:00:04,  4.71s/it] 80%|███████▉  | 2989/3753 [3:58:50<1:11:49,  5.64s/it] 80%|███████▉  | 2990/3753 [3:58:55<1:07:01,  5.27s/it]{'loss': 51.6736, 'grad_norm': 1403.645263671875, 'learning_rate': 1.2106109843994588e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.4008846282958984, 'weight_rejected': 3.6242434978485107, 'kl_term_chosen': 3.2508556842803955, 'kl_term_rejected': 3.4761962890625, 'epoch': 0.7968021319120586}
                                                       {'loss': 51.6736, 'grad_norm': 1403.645263671875, 'learning_rate': 1.2106109843994588e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.4008846282958984, 'weight_rejected': 3.6242434978485107, 'kl_term_chosen': 3.2508556842803955, 'kl_term_rejected': 3.4761962890625, 'epoch': 0.8}
 80%|███████▉  | 2990/3753 [3:58:55<1:07:01,  5.27s/it] 80%|███████▉  | 2991/3753 [3:58:59<1:03:24,  4.99s/it] 80%|███████▉  | 2992/3753 [3:59:02<55:07,  4.35s/it]   80%|███████▉  | 2993/3753 [3:59:06<56:01,  4.42s/it] 80%|███████▉  | 2994/3753 [3:59:12<1:02:07,  4.91s/it] 80%|███████▉  | 2995/3753 [3:59:16<57:32,  4.55s/it]   80%|███████▉  | 2996/3753 [3:59:21<56:51,  4.51s/it] 80%|███████▉  | 2997/3753 [3:59:29<1:13:31,  5.84s/it] 80%|███████▉  | 2998/3753 [3:59:34<1:08:01,  5.41s/it] 80%|███████▉  | 2999/3753 [3:59:37<1:00:53,  4.85s/it] 80%|███████▉  | 3000/3753 [3:59:41<57:11,  4.56s/it]  {'loss': 53.4797, 'grad_norm': 0.0, 'learning_rate': 1.1804294650040042e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.555729866027832, 'weight_rejected': -3.6094517707824707, 'kl_term_chosen': -1.6877959966659546, 'kl_term_rejected': -3.683148145675659, 'epoch': 0.7994670219853431}
                                                     {'loss': 53.4797, 'grad_norm': 0.0, 'learning_rate': 1.1804294650040042e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.555729866027832, 'weight_rejected': -3.6094517707824707, 'kl_term_chosen': -1.6877959966659546, 'kl_term_rejected': -3.683148145675659, 'epoch': 0.8}
 80%|███████▉  | 3000/3753 [3:59:41<57:11,  4.56s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 80%|███████▉  | 3001/3753 [4:00:39<4:15:29, 20.38s/it] 80%|███████▉  | 3002/3753 [4:00:43<3:15:09, 15.59s/it] 80%|████████  | 3003/3753 [4:00:50<2:41:51, 12.95s/it] 80%|████████  | 3004/3753 [4:00:54<2:08:24, 10.29s/it] 80%|████████  | 3005/3753 [4:00:59<1:49:35,  8.79s/it] 80%|████████  | 3006/3753 [4:01:08<1:49:04,  8.76s/it] 80%|████████  | 3007/3753 [4:01:13<1:33:58,  7.56s/it] 80%|████████  | 3008/3753 [4:01:17<1:20:55,  6.52s/it] 80%|████████  | 3009/3753 [4:01:21<1:13:23,  5.92s/it] 80%|████████  | 3010/3753 [4:01:25<1:05:46,  5.31s/it]{'loss': 56.468, 'grad_norm': 589.4550170898438, 'learning_rate': 1.1505785046392952e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.6588356494903564, 'weight_rejected': 0.6984631419181824, 'kl_term_chosen': 4.556530952453613, 'kl_term_rejected': 0.6524292230606079, 'epoch': 0.8021319120586275}
                                                       {'loss': 56.468, 'grad_norm': 589.4550170898438, 'learning_rate': 1.1505785046392952e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.6588356494903564, 'weight_rejected': 0.6984631419181824, 'kl_term_chosen': 4.556530952453613, 'kl_term_rejected': 0.6524292230606079, 'epoch': 0.8}
 80%|████████  | 3010/3753 [4:01:25<1:05:46,  5.31s/it] 80%|████████  | 3011/3753 [4:01:29<1:00:54,  4.93s/it] 80%|████████  | 3012/3753 [4:01:35<1:03:08,  5.11s/it] 80%|████████  | 3013/3753 [4:01:39<58:19,  4.73s/it]   80%|████████  | 3014/3753 [4:01:43<56:51,  4.62s/it] 80%|████████  | 3015/3753 [4:01:47<54:46,  4.45s/it] 80%|████████  | 3016/3753 [4:01:51<52:06,  4.24s/it] 80%|████████  | 3017/3753 [4:01:55<51:05,  4.16s/it] 80%|████████  | 3018/3753 [4:01:59<50:40,  4.14s/it] 80%|████████  | 3019/3753 [4:02:03<50:14,  4.11s/it] 80%|████████  | 3020/3753 [4:02:07<49:16,  4.03s/it]{'loss': 51.7527, 'grad_norm': 0.0, 'learning_rate': 1.1210606867121402e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.2796316146850586, 'weight_rejected': 1.582291841506958, 'kl_term_chosen': 4.163671016693115, 'kl_term_rejected': 1.4842125177383423, 'epoch': 0.8047968021319121}
                                                     {'loss': 51.7527, 'grad_norm': 0.0, 'learning_rate': 1.1210606867121402e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.2796316146850586, 'weight_rejected': 1.582291841506958, 'kl_term_chosen': 4.163671016693115, 'kl_term_rejected': 1.4842125177383423, 'epoch': 0.8}
 80%|████████  | 3020/3753 [4:02:07<49:16,  4.03s/it] 80%|████████  | 3021/3753 [4:02:14<1:01:55,  5.08s/it] 81%|████████  | 3022/3753 [4:02:19<1:02:03,  5.09s/it] 81%|████████  | 3023/3753 [4:02:23<57:03,  4.69s/it]   81%|████████  | 3024/3753 [4:02:27<53:52,  4.43s/it] 81%|████████  | 3025/3753 [4:02:33<58:06,  4.79s/it] 81%|████████  | 3026/3753 [4:02:38<59:59,  4.95s/it] 81%|████████  | 3027/3753 [4:02:42<57:55,  4.79s/it] 81%|████████  | 3028/3753 [4:02:46<53:31,  4.43s/it] 81%|████████  | 3029/3753 [4:02:50<52:48,  4.38s/it] 81%|████████  | 3030/3753 [4:02:54<51:52,  4.30s/it]{'loss': 50.4431, 'grad_norm': 904.1417236328125, 'learning_rate': 1.0918785657980328e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.0927109718322754, 'weight_rejected': 5.120283126831055, 'kl_term_chosen': 2.6825454235076904, 'kl_term_rejected': 4.826878547668457, 'epoch': 0.8074616922051966}
                                                     {'loss': 50.4431, 'grad_norm': 904.1417236328125, 'learning_rate': 1.0918785657980328e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.0927109718322754, 'weight_rejected': 5.120283126831055, 'kl_term_chosen': 2.6825454235076904, 'kl_term_rejected': 4.826878547668457, 'epoch': 0.81}
 81%|████████  | 3030/3753 [4:02:54<51:52,  4.30s/it] 81%|████████  | 3031/3753 [4:02:58<48:49,  4.06s/it] 81%|████████  | 3032/3753 [4:03:02<48:39,  4.05s/it] 81%|████████  | 3033/3753 [4:03:06<47:32,  3.96s/it] 81%|████████  | 3034/3753 [4:03:09<45:14,  3.78s/it] 81%|████████  | 3035/3753 [4:03:13<46:15,  3.87s/it] 81%|████████  | 3036/3753 [4:03:17<47:47,  4.00s/it] 81%|████████  | 3037/3753 [4:03:21<47:58,  4.02s/it] 81%|████████  | 3038/3753 [4:03:26<48:59,  4.11s/it] 81%|████████  | 3039/3753 [4:03:30<50:14,  4.22s/it] 81%|████████  | 3040/3753 [4:03:34<47:42,  4.01s/it]{'loss': 50.1629, 'grad_norm': 1391.9853515625, 'learning_rate': 1.0630346674200702e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.596982717514038, 'weight_rejected': 10.539362907409668, 'kl_term_chosen': 2.4324662685394287, 'kl_term_rejected': 10.435614585876465, 'epoch': 0.810126582278481}
                                                     {'loss': 50.1629, 'grad_norm': 1391.9853515625, 'learning_rate': 1.0630346674200702e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.596982717514038, 'weight_rejected': 10.539362907409668, 'kl_term_chosen': 2.4324662685394287, 'kl_term_rejected': 10.435614585876465, 'epoch': 0.81}
 81%|████████  | 3040/3753 [4:03:34<47:42,  4.01s/it] 81%|████████  | 3041/3753 [4:03:39<51:04,  4.30s/it] 81%|████████  | 3042/3753 [4:03:43<50:24,  4.25s/it] 81%|████████  | 3043/3753 [4:03:51<1:04:04,  5.41s/it] 81%|████████  | 3044/3753 [4:03:57<1:06:22,  5.62s/it] 81%|████████  | 3045/3753 [4:04:01<1:00:12,  5.10s/it] 81%|████████  | 3046/3753 [4:04:05<57:39,  4.89s/it]   81%|████████  | 3047/3753 [4:04:09<53:00,  4.50s/it] 81%|████████  | 3048/3753 [4:04:13<51:59,  4.42s/it] 81%|████████  | 3049/3753 [4:04:18<53:48,  4.59s/it] 81%|████████▏ | 3050/3753 [4:04:22<53:03,  4.53s/it]{'loss': 56.3374, 'grad_norm': 109.64788055419922, 'learning_rate': 1.0345314878303823e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.5349505543708801, 'weight_rejected': 9.859675407409668, 'kl_term_chosen': 0.3835296630859375, 'kl_term_rejected': 9.760205268859863, 'epoch': 0.8127914723517655}
                                                     {'loss': 56.3374, 'grad_norm': 109.64788055419922, 'learning_rate': 1.0345314878303823e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.5349505543708801, 'weight_rejected': 9.859675407409668, 'kl_term_chosen': 0.3835296630859375, 'kl_term_rejected': 9.760205268859863, 'epoch': 0.81}
 81%|████████▏ | 3050/3753 [4:04:23<53:03,  4.53s/it] 81%|████████▏ | 3051/3753 [4:04:26<49:27,  4.23s/it] 81%|████████▏ | 3052/3753 [4:04:31<51:35,  4.42s/it] 81%|████████▏ | 3053/3753 [4:04:34<48:49,  4.18s/it] 81%|████████▏ | 3054/3753 [4:04:39<51:26,  4.42s/it] 81%|████████▏ | 3055/3753 [4:04:43<47:11,  4.06s/it] 81%|████████▏ | 3056/3753 [4:04:47<49:28,  4.26s/it] 81%|████████▏ | 3057/3753 [4:04:52<50:58,  4.39s/it] 81%|████████▏ | 3058/3753 [4:04:57<53:59,  4.66s/it] 82%|████████▏ | 3059/3753 [4:05:01<49:44,  4.30s/it] 82%|████████▏ | 3060/3753 [4:05:06<52:01,  4.50s/it]{'loss': 49.4152, 'grad_norm': 29.928871154785156, 'learning_rate': 1.0063714937941025e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.3615052700042725, 'weight_rejected': 2.5345160961151123, 'kl_term_chosen': 4.243933200836182, 'kl_term_rejected': 2.4917938709259033, 'epoch': 0.8154563624250499}
                                                     {'loss': 49.4152, 'grad_norm': 29.928871154785156, 'learning_rate': 1.0063714937941025e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.3615052700042725, 'weight_rejected': 2.5345160961151123, 'kl_term_chosen': 4.243933200836182, 'kl_term_rejected': 2.4917938709259033, 'epoch': 0.82}
 82%|████████▏ | 3060/3753 [4:05:06<52:01,  4.50s/it] 82%|████████▏ | 3061/3753 [4:05:12<59:19,  5.14s/it] 82%|████████▏ | 3062/3753 [4:05:17<58:17,  5.06s/it] 82%|████████▏ | 3063/3753 [4:05:21<54:49,  4.77s/it] 82%|████████▏ | 3064/3753 [4:05:28<1:01:45,  5.38s/it] 82%|████████▏ | 3065/3753 [4:05:33<58:00,  5.06s/it]   82%|████████▏ | 3066/3753 [4:05:37<54:24,  4.75s/it] 82%|████████▏ | 3067/3753 [4:05:40<48:43,  4.26s/it] 82%|████████▏ | 3068/3753 [4:05:44<49:53,  4.37s/it] 82%|████████▏ | 3069/3753 [4:05:49<49:17,  4.32s/it] 82%|████████▏ | 3070/3753 [4:05:52<47:33,  4.18s/it]{'loss': 51.8802, 'grad_norm': 364.3356628417969, 'learning_rate': 9.785571223758826e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.39018988609313965, 'weight_rejected': 8.478866577148438, 'kl_term_chosen': 1.2804840803146362, 'kl_term_rejected': 8.394976615905762, 'epoch': 0.8181212524983345}
                                                     {'loss': 51.8802, 'grad_norm': 364.3356628417969, 'learning_rate': 9.785571223758826e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.39018988609313965, 'weight_rejected': 8.478866577148438, 'kl_term_chosen': 1.2804840803146362, 'kl_term_rejected': 8.394976615905762, 'epoch': 0.82}
 82%|████████▏ | 3070/3753 [4:05:52<47:33,  4.18s/it] 82%|████████▏ | 3071/3753 [4:05:57<50:44,  4.46s/it] 82%|████████▏ | 3072/3753 [4:06:03<53:45,  4.74s/it] 82%|████████▏ | 3073/3753 [4:06:08<54:24,  4.80s/it] 82%|████████▏ | 3074/3753 [4:06:12<51:18,  4.53s/it] 82%|████████▏ | 3075/3753 [4:06:18<57:06,  5.05s/it] 82%|████████▏ | 3076/3753 [4:06:22<52:57,  4.69s/it] 82%|████████▏ | 3077/3753 [4:06:26<50:07,  4.45s/it] 82%|████████▏ | 3078/3753 [4:06:31<53:19,  4.74s/it] 82%|████████▏ | 3079/3753 [4:06:35<50:51,  4.53s/it] 82%|████████▏ | 3080/3753 [4:06:41<53:32,  4.77s/it]{'loss': 56.1831, 'grad_norm': 776.40625, 'learning_rate': 9.510907807289814e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.9588561058044434, 'weight_rejected': 6.702579021453857, 'kl_term_chosen': 3.599491834640503, 'kl_term_rejected': 6.415611267089844, 'epoch': 0.820786142571619}
                                                     {'loss': 56.1831, 'grad_norm': 776.40625, 'learning_rate': 9.510907807289814e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.9588561058044434, 'weight_rejected': 6.702579021453857, 'kl_term_chosen': 3.599491834640503, 'kl_term_rejected': 6.415611267089844, 'epoch': 0.82}
 82%|████████▏ | 3080/3753 [4:06:41<53:32,  4.77s/it] 82%|████████▏ | 3081/3753 [4:06:44<47:31,  4.24s/it] 82%|████████▏ | 3082/3753 [4:06:47<46:24,  4.15s/it] 82%|████████▏ | 3083/3753 [4:06:52<49:03,  4.39s/it] 82%|████████▏ | 3084/3753 [4:06:57<51:15,  4.60s/it] 82%|████████▏ | 3085/3753 [4:07:01<47:11,  4.24s/it] 82%|████████▏ | 3086/3753 [4:07:04<44:34,  4.01s/it] 82%|████████▏ | 3087/3753 [4:07:08<44:14,  3.99s/it] 82%|████████▏ | 3088/3753 [4:07:13<45:50,  4.14s/it] 82%|████████▏ | 3089/3753 [4:07:17<46:58,  4.25s/it] 82%|████████▏ | 3090/3753 [4:07:21<45:10,  4.09s/it]{'loss': 56.9714, 'grad_norm': 38.92055130004883, 'learning_rate': 9.239748458869379e-08, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.300910711288452, 'weight_rejected': -1.9016554355621338, 'kl_term_chosen': -3.2902581691741943, 'kl_term_rejected': -2.8852524757385254, 'epoch': 0.8234510326449034}
                                                     {'loss': 56.9714, 'grad_norm': 38.92055130004883, 'learning_rate': 9.239748458869379e-08, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.300910711288452, 'weight_rejected': -1.9016554355621338, 'kl_term_chosen': -3.2902581691741943, 'kl_term_rejected': -2.8852524757385254, 'epoch': 0.82}
 82%|████████▏ | 3090/3753 [4:07:21<45:10,  4.09s/it] 82%|████████▏ | 3091/3753 [4:07:26<46:46,  4.24s/it] 82%|████████▏ | 3092/3753 [4:07:30<46:45,  4.24s/it] 82%|████████▏ | 3093/3753 [4:07:34<46:58,  4.27s/it] 82%|████████▏ | 3094/3753 [4:07:38<45:34,  4.15s/it] 82%|████████▏ | 3095/3753 [4:07:42<44:17,  4.04s/it] 82%|████████▏ | 3096/3753 [4:07:45<42:35,  3.89s/it] 83%|████████▎ | 3097/3753 [4:07:52<50:08,  4.59s/it] 83%|████████▎ | 3098/3753 [4:07:59<1:00:00,  5.50s/it] 83%|████████▎ | 3099/3753 [4:08:03<53:51,  4.94s/it]   83%|████████▎ | 3100/3753 [4:08:07<50:49,  4.67s/it]{'loss': 57.9662, 'grad_norm': 1497.919921875, 'learning_rate': 8.972116645578592e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.3698917627334595, 'weight_rejected': 9.932049751281738, 'kl_term_chosen': 0.573455810546875, 'kl_term_rejected': 9.840667724609375, 'epoch': 0.8261159227181879}
                                                     {'loss': 57.9662, 'grad_norm': 1497.919921875, 'learning_rate': 8.972116645578592e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.3698917627334595, 'weight_rejected': 9.932049751281738, 'kl_term_chosen': 0.573455810546875, 'kl_term_rejected': 9.840667724609375, 'epoch': 0.83}
 83%|████████▎ | 3100/3753 [4:08:07<50:49,  4.67s/it] 83%|████████▎ | 3101/3753 [4:08:15<1:00:41,  5.59s/it] 83%|████████▎ | 3102/3753 [4:08:19<56:01,  5.16s/it]   83%|████████▎ | 3103/3753 [4:08:23<54:22,  5.02s/it] 83%|████████▎ | 3104/3753 [4:08:28<52:09,  4.82s/it] 83%|████████▎ | 3105/3753 [4:08:33<54:41,  5.06s/it] 83%|████████▎ | 3106/3753 [4:08:38<51:24,  4.77s/it] 83%|████████▎ | 3107/3753 [4:08:42<50:32,  4.69s/it] 83%|████████▎ | 3108/3753 [4:08:46<48:47,  4.54s/it] 83%|████████▎ | 3109/3753 [4:08:50<45:34,  4.25s/it] 83%|████████▎ | 3110/3753 [4:08:53<42:51,  4.00s/it]{'loss': 52.7131, 'grad_norm': 1561.067626953125, 'learning_rate': 8.70803552921327e-08, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.640437602996826, 'weight_rejected': -0.9551132917404175, 'kl_term_chosen': -2.3297431468963623, 'kl_term_rejected': -1.7582870721817017, 'epoch': 0.8287808127914723}
                                                     {'loss': 52.7131, 'grad_norm': 1561.067626953125, 'learning_rate': 8.70803552921327e-08, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.640437602996826, 'weight_rejected': -0.9551132917404175, 'kl_term_chosen': -2.3297431468963623, 'kl_term_rejected': -1.7582870721817017, 'epoch': 0.83}
 83%|████████▎ | 3110/3753 [4:08:53<42:51,  4.00s/it] 83%|████████▎ | 3111/3753 [4:08:58<43:49,  4.10s/it] 83%|████████▎ | 3112/3753 [4:09:01<42:18,  3.96s/it] 83%|████████▎ | 3113/3753 [4:09:06<45:13,  4.24s/it] 83%|████████▎ | 3114/3753 [4:09:11<46:46,  4.39s/it] 83%|████████▎ | 3115/3753 [4:09:15<46:12,  4.35s/it] 83%|████████▎ | 3116/3753 [4:09:20<46:58,  4.42s/it] 83%|████████▎ | 3117/3753 [4:09:24<48:00,  4.53s/it] 83%|████████▎ | 3118/3753 [4:09:28<45:31,  4.30s/it] 83%|████████▎ | 3119/3753 [4:09:33<46:18,  4.38s/it] 83%|████████▎ | 3120/3753 [4:09:39<51:21,  4.87s/it]{'loss': 50.2566, 'grad_norm': 0.0, 'learning_rate': 8.447527964279455e-08, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.944605350494385, 'weight_rejected': -2.1516470909118652, 'kl_term_chosen': -3.995687961578369, 'kl_term_rejected': -2.2126221656799316, 'epoch': 0.8314457028647568}
                                                     {'loss': 50.2566, 'grad_norm': 0.0, 'learning_rate': 8.447527964279455e-08, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.944605350494385, 'weight_rejected': -2.1516470909118652, 'kl_term_chosen': -3.995687961578369, 'kl_term_rejected': -2.2126221656799316, 'epoch': 0.83}
 83%|████████▎ | 3120/3753 [4:09:39<51:21,  4.87s/it] 83%|████████▎ | 3121/3753 [4:09:43<49:58,  4.74s/it] 83%|████████▎ | 3122/3753 [4:09:49<52:58,  5.04s/it] 83%|████████▎ | 3123/3753 [4:09:53<49:37,  4.73s/it] 83%|████████▎ | 3124/3753 [4:09:57<48:53,  4.66s/it] 83%|████████▎ | 3125/3753 [4:10:02<47:23,  4.53s/it] 83%|████████▎ | 3126/3753 [4:10:05<44:29,  4.26s/it] 83%|████████▎ | 3127/3753 [4:10:10<44:46,  4.29s/it] 83%|████████▎ | 3128/3753 [4:10:14<45:00,  4.32s/it] 83%|████████▎ | 3129/3753 [4:10:18<42:33,  4.09s/it] 83%|████████▎ | 3130/3753 [4:10:22<42:29,  4.09s/it]{'loss': 49.0012, 'grad_norm': 168.0299530029297, 'learning_rate': 8.190616496015496e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.0619652271270752, 'weight_rejected': 1.8690149784088135, 'kl_term_chosen': 1.4749687910079956, 'kl_term_rejected': 1.3971832990646362, 'epoch': 0.8341105929380414}
                                                     {'loss': 49.0012, 'grad_norm': 168.0299530029297, 'learning_rate': 8.190616496015496e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.0619652271270752, 'weight_rejected': 1.8690149784088135, 'kl_term_chosen': 1.4749687910079956, 'kl_term_rejected': 1.3971832990646362, 'epoch': 0.83}
 83%|████████▎ | 3130/3753 [4:10:22<42:29,  4.09s/it] 83%|████████▎ | 3131/3753 [4:10:26<41:55,  4.04s/it] 83%|████████▎ | 3132/3753 [4:10:30<42:50,  4.14s/it] 83%|████████▎ | 3133/3753 [4:10:34<40:43,  3.94s/it] 84%|████████▎ | 3134/3753 [4:10:38<41:53,  4.06s/it] 84%|████████▎ | 3135/3753 [4:10:42<41:56,  4.07s/it] 84%|████████▎ | 3136/3753 [4:10:46<40:51,  3.97s/it] 84%|████████▎ | 3137/3753 [4:10:50<43:10,  4.20s/it] 84%|████████▎ | 3138/3753 [4:10:56<45:56,  4.48s/it] 84%|████████▎ | 3139/3753 [4:10:59<43:00,  4.20s/it] 84%|████████▎ | 3140/3753 [4:11:04<43:54,  4.30s/it]{'loss': 57.4918, 'grad_norm': 20.397653579711914, 'learning_rate': 7.937323358440934e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.14922910928726196, 'weight_rejected': 1.4725186824798584, 'kl_term_chosen': 1.0425385236740112, 'kl_term_rejected': 1.3101387023925781, 'epoch': 0.8367754830113258}
                                                     {'loss': 57.4918, 'grad_norm': 20.397653579711914, 'learning_rate': 7.937323358440934e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.14922910928726196, 'weight_rejected': 1.4725186824798584, 'kl_term_chosen': 1.0425385236740112, 'kl_term_rejected': 1.3101387023925781, 'epoch': 0.84}
 84%|████████▎ | 3140/3753 [4:11:04<43:54,  4.30s/it] 84%|████████▎ | 3141/3753 [4:11:09<46:44,  4.58s/it] 84%|████████▎ | 3142/3753 [4:11:13<43:49,  4.30s/it] 84%|████████▎ | 3143/3753 [4:11:17<44:21,  4.36s/it] 84%|████████▍ | 3144/3753 [4:11:21<41:43,  4.11s/it] 84%|████████▍ | 3145/3753 [4:11:24<39:34,  3.91s/it] 84%|████████▍ | 3146/3753 [4:11:30<44:34,  4.41s/it] 84%|████████▍ | 3147/3753 [4:11:33<40:59,  4.06s/it] 84%|████████▍ | 3148/3753 [4:11:38<43:40,  4.33s/it] 84%|████████▍ | 3149/3753 [4:11:42<43:23,  4.31s/it] 84%|████████▍ | 3150/3753 [4:11:47<43:48,  4.36s/it]{'loss': 50.86, 'grad_norm': 1002.4295043945312, 'learning_rate': 7.687670472432328e-08, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.418605327606201, 'weight_rejected': -2.070591688156128, 'kl_term_chosen': -1.7284637689590454, 'kl_term_rejected': -2.4263665676116943, 'epoch': 0.8394403730846103}
                                                     {'loss': 50.86, 'grad_norm': 1002.4295043945312, 'learning_rate': 7.687670472432328e-08, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.418605327606201, 'weight_rejected': -2.070591688156128, 'kl_term_chosen': -1.7284637689590454, 'kl_term_rejected': -2.4263665676116943, 'epoch': 0.84}
 84%|████████▍ | 3150/3753 [4:11:47<43:48,  4.36s/it] 84%|████████▍ | 3151/3753 [4:11:51<44:38,  4.45s/it] 84%|████████▍ | 3152/3753 [4:11:55<42:56,  4.29s/it] 84%|████████▍ | 3153/3753 [4:11:59<41:04,  4.11s/it] 84%|████████▍ | 3154/3753 [4:12:02<37:58,  3.80s/it] 84%|████████▍ | 3155/3753 [4:12:06<37:54,  3.80s/it] 84%|████████▍ | 3156/3753 [4:12:09<36:58,  3.72s/it] 84%|████████▍ | 3157/3753 [4:12:14<39:36,  3.99s/it] 84%|████████▍ | 3158/3753 [4:12:18<39:16,  3.96s/it] 84%|████████▍ | 3159/3753 [4:12:21<38:23,  3.88s/it] 84%|████████▍ | 3160/3753 [4:12:28<46:16,  4.68s/it]{'loss': 55.5899, 'grad_norm': 505.6969299316406, 'learning_rate': 7.441679443826021e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -8.891138076782227, 'weight_rejected': -0.9618867039680481, 'kl_term_chosen': 9.452112197875977, 'kl_term_rejected': -1.4655029773712158, 'epoch': 0.8421052631578947}
                                                     {'loss': 55.5899, 'grad_norm': 505.6969299316406, 'learning_rate': 7.441679443826021e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -8.891138076782227, 'weight_rejected': -0.9618867039680481, 'kl_term_chosen': 9.452112197875977, 'kl_term_rejected': -1.4655029773712158, 'epoch': 0.84}
 84%|████████▍ | 3160/3753 [4:12:28<46:16,  4.68s/it] 84%|████████▍ | 3161/3753 [4:12:32<45:05,  4.57s/it] 84%|████████▍ | 3162/3753 [4:12:36<43:34,  4.42s/it] 84%|████████▍ | 3163/3753 [4:12:41<45:22,  4.61s/it] 84%|████████▍ | 3164/3753 [4:12:46<44:55,  4.58s/it] 84%|████████▍ | 3165/3753 [4:12:50<43:45,  4.47s/it] 84%|████████▍ | 3166/3753 [4:12:54<43:01,  4.40s/it] 84%|████████▍ | 3167/3753 [4:12:58<42:14,  4.33s/it] 84%|████████▍ | 3168/3753 [4:13:02<41:15,  4.23s/it] 84%|████████▍ | 3169/3753 [4:13:06<39:33,  4.06s/it] 84%|████████▍ | 3170/3753 [4:13:10<37:43,  3.88s/it]{'loss': 59.4126, 'grad_norm': 27.360031127929688, 'learning_rate': 7.199371561548422e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -7.681962490081787, 'weight_rejected': -1.471075415611267, 'kl_term_chosen': 8.599265098571777, 'kl_term_rejected': -1.5480362176895142, 'epoch': 0.8447701532311792}
                                                     {'loss': 59.4126, 'grad_norm': 27.360031127929688, 'learning_rate': 7.199371561548422e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -7.681962490081787, 'weight_rejected': -1.471075415611267, 'kl_term_chosen': 8.599265098571777, 'kl_term_rejected': -1.5480362176895142, 'epoch': 0.84}
 84%|████████▍ | 3170/3753 [4:13:10<37:43,  3.88s/it] 84%|████████▍ | 3171/3753 [4:13:14<40:13,  4.15s/it] 85%|████████▍ | 3172/3753 [4:13:21<47:50,  4.94s/it] 85%|████████▍ | 3173/3753 [4:13:25<43:20,  4.48s/it] 85%|████████▍ | 3174/3753 [4:13:28<41:03,  4.25s/it] 85%|████████▍ | 3175/3753 [4:13:31<37:51,  3.93s/it] 85%|████████▍ | 3176/3753 [4:13:36<38:45,  4.03s/it] 85%|████████▍ | 3177/3753 [4:13:38<34:44,  3.62s/it] 85%|████████▍ | 3178/3753 [4:13:42<35:16,  3.68s/it] 85%|████████▍ | 3179/3753 [4:13:50<46:26,  4.85s/it] 85%|████████▍ | 3180/3753 [4:13:55<46:22,  4.86s/it]{'loss': 47.8755, 'grad_norm': 219.73870849609375, 'learning_rate': 6.960767795773531e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.8917787075042725, 'weight_rejected': 2.8014752864837646, 'kl_term_chosen': 2.6510040760040283, 'kl_term_rejected': 2.753338575363159, 'epoch': 0.8474350433044637}
                                                     {'loss': 47.8755, 'grad_norm': 219.73870849609375, 'learning_rate': 6.960767795773531e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.8917787075042725, 'weight_rejected': 2.8014752864837646, 'kl_term_chosen': 2.6510040760040283, 'kl_term_rejected': 2.753338575363159, 'epoch': 0.85}
 85%|████████▍ | 3180/3753 [4:13:55<46:22,  4.86s/it] 85%|████████▍ | 3181/3753 [4:13:59<44:47,  4.70s/it] 85%|████████▍ | 3182/3753 [4:14:04<44:36,  4.69s/it] 85%|████████▍ | 3183/3753 [4:14:08<43:49,  4.61s/it] 85%|████████▍ | 3184/3753 [4:14:12<41:37,  4.39s/it] 85%|████████▍ | 3185/3753 [4:14:18<45:27,  4.80s/it] 85%|████████▍ | 3186/3753 [4:14:22<44:01,  4.66s/it] 85%|████████▍ | 3187/3753 [4:14:27<43:57,  4.66s/it] 85%|████████▍ | 3188/3753 [4:14:34<50:04,  5.32s/it] 85%|████████▍ | 3189/3753 [4:14:37<45:28,  4.84s/it] 85%|████████▍ | 3190/3753 [4:14:41<42:47,  4.56s/it]{'loss': 58.3128, 'grad_norm': 10.348857879638672, 'learning_rate': 6.725888796108115e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.256467819213867, 'weight_rejected': 0.6219411492347717, 'kl_term_chosen': 3.064534902572632, 'kl_term_rejected': 0.5817031860351562, 'epoch': 0.8500999333777481}
                                                     {'loss': 58.3128, 'grad_norm': 10.348857879638672, 'learning_rate': 6.725888796108115e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.256467819213867, 'weight_rejected': 0.6219411492347717, 'kl_term_chosen': 3.064534902572632, 'kl_term_rejected': 0.5817031860351562, 'epoch': 0.85}
 85%|████████▍ | 3190/3753 [4:14:41<42:47,  4.56s/it] 85%|████████▌ | 3191/3753 [4:14:45<39:45,  4.24s/it] 85%|████████▌ | 3192/3753 [4:14:49<38:56,  4.17s/it] 85%|████████▌ | 3193/3753 [4:14:53<38:26,  4.12s/it] 85%|████████▌ | 3194/3753 [4:14:57<38:56,  4.18s/it] 85%|████████▌ | 3195/3753 [4:15:00<36:45,  3.95s/it] 85%|████████▌ | 3196/3753 [4:15:04<36:14,  3.90s/it] 85%|████████▌ | 3197/3753 [4:15:09<37:09,  4.01s/it] 85%|████████▌ | 3198/3753 [4:15:13<37:54,  4.10s/it] 85%|████████▌ | 3199/3753 [4:15:18<39:26,  4.27s/it] 85%|████████▌ | 3200/3753 [4:15:21<37:40,  4.09s/it]{'loss': 53.9094, 'grad_norm': 473.6029357910156, 'learning_rate': 6.494754889804587e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -7.61203670501709, 'weight_rejected': -1.8090591430664062, 'kl_term_chosen': 8.297143936157227, 'kl_term_rejected': -2.012133836746216, 'epoch': 0.8527648234510327}
                                                     {'loss': 53.9094, 'grad_norm': 473.6029357910156, 'learning_rate': 6.494754889804587e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -7.61203670501709, 'weight_rejected': -1.8090591430664062, 'kl_term_chosen': 8.297143936157227, 'kl_term_rejected': -2.012133836746216, 'epoch': 0.85}
 85%|████████▌ | 3200/3753 [4:15:21<37:40,  4.09s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 85%|████████▌ | 3201/3753 [4:16:18<3:04:16, 20.03s/it] 85%|████████▌ | 3202/3753 [4:16:23<2:20:07, 15.26s/it] 85%|████████▌ | 3203/3753 [4:16:28<1:52:47, 12.30s/it] 85%|████████▌ | 3204/3753 [4:16:32<1:29:50,  9.82s/it] 85%|████████▌ | 3205/3753 [4:16:40<1:23:47,  9.17s/it] 85%|████████▌ | 3206/3753 [4:16:44<1:10:09,  7.70s/it] 85%|████████▌ | 3207/3753 [4:16:49<1:02:29,  6.87s/it] 85%|████████▌ | 3208/3753 [4:16:53<55:16,  6.09s/it]   86%|████████▌ | 3209/3753 [4:16:57<50:26,  5.56s/it] 86%|████████▌ | 3210/3753 [4:17:02<48:23,  5.35s/it]{'loss': 56.7266, 'grad_norm': 1321.2822265625, 'learning_rate': 6.26738608000189e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.612803041934967, 'weight_rejected': 10.661760330200195, 'kl_term_chosen': 0.25779420137405396, 'kl_term_rejected': 10.584799766540527, 'epoch': 0.8554297135243171}
                                                     {'loss': 56.7266, 'grad_norm': 1321.2822265625, 'learning_rate': 6.26738608000189e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.612803041934967, 'weight_rejected': 10.661760330200195, 'kl_term_chosen': 0.25779420137405396, 'kl_term_rejected': 10.584799766540527, 'epoch': 0.86}
 86%|████████▌ | 3210/3753 [4:17:02<48:23,  5.35s/it] 86%|████████▌ | 3211/3753 [4:17:07<46:10,  5.11s/it] 86%|████████▌ | 3212/3753 [4:17:15<53:14,  5.91s/it] 86%|████████▌ | 3213/3753 [4:17:20<51:13,  5.69s/it] 86%|████████▌ | 3214/3753 [4:17:24<46:04,  5.13s/it] 86%|████████▌ | 3215/3753 [4:17:31<51:43,  5.77s/it] 86%|████████▌ | 3216/3753 [4:17:38<54:36,  6.10s/it] 86%|████████▌ | 3217/3753 [4:17:44<55:51,  6.25s/it] 86%|████████▌ | 3218/3753 [4:17:49<52:26,  5.88s/it] 86%|████████▌ | 3219/3753 [4:17:53<45:46,  5.14s/it] 86%|████████▌ | 3220/3753 [4:17:56<40:36,  4.57s/it]{'loss': 55.04, 'grad_norm': 116.9482421875, 'learning_rate': 6.043802043994295e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.2036213874816895, 'weight_rejected': 1.3091859817504883, 'kl_term_chosen': 2.1148011684417725, 'kl_term_rejected': 1.191613793373108, 'epoch': 0.8580946035976016}
                                                     {'loss': 55.04, 'grad_norm': 116.9482421875, 'learning_rate': 6.043802043994295e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.2036213874816895, 'weight_rejected': 1.3091859817504883, 'kl_term_chosen': 2.1148011684417725, 'kl_term_rejected': 1.191613793373108, 'epoch': 0.86}
 86%|████████▌ | 3220/3753 [4:17:56<40:36,  4.57s/it] 86%|████████▌ | 3221/3753 [4:18:00<38:28,  4.34s/it] 86%|████████▌ | 3222/3753 [4:18:03<35:48,  4.05s/it] 86%|████████▌ | 3223/3753 [4:18:09<40:06,  4.54s/it] 86%|████████▌ | 3224/3753 [4:18:13<38:44,  4.39s/it] 86%|████████▌ | 3225/3753 [4:18:17<38:30,  4.38s/it] 86%|████████▌ | 3226/3753 [4:18:22<38:43,  4.41s/it] 86%|████████▌ | 3227/3753 [4:18:26<37:46,  4.31s/it] 86%|████████▌ | 3228/3753 [4:18:29<35:43,  4.08s/it] 86%|████████▌ | 3229/3753 [4:18:34<37:41,  4.32s/it] 86%|████████▌ | 3230/3753 [4:18:38<36:50,  4.23s/it]{'loss': 51.7318, 'grad_norm': 0.0, 'learning_rate': 5.8240221315284667e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -10.194247245788574, 'weight_rejected': -2.505101203918457, 'kl_term_chosen': 11.064844131469727, 'kl_term_rejected': -2.5914247035980225, 'epoch': 0.8607594936708861}
                                                     {'loss': 51.7318, 'grad_norm': 0.0, 'learning_rate': 5.8240221315284667e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -10.194247245788574, 'weight_rejected': -2.505101203918457, 'kl_term_chosen': 11.064844131469727, 'kl_term_rejected': -2.5914247035980225, 'epoch': 0.86}
 86%|████████▌ | 3230/3753 [4:18:38<36:50,  4.23s/it] 86%|████████▌ | 3231/3753 [4:18:43<37:58,  4.37s/it] 86%|████████▌ | 3232/3753 [4:18:47<36:33,  4.21s/it] 86%|████████▌ | 3233/3753 [4:18:51<37:44,  4.35s/it] 86%|████████▌ | 3234/3753 [4:18:55<36:27,  4.22s/it] 86%|████████▌ | 3235/3753 [4:18:59<34:43,  4.02s/it] 86%|████████▌ | 3236/3753 [4:19:03<35:26,  4.11s/it] 86%|████████▋ | 3237/3753 [4:19:07<33:39,  3.91s/it] 86%|████████▋ | 3238/3753 [4:19:11<34:23,  4.01s/it] 86%|████████▋ | 3239/3753 [4:19:15<35:28,  4.14s/it] 86%|████████▋ | 3240/3753 [4:19:22<41:41,  4.88s/it]{'loss': 57.9671, 'grad_norm': 12.93809700012207, 'learning_rate': 5.608065363128861e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.917840003967285, 'weight_rejected': 2.1741433143615723, 'kl_term_chosen': 7.626859188079834, 'kl_term_rejected': 1.843023657798767, 'epoch': 0.8634243837441705}
                                                     {'loss': 57.9671, 'grad_norm': 12.93809700012207, 'learning_rate': 5.608065363128861e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.917840003967285, 'weight_rejected': 2.1741433143615723, 'kl_term_chosen': 7.626859188079834, 'kl_term_rejected': 1.843023657798767, 'epoch': 0.86}
 86%|████████▋ | 3240/3753 [4:19:22<41:41,  4.88s/it] 86%|████████▋ | 3241/3753 [4:19:28<43:25,  5.09s/it] 86%|████████▋ | 3242/3753 [4:19:36<51:15,  6.02s/it] 86%|████████▋ | 3243/3753 [4:19:44<56:41,  6.67s/it] 86%|████████▋ | 3244/3753 [4:19:48<50:36,  5.97s/it] 86%|████████▋ | 3245/3753 [4:19:53<46:20,  5.47s/it] 86%|████████▋ | 3246/3753 [4:19:57<43:53,  5.19s/it] 87%|████████▋ | 3247/3753 [4:20:01<40:01,  4.75s/it] 87%|████████▋ | 3248/3753 [4:20:06<41:16,  4.90s/it] 87%|████████▋ | 3249/3753 [4:20:10<39:06,  4.66s/it] 87%|████████▋ | 3250/3753 [4:20:15<38:37,  4.61s/it]{'loss': 50.9574, 'grad_norm': 0.0, 'learning_rate': 5.395950428451679e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.6592807769775391, 'weight_rejected': 2.9702725410461426, 'kl_term_chosen': 1.3723129034042358, 'kl_term_rejected': 2.6703476905822754, 'epoch': 0.866089273817455}
                                                     {'loss': 50.9574, 'grad_norm': 0.0, 'learning_rate': 5.395950428451679e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.6592807769775391, 'weight_rejected': 2.9702725410461426, 'kl_term_chosen': 1.3723129034042358, 'kl_term_rejected': 2.6703476905822754, 'epoch': 0.87}
 87%|████████▋ | 3250/3753 [4:20:15<38:37,  4.61s/it] 87%|████████▋ | 3251/3753 [4:20:21<44:04,  5.27s/it] 87%|████████▋ | 3252/3753 [4:20:25<40:00,  4.79s/it] 87%|████████▋ | 3253/3753 [4:20:30<40:13,  4.83s/it] 87%|████████▋ | 3254/3753 [4:20:34<37:55,  4.56s/it] 87%|████████▋ | 3255/3753 [4:20:38<36:06,  4.35s/it] 87%|████████▋ | 3256/3753 [4:20:42<36:22,  4.39s/it] 87%|████████▋ | 3257/3753 [4:20:46<34:20,  4.15s/it] 87%|████████▋ | 3258/3753 [4:20:51<35:28,  4.30s/it] 87%|████████▋ | 3259/3753 [4:20:55<35:20,  4.29s/it] 87%|████████▋ | 3260/3753 [4:21:00<36:36,  4.46s/it]{'loss': 55.5712, 'grad_norm': 0.0, 'learning_rate': 5.1876956846673145e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.6998310089111328, 'weight_rejected': 3.3717639446258545, 'kl_term_chosen': 2.674652099609375, 'kl_term_rejected': 3.348074436187744, 'epoch': 0.8687541638907396}
                                                     {'loss': 55.5712, 'grad_norm': 0.0, 'learning_rate': 5.1876956846673145e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.6998310089111328, 'weight_rejected': 3.3717639446258545, 'kl_term_chosen': 2.674652099609375, 'kl_term_rejected': 3.348074436187744, 'epoch': 0.87}
 87%|████████▋ | 3260/3753 [4:21:00<36:36,  4.46s/it] 87%|████████▋ | 3261/3753 [4:21:04<35:59,  4.39s/it] 87%|████████▋ | 3262/3753 [4:21:08<36:20,  4.44s/it] 87%|████████▋ | 3263/3753 [4:21:16<43:03,  5.27s/it] 87%|████████▋ | 3264/3753 [4:21:20<41:33,  5.10s/it] 87%|████████▋ | 3265/3753 [4:21:25<39:37,  4.87s/it] 87%|████████▋ | 3266/3753 [4:21:29<39:12,  4.83s/it] 87%|████████▋ | 3267/3753 [4:21:37<46:23,  5.73s/it] 87%|████████▋ | 3268/3753 [4:21:42<43:33,  5.39s/it] 87%|████████▋ | 3269/3753 [4:21:47<41:44,  5.18s/it] 87%|████████▋ | 3270/3753 [4:21:50<37:51,  4.70s/it]{'loss': 58.29, 'grad_norm': 969.4136352539062, 'learning_rate': 4.9833191548717404e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.364524841308594, 'weight_rejected': 1.6073861122131348, 'kl_term_chosen': 10.287564277648926, 'kl_term_rejected': 1.5867401361465454, 'epoch': 0.871419053964024}
                                                     {'loss': 58.29, 'grad_norm': 969.4136352539062, 'learning_rate': 4.9833191548717404e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.364524841308594, 'weight_rejected': 1.6073861122131348, 'kl_term_chosen': 10.287564277648926, 'kl_term_rejected': 1.5867401361465454, 'epoch': 0.87}
 87%|████████▋ | 3270/3753 [4:21:50<37:51,  4.70s/it] 87%|████████▋ | 3271/3753 [4:21:55<37:54,  4.72s/it] 87%|████████▋ | 3272/3753 [4:21:59<35:43,  4.46s/it] 87%|████████▋ | 3273/3753 [4:22:08<47:12,  5.90s/it] 87%|████████▋ | 3274/3753 [4:22:12<43:31,  5.45s/it] 87%|████████▋ | 3275/3753 [4:22:17<40:19,  5.06s/it] 87%|████████▋ | 3276/3753 [4:22:20<37:09,  4.67s/it] 87%|████████▋ | 3277/3753 [4:22:24<35:25,  4.47s/it] 87%|████████▋ | 3278/3753 [4:22:28<33:44,  4.26s/it] 87%|████████▋ | 3279/3753 [4:22:32<33:32,  4.25s/it] 87%|████████▋ | 3280/3753 [4:22:37<34:56,  4.43s/it]{'loss': 53.9167, 'grad_norm': 0.0, 'learning_rate': 4.7828385265266556e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.279402017593384, 'weight_rejected': 1.6391048431396484, 'kl_term_chosen': 4.172711372375488, 'kl_term_rejected': 1.582452416419983, 'epoch': 0.8740839440373085}
                                                     {'loss': 53.9167, 'grad_norm': 0.0, 'learning_rate': 4.7828385265266556e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.279402017593384, 'weight_rejected': 1.6391048431396484, 'kl_term_chosen': 4.172711372375488, 'kl_term_rejected': 1.582452416419983, 'epoch': 0.87}
 87%|████████▋ | 3280/3753 [4:22:37<34:56,  4.43s/it] 87%|████████▋ | 3281/3753 [4:22:41<33:48,  4.30s/it] 87%|████████▋ | 3282/3753 [4:22:46<34:02,  4.34s/it] 87%|████████▋ | 3283/3753 [4:22:50<33:43,  4.30s/it] 88%|████████▊ | 3284/3753 [4:22:57<39:42,  5.08s/it] 88%|████████▊ | 3285/3753 [4:23:02<39:19,  5.04s/it] 88%|████████▊ | 3286/3753 [4:23:06<36:46,  4.73s/it] 88%|████████▊ | 3287/3753 [4:23:10<36:06,  4.65s/it] 88%|████████▊ | 3288/3753 [4:23:16<39:31,  5.10s/it] 88%|████████▊ | 3289/3753 [4:23:24<44:42,  5.78s/it] 88%|████████▊ | 3290/3753 [4:23:27<40:03,  5.19s/it]{'loss': 54.0101, 'grad_norm': 33.27070617675781, 'learning_rate': 4.5862711499288e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.26121187210083, 'weight_rejected': 4.056128025054932, 'kl_term_chosen': 4.051742076873779, 'kl_term_rejected': 3.87370228767395, 'epoch': 0.8767488341105929}
                                                     {'loss': 54.0101, 'grad_norm': 33.27070617675781, 'learning_rate': 4.5862711499288e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.26121187210083, 'weight_rejected': 4.056128025054932, 'kl_term_chosen': 4.051742076873779, 'kl_term_rejected': 3.87370228767395, 'epoch': 0.88}
 88%|████████▊ | 3290/3753 [4:23:28<40:03,  5.19s/it] 88%|████████▊ | 3291/3753 [4:23:32<38:05,  4.95s/it] 88%|████████▊ | 3292/3753 [4:23:35<34:55,  4.55s/it] 88%|████████▊ | 3293/3753 [4:23:40<34:19,  4.48s/it] 88%|████████▊ | 3294/3753 [4:23:45<34:56,  4.57s/it] 88%|████████▊ | 3295/3753 [4:23:51<39:02,  5.11s/it] 88%|████████▊ | 3296/3753 [4:23:55<37:01,  4.86s/it] 88%|████████▊ | 3297/3753 [4:24:00<36:11,  4.76s/it] 88%|████████▊ | 3298/3753 [4:24:07<42:46,  5.64s/it] 88%|████████▊ | 3299/3753 [4:24:12<40:15,  5.32s/it] 88%|████████▊ | 3300/3753 [4:24:18<42:19,  5.61s/it]{'loss': 61.155, 'grad_norm': 503.021240234375, 'learning_rate': 4.393634036708388e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.8004881143569946, 'weight_rejected': 2.0927271842956543, 'kl_term_chosen': 2.5346076488494873, 'kl_term_rejected': 1.9799317121505737, 'epoch': 0.8794137241838774}
                                                     {'loss': 61.155, 'grad_norm': 503.021240234375, 'learning_rate': 4.393634036708388e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.8004881143569946, 'weight_rejected': 2.0927271842956543, 'kl_term_chosen': 2.5346076488494873, 'kl_term_rejected': 1.9799317121505737, 'epoch': 0.88}
 88%|████████▊ | 3300/3753 [4:24:19<42:19,  5.61s/it] 88%|████████▊ | 3301/3753 [4:24:23<39:42,  5.27s/it] 88%|████████▊ | 3302/3753 [4:24:26<35:58,  4.78s/it] 88%|████████▊ | 3303/3753 [4:24:30<33:18,  4.44s/it] 88%|████████▊ | 3304/3753 [4:24:35<34:47,  4.65s/it] 88%|████████▊ | 3305/3753 [4:24:40<33:57,  4.55s/it] 88%|████████▊ | 3306/3753 [4:24:45<35:30,  4.77s/it] 88%|████████▊ | 3307/3753 [4:24:48<32:05,  4.32s/it] 88%|████████▊ | 3308/3753 [4:24:53<33:38,  4.54s/it] 88%|████████▊ | 3309/3753 [4:24:58<33:13,  4.49s/it] 88%|████████▊ | 3310/3753 [4:25:02<33:41,  4.56s/it]{'loss': 53.8839, 'grad_norm': 3.5102601051330566, 'learning_rate': 4.2049438583568354e-08, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 2.77250599861145, 'weight_rejected': 7.561605453491211, 'kl_term_chosen': -1.85760498046875, 'kl_term_rejected': 7.498816013336182, 'epoch': 0.8820786142571619}
                                                     {'loss': 53.8839, 'grad_norm': 3.5102601051330566, 'learning_rate': 4.2049438583568354e-08, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 2.77250599861145, 'weight_rejected': 7.561605453491211, 'kl_term_chosen': -1.85760498046875, 'kl_term_rejected': 7.498816013336182, 'epoch': 0.88}
 88%|████████▊ | 3310/3753 [4:25:02<33:41,  4.56s/it] 88%|████████▊ | 3311/3753 [4:25:08<35:48,  4.86s/it] 88%|████████▊ | 3312/3753 [4:25:12<34:51,  4.74s/it] 88%|████████▊ | 3313/3753 [4:25:18<36:06,  4.92s/it] 88%|████████▊ | 3314/3753 [4:25:22<34:29,  4.71s/it] 88%|████████▊ | 3315/3753 [4:25:28<38:38,  5.29s/it] 88%|████████▊ | 3316/3753 [4:25:32<35:40,  4.90s/it] 88%|████████▊ | 3317/3753 [4:25:36<32:43,  4.50s/it] 88%|████████▊ | 3318/3753 [4:25:41<34:00,  4.69s/it] 88%|████████▊ | 3319/3753 [4:25:45<32:23,  4.48s/it] 88%|████████▊ | 3320/3753 [4:25:49<31:43,  4.40s/it]{'loss': 57.2389, 'grad_norm': 33.3458251953125, 'learning_rate': 4.020216944783983e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.9576016664505005, 'weight_rejected': 2.3008811473846436, 'kl_term_chosen': 2.825535535812378, 'kl_term_rejected': 2.1865127086639404, 'epoch': 0.8847435043304464}
                                                     {'loss': 57.2389, 'grad_norm': 33.3458251953125, 'learning_rate': 4.020216944783983e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.9576016664505005, 'weight_rejected': 2.3008811473846436, 'kl_term_chosen': 2.825535535812378, 'kl_term_rejected': 2.1865127086639404, 'epoch': 0.88}
 88%|████████▊ | 3320/3753 [4:25:49<31:43,  4.40s/it] 88%|████████▊ | 3321/3753 [4:25:53<30:27,  4.23s/it] 89%|████████▊ | 3322/3753 [4:25:59<33:52,  4.72s/it] 89%|████████▊ | 3323/3753 [4:26:04<33:48,  4.72s/it] 89%|████████▊ | 3324/3753 [4:26:09<35:13,  4.93s/it] 89%|████████▊ | 3325/3753 [4:26:15<37:58,  5.32s/it] 89%|████████▊ | 3326/3753 [4:26:20<36:14,  5.09s/it] 89%|████████▊ | 3327/3753 [4:26:24<34:33,  4.87s/it] 89%|████████▊ | 3328/3753 [4:26:29<33:54,  4.79s/it] 89%|████████▊ | 3329/3753 [4:26:32<30:48,  4.36s/it] 89%|████████▊ | 3330/3753 [4:26:36<28:26,  4.03s/it]{'loss': 55.0213, 'grad_norm': 0.0, 'learning_rate': 3.8394692829048395e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.2927424907684326, 'weight_rejected': -3.2794764041900635, 'kl_term_chosen': 3.008166551589966, 'kl_term_rejected': -3.3633668422698975, 'epoch': 0.8874083944037309}
                                                     {'loss': 55.0213, 'grad_norm': 0.0, 'learning_rate': 3.8394692829048395e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.2927424907684326, 'weight_rejected': -3.2794764041900635, 'kl_term_chosen': 3.008166551589966, 'kl_term_rejected': -3.3633668422698975, 'epoch': 0.89}
 89%|████████▊ | 3330/3753 [4:26:36<28:26,  4.03s/it] 89%|████████▉ | 3331/3753 [4:26:40<28:39,  4.07s/it] 89%|████████▉ | 3332/3753 [4:26:45<30:59,  4.42s/it] 89%|████████▉ | 3333/3753 [4:26:48<28:25,  4.06s/it] 89%|████████▉ | 3334/3753 [4:26:57<38:58,  5.58s/it] 89%|████████▉ | 3335/3753 [4:27:01<35:20,  5.07s/it] 89%|████████▉ | 3336/3753 [4:27:05<32:41,  4.70s/it] 89%|████████▉ | 3337/3753 [4:27:09<31:38,  4.56s/it] 89%|████████▉ | 3338/3753 [4:27:13<29:44,  4.30s/it] 89%|████████▉ | 3339/3753 [4:27:17<28:31,  4.14s/it] 89%|████████▉ | 3340/3753 [4:27:20<26:31,  3.85s/it]{'loss': 49.4887, 'grad_norm': 0.0, 'learning_rate': 3.662716515256026e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.677506446838379, 'weight_rejected': 4.354527950286865, 'kl_term_chosen': 3.3592331409454346, 'kl_term_rejected': 4.153970241546631, 'epoch': 0.8900732844770153}
                                                     {'loss': 49.4887, 'grad_norm': 0.0, 'learning_rate': 3.662716515256026e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.677506446838379, 'weight_rejected': 4.354527950286865, 'kl_term_chosen': 3.3592331409454346, 'kl_term_rejected': 4.153970241546631, 'epoch': 0.89}
 89%|████████▉ | 3340/3753 [4:27:20<26:31,  3.85s/it] 89%|████████▉ | 3341/3753 [4:27:24<26:48,  3.90s/it] 89%|████████▉ | 3342/3753 [4:27:27<25:57,  3.79s/it] 89%|████████▉ | 3343/3753 [4:27:32<28:18,  4.14s/it] 89%|████████▉ | 3344/3753 [4:27:36<27:37,  4.05s/it] 89%|████████▉ | 3345/3753 [4:27:40<27:24,  4.03s/it] 89%|████████▉ | 3346/3753 [4:27:45<29:12,  4.31s/it] 89%|████████▉ | 3347/3753 [4:27:49<27:46,  4.11s/it] 89%|████████▉ | 3348/3753 [4:27:57<36:45,  5.45s/it] 89%|████████▉ | 3349/3753 [4:28:01<32:33,  4.84s/it] 89%|████████▉ | 3350/3753 [4:28:04<29:32,  4.40s/it]{'loss': 50.7537, 'grad_norm': 790.4151611328125, 'learning_rate': 3.489973938641966e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.198411226272583, 'weight_chosen': -1.427037000656128, 'weight_rejected': 0.503185510635376, 'kl_term_chosen': 2.151127576828003, 'kl_term_rejected': 0.07877349853515625, 'epoch': 0.8927381745502998}
                                                     {'loss': 50.7537, 'grad_norm': 790.4151611328125, 'learning_rate': 3.489973938641966e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.198411226272583, 'weight_chosen': -1.427037000656128, 'weight_rejected': 0.503185510635376, 'kl_term_chosen': 2.151127576828003, 'kl_term_rejected': 0.07877349853515625, 'epoch': 0.89}
 89%|████████▉ | 3350/3753 [4:28:04<29:32,  4.40s/it] 89%|████████▉ | 3351/3753 [4:28:08<28:35,  4.27s/it] 89%|████████▉ | 3352/3753 [4:28:13<29:11,  4.37s/it] 89%|████████▉ | 3353/3753 [4:28:19<32:56,  4.94s/it] 89%|████████▉ | 3354/3753 [4:28:24<32:57,  4.96s/it] 89%|████████▉ | 3355/3753 [4:28:28<30:35,  4.61s/it] 89%|████████▉ | 3356/3753 [4:28:32<28:51,  4.36s/it] 89%|████████▉ | 3357/3753 [4:28:36<29:26,  4.46s/it] 89%|████████▉ | 3358/3753 [4:28:41<30:14,  4.59s/it] 90%|████████▉ | 3359/3753 [4:28:49<36:30,  5.56s/it] 90%|████████▉ | 3360/3753 [4:28:57<40:49,  6.23s/it]{'loss': 55.8181, 'grad_norm': 0.0, 'learning_rate': 3.3212565028111314e-08, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.5013067722320557, 'weight_rejected': -0.0056195855140686035, 'kl_term_chosen': -0.34520187973976135, 'kl_term_rejected': -0.8535873293876648, 'epoch': 0.8954030646235843}
                                                     {'loss': 55.8181, 'grad_norm': 0.0, 'learning_rate': 3.3212565028111314e-08, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.5013067722320557, 'weight_rejected': -0.0056195855140686035, 'kl_term_chosen': -0.34520187973976135, 'kl_term_rejected': -0.8535873293876648, 'epoch': 0.9}
 90%|████████▉ | 3360/3753 [4:28:57<40:49,  6.23s/it] 90%|████████▉ | 3361/3753 [4:29:01<36:36,  5.60s/it] 90%|████████▉ | 3362/3753 [4:29:09<41:43,  6.40s/it] 90%|████████▉ | 3363/3753 [4:29:13<37:25,  5.76s/it] 90%|████████▉ | 3364/3753 [4:29:17<33:13,  5.12s/it] 90%|████████▉ | 3365/3753 [4:29:24<36:28,  5.64s/it] 90%|████████▉ | 3366/3753 [4:29:29<34:37,  5.37s/it] 90%|████████▉ | 3367/3753 [4:29:32<31:19,  4.87s/it] 90%|████████▉ | 3368/3753 [4:29:36<28:50,  4.50s/it] 90%|████████▉ | 3369/3753 [4:29:39<26:19,  4.11s/it] 90%|████████▉ | 3370/3753 [4:29:47<33:26,  5.24s/it]{'loss': 54.4865, 'grad_norm': 94.10499572753906, 'learning_rate': 3.156578809162169e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.44432544708252, 'weight_rejected': 0.31255102157592773, 'kl_term_chosen': 9.40347957611084, 'kl_term_rejected': 0.2607055604457855, 'epoch': 0.8980679546968687}
                                                     {'loss': 54.4865, 'grad_norm': 94.10499572753906, 'learning_rate': 3.156578809162169e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.44432544708252, 'weight_rejected': 0.31255102157592773, 'kl_term_chosen': 9.40347957611084, 'kl_term_rejected': 0.2607055604457855, 'epoch': 0.9}
 90%|████████▉ | 3370/3753 [4:29:47<33:26,  5.24s/it] 90%|████████▉ | 3371/3753 [4:29:51<31:28,  4.94s/it] 90%|████████▉ | 3372/3753 [4:29:55<28:26,  4.48s/it] 90%|████████▉ | 3373/3753 [4:29:58<25:57,  4.10s/it] 90%|████████▉ | 3374/3753 [4:30:03<28:29,  4.51s/it] 90%|████████▉ | 3375/3753 [4:30:08<28:10,  4.47s/it] 90%|████████▉ | 3376/3753 [4:30:12<26:50,  4.27s/it] 90%|████████▉ | 3377/3753 [4:30:17<29:46,  4.75s/it] 90%|█████████ | 3378/3753 [4:30:22<29:54,  4.78s/it] 90%|█████████ | 3379/3753 [4:30:27<29:35,  4.75s/it] 90%|█████████ | 3380/3753 [4:30:32<29:37,  4.77s/it]{'loss': 60.4895, 'grad_norm': 0.0, 'learning_rate': 2.995955109480275e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.558272361755371, 'weight_rejected': 1.6224559545516968, 'kl_term_chosen': 9.547619819641113, 'kl_term_rejected': 1.6092331409454346, 'epoch': 0.9007328447701533}
                                                     {'loss': 60.4895, 'grad_norm': 0.0, 'learning_rate': 2.995955109480275e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.558272361755371, 'weight_rejected': 1.6224559545516968, 'kl_term_chosen': 9.547619819641113, 'kl_term_rejected': 1.6092331409454346, 'epoch': 0.9}
 90%|█████████ | 3380/3753 [4:30:32<29:37,  4.77s/it] 90%|█████████ | 3381/3753 [4:30:36<28:32,  4.60s/it] 90%|█████████ | 3382/3753 [4:30:41<28:57,  4.68s/it] 90%|█████████ | 3383/3753 [4:30:45<28:24,  4.61s/it] 90%|█████████ | 3384/3753 [4:30:49<26:52,  4.37s/it] 90%|█████████ | 3385/3753 [4:30:55<29:21,  4.79s/it] 90%|█████████ | 3386/3753 [4:30:59<28:33,  4.67s/it] 90%|█████████ | 3387/3753 [4:31:03<27:05,  4.44s/it] 90%|█████████ | 3388/3753 [4:31:10<30:58,  5.09s/it] 90%|█████████ | 3389/3753 [4:31:14<29:04,  4.79s/it] 90%|█████████ | 3390/3753 [4:31:17<26:28,  4.38s/it]{'loss': 48.4503, 'grad_norm': 200.06298828125, 'learning_rate': 2.8393993047037712e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.528212785720825, 'weight_rejected': 3.835847854614258, 'kl_term_chosen': 3.496112108230591, 'kl_term_rejected': 3.767310380935669, 'epoch': 0.9033977348434377}
                                                     {'loss': 48.4503, 'grad_norm': 200.06298828125, 'learning_rate': 2.8393993047037712e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.528212785720825, 'weight_rejected': 3.835847854614258, 'kl_term_chosen': 3.496112108230591, 'kl_term_rejected': 3.767310380935669, 'epoch': 0.9}
 90%|█████████ | 3390/3753 [4:31:17<26:28,  4.38s/it] 90%|█████████ | 3391/3753 [4:31:21<24:29,  4.06s/it] 90%|█████████ | 3392/3753 [4:31:26<26:26,  4.40s/it] 90%|█████████ | 3393/3753 [4:31:29<25:00,  4.17s/it] 90%|█████████ | 3394/3753 [4:31:34<25:20,  4.23s/it] 90%|█████████ | 3395/3753 [4:31:39<26:30,  4.44s/it] 90%|█████████ | 3396/3753 [4:31:42<24:23,  4.10s/it] 91%|█████████ | 3397/3753 [4:31:51<32:34,  5.49s/it] 91%|█████████ | 3398/3753 [4:31:56<31:02,  5.25s/it] 91%|█████████ | 3399/3753 [4:32:01<31:43,  5.38s/it] 91%|█████████ | 3400/3753 [4:32:06<29:52,  5.08s/it]{'loss': 50.6385, 'grad_norm': 139.30859375, 'learning_rate': 2.686924943721125e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.6241710186004639, 'weight_rejected': 2.428480863571167, 'kl_term_chosen': 2.5204224586486816, 'kl_term_rejected': 2.33966064453125, 'epoch': 0.9060626249167222}
                                                     {'loss': 50.6385, 'grad_norm': 139.30859375, 'learning_rate': 2.686924943721125e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.6241710186004639, 'weight_rejected': 2.428480863571167, 'kl_term_chosen': 2.5204224586486816, 'kl_term_rejected': 2.33966064453125, 'epoch': 0.91}
 91%|█████████ | 3400/3753 [4:32:06<29:52,  5.08s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 91%|█████████ | 3401/3753 [4:33:04<2:03:22, 21.03s/it] 91%|█████████ | 3402/3753 [4:33:08<1:33:13, 15.94s/it] 91%|█████████ | 3403/3753 [4:33:14<1:16:39, 13.14s/it] 91%|█████████ | 3404/3753 [4:33:18<1:00:21, 10.38s/it] 91%|█████████ | 3405/3753 [4:33:24<51:00,  8.80s/it]   91%|█████████ | 3406/3753 [4:33:32<49:34,  8.57s/it] 91%|█████████ | 3407/3753 [4:33:35<41:02,  7.12s/it] 91%|█████████ | 3408/3753 [4:33:40<36:50,  6.41s/it] 91%|█████████ | 3409/3753 [4:33:44<32:29,  5.67s/it] 91%|█████████ | 3410/3753 [4:33:48<28:56,  5.06s/it]{'loss': 52.4262, 'grad_norm': 1719.718994140625, 'learning_rate': 2.538545222198313e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.4817628860473633, 'weight_rejected': -4.852906227111816, 'kl_term_chosen': 2.6873779296875, 'kl_term_rejected': -5.017422676086426, 'epoch': 0.9087275149900067}
                                                     {'loss': 52.4262, 'grad_norm': 1719.718994140625, 'learning_rate': 2.538545222198313e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.4817628860473633, 'weight_rejected': -4.852906227111816, 'kl_term_chosen': 2.6873779296875, 'kl_term_rejected': -5.017422676086426, 'epoch': 0.91}
 91%|█████████ | 3410/3753 [4:33:48<28:56,  5.06s/it] 91%|█████████ | 3411/3753 [4:33:52<27:12,  4.77s/it] 91%|█████████ | 3412/3753 [4:33:56<26:58,  4.75s/it] 91%|█████████ | 3413/3753 [4:34:01<26:28,  4.67s/it] 91%|█████████ | 3414/3753 [4:34:06<27:28,  4.86s/it] 91%|█████████ | 3415/3753 [4:34:12<28:11,  5.01s/it] 91%|█████████ | 3416/3753 [4:34:16<26:33,  4.73s/it] 91%|█████████ | 3417/3753 [4:34:19<24:39,  4.40s/it] 91%|█████████ | 3418/3753 [4:34:25<26:10,  4.69s/it] 91%|█████████ | 3419/3753 [4:34:29<24:44,  4.44s/it] 91%|█████████ | 3420/3753 [4:34:33<24:39,  4.44s/it]{'loss': 53.384, 'grad_norm': 37.42057418823242, 'learning_rate': 2.3942729814368512e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -12.305339813232422, 'weight_rejected': 1.9671850204467773, 'kl_term_chosen': 13.275125503540039, 'kl_term_rejected': 1.9502700567245483, 'epoch': 0.9113924050632911}
                                                     {'loss': 53.384, 'grad_norm': 37.42057418823242, 'learning_rate': 2.3942729814368512e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -12.305339813232422, 'weight_rejected': 1.9671850204467773, 'kl_term_chosen': 13.275125503540039, 'kl_term_rejected': 1.9502700567245483, 'epoch': 0.91}
 91%|█████████ | 3420/3753 [4:34:33<24:39,  4.44s/it] 91%|█████████ | 3421/3753 [4:34:37<24:19,  4.40s/it] 91%|█████████ | 3422/3753 [4:34:41<23:59,  4.35s/it] 91%|█████████ | 3423/3753 [4:34:45<22:44,  4.14s/it] 91%|█████████ | 3424/3753 [4:34:49<22:30,  4.11s/it] 91%|█████████▏| 3425/3753 [4:34:53<21:26,  3.92s/it] 91%|█████████▏| 3426/3753 [4:34:56<20:43,  3.80s/it] 91%|█████████▏| 3427/3753 [4:35:00<21:03,  3.88s/it] 91%|█████████▏| 3428/3753 [4:35:05<22:18,  4.12s/it] 91%|█████████▏| 3429/3753 [4:35:09<22:49,  4.23s/it] 91%|█████████▏| 3430/3753 [4:35:18<29:06,  5.41s/it]{'loss': 57.015, 'grad_norm': 2840.19287109375, 'learning_rate': 2.254120707262469e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.5904680490493774, 'weight_rejected': 8.694201469421387, 'kl_term_chosen': 1.1646240949630737, 'kl_term_rejected': 8.258780479431152, 'epoch': 0.9140572951365756}
                                                     {'loss': 57.015, 'grad_norm': 2840.19287109375, 'learning_rate': 2.254120707262469e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.5904680490493774, 'weight_rejected': 8.694201469421387, 'kl_term_chosen': 1.1646240949630737, 'kl_term_rejected': 8.258780479431152, 'epoch': 0.91}
 91%|█████████▏| 3430/3753 [4:35:18<29:06,  5.41s/it] 91%|█████████▏| 3431/3753 [4:35:22<27:13,  5.07s/it] 91%|█████████▏| 3432/3753 [4:35:25<24:33,  4.59s/it] 91%|█████████▏| 3433/3753 [4:35:29<23:10,  4.35s/it] 92%|█████████▏| 3434/3753 [4:35:34<23:37,  4.44s/it] 92%|█████████▏| 3435/3753 [4:35:38<22:56,  4.33s/it] 92%|█████████▏| 3436/3753 [4:35:43<24:21,  4.61s/it] 92%|█████████▏| 3437/3753 [4:35:47<22:48,  4.33s/it] 92%|█████████▏| 3438/3753 [4:35:50<21:45,  4.14s/it] 92%|█████████▏| 3439/3753 [4:35:55<21:58,  4.20s/it] 92%|█████████▏| 3440/3753 [4:35:58<20:37,  3.96s/it]{'loss': 53.4135, 'grad_norm': 0.0, 'learning_rate': 2.1181005289445496e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.7748215198516846, 'weight_rejected': -2.4493815898895264, 'kl_term_chosen': 4.571746826171875, 'kl_term_rejected': -2.635328769683838, 'epoch': 0.91672218520986}
                                                     {'loss': 53.4135, 'grad_norm': 0.0, 'learning_rate': 2.1181005289445496e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.7748215198516846, 'weight_rejected': -2.4493815898895264, 'kl_term_chosen': 4.571746826171875, 'kl_term_rejected': -2.635328769683838, 'epoch': 0.92}
 92%|█████████▏| 3440/3753 [4:35:58<20:37,  3.96s/it] 92%|█████████▏| 3441/3753 [4:36:02<19:51,  3.82s/it] 92%|█████████▏| 3442/3753 [4:36:09<25:02,  4.83s/it] 92%|█████████▏| 3443/3753 [4:36:13<23:15,  4.50s/it] 92%|█████████▏| 3444/3753 [4:36:18<25:01,  4.86s/it] 92%|█████████▏| 3445/3753 [4:36:23<24:12,  4.72s/it] 92%|█████████▏| 3446/3753 [4:36:27<23:58,  4.69s/it] 92%|█████████▏| 3447/3753 [4:36:31<22:05,  4.33s/it] 92%|█████████▏| 3448/3753 [4:36:35<21:59,  4.33s/it] 92%|█████████▏| 3449/3753 [4:36:40<22:13,  4.39s/it] 92%|█████████▏| 3450/3753 [4:36:44<22:08,  4.38s/it]{'loss': 59.7265, 'grad_norm': 1043.25341796875, 'learning_rate': 1.9862242181463985e-08, 'mean_ratio_chosen': 1.9489330053329468, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.7812395095825195, 'weight_rejected': 2.2983036041259766, 'kl_term_chosen': 0.06672821193933487, 'kl_term_rejected': 2.120492696762085, 'epoch': 0.9193870752831446}
                                                     {'loss': 59.7265, 'grad_norm': 1043.25341796875, 'learning_rate': 1.9862242181463985e-08, 'mean_ratio_chosen': 1.9489330053329468, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.7812395095825195, 'weight_rejected': 2.2983036041259766, 'kl_term_chosen': 0.06672821193933487, 'kl_term_rejected': 2.120492696762085, 'epoch': 0.92}
 92%|█████████▏| 3450/3753 [4:36:44<22:08,  4.38s/it] 92%|█████████▏| 3451/3753 [4:36:48<21:35,  4.29s/it] 92%|█████████▏| 3452/3753 [4:36:52<20:41,  4.12s/it] 92%|█████████▏| 3453/3753 [4:36:56<20:01,  4.00s/it] 92%|█████████▏| 3454/3753 [4:36:59<18:53,  3.79s/it] 92%|█████████▏| 3455/3753 [4:37:02<17:51,  3.60s/it] 92%|█████████▏| 3456/3753 [4:37:06<17:58,  3.63s/it] 92%|█████████▏| 3457/3753 [4:37:15<26:10,  5.30s/it] 92%|█████████▏| 3458/3753 [4:37:18<23:26,  4.77s/it] 92%|█████████▏| 3459/3753 [4:37:22<21:59,  4.49s/it] 92%|█████████▏| 3460/3753 [4:37:25<19:35,  4.01s/it]{'loss': 53.9745, 'grad_norm': 5.575486660003662, 'learning_rate': 1.8585031879064796e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.2162327766418457, 'weight_rejected': 2.0943524837493896, 'kl_term_chosen': 3.160409688949585, 'kl_term_rejected': 2.0597336292266846, 'epoch': 0.9220519653564291}
                                                     {'loss': 53.9745, 'grad_norm': 5.575486660003662, 'learning_rate': 1.8585031879064796e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.2162327766418457, 'weight_rejected': 2.0943524837493896, 'kl_term_chosen': 3.160409688949585, 'kl_term_rejected': 2.0597336292266846, 'epoch': 0.92}
 92%|█████████▏| 3460/3753 [4:37:25<19:35,  4.01s/it] 92%|█████████▏| 3461/3753 [4:37:29<19:58,  4.10s/it] 92%|█████████▏| 3462/3753 [4:37:33<19:34,  4.04s/it] 92%|█████████▏| 3463/3753 [4:37:37<19:20,  4.00s/it] 92%|█████████▏| 3464/3753 [4:37:41<18:55,  3.93s/it] 92%|█████████▏| 3465/3753 [4:37:45<19:23,  4.04s/it] 92%|█████████▏| 3466/3753 [4:37:50<19:46,  4.14s/it] 92%|█████████▏| 3467/3753 [4:37:55<20:54,  4.39s/it] 92%|█████████▏| 3468/3753 [4:37:59<20:06,  4.23s/it] 92%|█████████▏| 3469/3753 [4:38:04<21:04,  4.45s/it] 92%|█████████▏| 3470/3753 [4:38:07<19:44,  4.18s/it]{'loss': 50.2782, 'grad_norm': 743.535888671875, 'learning_rate': 1.7349484916507173e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.7633308172225952, 'weight_rejected': 4.395501613616943, 'kl_term_chosen': 2.6927711963653564, 'kl_term_rejected': 4.052159786224365, 'epoch': 0.9247168554297135}
                                                     {'loss': 50.2782, 'grad_norm': 743.535888671875, 'learning_rate': 1.7349484916507173e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.7633308172225952, 'weight_rejected': 4.395501613616943, 'kl_term_chosen': 2.6927711963653564, 'kl_term_rejected': 4.052159786224365, 'epoch': 0.92}
 92%|█████████▏| 3470/3753 [4:38:07<19:44,  4.18s/it] 92%|█████████▏| 3471/3753 [4:38:12<20:34,  4.38s/it] 93%|█████████▎| 3472/3753 [4:38:16<20:31,  4.38s/it] 93%|█████████▎| 3473/3753 [4:38:23<23:43,  5.09s/it] 93%|█████████▎| 3474/3753 [4:38:30<25:50,  5.56s/it] 93%|█████████▎| 3475/3753 [4:38:33<23:06,  4.99s/it] 93%|█████████▎| 3476/3753 [4:38:37<21:17,  4.61s/it] 93%|█████████▎| 3477/3753 [4:38:41<20:13,  4.40s/it] 93%|█████████▎| 3478/3753 [4:38:45<19:32,  4.26s/it] 93%|█████████▎| 3479/3753 [4:38:50<20:18,  4.45s/it] 93%|█████████▎| 3480/3753 [4:38:54<19:36,  4.31s/it]{'loss': 50.2709, 'grad_norm': 0.0, 'learning_rate': 1.6155708222358843e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -7.295407772064209, 'weight_rejected': -5.740782737731934, 'kl_term_chosen': 7.915109157562256, 'kl_term_rejected': -6.10194730758667, 'epoch': 0.927381745502998}
                                                     {'loss': 50.2709, 'grad_norm': 0.0, 'learning_rate': 1.6155708222358843e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -7.295407772064209, 'weight_rejected': -5.740782737731934, 'kl_term_chosen': 7.915109157562256, 'kl_term_rejected': -6.10194730758667, 'epoch': 0.93}
 93%|█████████▎| 3480/3753 [4:38:54<19:36,  4.31s/it] 93%|█████████▎| 3481/3753 [4:38:58<18:57,  4.18s/it] 93%|█████████▎| 3482/3753 [4:39:01<17:27,  3.86s/it] 93%|█████████▎| 3483/3753 [4:39:05<17:57,  3.99s/it] 93%|█████████▎| 3484/3753 [4:39:09<17:39,  3.94s/it] 93%|█████████▎| 3485/3753 [4:39:13<18:07,  4.06s/it] 93%|█████████▎| 3486/3753 [4:39:22<24:32,  5.51s/it] 93%|█████████▎| 3487/3753 [4:39:26<21:49,  4.92s/it] 93%|█████████▎| 3488/3753 [4:39:29<19:48,  4.48s/it] 93%|█████████▎| 3489/3753 [4:39:33<18:46,  4.27s/it] 93%|█████████▎| 3490/3753 [4:39:37<18:12,  4.15s/it]{'loss': 56.831, 'grad_norm': 10.627766609191895, 'learning_rate': 1.5003805110241964e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -4.903931617736816, 'weight_rejected': -1.0447689294815063, 'kl_term_chosen': 5.8188323974609375, 'kl_term_rejected': -1.088134765625, 'epoch': 0.9300466355762825}
                                                     {'loss': 56.831, 'grad_norm': 10.627766609191895, 'learning_rate': 1.5003805110241964e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -4.903931617736816, 'weight_rejected': -1.0447689294815063, 'kl_term_chosen': 5.8188323974609375, 'kl_term_rejected': -1.088134765625, 'epoch': 0.93}
 93%|█████████▎| 3490/3753 [4:39:37<18:12,  4.15s/it] 93%|█████████▎| 3491/3753 [4:39:41<18:43,  4.29s/it] 93%|█████████▎| 3492/3753 [4:39:47<19:58,  4.59s/it] 93%|█████████▎| 3493/3753 [4:39:50<18:12,  4.20s/it] 93%|█████████▎| 3494/3753 [4:39:54<18:06,  4.20s/it] 93%|█████████▎| 3495/3753 [4:39:58<17:34,  4.09s/it] 93%|█████████▎| 3496/3753 [4:40:01<16:06,  3.76s/it] 93%|█████████▎| 3497/3753 [4:40:06<17:44,  4.16s/it] 93%|█████████▎| 3498/3753 [4:40:12<19:50,  4.67s/it] 93%|█████████▎| 3499/3753 [4:40:16<18:59,  4.49s/it] 93%|█████████▎| 3500/3753 [4:40:25<24:19,  5.77s/it]{'loss': 54.7883, 'grad_norm': 1050.8570556640625, 'learning_rate': 1.3893875269891941e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.8661320209503174, 'weight_rejected': 10.637001037597656, 'kl_term_chosen': 1.9698807001113892, 'kl_term_rejected': 10.121441841125488, 'epoch': 0.9327115256495669}
                                                     {'loss': 54.7883, 'grad_norm': 1050.8570556640625, 'learning_rate': 1.3893875269891941e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.8661320209503174, 'weight_rejected': 10.637001037597656, 'kl_term_chosen': 1.9698807001113892, 'kl_term_rejected': 10.121441841125488, 'epoch': 0.93}
 93%|█████████▎| 3500/3753 [4:40:25<24:19,  5.77s/it] 93%|█████████▎| 3501/3753 [4:40:29<22:44,  5.42s/it] 93%|█████████▎| 3502/3753 [4:40:33<20:56,  5.01s/it] 93%|█████████▎| 3503/3753 [4:40:38<19:48,  4.75s/it] 93%|█████████▎| 3504/3753 [4:40:41<17:51,  4.31s/it] 93%|█████████▎| 3505/3753 [4:40:45<17:43,  4.29s/it] 93%|█████████▎| 3506/3753 [4:40:50<18:22,  4.46s/it] 93%|█████████▎| 3507/3753 [4:40:53<16:45,  4.09s/it] 93%|█████████▎| 3508/3753 [4:40:57<16:21,  4.01s/it] 93%|█████████▎| 3509/3753 [4:41:01<16:19,  4.01s/it] 94%|█████████▎| 3510/3753 [4:41:05<16:14,  4.01s/it]{'loss': 52.9373, 'grad_norm': 0.0, 'learning_rate': 1.2826014758530013e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.029062271118164062, 'weight_rejected': 0.5837787389755249, 'kl_term_chosen': 0.6551864743232727, 'kl_term_rejected': 0.3031623959541321, 'epoch': 0.9353764157228515}
                                                     {'loss': 52.9373, 'grad_norm': 0.0, 'learning_rate': 1.2826014758530013e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.029062271118164062, 'weight_rejected': 0.5837787389755249, 'kl_term_chosen': 0.6551864743232727, 'kl_term_rejected': 0.3031623959541321, 'epoch': 0.94}
 94%|█████████▎| 3510/3753 [4:41:05<16:14,  4.01s/it] 94%|█████████▎| 3511/3753 [4:41:11<18:42,  4.64s/it] 94%|█████████▎| 3512/3753 [4:41:15<17:33,  4.37s/it] 94%|█████████▎| 3513/3753 [4:41:19<17:01,  4.26s/it] 94%|█████████▎| 3514/3753 [4:41:23<16:15,  4.08s/it] 94%|█████████▎| 3515/3753 [4:41:29<18:29,  4.66s/it] 94%|█████████▎| 3516/3753 [4:41:32<17:08,  4.34s/it] 94%|█████████▎| 3517/3753 [4:41:37<17:53,  4.55s/it] 94%|█████████▎| 3518/3753 [4:41:42<17:32,  4.48s/it] 94%|█████████▍| 3519/3753 [4:41:49<21:14,  5.45s/it] 94%|█████████▍| 3520/3753 [4:41:57<24:20,  6.27s/it]{'loss': 52.7353, 'grad_norm': 252.82501220703125, 'learning_rate': 1.180031599255038e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.6867877840995789, 'weight_rejected': 1.7976257801055908, 'kl_term_chosen': 1.6309646368026733, 'kl_term_rejected': 1.7501999139785767, 'epoch': 0.9380413057961359}
                                                     {'loss': 52.7353, 'grad_norm': 252.82501220703125, 'learning_rate': 1.180031599255038e-08, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.6867877840995789, 'weight_rejected': 1.7976257801055908, 'kl_term_chosen': 1.6309646368026733, 'kl_term_rejected': 1.7501999139785767, 'epoch': 0.94}
 94%|█████████▍| 3520/3753 [4:41:57<24:20,  6.27s/it] 94%|█████████▍| 3521/3753 [4:42:03<24:00,  6.21s/it] 94%|█████████▍| 3522/3753 [4:42:08<21:43,  5.64s/it] 94%|█████████▍| 3523/3753 [4:42:13<20:46,  5.42s/it] 94%|█████████▍| 3524/3753 [4:42:17<19:56,  5.22s/it] 94%|█████████▍| 3525/3753 [4:42:22<19:20,  5.09s/it] 94%|█████████▍| 3526/3753 [4:42:26<17:20,  4.58s/it] 94%|█████████▍| 3527/3753 [4:42:30<17:00,  4.52s/it] 94%|█████████▍| 3528/3753 [4:42:39<21:26,  5.72s/it] 94%|█████████▍| 3529/3753 [4:42:44<21:34,  5.78s/it] 94%|█████████▍| 3530/3753 [4:42:49<19:55,  5.36s/it]{'loss': 55.3295, 'grad_norm': 0.0, 'learning_rate': 1.0816867739521619e-08, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.947117805480957, 'weight_rejected': -2.4816298484802246, 'kl_term_chosen': -2.3320298194885254, 'kl_term_rejected': -2.7070465087890625, 'epoch': 0.9407061958694204}
                                                     {'loss': 55.3295, 'grad_norm': 0.0, 'learning_rate': 1.0816867739521619e-08, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.947117805480957, 'weight_rejected': -2.4816298484802246, 'kl_term_chosen': -2.3320298194885254, 'kl_term_rejected': -2.7070465087890625, 'epoch': 0.94}
 94%|█████████▍| 3530/3753 [4:42:49<19:55,  5.36s/it] 94%|█████████▍| 3531/3753 [4:42:57<22:56,  6.20s/it] 94%|█████████▍| 3532/3753 [4:43:01<20:49,  5.65s/it] 94%|█████████▍| 3533/3753 [4:43:05<18:36,  5.07s/it] 94%|█████████▍| 3534/3753 [4:43:11<19:44,  5.41s/it] 94%|█████████▍| 3535/3753 [4:43:15<17:27,  4.80s/it] 94%|█████████▍| 3536/3753 [4:43:26<24:40,  6.82s/it] 94%|█████████▍| 3537/3753 [4:43:31<22:47,  6.33s/it] 94%|█████████▍| 3538/3753 [4:43:36<20:26,  5.70s/it] 94%|█████████▍| 3539/3753 [4:43:39<18:10,  5.10s/it] 94%|█████████▍| 3540/3753 [4:43:46<19:40,  5.54s/it]{'loss': 53.5735, 'grad_norm': 0.0, 'learning_rate': 9.87575511050498e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.52028226852417, 'weight_rejected': 9.422228813171387, 'kl_term_chosen': 3.431462049484253, 'kl_term_rejected': 9.302203178405762, 'epoch': 0.9433710859427049}
                                                     {'loss': 53.5735, 'grad_norm': 0.0, 'learning_rate': 9.87575511050498e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.52028226852417, 'weight_rejected': 9.422228813171387, 'kl_term_chosen': 3.431462049484253, 'kl_term_rejected': 9.302203178405762, 'epoch': 0.94}
 94%|█████████▍| 3540/3753 [4:43:46<19:40,  5.54s/it] 94%|█████████▍| 3541/3753 [4:43:51<19:13,  5.44s/it] 94%|█████████▍| 3542/3753 [4:43:55<18:00,  5.12s/it] 94%|█████████▍| 3543/3753 [4:44:00<17:35,  5.03s/it] 94%|█████████▍| 3544/3753 [4:44:04<16:08,  4.63s/it] 94%|█████████▍| 3545/3753 [4:44:07<14:52,  4.29s/it] 94%|█████████▍| 3546/3753 [4:44:12<14:49,  4.30s/it] 95%|█████████▍| 3547/3753 [4:44:16<15:00,  4.37s/it] 95%|█████████▍| 3548/3753 [4:44:19<13:29,  3.95s/it] 95%|█████████▍| 3549/3753 [4:44:24<13:51,  4.07s/it] 95%|█████████▍| 3550/3753 [4:44:29<15:27,  4.57s/it]{'loss': 57.1651, 'grad_norm': 0.0, 'learning_rate': 8.977059552688127e-09, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.295937418937683, 'weight_rejected': 4.807252407073975, 'kl_term_chosen': -0.4235900938510895, 'kl_term_rejected': 4.616528511047363, 'epoch': 0.9460359760159893}
                                                     {'loss': 57.1651, 'grad_norm': 0.0, 'learning_rate': 8.977059552688127e-09, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.295937418937683, 'weight_rejected': 4.807252407073975, 'kl_term_chosen': -0.4235900938510895, 'kl_term_rejected': 4.616528511047363, 'epoch': 0.95}
 95%|█████████▍| 3550/3753 [4:44:29<15:27,  4.57s/it] 95%|█████████▍| 3551/3753 [4:44:33<14:09,  4.21s/it] 95%|█████████▍| 3552/3753 [4:44:37<13:59,  4.18s/it] 95%|█████████▍| 3553/3753 [4:44:40<13:17,  3.99s/it] 95%|█████████▍| 3554/3753 [4:44:45<13:24,  4.04s/it] 95%|█████████▍| 3555/3753 [4:44:50<14:46,  4.48s/it] 95%|█████████▍| 3556/3753 [4:44:54<14:22,  4.38s/it] 95%|█████████▍| 3557/3753 [4:44:59<14:30,  4.44s/it] 95%|█████████▍| 3558/3753 [4:45:03<14:29,  4.46s/it] 95%|█████████▍| 3559/3753 [4:45:08<15:03,  4.66s/it] 95%|█████████▍| 3560/3753 [4:45:12<14:17,  4.45s/it]{'loss': 53.5188, 'grad_norm': 76.47505187988281, 'learning_rate': 8.120858842336765e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.4642544984817505, 'weight_rejected': 10.601991653442383, 'kl_term_chosen': 1.3339691162109375, 'kl_term_rejected': 10.523913383483887, 'epoch': 0.9487008660892738}
                                                     {'loss': 53.5188, 'grad_norm': 76.47505187988281, 'learning_rate': 8.120858842336765e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.4642544984817505, 'weight_rejected': 10.601991653442383, 'kl_term_chosen': 1.3339691162109375, 'kl_term_rejected': 10.523913383483887, 'epoch': 0.95}
 95%|█████████▍| 3560/3753 [4:45:12<14:17,  4.45s/it] 95%|█████████▍| 3561/3753 [4:45:17<14:15,  4.45s/it] 95%|█████████▍| 3562/3753 [4:45:20<13:23,  4.21s/it] 95%|█████████▍| 3563/3753 [4:45:25<13:23,  4.23s/it] 95%|█████████▍| 3564/3753 [4:45:28<12:45,  4.05s/it] 95%|█████████▍| 3565/3753 [4:45:32<12:26,  3.97s/it] 95%|█████████▌| 3566/3753 [4:45:36<12:18,  3.95s/it] 95%|█████████▌| 3567/3753 [4:45:40<12:38,  4.08s/it] 95%|█████████▌| 3568/3753 [4:45:43<11:21,  3.68s/it] 95%|█████████▌| 3569/3753 [4:45:47<11:31,  3.76s/it] 95%|█████████▌| 3570/3753 [4:45:51<11:35,  3.80s/it]{'loss': 53.7888, 'grad_norm': 0.0, 'learning_rate': 7.30722707806325e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -5.174558639526367, 'weight_rejected': -2.2014193534851074, 'kl_term_chosen': 5.839969158172607, 'kl_term_rejected': -2.443624973297119, 'epoch': 0.9513657561625583}
                                                     {'loss': 53.7888, 'grad_norm': 0.0, 'learning_rate': 7.30722707806325e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -5.174558639526367, 'weight_rejected': -2.2014193534851074, 'kl_term_chosen': 5.839969158172607, 'kl_term_rejected': -2.443624973297119, 'epoch': 0.95}
 95%|█████████▌| 3570/3753 [4:45:51<11:35,  3.80s/it] 95%|█████████▌| 3571/3753 [4:45:55<11:52,  3.92s/it] 95%|█████████▌| 3572/3753 [4:46:02<14:15,  4.73s/it] 95%|█████████▌| 3573/3753 [4:46:08<15:36,  5.20s/it] 95%|█████████▌| 3574/3753 [4:46:11<13:34,  4.55s/it] 95%|█████████▌| 3575/3753 [4:46:15<13:02,  4.40s/it] 95%|█████████▌| 3576/3753 [4:46:19<12:12,  4.14s/it] 95%|█████████▌| 3577/3753 [4:46:23<12:05,  4.12s/it] 95%|█████████▌| 3578/3753 [4:46:26<11:29,  3.94s/it] 95%|█████████▌| 3579/3753 [4:46:33<13:23,  4.62s/it] 95%|█████████▌| 3580/3753 [4:46:38<14:24,  5.00s/it]{'loss': 48.4159, 'grad_norm': 0.0, 'learning_rate': 6.536234674414276e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.8426326513290405, 'weight_rejected': 9.517427444458008, 'kl_term_chosen': 1.7884339094161987, 'kl_term_rejected': 9.490668296813965, 'epoch': 0.9540306462358428}
                                                     {'loss': 48.4159, 'grad_norm': 0.0, 'learning_rate': 6.536234674414276e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.8426326513290405, 'weight_rejected': 9.517427444458008, 'kl_term_chosen': 1.7884339094161987, 'kl_term_rejected': 9.490668296813965, 'epoch': 0.95}
 95%|█████████▌| 3580/3753 [4:46:39<14:24,  5.00s/it] 95%|█████████▌| 3581/3753 [4:46:42<13:21,  4.66s/it] 95%|█████████▌| 3582/3753 [4:46:47<13:25,  4.71s/it] 95%|█████████▌| 3583/3753 [4:46:53<14:10,  5.00s/it] 95%|█████████▌| 3584/3753 [4:46:57<13:27,  4.78s/it] 96%|█████████▌| 3585/3753 [4:47:01<12:45,  4.56s/it] 96%|█████████▌| 3586/3753 [4:47:05<12:26,  4.47s/it] 96%|█████████▌| 3587/3753 [4:47:09<11:31,  4.16s/it] 96%|█████████▌| 3588/3753 [4:47:13<11:32,  4.19s/it] 96%|█████████▌| 3589/3753 [4:47:17<11:32,  4.22s/it] 96%|█████████▌| 3590/3753 [4:47:23<12:54,  4.75s/it]{'loss': 56.5911, 'grad_norm': 847.6256103515625, 'learning_rate': 5.807948355776637e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.038969039916992, 'weight_rejected': 7.773740291595459, 'kl_term_chosen': 2.4472458362579346, 'kl_term_rejected': 7.477086067199707, 'epoch': 0.9566955363091273}
                                                     {'loss': 56.5911, 'grad_norm': 847.6256103515625, 'learning_rate': 5.807948355776637e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.038969039916992, 'weight_rejected': 7.773740291595459, 'kl_term_chosen': 2.4472458362579346, 'kl_term_rejected': 7.477086067199707, 'epoch': 0.96}
 96%|█████████▌| 3590/3753 [4:47:23<12:54,  4.75s/it] 96%|█████████▌| 3591/3753 [4:47:28<13:06,  4.86s/it] 96%|█████████▌| 3592/3753 [4:47:33<12:28,  4.65s/it] 96%|█████████▌| 3593/3753 [4:47:37<12:16,  4.60s/it] 96%|█████████▌| 3594/3753 [4:47:41<11:44,  4.43s/it] 96%|█████████▌| 3595/3753 [4:47:47<12:36,  4.79s/it] 96%|█████████▌| 3596/3753 [4:47:53<13:16,  5.07s/it] 96%|█████████▌| 3597/3753 [4:47:56<12:01,  4.62s/it] 96%|█████████▌| 3598/3753 [4:48:01<11:46,  4.56s/it] 96%|█████████▌| 3599/3753 [4:48:05<11:17,  4.40s/it] 96%|█████████▌| 3600/3753 [4:48:09<11:18,  4.44s/it]{'loss': 54.4959, 'grad_norm': 2119.97900390625, 'learning_rate': 5.122431150602624e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -8.899941444396973, 'weight_rejected': -1.5472885370254517, 'kl_term_chosen': 9.811120986938477, 'kl_term_rejected': -1.5947144031524658, 'epoch': 0.9593604263824117}
                                                     {'loss': 54.4959, 'grad_norm': 2119.97900390625, 'learning_rate': 5.122431150602624e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -8.899941444396973, 'weight_rejected': -1.5472885370254517, 'kl_term_chosen': 9.811120986938477, 'kl_term_rejected': -1.5947144031524658, 'epoch': 0.96}
 96%|█████████▌| 3600/3753 [4:48:09<11:18,  4.44s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 96%|█████████▌| 3601/3753 [4:49:07<51:37, 20.38s/it] 96%|█████████▌| 3602/3753 [4:49:11<39:28, 15.68s/it] 96%|█████████▌| 3603/3753 [4:49:15<30:18, 12.12s/it] 96%|█████████▌| 3604/3753 [4:49:19<23:38,  9.52s/it] 96%|█████████▌| 3605/3753 [4:49:28<23:05,  9.36s/it] 96%|█████████▌| 3606/3753 [4:49:33<19:46,  8.07s/it] 96%|█████████▌| 3607/3753 [4:49:39<18:36,  7.64s/it] 96%|█████████▌| 3608/3753 [4:49:43<15:21,  6.36s/it] 96%|█████████▌| 3609/3753 [4:49:51<16:35,  6.91s/it] 96%|█████████▌| 3610/3753 [4:49:55<14:41,  6.16s/it]{'loss': 58.0184, 'grad_norm': 100.26639556884766, 'learning_rate': 4.4797423859555535e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.1428234577178955, 'weight_rejected': 1.616418719291687, 'kl_term_chosen': 2.7680327892303467, 'kl_term_rejected': 1.2507355213165283, 'epoch': 0.9620253164556962}
                                                     {'loss': 58.0184, 'grad_norm': 100.26639556884766, 'learning_rate': 4.4797423859555535e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.1428234577178955, 'weight_rejected': 1.616418719291687, 'kl_term_chosen': 2.7680327892303467, 'kl_term_rejected': 1.2507355213165283, 'epoch': 0.96}
 96%|█████████▌| 3610/3753 [4:49:55<14:41,  6.16s/it] 96%|█████████▌| 3611/3753 [4:50:01<14:22,  6.07s/it] 96%|█████████▌| 3612/3753 [4:50:06<13:32,  5.76s/it] 96%|█████████▋| 3613/3753 [4:50:10<12:14,  5.25s/it] 96%|█████████▋| 3614/3753 [4:50:15<11:31,  4.97s/it] 96%|█████████▋| 3615/3753 [4:50:19<10:51,  4.72s/it] 96%|█████████▋| 3616/3753 [4:50:23<10:23,  4.55s/it] 96%|█████████▋| 3617/3753 [4:50:26<09:18,  4.10s/it] 96%|█████████▋| 3618/3753 [4:50:31<09:56,  4.42s/it] 96%|█████████▋| 3619/3753 [4:50:35<09:12,  4.12s/it] 96%|█████████▋| 3620/3753 [4:50:39<09:28,  4.28s/it]{'loss': 50.2011, 'grad_norm': 0.0, 'learning_rate': 3.879937682375323e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.662439346313477, 'weight_rejected': 3.120438575744629, 'kl_term_chosen': 10.347546577453613, 'kl_term_rejected': 2.8853302001953125, 'epoch': 0.9646902065289806}
                                                     {'loss': 50.2011, 'grad_norm': 0.0, 'learning_rate': 3.879937682375323e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -9.662439346313477, 'weight_rejected': 3.120438575744629, 'kl_term_chosen': 10.347546577453613, 'kl_term_rejected': 2.8853302001953125, 'epoch': 0.96}
 96%|█████████▋| 3620/3753 [4:50:39<09:28,  4.28s/it] 96%|█████████▋| 3621/3753 [4:50:45<10:19,  4.69s/it] 97%|█████████▋| 3622/3753 [4:50:48<09:29,  4.34s/it] 97%|█████████▋| 3623/3753 [4:50:53<09:22,  4.32s/it] 97%|█████████▋| 3624/3753 [4:50:57<09:06,  4.24s/it] 97%|█████████▋| 3625/3753 [4:51:01<08:55,  4.19s/it] 97%|█████████▋| 3626/3753 [4:51:05<08:45,  4.14s/it] 97%|█████████▋| 3627/3753 [4:51:12<10:49,  5.15s/it] 97%|█████████▋| 3628/3753 [4:51:16<09:42,  4.66s/it] 97%|█████████▋| 3629/3753 [4:51:20<09:12,  4.46s/it] 97%|█████████▋| 3630/3753 [4:51:24<09:05,  4.44s/it]{'loss': 62.6692, 'grad_norm': 0.0, 'learning_rate': 3.3230689490647e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.921374797821045, 'weight_rejected': 3.929706335067749, 'kl_term_chosen': 3.865551710128784, 'kl_term_rejected': 3.8704960346221924, 'epoch': 0.9673550966022652}
                                                     {'loss': 62.6692, 'grad_norm': 0.0, 'learning_rate': 3.3230689490647e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.921374797821045, 'weight_rejected': 3.929706335067749, 'kl_term_chosen': 3.865551710128784, 'kl_term_rejected': 3.8704960346221924, 'epoch': 0.97}
 97%|█████████▋| 3630/3753 [4:51:24<09:05,  4.44s/it] 97%|█████████▋| 3631/3753 [4:51:28<08:22,  4.12s/it] 97%|█████████▋| 3632/3753 [4:51:36<10:42,  5.31s/it] 97%|█████████▋| 3633/3753 [4:51:40<10:16,  5.14s/it] 97%|█████████▋| 3634/3753 [4:51:44<09:13,  4.65s/it] 97%|█████████▋| 3635/3753 [4:51:48<08:58,  4.56s/it] 97%|█████████▋| 3636/3753 [4:51:53<09:05,  4.67s/it] 97%|█████████▋| 3637/3753 [4:51:57<08:36,  4.45s/it] 97%|█████████▋| 3638/3753 [4:52:01<08:23,  4.38s/it] 97%|█████████▋| 3639/3753 [4:52:06<08:18,  4.37s/it] 97%|█████████▋| 3640/3753 [4:52:09<07:43,  4.10s/it]{'loss': 53.982, 'grad_norm': 6.457342624664307, 'learning_rate': 2.8091843793969784e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.768089771270752, 'weight_rejected': 10.014443397521973, 'kl_term_chosen': 1.6900116205215454, 'kl_term_rejected': 9.936365127563477, 'epoch': 0.9700199866755497}
                                                     {'loss': 53.982, 'grad_norm': 6.457342624664307, 'learning_rate': 2.8091843793969784e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.768089771270752, 'weight_rejected': 10.014443397521973, 'kl_term_chosen': 1.6900116205215454, 'kl_term_rejected': 9.936365127563477, 'epoch': 0.97}
 97%|█████████▋| 3640/3753 [4:52:09<07:43,  4.10s/it] 97%|█████████▋| 3641/3753 [4:52:14<08:12,  4.39s/it] 97%|█████████▋| 3642/3753 [4:52:18<07:52,  4.26s/it] 97%|█████████▋| 3643/3753 [4:52:22<07:45,  4.24s/it] 97%|█████████▋| 3644/3753 [4:52:26<07:32,  4.15s/it] 97%|█████████▋| 3645/3753 [4:52:30<06:59,  3.89s/it] 97%|█████████▋| 3646/3753 [4:52:34<07:21,  4.12s/it] 97%|█████████▋| 3647/3753 [4:52:38<06:55,  3.92s/it] 97%|█████████▋| 3648/3753 [4:52:45<08:50,  5.05s/it] 97%|█████████▋| 3649/3753 [4:52:50<08:35,  4.96s/it] 97%|█████████▋| 3650/3753 [4:52:54<07:52,  4.59s/it]{'loss': 54.2338, 'grad_norm': 257.2447509765625, 'learning_rate': 2.338328446745197e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.794822692871094, 'weight_rejected': 2.7361338138580322, 'kl_term_chosen': 7.728253364562988, 'kl_term_rejected': 2.5560271739959717, 'epoch': 0.9726848767488341}
                                                     {'loss': 54.2338, 'grad_norm': 257.2447509765625, 'learning_rate': 2.338328446745197e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.794822692871094, 'weight_rejected': 2.7361338138580322, 'kl_term_chosen': 7.728253364562988, 'kl_term_rejected': 2.5560271739959717, 'epoch': 0.97}
 97%|█████████▋| 3650/3753 [4:52:54<07:52,  4.59s/it] 97%|█████████▋| 3651/3753 [4:52:59<08:19,  4.90s/it] 97%|█████████▋| 3652/3753 [4:53:03<07:39,  4.55s/it] 97%|█████████▋| 3653/3753 [4:53:07<07:24,  4.45s/it] 97%|█████████▋| 3654/3753 [4:53:12<07:32,  4.57s/it] 97%|█████████▋| 3655/3753 [4:53:16<07:12,  4.42s/it] 97%|█████████▋| 3656/3753 [4:53:23<08:25,  5.21s/it] 97%|█████████▋| 3657/3753 [4:53:28<07:50,  4.90s/it] 97%|█████████▋| 3658/3753 [4:53:32<07:26,  4.70s/it] 97%|█████████▋| 3659/3753 [4:53:38<07:51,  5.02s/it] 98%|█████████▊| 3660/3753 [4:53:41<07:02,  4.55s/it]{'loss': 56.9746, 'grad_norm': 1652.940185546875, 'learning_rate': 1.910541900633278e-09, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.021333932876587, 'weight_rejected': -2.1782641410827637, 'kl_term_chosen': -0.9983566403388977, 'kl_term_rejected': -2.540330648422241, 'epoch': 0.9753497668221186}
                                                     {'loss': 56.9746, 'grad_norm': 1652.940185546875, 'learning_rate': 1.910541900633278e-09, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.021333932876587, 'weight_rejected': -2.1782641410827637, 'kl_term_chosen': -0.9983566403388977, 'kl_term_rejected': -2.540330648422241, 'epoch': 0.98}
 98%|█████████▊| 3660/3753 [4:53:41<07:02,  4.55s/it] 98%|█████████▊| 3661/3753 [4:53:46<07:08,  4.65s/it] 98%|█████████▊| 3662/3753 [4:53:50<06:39,  4.39s/it] 98%|█████████▊| 3663/3753 [4:54:01<09:31,  6.35s/it] 98%|█████████▊| 3664/3753 [4:54:04<08:18,  5.60s/it] 98%|█████████▊| 3665/3753 [4:54:07<06:56,  4.73s/it] 98%|█████████▊| 3666/3753 [4:54:11<06:33,  4.53s/it] 98%|█████████▊| 3667/3753 [4:54:14<05:54,  4.12s/it] 98%|█████████▊| 3668/3753 [4:54:20<06:32,  4.61s/it] 98%|█████████▊| 3669/3753 [4:54:28<07:45,  5.55s/it] 98%|█████████▊| 3670/3753 [4:54:31<06:48,  4.92s/it]{'loss': 54.4982, 'grad_norm': 1016.607421875, 'learning_rate': 1.5258617632092907e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 6.224678039550781, 'weight_chosen': -6.8026556968688965, 'weight_rejected': 0.23785746097564697, 'kl_term_chosen': 7.7492523193359375, 'kl_term_rejected': 0.18285217881202698, 'epoch': 0.978014656895403}
                                                     {'loss': 54.4982, 'grad_norm': 1016.607421875, 'learning_rate': 1.5258617632092907e-09, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 6.224678039550781, 'weight_chosen': -6.8026556968688965, 'weight_rejected': 0.23785746097564697, 'kl_term_chosen': 7.7492523193359375, 'kl_term_rejected': 0.18285217881202698, 'epoch': 0.98}
 98%|█████████▊| 3670/3753 [4:54:31<06:48,  4.92s/it] 98%|█████████▊| 3671/3753 [4:54:35<06:00,  4.40s/it] 98%|█████████▊| 3672/3753 [4:54:42<07:12,  5.34s/it] 98%|█████████▊| 3673/3753 [4:54:46<06:32,  4.90s/it] 98%|█████████▊| 3674/3753 [4:54:49<05:50,  4.44s/it] 98%|█████████▊| 3675/3753 [4:54:54<05:44,  4.42s/it] 98%|█████████▊| 3676/3753 [4:54:58<05:27,  4.25s/it] 98%|█████████▊| 3677/3753 [4:55:01<05:14,  4.14s/it] 98%|█████████▊| 3678/3753 [4:55:06<05:19,  4.25s/it] 98%|█████████▊| 3679/3753 [4:55:11<05:24,  4.39s/it] 98%|█████████▊| 3680/3753 [4:55:15<05:13,  4.30s/it]{'loss': 53.1358, 'grad_norm': 0.0, 'learning_rate': 1.1843213260415708e-09, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.846480369567871, 'weight_rejected': -9.634597778320312, 'kl_term_chosen': -5.084410190582275, 'kl_term_rejected': -9.83142375946045, 'epoch': 0.9806795469686875}
                                                     {'loss': 53.1358, 'grad_norm': 0.0, 'learning_rate': 1.1843213260415708e-09, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.846480369567871, 'weight_rejected': -9.634597778320312, 'kl_term_chosen': -5.084410190582275, 'kl_term_rejected': -9.83142375946045, 'epoch': 0.98}
 98%|█████████▊| 3680/3753 [4:55:15<05:13,  4.30s/it] 98%|█████████▊| 3681/3753 [4:55:19<05:12,  4.34s/it] 98%|█████████▊| 3682/3753 [4:55:23<04:54,  4.14s/it] 98%|█████████▊| 3683/3753 [4:55:29<05:40,  4.86s/it] 98%|█████████▊| 3684/3753 [4:55:33<05:13,  4.54s/it] 98%|█████████▊| 3685/3753 [4:55:38<05:19,  4.70s/it] 98%|█████████▊| 3686/3753 [4:55:43<05:06,  4.58s/it] 98%|█████████▊| 3687/3753 [4:55:47<04:59,  4.54s/it] 98%|█████████▊| 3688/3753 [4:55:52<04:59,  4.61s/it] 98%|█████████▊| 3689/3753 [4:55:56<04:49,  4.52s/it] 98%|█████████▊| 3690/3753 [4:55:59<04:18,  4.11s/it]{'loss': 55.7615, 'grad_norm': 1573.414794921875, 'learning_rate': 8.859501472374131e-10, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.7170953750610352, 'weight_rejected': 1.7378685474395752, 'kl_term_chosen': 1.0464870929718018, 'kl_term_rejected': 1.0741996765136719, 'epoch': 0.983344437041972}
                                                     {'loss': 55.7615, 'grad_norm': 1573.414794921875, 'learning_rate': 8.859501472374131e-10, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.7170953750610352, 'weight_rejected': 1.7378685474395752, 'kl_term_chosen': 1.0464870929718018, 'kl_term_rejected': 1.0741996765136719, 'epoch': 0.98}
 98%|█████████▊| 3690/3753 [4:55:59<04:18,  4.11s/it] 98%|█████████▊| 3691/3753 [4:56:04<04:31,  4.38s/it] 98%|█████████▊| 3692/3753 [4:56:09<04:30,  4.44s/it] 98%|█████████▊| 3693/3753 [4:56:12<04:11,  4.19s/it] 98%|█████████▊| 3694/3753 [4:56:17<04:18,  4.39s/it] 98%|█████████▊| 3695/3753 [4:56:21<04:04,  4.21s/it] 98%|█████████▊| 3696/3753 [4:56:25<03:56,  4.15s/it] 99%|█████████▊| 3697/3753 [4:56:29<03:49,  4.10s/it] 99%|█████████▊| 3698/3753 [4:56:33<03:34,  3.90s/it] 99%|█████████▊| 3699/3753 [4:56:37<03:32,  3.93s/it] 99%|█████████▊| 3700/3753 [4:56:40<03:16,  3.71s/it]{'loss': 55.6563, 'grad_norm': 155.42466735839844, 'learning_rate': 6.307740488851743e-10, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -9.654900550842285, 'weight_rejected': -0.4407251477241516, 'kl_term_chosen': 10.41125774383545, 'kl_term_rejected': -0.6084885001182556, 'epoch': 0.9860093271152565}
                                                     {'loss': 55.6563, 'grad_norm': 155.42466735839844, 'learning_rate': 6.307740488851743e-10, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -9.654900550842285, 'weight_rejected': -0.4407251477241516, 'kl_term_chosen': 10.41125774383545, 'kl_term_rejected': -0.6084885001182556, 'epoch': 0.99}
 99%|█████████▊| 3700/3753 [4:56:40<03:16,  3.71s/it] 99%|█████████▊| 3701/3753 [4:56:45<03:32,  4.08s/it] 99%|█████████▊| 3702/3753 [4:56:49<03:33,  4.19s/it] 99%|█████████▊| 3703/3753 [4:56:54<03:34,  4.29s/it] 99%|█████████▊| 3704/3753 [4:56:58<03:26,  4.22s/it] 99%|█████████▊| 3705/3753 [4:57:02<03:24,  4.25s/it] 99%|█████████▊| 3706/3753 [4:57:06<03:22,  4.32s/it] 99%|█████████▉| 3707/3753 [4:57:10<03:12,  4.19s/it] 99%|█████████▉| 3708/3753 [4:57:15<03:21,  4.48s/it] 99%|█████████▉| 3709/3753 [4:57:23<03:53,  5.30s/it] 99%|█████████▉| 3710/3753 [4:57:27<03:35,  5.01s/it]{'loss': 58.3285, 'grad_norm': 1436.1094970703125, 'learning_rate': 4.1881511481939303e-10, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 8.07674789428711, 'weight_chosen': -3.373345375061035, 'weight_rejected': 0.2516211271286011, 'kl_term_chosen': 4.319146633148193, 'kl_term_rejected': 0.20889893174171448, 'epoch': 0.988674217188541}
                                                     {'loss': 58.3285, 'grad_norm': 1436.1094970703125, 'learning_rate': 4.1881511481939303e-10, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 8.07674789428711, 'weight_chosen': -3.373345375061035, 'weight_rejected': 0.2516211271286011, 'kl_term_chosen': 4.319146633148193, 'kl_term_rejected': 0.20889893174171448, 'epoch': 0.99}
 99%|█████████▉| 3710/3753 [4:57:27<03:35,  5.01s/it] 99%|█████████▉| 3711/3753 [4:57:31<03:11,  4.56s/it] 99%|█████████▉| 3712/3753 [4:57:35<03:05,  4.51s/it] 99%|█████████▉| 3713/3753 [4:57:40<03:03,  4.58s/it] 99%|█████████▉| 3714/3753 [4:57:45<03:12,  4.93s/it] 99%|█████████▉| 3715/3753 [4:57:50<03:01,  4.76s/it] 99%|█████████▉| 3716/3753 [4:57:54<02:52,  4.66s/it] 99%|█████████▉| 3717/3753 [4:57:57<02:31,  4.22s/it] 99%|█████████▉| 3718/3753 [4:58:01<02:25,  4.16s/it] 99%|█████████▉| 3719/3753 [4:58:06<02:22,  4.20s/it] 99%|█████████▉| 3720/3753 [4:58:14<02:55,  5.33s/it]{'loss': 50.5144, 'grad_norm': 127.1239242553711, 'learning_rate': 2.500916887095972e-10, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.398108720779419, 'weight_rejected': 8.136930465698242, 'kl_term_chosen': -0.8562149405479431, 'kl_term_rejected': 7.923553466796875, 'epoch': 0.9913391072618255}
                                                     {'loss': 50.5144, 'grad_norm': 127.1239242553711, 'learning_rate': 2.500916887095972e-10, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.398108720779419, 'weight_rejected': 8.136930465698242, 'kl_term_chosen': -0.8562149405479431, 'kl_term_rejected': 7.923553466796875, 'epoch': 0.99}
 99%|█████████▉| 3720/3753 [4:58:14<02:55,  5.33s/it] 99%|█████████▉| 3721/3753 [4:58:17<02:27,  4.62s/it] 99%|█████████▉| 3722/3753 [4:58:21<02:23,  4.62s/it] 99%|█████████▉| 3723/3753 [4:58:25<02:11,  4.39s/it] 99%|█████████▉| 3724/3753 [4:58:30<02:07,  4.39s/it] 99%|█████████▉| 3725/3753 [4:58:36<02:18,  4.96s/it] 99%|█████████▉| 3726/3753 [4:58:41<02:16,  5.05s/it] 99%|█████████▉| 3727/3753 [4:58:45<01:59,  4.60s/it] 99%|█████████▉| 3728/3753 [4:58:49<01:52,  4.51s/it] 99%|█████████▉| 3729/3753 [4:58:53<01:43,  4.31s/it] 99%|█████████▉| 3730/3753 [4:58:57<01:36,  4.19s/it]{'loss': 54.2324, 'grad_norm': 1614.832763671875, 'learning_rate': 1.2461837247296215e-10, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.1271538734436035, 'weight_rejected': 8.854937553405762, 'kl_term_chosen': 2.086308240890503, 'kl_term_rejected': 8.798285484313965, 'epoch': 0.9940039973351099}
                                                     {'loss': 54.2324, 'grad_norm': 1614.832763671875, 'learning_rate': 1.2461837247296215e-10, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.1271538734436035, 'weight_rejected': 8.854937553405762, 'kl_term_chosen': 2.086308240890503, 'kl_term_rejected': 8.798285484313965, 'epoch': 0.99}
 99%|█████████▉| 3730/3753 [4:58:57<01:36,  4.19s/it] 99%|█████████▉| 3731/3753 [4:59:01<01:32,  4.21s/it] 99%|█████████▉| 3732/3753 [4:59:09<01:52,  5.36s/it] 99%|█████████▉| 3733/3753 [4:59:13<01:41,  5.10s/it] 99%|█████████▉| 3734/3753 [4:59:16<01:24,  4.46s/it]100%|█████████▉| 3735/3753 [4:59:21<01:19,  4.44s/it]100%|█████████▉| 3736/3753 [4:59:26<01:18,  4.60s/it]100%|█████████▉| 3737/3753 [4:59:30<01:10,  4.41s/it]100%|█████████▉| 3738/3753 [4:59:34<01:07,  4.50s/it]100%|█████████▉| 3739/3753 [4:59:39<01:02,  4.45s/it]100%|█████████▉| 3740/3753 [4:59:43<00:58,  4.48s/it]{'loss': 59.1014, 'grad_norm': 0.0, 'learning_rate': 4.2406025010266466e-11, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -6.358213901519775, 'weight_rejected': -1.369038701057434, 'kl_term_chosen': 7.285577297210693, 'kl_term_rejected': -1.4685089588165283, 'epoch': 0.9966688874083944}
                                                     {'loss': 59.1014, 'grad_norm': 0.0, 'learning_rate': 4.2406025010266466e-11, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -6.358213901519775, 'weight_rejected': -1.369038701057434, 'kl_term_chosen': 7.285577297210693, 'kl_term_rejected': -1.4685089588165283, 'epoch': 1.0}
100%|█████████▉| 3740/3753 [4:59:43<00:58,  4.48s/it]100%|█████████▉| 3741/3753 [4:59:47<00:51,  4.31s/it]100%|█████████▉| 3742/3753 [4:59:52<00:49,  4.52s/it]100%|█████████▉| 3743/3753 [4:59:57<00:45,  4.58s/it]100%|█████████▉| 3744/3753 [5:00:03<00:44,  4.97s/it]100%|█████████▉| 3745/3753 [5:00:07<00:38,  4.77s/it]100%|█████████▉| 3746/3753 [5:00:11<00:32,  4.58s/it]100%|█████████▉| 3747/3753 [5:00:15<00:25,  4.32s/it]100%|█████████▉| 3748/3753 [5:00:19<00:21,  4.21s/it]100%|█████████▉| 3749/3753 [5:00:24<00:17,  4.35s/it]100%|█████████▉| 3750/3753 [5:00:33<00:17,  5.81s/it]{'loss': 53.6439, 'grad_norm': 166.83212280273438, 'learning_rate': 3.4617612664211704e-12, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 2.0491652488708496, 'weight_rejected': 6.952948093414307, 'kl_term_chosen': -1.6642532348632812, 'kl_term_rejected': 6.456884860992432, 'epoch': 0.9993337774816788}
                                                     {'loss': 53.6439, 'grad_norm': 166.83212280273438, 'learning_rate': 3.4617612664211704e-12, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 2.0491652488708496, 'weight_rejected': 6.952948093414307, 'kl_term_chosen': -1.6642532348632812, 'kl_term_rejected': 6.456884860992432, 'epoch': 1.0}
100%|█████████▉| 3750/3753 [5:00:33<00:17,  5.81s/it]100%|█████████▉| 3751/3753 [5:00:37<00:10,  5.22s/it]100%|█████████▉| 3752/3753 [5:00:41<00:05,  5.03s/it]100%|██████████| 3753/3753 [5:00:43<00:00,  4.08s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
{'train_runtime': 18099.1582, 'train_samples_per_second': 3.317, 'train_steps_per_second': 0.207, 'total_flos': 0.0, 'train_loss': 44.81845189021519, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.0552148818969727, 'weight_rejected': 1.8966814279556274, 'kl_term_chosen': -0.3090759217739105, 'kl_term_rejected': 1.508527398109436, 'epoch': 1.0}所有任务已完成！

============================================================
*** Save final model ***
============================================================
⚠️  注意: 如果使用 FSDP，此步骤会自动合并分片权重并保存为 HuggingFace 格式
保存路径: /train/output_model/llama3-8b-sympo-1e-6_0.1所有任务已完成！
检测到 FSDP，设置状态字典类型为 FULL_STATE_DICT...


============================================================
*** Save final model ***
============================================================
⚠️  注意: 如果使用 FSDP，此步骤会自动合并分片权重并保存为 HuggingFace 格式
保存路径: /train/output_model/llama3-8b-sympo-1e-6_0.1

检测到 FSDP，设置状态字典类型为 FULL_STATE_DICT...
                                                     {'train_runtime': 18099.1582, 'train_samples_per_second': 3.317, 'train_steps_per_second': 0.207, 'train_loss': 44.81845189021519, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.0552148818969727, 'weight_rejected': 1.8966814279556274, 'kl_term_chosen': -0.3090759217739105, 'kl_term_rejected': 1.508527398109436, 'epoch': 1.0}
100%|██████████| 3753/3753 [5:01:38<00:00,  4.08s/it]100%|██████████| 3753/3753 [5:01:38<00:00,  4.82s/it]
所有任务已完成！

============================================================
*** Save final model ***
============================================================
⚠️  注意: 如果使用 FSDP，此步骤会自动合并分片权重并保存为 HuggingFace 格式
保存路径: /train/output_model/llama3-8b-sympo-1e-6_0.1
检测到 FSDP，设置状态字典类型为 FULL_STATE_DICT...
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
所有任务已完成！

============================================================
*** Save final model ***
============================================================
⚠️  注意: 如果使用 FSDP，此步骤会自动合并分片权重并保存为 HuggingFace 格式
保存路径: /train/output_model/llama3-8b-sympo-1e-6_0.1
检测到 FSDP，设置状态字典类型为 FULL_STATE_DICT...
✅ 模型已保存到: /train/output_model/llama3-8b-sympo-1e-6_0.1
✅ 模型已保存到: /train/output_model/llama3-8b-sympo-1e-6_0.1
✅ 模型已保存到: /train/output_model/llama3-8b-sympo-1e-6_0.1
✅ Tokenizer 已保存

============================================================
🎉 训练和模型保存完成！
============================================================

最终 HuggingFace 模型已保存到: /train/output_model/llama3-8b-sympo-1e-6_0.1
可以直接使用 HuggingFace 的 from_pretrained() 加载模型

注意: checkpoint-* 目录是训练过程中的中间检查点（FSDP 分片格式）
最终模型保存在 /train/output_model/llama3-8b-sympo-1e-6_0.1 根目录（HuggingFace 格式）
✅ Tokenizer 已保存

============================================================
🎉 训练和模型保存完成！
============================================================

最终 HuggingFace 模型已保存到: /train/output_model/llama3-8b-sympo-1e-6_0.1
可以直接使用 HuggingFace 的 from_pretrained() 加载模型

注意: checkpoint-* 目录是训练过程中的中间检查点（FSDP 分片格式）
最终模型保存在 /train/output_model/llama3-8b-sympo-1e-6_0.1 根目录（HuggingFace 格式）
✅ Tokenizer 已保存

============================================================
🎉 训练和模型保存完成！
============================================================

最终 HuggingFace 模型已保存到: /train/output_model/llama3-8b-sympo-1e-6_0.1
可以直接使用 HuggingFace 的 from_pretrained() 加载模型

注意: checkpoint-* 目录是训练过程中的中间检查点（FSDP 分片格式）
最终模型保存在 /train/output_model/llama3-8b-sympo-1e-6_0.1 根目录（HuggingFace 格式）
Traceback (most recent call last):
  File "/rlhf_code/code/implement_final_v3.py", line 378, in <module>
    main()
  File "/rlhf_code/code/implement_final_v3.py", line 354, in main
    trainer.save_model(args.output_dir)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/transformers/trainer.py", line 4189, in save_model
    self._save(output_dir, state_dict=state_dict)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/transformers/trainer.py", line 4299, in _save
    self.accelerator.unwrap_model(self.model, keep_torch_compile=False).save_pretrained(
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/transformers/modeling_utils.py", line 4289, in save_pretrained
    safe_save_file(shard, os.path.join(save_directory, shard_file), metadata={"format": "pt"})
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/safetensors/torch.py", line 352, in save_file
    serialize_file(_flatten(tensors), filename, metadata=metadata)
safetensors_rust.SafetensorError: Error while serializing: I/O error: No space left on device (os error 28)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/rlhf_code/code/implement_final_v3.py", line 378, in <module>
[rank0]:     main()
[rank0]:   File "/rlhf_code/code/implement_final_v3.py", line 354, in main
[rank0]:     trainer.save_model(args.output_dir)
[rank0]:   File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/transformers/trainer.py", line 4189, in save_model
[rank0]:     self._save(output_dir, state_dict=state_dict)
[rank0]:   File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/transformers/trainer.py", line 4299, in _save
[rank0]:     self.accelerator.unwrap_model(self.model, keep_torch_compile=False).save_pretrained(
[rank0]:   File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/transformers/modeling_utils.py", line 4289, in save_pretrained
[rank0]:     safe_save_file(shard, os.path.join(save_directory, shard_file), metadata={"format": "pt"})
[rank0]:   File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/safetensors/torch.py", line 352, in save_file
[rank0]:     serialize_file(_flatten(tensors), filename, metadata=metadata)
[rank0]: safetensors_rust.SafetensorError: Error while serializing: I/O error: No space left on device (os error 28)
[1;34mwandb[0m: 
[1;34mwandb[0m: You can sync this run to the cloud by running:
[1;34mwandb[0m: [1mwandb sync /root/wandb/offline-run-20251114_050750-m8igu0ok[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/offline-run-20251114_050750-m8igu0ok/logs[0m
E1114 10:09:45.244000 29596 site-packages/torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 29709) of binary: /root/miniconda3/envs/advan/bin/python3.12
Traceback (most recent call last):
  File "/root/miniconda3/envs/advan/bin/accelerate", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/launch.py", line 1222, in launch_command
    multi_gpu_launcher(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/launch.py", line 853, in multi_gpu_launcher
    distrib_run.run(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/rlhf_code/code/implement_final_v3.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-11-14_10:09:45
  host      : ZBJjrr
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 29709)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
