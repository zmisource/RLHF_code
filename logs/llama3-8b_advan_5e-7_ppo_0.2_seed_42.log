nohup: ignoring input
[W1114 10:50:23.678527079 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 42
⚙️  Running in WANDB offline mode
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.00it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.47it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.46it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.20it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.60it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.03it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.21it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.29it/s]
[W1114 10:50:28.060780444 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1114 10:50:28.069512025 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1114 10:50:28.079636412 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1114 10:50:28.083223207 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_ppo.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_ppo.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_ppo.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_ppo.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /root/wandb/offline-run-20251114_105036-us6wn4iu
  0%|          | 0/3753 [00:00<?, ?it/s]Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
  0%|          | 1/3753 [00:04<4:56:16,  4.74s/it]{'loss': -0.3989, 'grad_norm': 810.34716796875, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 6.590037822723389, 'chosen_loss': -1.1063063144683838, 'rejected_loss': -0.05361704155802727, 'epoch': 0.0002664890073284477}
                                                  {'loss': -0.3989, 'grad_norm': 810.34716796875, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 6.590037822723389, 'chosen_loss': -1.1063063144683838, 'rejected_loss': -0.05361704155802727, 'epoch': 0.0}
  0%|          | 1/3753 [00:04<4:56:16,  4.74s/it]  0%|          | 2/3753 [00:10<5:17:45,  5.08s/it]  0%|          | 3/3753 [00:14<5:05:54,  4.89s/it]  0%|          | 4/3753 [00:18<4:41:42,  4.51s/it]  0%|          | 5/3753 [00:22<4:33:25,  4.38s/it]  0%|          | 6/3753 [00:28<4:52:58,  4.69s/it]  0%|          | 7/3753 [00:32<4:41:40,  4.51s/it]  0%|          | 8/3753 [00:36<4:39:52,  4.48s/it]  0%|          | 9/3753 [00:40<4:22:15,  4.20s/it]  0%|          | 10/3753 [00:43<4:12:28,  4.05s/it]{'loss': -0.4886, 'grad_norm': 1495.6544189453125, 'learning_rate': 1.1968085106382978e-08, 'mean_ratio_chosen': 0.5701742172241211, 'mean_ratio_rejected': 1.257040023803711, 'chosen_loss': -0.13974115252494812, 'rejected_loss': -0.4995863735675812, 'epoch': 0.002664890073284477}
                                                   {'loss': -0.4886, 'grad_norm': 1495.6544189453125, 'learning_rate': 1.1968085106382978e-08, 'mean_ratio_chosen': 0.5701742172241211, 'mean_ratio_rejected': 1.257040023803711, 'chosen_loss': -0.13974115252494812, 'rejected_loss': -0.4995863735675812, 'epoch': 0.0}
  0%|          | 10/3753 [00:44<4:12:28,  4.05s/it]  0%|          | 11/3753 [00:48<4:20:18,  4.17s/it]  0%|          | 12/3753 [00:53<4:33:26,  4.39s/it]  0%|          | 13/3753 [00:57<4:31:36,  4.36s/it]  0%|          | 14/3753 [01:01<4:25:24,  4.26s/it]  0%|          | 15/3753 [01:05<4:15:23,  4.10s/it]  0%|          | 16/3753 [01:09<4:09:32,  4.01s/it]  0%|          | 17/3753 [01:12<4:03:52,  3.92s/it]  0%|          | 18/3753 [01:17<4:21:35,  4.20s/it]  1%|          | 19/3753 [01:21<4:05:09,  3.94s/it]  1%|          | 20/3753 [01:24<4:03:33,  3.91s/it]{'loss': -0.4621, 'grad_norm': 1579.9583740234375, 'learning_rate': 2.526595744680851e-08, 'mean_ratio_chosen': 1.0685425996780396, 'mean_ratio_rejected': 1.443519949913025, 'chosen_loss': -0.7828055620193481, 'rejected_loss': -0.3559851050376892, 'epoch': 0.005329780146568954}
                                                   {'loss': -0.4621, 'grad_norm': 1579.9583740234375, 'learning_rate': 2.526595744680851e-08, 'mean_ratio_chosen': 1.0685425996780396, 'mean_ratio_rejected': 1.443519949913025, 'chosen_loss': -0.7828055620193481, 'rejected_loss': -0.3559851050376892, 'epoch': 0.01}
  1%|          | 20/3753 [01:24<4:03:33,  3.91s/it]  1%|          | 21/3753 [01:28<4:06:36,  3.96s/it]  1%|          | 22/3753 [01:36<5:13:25,  5.04s/it]  1%|          | 23/3753 [01:41<5:12:25,  5.03s/it]  1%|          | 24/3753 [01:44<4:39:24,  4.50s/it]  1%|          | 25/3753 [01:48<4:33:46,  4.41s/it]  1%|          | 26/3753 [01:51<4:07:56,  3.99s/it]  1%|          | 27/3753 [01:55<4:07:43,  3.99s/it]  1%|          | 28/3753 [01:59<4:04:01,  3.93s/it]  1%|          | 29/3753 [02:03<4:01:51,  3.90s/it]  1%|          | 30/3753 [02:07<4:06:21,  3.97s/it]{'loss': -0.5023, 'grad_norm': 1222.876953125, 'learning_rate': 3.856382978723404e-08, 'mean_ratio_chosen': 1.4196772575378418, 'mean_ratio_rejected': 1.6250250339508057, 'chosen_loss': -0.7535414695739746, 'rejected_loss': -0.7185378670692444, 'epoch': 0.007994670219853431}
                                                   {'loss': -0.5023, 'grad_norm': 1222.876953125, 'learning_rate': 3.856382978723404e-08, 'mean_ratio_chosen': 1.4196772575378418, 'mean_ratio_rejected': 1.6250250339508057, 'chosen_loss': -0.7535414695739746, 'rejected_loss': -0.7185378670692444, 'epoch': 0.01}
  1%|          | 30/3753 [02:07<4:06:21,  3.97s/it]  1%|          | 31/3753 [02:12<4:29:28,  4.34s/it]  1%|          | 32/3753 [02:16<4:15:45,  4.12s/it]  1%|          | 33/3753 [02:20<4:05:32,  3.96s/it]  1%|          | 34/3753 [02:26<4:54:08,  4.75s/it]  1%|          | 35/3753 [02:32<5:08:57,  4.99s/it]  1%|          | 36/3753 [02:38<5:31:15,  5.35s/it]  1%|          | 37/3753 [02:44<5:37:28,  5.45s/it]  1%|          | 38/3753 [02:48<5:15:36,  5.10s/it]  1%|          | 39/3753 [02:56<6:10:20,  5.98s/it]  1%|          | 40/3753 [03:00<5:33:53,  5.40s/it]{'loss': -0.6058, 'grad_norm': 837.7186889648438, 'learning_rate': 5.1861702127659574e-08, 'mean_ratio_chosen': 1.0302332639694214, 'mean_ratio_rejected': 2.237499237060547, 'chosen_loss': -0.7807049751281738, 'rejected_loss': -0.15318316221237183, 'epoch': 0.010659560293137908}
                                                   {'loss': -0.6058, 'grad_norm': 837.7186889648438, 'learning_rate': 5.1861702127659574e-08, 'mean_ratio_chosen': 1.0302332639694214, 'mean_ratio_rejected': 2.237499237060547, 'chosen_loss': -0.7807049751281738, 'rejected_loss': -0.15318316221237183, 'epoch': 0.01}
  1%|          | 40/3753 [03:00<5:33:53,  5.40s/it]  1%|          | 41/3753 [03:07<5:55:01,  5.74s/it]  1%|          | 42/3753 [03:09<5:03:45,  4.91s/it]  1%|          | 43/3753 [03:14<5:01:48,  4.88s/it]  1%|          | 44/3753 [03:18<4:44:34,  4.60s/it]  1%|          | 45/3753 [03:23<4:49:09,  4.68s/it]  1%|          | 46/3753 [03:28<4:53:52,  4.76s/it]  1%|▏         | 47/3753 [03:31<4:19:39,  4.20s/it]  1%|▏         | 48/3753 [03:35<4:16:02,  4.15s/it]  1%|▏         | 49/3753 [03:39<4:18:18,  4.18s/it]  1%|▏         | 50/3753 [03:43<4:10:52,  4.07s/it]{'loss': -0.6001, 'grad_norm': 191.37193298339844, 'learning_rate': 6.515957446808511e-08, 'mean_ratio_chosen': 3.8144869804382324, 'mean_ratio_rejected': 6.6767802238464355, 'chosen_loss': -1.0360699892044067, 'rejected_loss': -0.8221288323402405, 'epoch': 0.013324450366422385}
                                                   {'loss': -0.6001, 'grad_norm': 191.37193298339844, 'learning_rate': 6.515957446808511e-08, 'mean_ratio_chosen': 3.8144869804382324, 'mean_ratio_rejected': 6.6767802238464355, 'chosen_loss': -1.0360699892044067, 'rejected_loss': -0.8221288323402405, 'epoch': 0.01}
  1%|▏         | 50/3753 [03:43<4:10:52,  4.07s/it]  1%|▏         | 51/3753 [03:47<4:11:37,  4.08s/it]  1%|▏         | 52/3753 [03:52<4:22:06,  4.25s/it]  1%|▏         | 53/3753 [03:58<4:50:53,  4.72s/it]  1%|▏         | 54/3753 [04:01<4:27:22,  4.34s/it]  1%|▏         | 55/3753 [04:09<5:29:07,  5.34s/it]  1%|▏         | 56/3753 [04:16<6:12:52,  6.05s/it]  2%|▏         | 57/3753 [04:21<5:50:52,  5.70s/it]  2%|▏         | 58/3753 [04:25<5:09:00,  5.02s/it]  2%|▏         | 59/3753 [04:32<5:55:37,  5.78s/it]  2%|▏         | 60/3753 [04:35<5:06:30,  4.98s/it]{'loss': -0.6317, 'grad_norm': 0.0, 'learning_rate': 7.845744680851063e-08, 'mean_ratio_chosen': 3.9315950870513916, 'mean_ratio_rejected': 3.0394113063812256, 'chosen_loss': -0.036257531493902206, 'rejected_loss': -1.1246529817581177, 'epoch': 0.015989340439706862}
                                                   {'loss': -0.6317, 'grad_norm': 0.0, 'learning_rate': 7.845744680851063e-08, 'mean_ratio_chosen': 3.9315950870513916, 'mean_ratio_rejected': 3.0394113063812256, 'chosen_loss': -0.036257531493902206, 'rejected_loss': -1.1246529817581177, 'epoch': 0.02}
  2%|▏         | 60/3753 [04:36<5:06:30,  4.98s/it]  2%|▏         | 61/3753 [04:41<5:13:25,  5.09s/it]  2%|▏         | 62/3753 [04:45<4:58:39,  4.85s/it]  2%|▏         | 63/3753 [04:49<4:50:08,  4.72s/it]  2%|▏         | 64/3753 [04:55<4:59:32,  4.87s/it]  2%|▏         | 65/3753 [04:59<4:41:11,  4.57s/it]  2%|▏         | 66/3753 [05:03<4:46:17,  4.66s/it]  2%|▏         | 67/3753 [05:08<4:42:51,  4.60s/it]  2%|▏         | 68/3753 [05:12<4:25:54,  4.33s/it]  2%|▏         | 69/3753 [05:16<4:29:17,  4.39s/it]  2%|▏         | 70/3753 [05:20<4:16:04,  4.17s/it]{'loss': -0.6628, 'grad_norm': 30.768714904785156, 'learning_rate': 9.175531914893617e-08, 'mean_ratio_chosen': 29.225175857543945, 'mean_ratio_rejected': 9.608953475952148, 'chosen_loss': -1.1558767557144165, 'rejected_loss': -0.05361704155802727, 'epoch': 0.018654230512991338}
                                                   {'loss': -0.6628, 'grad_norm': 30.768714904785156, 'learning_rate': 9.175531914893617e-08, 'mean_ratio_chosen': 29.225175857543945, 'mean_ratio_rejected': 9.608953475952148, 'chosen_loss': -1.1558767557144165, 'rejected_loss': -0.05361704155802727, 'epoch': 0.02}
  2%|▏         | 70/3753 [05:20<4:16:04,  4.17s/it]  2%|▏         | 71/3753 [05:25<4:29:23,  4.39s/it]  2%|▏         | 72/3753 [05:29<4:30:59,  4.42s/it]  2%|▏         | 73/3753 [05:33<4:18:21,  4.21s/it]  2%|▏         | 74/3753 [05:37<4:09:09,  4.06s/it]  2%|▏         | 75/3753 [05:40<4:01:03,  3.93s/it]  2%|▏         | 76/3753 [05:46<4:32:42,  4.45s/it]  2%|▏         | 77/3753 [05:49<4:09:05,  4.07s/it]  2%|▏         | 78/3753 [05:54<4:25:09,  4.33s/it]  2%|▏         | 79/3753 [05:58<4:24:18,  4.32s/it]  2%|▏         | 80/3753 [06:03<4:38:13,  4.55s/it]{'loss': -0.6114, 'grad_norm': 0.0, 'learning_rate': 1.050531914893617e-07, 'mean_ratio_chosen': 1251.8594970703125, 'mean_ratio_rejected': 16.297563552856445, 'chosen_loss': -1.1140905618667603, 'rejected_loss': -0.12276566028594971, 'epoch': 0.021319120586275817}
                                                   {'loss': -0.6114, 'grad_norm': 0.0, 'learning_rate': 1.050531914893617e-07, 'mean_ratio_chosen': 1251.8594970703125, 'mean_ratio_rejected': 16.297563552856445, 'chosen_loss': -1.1140905618667603, 'rejected_loss': -0.12276566028594971, 'epoch': 0.02}
  2%|▏         | 80/3753 [06:03<4:38:13,  4.55s/it]  2%|▏         | 81/3753 [06:08<4:41:08,  4.59s/it]  2%|▏         | 82/3753 [06:12<4:26:16,  4.35s/it]  2%|▏         | 83/3753 [06:19<5:07:51,  5.03s/it]  2%|▏         | 84/3753 [06:23<5:01:04,  4.92s/it]  2%|▏         | 85/3753 [06:27<4:34:33,  4.49s/it]  2%|▏         | 86/3753 [06:30<4:13:34,  4.15s/it]  2%|▏         | 87/3753 [06:37<5:03:52,  4.97s/it]  2%|▏         | 88/3753 [06:41<4:41:43,  4.61s/it]  2%|▏         | 89/3753 [06:45<4:34:42,  4.50s/it]  2%|▏         | 90/3753 [06:49<4:25:48,  4.35s/it]{'loss': -0.7003, 'grad_norm': 0.0, 'learning_rate': 1.1835106382978723e-07, 'mean_ratio_chosen': 9.149361610412598, 'mean_ratio_rejected': 162.92039489746094, 'chosen_loss': -0.9470804333686829, 'rejected_loss': -0.1800345778465271, 'epoch': 0.023984010659560292}
                                                   {'loss': -0.7003, 'grad_norm': 0.0, 'learning_rate': 1.1835106382978723e-07, 'mean_ratio_chosen': 9.149361610412598, 'mean_ratio_rejected': 162.92039489746094, 'chosen_loss': -0.9470804333686829, 'rejected_loss': -0.1800345778465271, 'epoch': 0.02}
  2%|▏         | 90/3753 [06:49<4:25:48,  4.35s/it]  2%|▏         | 91/3753 [06:52<4:06:21,  4.04s/it]  2%|▏         | 92/3753 [06:56<4:04:15,  4.00s/it]  2%|▏         | 93/3753 [07:02<4:30:40,  4.44s/it]  3%|▎         | 94/3753 [07:05<4:19:46,  4.26s/it]  3%|▎         | 95/3753 [07:12<5:00:23,  4.93s/it]  3%|▎         | 96/3753 [07:16<4:43:29,  4.65s/it]  3%|▎         | 97/3753 [07:20<4:35:32,  4.52s/it]  3%|▎         | 98/3753 [07:26<4:57:51,  4.89s/it]  3%|▎         | 99/3753 [07:29<4:31:00,  4.45s/it]  3%|▎         | 100/3753 [07:33<4:15:46,  4.20s/it]{'loss': -0.672, 'grad_norm': 0.0, 'learning_rate': 1.3164893617021275e-07, 'mean_ratio_chosen': 12.619365692138672, 'mean_ratio_rejected': 17.45720863342285, 'chosen_loss': -0.7535414695739746, 'rejected_loss': -0.17297863960266113, 'epoch': 0.02664890073284477}
                                                    {'loss': -0.672, 'grad_norm': 0.0, 'learning_rate': 1.3164893617021275e-07, 'mean_ratio_chosen': 12.619365692138672, 'mean_ratio_rejected': 17.45720863342285, 'chosen_loss': -0.7535414695739746, 'rejected_loss': -0.17297863960266113, 'epoch': 0.03}
  3%|▎         | 100/3753 [07:33<4:15:46,  4.20s/it]  3%|▎         | 101/3753 [07:37<4:20:04,  4.27s/it]  3%|▎         | 102/3753 [07:41<4:16:49,  4.22s/it]  3%|▎         | 103/3753 [07:45<4:07:11,  4.06s/it]  3%|▎         | 104/3753 [07:51<4:34:53,  4.52s/it]  3%|▎         | 105/3753 [07:55<4:26:57,  4.39s/it]  3%|▎         | 106/3753 [08:00<4:43:12,  4.66s/it]  3%|▎         | 107/3753 [08:05<4:41:55,  4.64s/it]  3%|▎         | 108/3753 [08:09<4:29:56,  4.44s/it]  3%|▎         | 109/3753 [08:13<4:20:12,  4.28s/it]  3%|▎         | 110/3753 [08:17<4:13:20,  4.17s/it]{'loss': -0.6423, 'grad_norm': 0.0, 'learning_rate': 1.4494680851063828e-07, 'mean_ratio_chosen': 4116.48095703125, 'mean_ratio_rejected': 38.74898147583008, 'chosen_loss': -1.0964118242263794, 'rejected_loss': -0.04975472390651703, 'epoch': 0.029313790806129246}
                                                    {'loss': -0.6423, 'grad_norm': 0.0, 'learning_rate': 1.4494680851063828e-07, 'mean_ratio_chosen': 4116.48095703125, 'mean_ratio_rejected': 38.74898147583008, 'chosen_loss': -1.0964118242263794, 'rejected_loss': -0.04975472390651703, 'epoch': 0.03}
  3%|▎         | 110/3753 [08:17<4:13:20,  4.17s/it]  3%|▎         | 111/3753 [08:22<4:39:28,  4.60s/it]  3%|▎         | 112/3753 [08:26<4:21:19,  4.31s/it]  3%|▎         | 113/3753 [08:29<4:02:54,  4.00s/it]  3%|▎         | 114/3753 [08:33<3:54:31,  3.87s/it]  3%|▎         | 115/3753 [08:36<3:53:05,  3.84s/it]