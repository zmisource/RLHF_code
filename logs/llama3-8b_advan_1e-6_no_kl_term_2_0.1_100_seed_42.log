nohup: ignoring input
[W1109 06:48:09.631321655 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...加载用于训练的策略模型 (Policy Model)...

加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 90.79it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 86.53it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 83.85it/s]
加载作为参考的SFT模型 (Reference Model)...
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 92.15it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 90.66it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 92.20it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 86.59it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 82.97it/s]
[W1109 06:48:15.149986704 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1109 06:48:15.167200358 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1109 06:48:15.170244573 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1109 06:48:15.173833871 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /root/wandb/offline-run-20251109_064826-6sz7e1iw
  0%|          | 0/3753 [00:00<?, ?it/s]--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -199.0
Sample 0 - pi_logp_chosen:  -198.81076049804688
Sample 0 - Difference (pi - ref): 0.189239501953125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -100.5
Sample 0 - pi_logp_chosen:  -100.34402465820312
Sample 0 - Difference (pi - ref): 0.155975341796875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -122.0
Sample 0 - pi_logp_chosen:  -121.57272338867188
Sample 0 - Difference (pi - ref): 0.427276611328125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -234.0
Sample 0 - pi_logp_chosen:  -233.57894897460938
Sample 0 - Difference (pi - ref): 0.421051025390625
---------------------------------
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -227.0
Sample 0 - pi_logp_chosen:  -227.50088500976562
Sample 0 - Difference (pi - ref): -0.500885009765625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -248.0
Sample 0 - pi_logp_chosen:  -248.47735595703125
Sample 0 - Difference (pi - ref): -0.47735595703125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -209.0
Sample 0 - pi_logp_chosen:  -208.26136779785156
Sample 0 - Difference (pi - ref): 0.7386322021484375
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -728.0
Sample 0 - pi_logp_chosen:  -730.50390625
Sample 0 - Difference (pi - ref): -2.50390625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -240.0
Sample 0 - pi_logp_chosen:  -240.2412567138672
Sample 0 - Difference (pi - ref): -0.2412567138671875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -253.0
Sample 0 - pi_logp_chosen:  -253.00314331054688
Sample 0 - Difference (pi - ref): -0.003143310546875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -350.0
Sample 0 - pi_logp_chosen:  -349.3069152832031
Sample 0 - Difference (pi - ref): 0.693084716796875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -452.0
Sample 0 - pi_logp_chosen:  -453.64239501953125
Sample 0 - Difference (pi - ref): -1.64239501953125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -127.5
Sample 0 - pi_logp_chosen:  -127.59747314453125
Sample 0 - Difference (pi - ref): -0.09747314453125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -98.5
Sample 0 - pi_logp_chosen:  -98.78225708007812
Sample 0 - Difference (pi - ref): -0.282257080078125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -251.0
Sample 0 - pi_logp_chosen:  -249.6898956298828
Sample 0 - Difference (pi - ref): 1.3101043701171875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -516.0
Sample 0 - pi_logp_chosen:  -514.2531127929688
Sample 0 - Difference (pi - ref): 1.74688720703125
---------------------------------
  0%|          | 1/3753 [00:04<4:55:16,  4.72s/it]{'loss': -0.6222, 'grad_norm': 4958.87060546875, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 6.590037822723389, 'weight_chosen': 0.7909114360809326, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 0.13101044297218323, 'epoch': 0.0002664890073284477}
                                                  {'loss': -0.6222, 'grad_norm': 4958.87060546875, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 6.590037822723389, 'weight_chosen': 0.7909114360809326, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 0.13101044297218323, 'epoch': 0.0}
  0%|          | 1/3753 [00:04<4:55:16,  4.72s/it]  0%|          | 2/3753 [00:10<5:19:00,  5.10s/it]  0%|          | 3/3753 [00:14<5:07:07,  4.91s/it]  0%|          | 4/3753 [00:18<4:42:33,  4.52s/it]  0%|          | 5/3753 [00:22<4:35:35,  4.41s/it]  0%|          | 6/3753 [00:28<4:59:32,  4.80s/it]  0%|          | 7/3753 [00:32<4:46:35,  4.59s/it]  0%|          | 8/3753 [00:37<4:43:21,  4.54s/it]  0%|          | 9/3753 [00:40<4:25:01,  4.25s/it]  0%|          | 10/3753 [00:44<4:16:20,  4.11s/it]{'loss': -0.7469, 'grad_norm': 6313.841796875, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 0.8372095227241516, 'mean_ratio_rejected': 1.1672289371490479, 'weight_chosen': 0.26285308599472046, 'weight_rejected': 0.4163219630718231, 'kl_term_chosen': -0.017768098041415215, 'epoch': 0.002664890073284477}
                                                   {'loss': -0.7469, 'grad_norm': 6313.841796875, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 0.8372095227241516, 'mean_ratio_rejected': 1.1672289371490479, 'weight_chosen': 0.26285308599472046, 'weight_rejected': 0.4163219630718231, 'kl_term_chosen': -0.017768098041415215, 'epoch': 0.0}
  0%|          | 10/3753 [00:44<4:16:20,  4.11s/it]  0%|          | 11/3753 [00:49<4:25:22,  4.26s/it]  0%|          | 12/3753 [00:53<4:37:55,  4.46s/it]  0%|          | 13/3753 [00:58<4:34:51,  4.41s/it]  0%|          | 14/3753 [01:02<4:28:04,  4.30s/it]  0%|          | 15/3753 [01:06<4:17:29,  4.13s/it]  0%|          | 16/3753 [01:10<4:14:24,  4.08s/it]  0%|          | 17/3753 [01:13<4:07:28,  3.97s/it]  0%|          | 18/3753 [01:18<4:24:32,  4.25s/it]  1%|          | 19/3753 [01:21<4:07:35,  3.98s/it]  1%|          | 20/3753 [01:25<4:05:35,  3.95s/it]{'loss': -0.8108, 'grad_norm': 11300.9384765625, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 0.914530873298645, 'mean_ratio_rejected': 1.5994590520858765, 'weight_chosen': 0.741526186466217, 'weight_rejected': 0.29665425419807434, 'kl_term_chosen': -0.008934402838349342, 'epoch': 0.005329780146568954}
                                                   {'loss': -0.8108, 'grad_norm': 11300.9384765625, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 0.914530873298645, 'mean_ratio_rejected': 1.5994590520858765, 'weight_chosen': 0.741526186466217, 'weight_rejected': 0.29665425419807434, 'kl_term_chosen': -0.008934402838349342, 'epoch': 0.01}
  1%|          | 20/3753 [01:25<4:05:35,  3.95s/it]  1%|          | 21/3753 [01:29<4:08:00,  3.99s/it]  1%|          | 22/3753 [01:37<5:16:09,  5.08s/it]  1%|          | 23/3753 [01:42<5:14:02,  5.05s/it]  1%|          | 24/3753 [01:45<4:40:59,  4.52s/it]  1%|          | 25/3753 [01:50<4:35:12,  4.43s/it]  1%|          | 26/3753 [01:53<4:09:15,  4.01s/it]  1%|          | 27/3753 [01:57<4:09:03,  4.01s/it]  1%|          | 28/3753 [02:01<4:08:16,  4.00s/it]  1%|          | 29/3753 [02:04<4:04:56,  3.95s/it]  1%|          | 30/3753 [02:09<4:09:02,  4.01s/it]{'loss': -2.6595, 'grad_norm': 33584.30078125, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 1.6316341161727905, 'mean_ratio_rejected': 2.0576908588409424, 'weight_chosen': 0.578993022441864, 'weight_rejected': 0.5987815260887146, 'kl_term_chosen': 0.04895820841193199, 'epoch': 0.007994670219853431}
                                                   {'loss': -2.6595, 'grad_norm': 33584.30078125, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 1.6316341161727905, 'mean_ratio_rejected': 2.0576908588409424, 'weight_chosen': 0.578993022441864, 'weight_rejected': 0.5987815260887146, 'kl_term_chosen': 0.04895820841193199, 'epoch': 0.01}
  1%|          | 30/3753 [02:09<4:09:02,  4.01s/it]  1%|          | 31/3753 [02:14<4:31:44,  4.38s/it]  1%|          | 32/3753 [02:17<4:17:25,  4.15s/it]  1%|          | 33/3753 [02:21<4:08:34,  4.01s/it]  1%|          | 34/3753 [02:28<4:57:09,  4.79s/it]  1%|          | 35/3753 [02:33<5:10:41,  5.01s/it]  1%|          | 36/3753 [02:39<5:33:03,  5.38s/it]  1%|          | 37/3753 [02:45<5:39:22,  5.48s/it]  1%|          | 38/3753 [02:49<5:17:12,  5.12s/it]  1%|          | 39/3753 [02:58<6:18:24,  6.11s/it]  1%|          | 40/3753 [03:02<5:39:17,  5.48s/it]{'loss': -0.1223, 'grad_norm': 17755.22265625, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 3.507641315460205, 'mean_ratio_rejected': 11.34909725189209, 'weight_chosen': 0.6323000192642212, 'weight_rejected': 0.1276526302099228, 'kl_term_chosen': 0.12549439072608948, 'epoch': 0.010659560293137908}
                                                   {'loss': -0.1223, 'grad_norm': 17755.22265625, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 3.507641315460205, 'mean_ratio_rejected': 11.34909725189209, 'weight_chosen': 0.6323000192642212, 'weight_rejected': 0.1276526302099228, 'kl_term_chosen': 0.12549439072608948, 'epoch': 0.01}
  1%|          | 40/3753 [03:02<5:39:17,  5.48s/it]  1%|          | 41/3753 [03:09<5:59:29,  5.81s/it]  1%|          | 42/3753 [03:11<5:07:05,  4.97s/it]  1%|          | 43/3753 [03:16<5:03:41,  4.91s/it]  1%|          | 44/3753 [03:20<4:46:19,  4.63s/it]  1%|          | 45/3753 [03:25<4:53:31,  4.75s/it]  1%|          | 46/3753 [03:30<4:57:02,  4.81s/it]  1%|▏         | 47/3753 [03:33<4:21:53,  4.24s/it]  1%|▏         | 48/3753 [03:37<4:17:46,  4.17s/it]  1%|▏         | 49/3753 [03:42<4:21:07,  4.23s/it]  1%|▏         | 50/3753 [03:45<4:14:21,  4.12s/it]{'loss': 16.615, 'grad_norm': 39019.9375, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': 0.3728368282318115, 'weight_rejected': 0.6851073503494263, 'kl_term_chosen': 0.4905548095703125, 'epoch': 0.013324450366422385}
                                                   {'loss': 16.615, 'grad_norm': 39019.9375, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': 0.3728368282318115, 'weight_rejected': 0.6851073503494263, 'kl_term_chosen': 0.4905548095703125, 'epoch': 0.01}
  1%|▏         | 50/3753 [03:45<4:14:21,  4.12s/it]  1%|▏         | 51/3753 [03:50<4:14:07,  4.12s/it]  1%|▏         | 52/3753 [03:54<4:24:09,  4.28s/it]  1%|▏         | 53/3753 [04:00<4:52:03,  4.74s/it]  1%|▏         | 54/3753 [04:03<4:28:20,  4.35s/it]  1%|▏         | 55/3753 [04:11<5:33:53,  5.42s/it]  1%|▏         | 56/3753 [04:19<6:17:35,  6.13s/it]  2%|▏         | 57/3753 [04:24<5:51:07,  5.70s/it]  2%|▏         | 58/3753 [04:27<5:09:00,  5.02s/it]  2%|▏         | 59/3753 [04:35<5:55:29,  5.77s/it]  2%|▏         | 60/3753 [04:38<5:06:21,  4.98s/it]{'loss': 32.7515, 'grad_norm': 19700.927734375, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 14.911051750183105, 'mean_ratio_rejected': 28.48818016052246, 'weight_chosen': -0.23999565839767456, 'weight_rejected': 0.937210738658905, 'kl_term_chosen': 0.27021026611328125, 'epoch': 0.015989340439706862}
                                                   {'loss': 32.7515, 'grad_norm': 19700.927734375, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 14.911051750183105, 'mean_ratio_rejected': 28.48818016052246, 'weight_chosen': -0.23999565839767456, 'weight_rejected': 0.937210738658905, 'kl_term_chosen': 0.27021026611328125, 'epoch': 0.02}
  2%|▏         | 60/3753 [04:38<5:06:21,  4.98s/it]  2%|▏         | 61/3753 [04:43<5:15:45,  5.13s/it]  2%|▏         | 62/3753 [04:48<5:00:15,  4.88s/it]  2%|▏         | 63/3753 [04:52<4:51:14,  4.74s/it]  2%|▏         | 64/3753 [04:57<5:00:10,  4.88s/it]  2%|▏         | 65/3753 [05:01<4:41:34,  4.58s/it]  2%|▏         | 66/3753 [05:06<4:49:38,  4.71s/it]  2%|▏         | 67/3753 [05:11<4:45:04,  4.64s/it]  2%|▏         | 68/3753 [05:14<4:27:20,  4.35s/it]  2%|▏         | 69/3753 [05:19<4:30:57,  4.41s/it]  2%|▏         | 70/3753 [05:23<4:17:11,  4.19s/it]{'loss': 25.9198, 'grad_norm': 23052.763671875, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': 0.23386651277542114, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 0.7293640375137329, 'epoch': 0.018654230512991338}
                                                   {'loss': 25.9198, 'grad_norm': 23052.763671875, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': 0.23386651277542114, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 0.7293640375137329, 'epoch': 0.02}
  2%|▏         | 70/3753 [05:23<4:17:11,  4.19s/it]  2%|▏         | 71/3753 [05:27<4:26:38,  4.35s/it]  2%|▏         | 72/3753 [05:32<4:31:49,  4.43s/it]  2%|▏         | 73/3753 [05:36<4:19:00,  4.22s/it]  2%|▏         | 74/3753 [05:39<4:09:33,  4.07s/it]  2%|▏         | 75/3753 [05:43<4:01:26,  3.94s/it]  2%|▏         | 76/3753 [05:49<4:33:57,  4.47s/it]  2%|▏         | 77/3753 [05:52<4:11:17,  4.10s/it]  2%|▏         | 78/3753 [05:57<4:28:02,  4.38s/it]  2%|▏         | 79/3753 [06:01<4:26:52,  4.36s/it]  2%|▏         | 80/3753 [06:06<4:36:39,  4.52s/it]{'loss': 21.9962, 'grad_norm': 28032.2734375, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.9473053812980652, 'weight_rejected': 0.10230471193790436, 'kl_term_chosen': 1.8757141828536987, 'epoch': 0.021319120586275817}
                                                   {'loss': 21.9962, 'grad_norm': 28032.2734375, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.9473053812980652, 'weight_rejected': 0.10230471193790436, 'kl_term_chosen': 1.8757141828536987, 'epoch': 0.02}
  2%|▏         | 80/3753 [06:06<4:36:39,  4.52s/it]  2%|▏         | 81/3753 [06:11<4:40:14,  4.58s/it]  2%|▏         | 82/3753 [06:15<4:25:23,  4.34s/it]  2%|▏         | 83/3753 [06:21<5:10:28,  5.08s/it]  2%|▏         | 84/3753 [06:26<5:04:20,  4.98s/it]  2%|▏         | 85/3753 [06:30<4:37:14,  4.54s/it]  2%|▏         | 86/3753 [06:33<4:15:33,  4.18s/it]  2%|▏         | 87/3753 [06:40<5:05:05,  4.99s/it]  2%|▏         | 88/3753 [06:44<4:42:25,  4.62s/it]  2%|▏         | 89/3753 [06:48<4:35:53,  4.52s/it]  2%|▏         | 90/3753 [06:52<4:28:14,  4.39s/it]{'loss': 26.907, 'grad_norm': 13974.099609375, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.2496945858001709, 'weight_rejected': 0.15002880990505219, 'kl_term_chosen': 1.0389282703399658, 'epoch': 0.023984010659560292}
                                                   {'loss': 26.907, 'grad_norm': 13974.099609375, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.2496945858001709, 'weight_rejected': 0.15002880990505219, 'kl_term_chosen': 1.0389282703399658, 'epoch': 0.02}
  2%|▏         | 90/3753 [06:52<4:28:14,  4.39s/it]  2%|▏         | 91/3753 [06:55<4:08:08,  4.07s/it]  2%|▏         | 92/3753 [06:59<4:05:33,  4.02s/it]  2%|▏         | 93/3753 [07:05<4:33:17,  4.48s/it]  3%|▎         | 94/3753 [07:09<4:23:04,  4.31s/it]  3%|▎         | 95/3753 [07:15<5:04:12,  4.99s/it]  3%|▎         | 96/3753 [07:19<4:46:03,  4.69s/it]  3%|▎         | 97/3753 [07:24<4:37:25,  4.55s/it]  3%|▎         | 98/3753 [07:29<4:59:17,  4.91s/it]  3%|▎         | 99/3753 [07:33<4:31:56,  4.47s/it]  3%|▎         | 100/3753 [07:36<4:18:16,  4.24s/it]{'loss': 32.7144, 'grad_norm': 8291.470703125, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 93.61764526367188, 'weight_chosen': 0.11497509479522705, 'weight_rejected': 0.14414885640144348, 'kl_term_chosen': 0.5129761099815369, 'epoch': 0.02664890073284477}
                                                    {'loss': 32.7144, 'grad_norm': 8291.470703125, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 93.61764526367188, 'weight_chosen': 0.11497509479522705, 'weight_rejected': 0.14414885640144348, 'kl_term_chosen': 0.5129761099815369, 'epoch': 0.03}
  3%|▎         | 100/3753 [07:37<4:18:16,  4.24s/it]  3%|▎         | 101/3753 [07:41<4:23:02,  4.32s/it]  3%|▎         | 102/3753 [07:45<4:18:57,  4.26s/it]  3%|▎         | 103/3753 [07:49<4:08:48,  4.09s/it]  3%|▎         | 104/3753 [07:54<4:35:48,  4.54s/it]  3%|▎         | 105/3753 [07:59<4:29:11,  4.43s/it]  3%|▎         | 106/3753 [08:04<4:45:45,  4.70s/it]  3%|▎         | 107/3753 [08:08<4:43:50,  4.67s/it]  3%|▎         | 108/3753 [08:12<4:31:16,  4.47s/it]  3%|▎         | 109/3753 [08:16<4:20:55,  4.30s/it]  3%|▎         | 110/3753 [08:20<4:13:52,  4.18s/it]{'loss': 45.0503, 'grad_norm': 10823.177734375, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -1.514521837234497, 'weight_rejected': 0.04146226868033409, 'kl_term_chosen': 2.4281983375549316, 'epoch': 0.029313790806129246}
                                                    {'loss': 45.0503, 'grad_norm': 10823.177734375, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -1.514521837234497, 'weight_rejected': 0.04146226868033409, 'kl_term_chosen': 2.4281983375549316, 'epoch': 0.03}
  3%|▎         | 110/3753 [08:20<4:13:52,  4.18s/it]  3%|▎         | 111/3753 [08:26<4:42:54,  4.66s/it]  3%|▎         | 112/3753 [08:30<4:23:46,  4.35s/it]  3%|▎         | 113/3753 [08:33<4:04:35,  4.03s/it]  3%|▎         | 114/3753 [08:37<3:55:40,  3.89s/it]  3%|▎         | 115/3753 [08:40<3:53:58,  3.86s/it]  3%|▎         | 116/3753 [08:45<4:08:40,  4.10s/it]  3%|▎         | 117/3753 [08:49<4:07:23,  4.08s/it]  3%|▎         | 118/3753 [08:53<4:11:59,  4.16s/it]  3%|▎         | 119/3753 [09:01<5:21:56,  5.32s/it]  3%|▎         | 120/3753 [09:06<5:05:17,  5.04s/it]{'loss': 35.2369, 'grad_norm': 10358.4814453125, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 3.5755956172943115, 'weight_chosen': -0.5536279678344727, 'weight_rejected': 0.49502578377723694, 'kl_term_chosen': 1.3901824951171875, 'epoch': 0.031978680879413725}
                                                    {'loss': 35.2369, 'grad_norm': 10358.4814453125, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 3.5755956172943115, 'weight_chosen': -0.5536279678344727, 'weight_rejected': 0.49502578377723694, 'kl_term_chosen': 1.3901824951171875, 'epoch': 0.03}
  3%|▎         | 120/3753 [09:06<5:05:17,  5.04s/it]  3%|▎         | 121/3753 [09:10<4:50:50,  4.80s/it]  3%|▎         | 122/3753 [09:15<4:47:31,  4.75s/it]  3%|▎         | 123/3753 [09:19<4:37:31,  4.59s/it]  3%|▎         | 124/3753 [09:23<4:22:48,  4.35s/it]  3%|▎         | 125/3753 [09:27<4:30:37,  4.48s/it]  3%|▎         | 126/3753 [09:32<4:39:13,  4.62s/it]  3%|▎         | 127/3753 [09:36<4:20:48,  4.32s/it]  3%|▎         | 128/3753 [09:41<4:27:46,  4.43s/it]  3%|▎         | 129/3753 [09:46<4:50:37,  4.81s/it]  3%|▎         | 130/3753 [09:51<4:45:14,  4.72s/it]{'loss': 34.1535, 'grad_norm': 5447.53076171875, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.33674031496047974, 'weight_rejected': 0.10970578342676163, 'kl_term_chosen': 0.6342102289199829, 'epoch': 0.034643570952698204}
                                                    {'loss': 34.1535, 'grad_norm': 5447.53076171875, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.33674031496047974, 'weight_rejected': 0.10970578342676163, 'kl_term_chosen': 0.6342102289199829, 'epoch': 0.03}
  3%|▎         | 130/3753 [09:51<4:45:14,  4.72s/it]  3%|▎         | 131/3753 [09:55<4:30:07,  4.47s/it]  4%|▎         | 132/3753 [09:58<4:08:50,  4.12s/it]  4%|▎         | 133/3753 [10:03<4:19:14,  4.30s/it]  4%|▎         | 134/3753 [10:07<4:22:13,  4.35s/it]  4%|▎         | 135/3753 [10:11<4:10:52,  4.16s/it]  4%|▎         | 136/3753 [10:15<3:59:11,  3.97s/it]  4%|▎         | 137/3753 [10:18<3:54:35,  3.89s/it]  4%|▎         | 138/3753 [10:23<4:07:34,  4.11s/it]  4%|▎         | 139/3753 [10:27<4:01:40,  4.01s/it]  4%|▎         | 140/3753 [10:32<4:18:13,  4.29s/it]{'loss': 20.5826, 'grad_norm': 18069.052734375, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.10916137695312, 'weight_chosen': 0.16955751180648804, 'weight_rejected': 0.14706450700759888, 'kl_term_chosen': 0.690106213092804, 'epoch': 0.037308461025982675}
                                                    {'loss': 20.5826, 'grad_norm': 18069.052734375, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.10916137695312, 'weight_chosen': 0.16955751180648804, 'weight_rejected': 0.14706450700759888, 'kl_term_chosen': 0.690106213092804, 'epoch': 0.04}
  4%|▎         | 140/3753 [10:32<4:18:13,  4.29s/it]  4%|▍         | 141/3753 [10:35<4:09:47,  4.15s/it]  4%|▍         | 142/3753 [10:42<4:52:06,  4.85s/it]  4%|▍         | 143/3753 [10:46<4:38:06,  4.62s/it]  4%|▍         | 144/3753 [10:52<5:01:25,  5.01s/it]  4%|▍         | 145/3753 [10:59<5:44:00,  5.72s/it]  4%|▍         | 146/3753 [11:04<5:33:12,  5.54s/it]  4%|▍         | 147/3753 [11:11<5:57:05,  5.94s/it]  4%|▍         | 148/3753 [11:16<5:40:39,  5.67s/it]  4%|▍         | 149/3753 [11:20<5:10:06,  5.16s/it]  4%|▍         | 150/3753 [11:27<5:37:37,  5.62s/it]{'loss': 51.396, 'grad_norm': 4101.822265625, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 36.60069274902344, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.02454701066017151, 'weight_rejected': 0.5903069972991943, 'kl_term_chosen': 0.360006719827652, 'epoch': 0.039973351099267154}
                                                    {'loss': 51.396, 'grad_norm': 4101.822265625, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 36.60069274902344, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.02454701066017151, 'weight_rejected': 0.5903069972991943, 'kl_term_chosen': 0.360006719827652, 'epoch': 0.04}
  4%|▍         | 150/3753 [11:27<5:37:37,  5.62s/it]  4%|▍         | 151/3753 [11:32<5:30:58,  5.51s/it]  4%|▍         | 152/3753 [11:36<5:01:15,  5.02s/it]  4%|▍         | 153/3753 [11:41<4:58:20,  4.97s/it]  4%|▍         | 154/3753 [11:45<4:46:30,  4.78s/it]  4%|▍         | 155/3753 [11:50<4:39:19,  4.66s/it]  4%|▍         | 156/3753 [11:54<4:33:00,  4.55s/it]  4%|▍         | 157/3753 [11:58<4:18:50,  4.32s/it]  4%|▍         | 158/3753 [12:02<4:26:22,  4.45s/it]  4%|▍         | 159/3753 [12:07<4:18:36,  4.32s/it]  4%|▍         | 160/3753 [12:11<4:23:26,  4.40s/it]{'loss': 45.0362, 'grad_norm': 25307.18359375, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 71.3116226196289, 'weight_chosen': -1.3063385486602783, 'weight_rejected': 0.3372035324573517, 'kl_term_chosen': 1.9863678216934204, 'epoch': 0.04263824117255163}
                                                    {'loss': 45.0362, 'grad_norm': 25307.18359375, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 71.3116226196289, 'weight_chosen': -1.3063385486602783, 'weight_rejected': 0.3372035324573517, 'kl_term_chosen': 1.9863678216934204, 'epoch': 0.04}
  4%|▍         | 160/3753 [12:11<4:23:26,  4.40s/it]  4%|▍         | 161/3753 [12:15<4:16:21,  4.28s/it]  4%|▍         | 162/3753 [12:19<4:13:59,  4.24s/it]  4%|▍         | 163/3753 [12:23<3:58:09,  3.98s/it]  4%|▍         | 164/3753 [12:29<4:47:42,  4.81s/it]  4%|▍         | 165/3753 [12:36<5:18:26,  5.33s/it]  4%|▍         | 166/3753 [12:39<4:47:22,  4.81s/it]  4%|▍         | 167/3753 [12:44<4:49:05,  4.84s/it]  4%|▍         | 168/3753 [12:50<4:56:49,  4.97s/it]  5%|▍         | 169/3753 [12:53<4:29:25,  4.51s/it]  5%|▍         | 170/3753 [12:56<4:07:19,  4.14s/it]{'loss': 43.8922, 'grad_norm': 10988.6318359375, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': 0.3652825355529785, 'weight_rejected': 0.13568955659866333, 'kl_term_chosen': 0.5070648193359375, 'epoch': 0.04530313124583611}
                                                    {'loss': 43.8922, 'grad_norm': 10988.6318359375, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': 0.3652825355529785, 'weight_rejected': 0.13568955659866333, 'kl_term_chosen': 0.5070648193359375, 'epoch': 0.05}
  5%|▍         | 170/3753 [12:57<4:07:19,  4.14s/it]  5%|▍         | 171/3753 [13:01<4:14:14,  4.26s/it]  5%|▍         | 172/3753 [13:10<5:34:11,  5.60s/it]  5%|▍         | 173/3753 [13:13<4:59:48,  5.02s/it]  5%|▍         | 174/3753 [13:18<4:48:31,  4.84s/it]  5%|▍         | 175/3753 [13:22<4:40:58,  4.71s/it]  5%|▍         | 176/3753 [13:26<4:19:04,  4.35s/it]  5%|▍         | 177/3753 [13:30<4:22:47,  4.41s/it]  5%|▍         | 178/3753 [13:35<4:29:23,  4.52s/it]  5%|▍         | 179/3753 [13:39<4:13:14,  4.25s/it]  5%|▍         | 180/3753 [13:43<4:13:19,  4.25s/it]{'loss': 54.4998, 'grad_norm': 19095.064453125, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.0976858139038086, 'weight_rejected': 0.09268777817487717, 'kl_term_chosen': 1.0330322980880737, 'epoch': 0.047968021319120584}
                                                    {'loss': 54.4998, 'grad_norm': 19095.064453125, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.0976858139038086, 'weight_rejected': 0.09268777817487717, 'kl_term_chosen': 1.0330322980880737, 'epoch': 0.05}
  5%|▍         | 180/3753 [13:43<4:13:19,  4.25s/it]  5%|▍         | 181/3753 [13:47<4:18:56,  4.35s/it]  5%|▍         | 182/3753 [13:54<5:07:02,  5.16s/it]  5%|▍         | 183/3753 [13:59<4:56:25,  4.98s/it]  5%|▍         | 184/3753 [14:04<5:03:27,  5.10s/it]  5%|▍         | 185/3753 [14:09<5:00:07,  5.05s/it]  5%|▍         | 186/3753 [14:13<4:41:32,  4.74s/it]  5%|▍         | 187/3753 [14:17<4:27:06,  4.49s/it]  5%|▌         | 188/3753 [14:21<4:21:36,  4.40s/it]  5%|▌         | 189/3753 [14:28<5:06:35,  5.16s/it]  5%|▌         | 190/3753 [14:33<4:52:29,  4.93s/it]{'loss': 53.766, 'grad_norm': 14836.029296875, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -1.7108044624328613, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 2.591601610183716, 'epoch': 0.05063291139240506}
                                                    {'loss': 53.766, 'grad_norm': 14836.029296875, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -1.7108044624328613, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 2.591601610183716, 'epoch': 0.05}
  5%|▌         | 190/3753 [14:33<4:52:29,  4.93s/it]  5%|▌         | 191/3753 [14:36<4:30:10,  4.55s/it]  5%|▌         | 192/3753 [14:44<5:20:39,  5.40s/it]  5%|▌         | 193/3753 [14:48<5:01:38,  5.08s/it]  5%|▌         | 194/3753 [14:53<5:03:20,  5.11s/it]  5%|▌         | 195/3753 [14:58<4:45:26,  4.81s/it]  5%|▌         | 196/3753 [15:01<4:23:37,  4.45s/it]  5%|▌         | 197/3753 [15:10<5:39:39,  5.73s/it]  5%|▌         | 198/3753 [15:14<5:06:41,  5.18s/it]  5%|▌         | 199/3753 [15:19<5:14:33,  5.31s/it]  5%|▌         | 200/3753 [15:24<4:55:17,  4.99s/it]{'loss': 72.7246, 'grad_norm': 11775.5869140625, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -1.8944882154464722, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 2.8378357887268066, 'epoch': 0.05329780146568954}
                                                    {'loss': 72.7246, 'grad_norm': 11775.5869140625, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -1.8944882154464722, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 2.8378357887268066, 'epoch': 0.05}
  5%|▌         | 200/3753 [15:24<4:55:17,  4.99s/it]  5%|▌         | 201/3753 [15:30<5:22:00,  5.44s/it]  5%|▌         | 202/3753 [15:34<4:57:49,  5.03s/it]  5%|▌         | 203/3753 [15:39<4:56:26,  5.01s/it]  5%|▌         | 204/3753 [15:43<4:31:56,  4.60s/it]  5%|▌         | 205/3753 [15:47<4:23:36,  4.46s/it]  5%|▌         | 206/3753 [15:54<5:03:41,  5.14s/it]  6%|▌         | 207/3753 [15:58<4:51:23,  4.93s/it]  6%|▌         | 208/3753 [16:03<4:55:59,  5.01s/it]  6%|▌         | 209/3753 [16:08<4:55:34,  5.00s/it]  6%|▌         | 210/3753 [16:13<4:48:22,  4.88s/it]{'loss': 53.1884, 'grad_norm': 5655.66455078125, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.523560643196106, 'weight_rejected': 0.15304215252399445, 'kl_term_chosen': 1.3422974348068237, 'epoch': 0.05596269153897402}
                                                    {'loss': 53.1884, 'grad_norm': 5655.66455078125, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.523560643196106, 'weight_rejected': 0.15304215252399445, 'kl_term_chosen': 1.3422974348068237, 'epoch': 0.06}
  6%|▌         | 210/3753 [16:13<4:48:22,  4.88s/it]  6%|▌         | 211/3753 [16:18<4:57:45,  5.04s/it]  6%|▌         | 212/3753 [16:22<4:28:32,  4.55s/it]  6%|▌         | 213/3753 [16:26<4:29:50,  4.57s/it]  6%|▌         | 214/3753 [16:32<4:48:02,  4.88s/it]  6%|▌         | 215/3753 [16:36<4:32:19,  4.62s/it]  6%|▌         | 216/3753 [16:40<4:30:27,  4.59s/it]  6%|▌         | 217/3753 [16:44<4:15:42,  4.34s/it]  6%|▌         | 218/3753 [16:49<4:18:23,  4.39s/it]  6%|▌         | 219/3753 [16:52<4:07:55,  4.21s/it]  6%|▌         | 220/3753 [16:56<3:59:35,  4.07s/it]{'loss': 85.4268, 'grad_norm': 21680.650390625, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 66.59358978271484, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': 0.2618659734725952, 'weight_rejected': 0.1200256198644638, 'kl_term_chosen': 0.41986083984375, 'epoch': 0.05862758161225849}
                                                    {'loss': 85.4268, 'grad_norm': 21680.650390625, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 66.59358978271484, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': 0.2618659734725952, 'weight_rejected': 0.1200256198644638, 'kl_term_chosen': 0.41986083984375, 'epoch': 0.06}
  6%|▌         | 220/3753 [16:56<3:59:35,  4.07s/it]  6%|▌         | 221/3753 [17:00<3:52:24,  3.95s/it]  6%|▌         | 222/3753 [17:04<4:01:19,  4.10s/it]  6%|▌         | 223/3753 [17:08<3:48:25,  3.88s/it]  6%|▌         | 224/3753 [17:12<3:50:29,  3.92s/it]  6%|▌         | 225/3753 [17:16<3:54:51,  3.99s/it]  6%|▌         | 226/3753 [17:20<3:52:44,  3.96s/it]  6%|▌         | 227/3753 [17:25<4:16:06,  4.36s/it]  6%|▌         | 228/3753 [17:28<4:00:05,  4.09s/it]  6%|▌         | 229/3753 [17:33<4:11:01,  4.27s/it]  6%|▌         | 230/3753 [17:40<4:50:49,  4.95s/it]{'loss': 62.0701, 'grad_norm': 27663.6875, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -1.7331383228302002, 'weight_rejected': 0.1490352898836136, 'kl_term_chosen': 2.67034912109375, 'epoch': 0.06129247168554297}
                                                    {'loss': 62.0701, 'grad_norm': 27663.6875, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -1.7331383228302002, 'weight_rejected': 0.1490352898836136, 'kl_term_chosen': 2.67034912109375, 'epoch': 0.06}
  6%|▌         | 230/3753 [17:40<4:50:49,  4.95s/it]  6%|▌         | 231/3753 [17:45<5:04:56,  5.20s/it]  6%|▌         | 232/3753 [17:50<4:49:36,  4.94s/it]  6%|▌         | 233/3753 [17:55<4:47:57,  4.91s/it]  6%|▌         | 234/3753 [18:00<4:52:39,  4.99s/it]  6%|▋         | 235/3753 [18:08<5:55:43,  6.07s/it]  6%|▋         | 236/3753 [18:13<5:24:23,  5.53s/it]  6%|▋         | 237/3753 [18:16<4:47:29,  4.91s/it]  6%|▋         | 238/3753 [18:21<4:44:36,  4.86s/it]  6%|▋         | 239/3753 [18:26<4:43:22,  4.84s/it]  6%|▋         | 240/3753 [18:30<4:36:29,  4.72s/it]{'loss': 80.5921, 'grad_norm': 6305.4033203125, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': -2.8024234771728516, 'weight_rejected': 0.17781086266040802, 'kl_term_chosen': 3.633566379547119, 'epoch': 0.06395736175882745}
                                                    {'loss': 80.5921, 'grad_norm': 6305.4033203125, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': -2.8024234771728516, 'weight_rejected': 0.17781086266040802, 'kl_term_chosen': 3.633566379547119, 'epoch': 0.06}
  6%|▋         | 240/3753 [18:30<4:36:29,  4.72s/it]  6%|▋         | 241/3753 [18:34<4:25:32,  4.54s/it]  6%|▋         | 242/3753 [18:38<4:17:55,  4.41s/it]  6%|▋         | 243/3753 [18:43<4:21:14,  4.47s/it]  7%|▋         | 244/3753 [18:49<4:46:13,  4.89s/it]  7%|▋         | 245/3753 [18:53<4:40:25,  4.80s/it]  7%|▋         | 246/3753 [18:57<4:20:32,  4.46s/it]  7%|▋         | 247/3753 [19:04<5:04:56,  5.22s/it]  7%|▋         | 248/3753 [19:09<5:00:51,  5.15s/it]  7%|▋         | 249/3753 [19:14<5:05:06,  5.22s/it]  7%|▋         | 250/3753 [19:20<5:02:44,  5.19s/it]{'loss': 76.4534, 'grad_norm': 792.4136962890625, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.8756939172744751, 'weight_rejected': 0.14804719388484955, 'kl_term_chosen': 1.770483374595642, 'epoch': 0.06662225183211193}
                                                    {'loss': 76.4534, 'grad_norm': 792.4136962890625, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.8756939172744751, 'weight_rejected': 0.14804719388484955, 'kl_term_chosen': 1.770483374595642, 'epoch': 0.07}
  7%|▋         | 250/3753 [19:20<5:02:44,  5.19s/it]  7%|▋         | 251/3753 [19:26<5:28:18,  5.63s/it]  7%|▋         | 252/3753 [19:31<5:19:28,  5.48s/it]  7%|▋         | 253/3753 [19:36<5:05:16,  5.23s/it]  7%|▋         | 254/3753 [19:39<4:34:01,  4.70s/it]  7%|▋         | 255/3753 [19:44<4:22:45,  4.51s/it]  7%|▋         | 256/3753 [19:47<4:06:45,  4.23s/it]  7%|▋         | 257/3753 [19:52<4:10:03,  4.29s/it]  7%|▋         | 258/3753 [19:55<4:03:46,  4.19s/it]  7%|▋         | 259/3753 [19:59<3:51:55,  3.98s/it]  7%|▋         | 260/3753 [20:04<4:05:23,  4.22s/it]{'loss': 147.8916, 'grad_norm': 594.8552856445312, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.464415967464447, 'weight_rejected': 0.13386748731136322, 'kl_term_chosen': 1.3516205549240112, 'epoch': 0.06928714190539641}
                                                    {'loss': 147.8916, 'grad_norm': 594.8552856445312, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.464415967464447, 'weight_rejected': 0.13386748731136322, 'kl_term_chosen': 1.3516205549240112, 'epoch': 0.07}
  7%|▋         | 260/3753 [20:04<4:05:23,  4.22s/it]  7%|▋         | 261/3753 [20:08<4:09:00,  4.28s/it]  7%|▋         | 262/3753 [20:13<4:12:05,  4.33s/it]  7%|▋         | 263/3753 [20:17<4:15:45,  4.40s/it]  7%|▋         | 264/3753 [20:21<4:08:43,  4.28s/it]  7%|▋         | 265/3753 [20:25<4:07:12,  4.25s/it]  7%|▋         | 266/3753 [20:29<3:57:32,  4.09s/it]  7%|▋         | 267/3753 [20:33<3:53:56,  4.03s/it]  7%|▋         | 268/3753 [20:38<4:09:22,  4.29s/it]  7%|▋         | 269/3753 [20:41<3:51:31,  3.99s/it]  7%|▋         | 270/3753 [20:46<4:01:54,  4.17s/it]{'loss': 166.9625, 'grad_norm': 3022.12353515625, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -3.772213935852051, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': 4.747790813446045, 'epoch': 0.07195203197868089}
                                                    {'loss': 166.9625, 'grad_norm': 3022.12353515625, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -3.772213935852051, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': 4.747790813446045, 'epoch': 0.07}
  7%|▋         | 270/3753 [20:46<4:01:54,  4.17s/it]  7%|▋         | 271/3753 [20:50<4:10:32,  4.32s/it]  7%|▋         | 272/3753 [20:55<4:11:34,  4.34s/it]  7%|▋         | 273/3753 [20:58<3:59:17,  4.13s/it]  7%|▋         | 274/3753 [21:02<3:52:01,  4.00s/it]  7%|▋         | 275/3753 [21:06<3:53:46,  4.03s/it]  7%|▋         | 276/3753 [21:10<3:45:55,  3.90s/it]  7%|▋         | 277/3753 [21:15<4:08:22,  4.29s/it]  7%|▋         | 278/3753 [21:18<3:53:19,  4.03s/it]  7%|▋         | 279/3753 [21:23<4:03:55,  4.21s/it]  7%|▋         | 280/3753 [21:28<4:12:49,  4.37s/it]{'loss': 152.4358, 'grad_norm': 8805.3779296875, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': 1.4168084859848022, 'weight_rejected': 0.07263670116662979, 'kl_term_chosen': -0.48635026812553406, 'epoch': 0.07461692205196535}
                                                    {'loss': 152.4358, 'grad_norm': 8805.3779296875, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': 1.4168084859848022, 'weight_rejected': 0.07263670116662979, 'kl_term_chosen': -0.48635026812553406, 'epoch': 0.07}
  7%|▋         | 280/3753 [21:28<4:12:49,  4.37s/it]  7%|▋         | 281/3753 [21:32<4:09:31,  4.31s/it]  8%|▊         | 282/3753 [21:38<4:41:57,  4.87s/it]  8%|▊         | 283/3753 [21:42<4:31:48,  4.70s/it]  8%|▊         | 284/3753 [21:47<4:22:43,  4.54s/it]  8%|▊         | 285/3753 [21:54<5:10:36,  5.37s/it]  8%|▊         | 286/3753 [21:58<4:42:37,  4.89s/it]  8%|▊         | 287/3753 [22:02<4:28:52,  4.65s/it]  8%|▊         | 288/3753 [22:11<5:40:49,  5.90s/it]  8%|▊         | 289/3753 [22:15<5:21:36,  5.57s/it]  8%|▊         | 290/3753 [22:24<6:14:36,  6.49s/it]{'loss': 133.4046, 'grad_norm': 14113.744140625, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.209835946559906, 'weight_rejected': 0.20946967601776123, 'kl_term_chosen': 0.9633026123046875, 'epoch': 0.07728181212524983}
                                                    {'loss': 133.4046, 'grad_norm': 14113.744140625, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.209835946559906, 'weight_rejected': 0.20946967601776123, 'kl_term_chosen': 0.9633026123046875, 'epoch': 0.08}
  8%|▊         | 290/3753 [22:24<6:14:36,  6.49s/it]  8%|▊         | 291/3753 [22:28<5:25:54,  5.65s/it]  8%|▊         | 292/3753 [22:34<5:31:51,  5.75s/it]  8%|▊         | 293/3753 [22:38<4:58:32,  5.18s/it]  8%|▊         | 294/3753 [22:42<4:38:47,  4.84s/it]  8%|▊         | 295/3753 [22:47<4:39:57,  4.86s/it]  8%|▊         | 296/3753 [22:50<4:23:02,  4.57s/it]  8%|▊         | 297/3753 [22:55<4:21:10,  4.53s/it]  8%|▊         | 298/3753 [23:01<4:44:34,  4.94s/it]  8%|▊         | 299/3753 [23:05<4:36:19,  4.80s/it]  8%|▊         | 300/3753 [23:09<4:26:24,  4.63s/it]{'loss': 137.5531, 'grad_norm': 6331.3681640625, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.7345038056373596, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 1.6586456298828125, 'epoch': 0.07994670219853431}
                                                    {'loss': 137.5531, 'grad_norm': 6331.3681640625, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.7345038056373596, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 1.6586456298828125, 'epoch': 0.08}
  8%|▊         | 300/3753 [23:10<4:26:24,  4.63s/it]  8%|▊         | 301/3753 [23:14<4:19:48,  4.52s/it]  8%|▊         | 302/3753 [23:19<4:26:31,  4.63s/it]  8%|▊         | 303/3753 [23:23<4:28:53,  4.68s/it]  8%|▊         | 304/3753 [23:27<4:04:28,  4.25s/it]  8%|▊         | 305/3753 [23:31<3:58:35,  4.15s/it]  8%|▊         | 306/3753 [23:35<3:56:32,  4.12s/it]  8%|▊         | 307/3753 [23:39<4:06:50,  4.30s/it]  8%|▊         | 308/3753 [23:45<4:32:12,  4.74s/it]  8%|▊         | 309/3753 [23:50<4:27:57,  4.67s/it]  8%|▊         | 310/3753 [23:54<4:23:54,  4.60s/it]{'loss': 134.5511, 'grad_norm': 3169.091796875, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 3.5083906650543213, 'weight_chosen': -0.06393349170684814, 'weight_rejected': 0.22815649211406708, 'kl_term_chosen': 0.7276024222373962, 'epoch': 0.08261159227181879}
                                                    {'loss': 134.5511, 'grad_norm': 3169.091796875, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 3.5083906650543213, 'weight_chosen': -0.06393349170684814, 'weight_rejected': 0.22815649211406708, 'kl_term_chosen': 0.7276024222373962, 'epoch': 0.08}
  8%|▊         | 310/3753 [23:54<4:23:54,  4.60s/it]  8%|▊         | 311/3753 [23:58<4:18:59,  4.51s/it]  8%|▊         | 312/3753 [24:02<4:10:39,  4.37s/it]  8%|▊         | 313/3753 [24:07<4:08:56,  4.34s/it]  8%|▊         | 314/3753 [24:14<4:57:13,  5.19s/it]  8%|▊         | 315/3753 [24:18<4:35:43,  4.81s/it]  8%|▊         | 316/3753 [24:22<4:20:28,  4.55s/it]  8%|▊         | 317/3753 [24:26<4:09:33,  4.36s/it]  8%|▊         | 318/3753 [24:30<4:12:52,  4.42s/it]  8%|▊         | 319/3753 [24:34<4:08:36,  4.34s/it]  9%|▊         | 320/3753 [24:39<4:14:24,  4.45s/it]{'loss': 117.7833, 'grad_norm': 6822.32861328125, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': 0.15926891565322876, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': 0.777941882610321, 'epoch': 0.08527648234510327}
                                                    {'loss': 117.7833, 'grad_norm': 6822.32861328125, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': 0.15926891565322876, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': 0.777941882610321, 'epoch': 0.09}
  9%|▊         | 320/3753 [24:39<4:14:24,  4.45s/it]  9%|▊         | 321/3753 [24:44<4:19:56,  4.54s/it]  9%|▊         | 322/3753 [24:48<4:11:34,  4.40s/it]  9%|▊         | 323/3753 [24:51<3:53:33,  4.09s/it]  9%|▊         | 324/3753 [24:58<4:46:40,  5.02s/it]  9%|▊         | 325/3753 [25:03<4:35:20,  4.82s/it]  9%|▊         | 326/3753 [25:06<4:14:06,  4.45s/it]  9%|▊         | 327/3753 [25:11<4:13:56,  4.45s/it]  9%|▊         | 328/3753 [25:15<4:03:08,  4.26s/it]  9%|▉         | 329/3753 [25:19<4:07:05,  4.33s/it]  9%|▉         | 330/3753 [25:24<4:16:27,  4.50s/it]{'loss': 101.7971, 'grad_norm': 17903.943359375, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 0.31689488887786865, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': 0.9764567613601685, 'weight_rejected': 0.22135066986083984, 'kl_term_chosen': -0.11491852253675461, 'epoch': 0.08794137241838774}
                                                    {'loss': 101.7971, 'grad_norm': 17903.943359375, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 0.31689488887786865, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': 0.9764567613601685, 'weight_rejected': 0.22135066986083984, 'kl_term_chosen': -0.11491852253675461, 'epoch': 0.09}
  9%|▉         | 330/3753 [25:24<4:16:27,  4.50s/it]  9%|▉         | 331/3753 [25:28<4:11:24,  4.41s/it]  9%|▉         | 332/3753 [25:32<4:02:05,  4.25s/it]  9%|▉         | 333/3753 [25:37<4:07:01,  4.33s/it]  9%|▉         | 334/3753 [25:45<5:08:20,  5.41s/it]  9%|▉         | 335/3753 [25:49<4:56:52,  5.21s/it]  9%|▉         | 336/3753 [25:53<4:24:27,  4.64s/it]  9%|▉         | 337/3753 [25:57<4:28:45,  4.72s/it]  9%|▉         | 338/3753 [26:01<4:06:22,  4.33s/it]  9%|▉         | 339/3753 [26:05<3:54:57,  4.13s/it]  9%|▉         | 340/3753 [26:09<3:58:58,  4.20s/it]{'loss': 80.1487, 'grad_norm': 11638.0908203125, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 1.8922386169433594, 'weight_rejected': 0.7826625108718872, 'kl_term_chosen': -1.648596167564392, 'epoch': 0.09060626249167222}
                                                    {'loss': 80.1487, 'grad_norm': 11638.0908203125, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 1.8922386169433594, 'weight_rejected': 0.7826625108718872, 'kl_term_chosen': -1.648596167564392, 'epoch': 0.09}
  9%|▉         | 340/3753 [26:09<3:58:58,  4.20s/it]  9%|▉         | 341/3753 [26:13<3:49:49,  4.04s/it]  9%|▉         | 342/3753 [26:17<3:47:17,  4.00s/it]  9%|▉         | 343/3753 [26:21<3:59:05,  4.21s/it]  9%|▉         | 344/3753 [26:25<3:52:23,  4.09s/it]  9%|▉         | 345/3753 [26:31<4:20:13,  4.58s/it]  9%|▉         | 346/3753 [26:35<4:11:15,  4.42s/it]  9%|▉         | 347/3753 [26:39<4:12:24,  4.45s/it]  9%|▉         | 348/3753 [26:45<4:30:43,  4.77s/it]  9%|▉         | 349/3753 [26:48<4:09:42,  4.40s/it]  9%|▉         | 350/3753 [26:53<4:15:54,  4.51s/it]{'loss': 105.1346, 'grad_norm': 4977.85986328125, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 0.5496798753738403, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': 0.8942487835884094, 'weight_rejected': 0.2186693549156189, 'kl_term_chosen': -0.05984191969037056, 'epoch': 0.09327115256495669}
                                                    {'loss': 105.1346, 'grad_norm': 4977.85986328125, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 0.5496798753738403, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': 0.8942487835884094, 'weight_rejected': 0.2186693549156189, 'kl_term_chosen': -0.05984191969037056, 'epoch': 0.09}
  9%|▉         | 350/3753 [26:53<4:15:54,  4.51s/it]  9%|▉         | 351/3753 [26:57<4:05:52,  4.34s/it]  9%|▉         | 352/3753 [27:00<3:47:43,  4.02s/it]  9%|▉         | 353/3753 [27:04<3:49:35,  4.05s/it]  9%|▉         | 354/3753 [27:09<3:58:00,  4.20s/it]  9%|▉         | 355/3753 [27:15<4:27:59,  4.73s/it]  9%|▉         | 356/3753 [27:19<4:20:25,  4.60s/it] 10%|▉         | 357/3753 [27:23<4:12:52,  4.47s/it] 10%|▉         | 358/3753 [27:28<4:13:00,  4.47s/it] 10%|▉         | 359/3753 [27:32<4:10:25,  4.43s/it] 10%|▉         | 360/3753 [27:36<3:56:05,  4.17s/it]{'loss': 122.9142, 'grad_norm': 1212.9066162109375, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -5.566089630126953, 'weight_rejected': 0.16667540371418, 'kl_term_chosen': 6.110406398773193, 'epoch': 0.09593604263824117}
                                                    {'loss': 122.9142, 'grad_norm': 1212.9066162109375, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -5.566089630126953, 'weight_rejected': 0.16667540371418, 'kl_term_chosen': 6.110406398773193, 'epoch': 0.1}
 10%|▉         | 360/3753 [27:36<3:56:05,  4.17s/it] 10%|▉         | 361/3753 [27:41<4:06:52,  4.37s/it] 10%|▉         | 362/3753 [27:45<4:04:44,  4.33s/it] 10%|▉         | 363/3753 [27:49<4:01:08,  4.27s/it] 10%|▉         | 364/3753 [27:54<4:04:47,  4.33s/it] 10%|▉         | 365/3753 [27:57<3:50:19,  4.08s/it] 10%|▉         | 366/3753 [28:01<3:41:14,  3.92s/it] 10%|▉         | 367/3753 [28:05<3:44:05,  3.97s/it] 10%|▉         | 368/3753 [28:09<3:58:05,  4.22s/it] 10%|▉         | 369/3753 [28:14<4:02:17,  4.30s/it] 10%|▉         | 370/3753 [28:18<4:02:10,  4.30s/it]{'loss': 126.796, 'grad_norm': 7041.26025390625, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 2.720813035964966, 'mean_ratio_rejected': 0.7958292365074158, 'weight_chosen': 0.7642173767089844, 'weight_rejected': 0.20561504364013672, 'kl_term_chosen': 0.10009308159351349, 'epoch': 0.09860093271152565}
                                                    {'loss': 126.796, 'grad_norm': 7041.26025390625, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 2.720813035964966, 'mean_ratio_rejected': 0.7958292365074158, 'weight_chosen': 0.7642173767089844, 'weight_rejected': 0.20561504364013672, 'kl_term_chosen': 0.10009308159351349, 'epoch': 0.1}
 10%|▉         | 370/3753 [28:18<4:02:10,  4.30s/it] 10%|▉         | 371/3753 [28:22<3:50:48,  4.09s/it] 10%|▉         | 372/3753 [28:27<4:01:32,  4.29s/it] 10%|▉         | 373/3753 [28:30<3:55:07,  4.17s/it] 10%|▉         | 374/3753 [28:38<4:44:16,  5.05s/it] 10%|▉         | 375/3753 [28:43<4:51:34,  5.18s/it] 10%|█         | 376/3753 [28:52<5:55:32,  6.32s/it] 10%|█         | 377/3753 [28:59<5:58:42,  6.38s/it] 10%|█         | 378/3753 [29:02<5:14:35,  5.59s/it] 10%|█         | 379/3753 [29:06<4:42:26,  5.02s/it] 10%|█         | 380/3753 [29:11<4:37:09,  4.93s/it]{'loss': 156.0268, 'grad_norm': 3193.73291015625, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -1.7640132904052734, 'weight_rejected': 0.02595735713839531, 'kl_term_chosen': 2.724374532699585, 'epoch': 0.10126582278481013}
                                                    {'loss': 156.0268, 'grad_norm': 3193.73291015625, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -1.7640132904052734, 'weight_rejected': 0.02595735713839531, 'kl_term_chosen': 2.724374532699585, 'epoch': 0.1}
 10%|█         | 380/3753 [29:11<4:37:09,  4.93s/it] 10%|█         | 381/3753 [29:15<4:22:47,  4.68s/it] 10%|█         | 382/3753 [29:19<4:21:58,  4.66s/it] 10%|█         | 383/3753 [29:23<4:10:41,  4.46s/it] 10%|█         | 384/3753 [29:29<4:24:31,  4.71s/it] 10%|█         | 385/3753 [29:39<5:52:08,  6.27s/it] 10%|█         | 386/3753 [29:42<5:09:36,  5.52s/it] 10%|█         | 387/3753 [29:47<4:50:17,  5.17s/it] 10%|█         | 388/3753 [29:51<4:36:42,  4.93s/it] 10%|█         | 389/3753 [29:56<4:33:58,  4.89s/it] 10%|█         | 390/3753 [30:02<4:52:01,  5.21s/it]{'loss': 137.6962, 'grad_norm': 2174.37060546875, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.1902775913476944, 'weight_chosen': 1.275321364402771, 'weight_rejected': 0.8164063692092896, 'kl_term_chosen': -0.6364860534667969, 'epoch': 0.1039307128580946}
                                                    {'loss': 137.6962, 'grad_norm': 2174.37060546875, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.1902775913476944, 'weight_chosen': 1.275321364402771, 'weight_rejected': 0.8164063692092896, 'kl_term_chosen': -0.6364860534667969, 'epoch': 0.1}
 10%|█         | 390/3753 [30:02<4:52:01,  5.21s/it] 10%|█         | 391/3753 [30:06<4:38:01,  4.96s/it] 10%|█         | 392/3753 [30:10<4:23:03,  4.70s/it] 10%|█         | 393/3753 [30:15<4:22:02,  4.68s/it] 10%|█         | 394/3753 [30:19<4:16:52,  4.59s/it] 11%|█         | 395/3753 [30:24<4:19:47,  4.64s/it] 11%|█         | 396/3753 [30:33<5:26:51,  5.84s/it] 11%|█         | 397/3753 [30:36<4:46:19,  5.12s/it] 11%|█         | 398/3753 [30:42<4:57:33,  5.32s/it] 11%|█         | 399/3753 [30:47<4:55:53,  5.29s/it] 11%|█         | 400/3753 [30:51<4:37:25,  4.96s/it]{'loss': 115.8911, 'grad_norm': 3844.54638671875, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 27.400733947753906, 'weight_chosen': 0.20330753922462463, 'weight_rejected': 0.25091278553009033, 'kl_term_chosen': 0.49182358384132385, 'epoch': 0.10659560293137908}
                                                    {'loss': 115.8911, 'grad_norm': 3844.54638671875, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 27.400733947753906, 'weight_chosen': 0.20330753922462463, 'weight_rejected': 0.25091278553009033, 'kl_term_chosen': 0.49182358384132385, 'epoch': 0.11}
 11%|█         | 400/3753 [30:51<4:37:25,  4.96s/it] 11%|█         | 401/3753 [30:55<4:21:27,  4.68s/it] 11%|█         | 402/3753 [31:00<4:22:32,  4.70s/it] 11%|█         | 403/3753 [31:04<4:02:08,  4.34s/it] 11%|█         | 404/3753 [31:08<3:57:55,  4.26s/it] 11%|█         | 405/3753 [31:13<4:11:39,  4.51s/it] 11%|█         | 406/3753 [31:17<4:11:49,  4.51s/it] 11%|█         | 407/3753 [31:21<3:59:52,  4.30s/it] 11%|█         | 408/3753 [31:26<4:09:39,  4.48s/it] 11%|█         | 409/3753 [31:30<4:07:03,  4.43s/it] 11%|█         | 410/3753 [31:35<4:07:13,  4.44s/it]{'loss': 172.6992, 'grad_norm': 63.81621551513672, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 0.48792287707328796, 'weight_chosen': -0.3758351802825928, 'weight_rejected': 0.28776782751083374, 'kl_term_chosen': 1.022741675376892, 'epoch': 0.10926049300466356}
                                                    {'loss': 172.6992, 'grad_norm': 63.81621551513672, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 0.48792287707328796, 'weight_chosen': -0.3758351802825928, 'weight_rejected': 0.28776782751083374, 'kl_term_chosen': 1.022741675376892, 'epoch': 0.11}
 11%|█         | 410/3753 [31:35<4:07:13,  4.44s/it] 11%|█         | 411/3753 [31:40<4:16:13,  4.60s/it] 11%|█         | 412/3753 [31:44<4:06:55,  4.43s/it] 11%|█         | 413/3753 [31:49<4:24:29,  4.75s/it] 11%|█         | 414/3753 [31:54<4:25:33,  4.77s/it] 11%|█         | 415/3753 [31:58<4:16:32,  4.61s/it] 11%|█         | 416/3753 [32:03<4:10:40,  4.51s/it] 11%|█         | 417/3753 [32:07<4:05:05,  4.41s/it] 11%|█         | 418/3753 [32:11<3:57:07,  4.27s/it] 11%|█         | 419/3753 [32:15<3:52:06,  4.18s/it] 11%|█         | 420/3753 [32:19<3:50:15,  4.15s/it]{'loss': 120.0585, 'grad_norm': 334.40264892578125, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': -2.55523681640625, 'weight_rejected': 0.2727987766265869, 'kl_term_chosen': 3.206591844558716, 'epoch': 0.11192538307794804}
                                                    {'loss': 120.0585, 'grad_norm': 334.40264892578125, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': -2.55523681640625, 'weight_rejected': 0.2727987766265869, 'kl_term_chosen': 3.206591844558716, 'epoch': 0.11}
 11%|█         | 420/3753 [32:19<3:50:15,  4.15s/it] 11%|█         | 421/3753 [32:23<3:53:52,  4.21s/it] 11%|█         | 422/3753 [32:27<3:50:26,  4.15s/it] 11%|█▏        | 423/3753 [32:31<3:46:47,  4.09s/it] 11%|█▏        | 424/3753 [32:34<3:30:13,  3.79s/it] 11%|█▏        | 425/3753 [32:38<3:37:19,  3.92s/it] 11%|█▏        | 426/3753 [32:43<3:46:06,  4.08s/it] 11%|█▏        | 427/3753 [32:47<3:52:38,  4.20s/it] 11%|█▏        | 428/3753 [32:52<4:01:10,  4.35s/it] 11%|█▏        | 429/3753 [32:56<3:56:19,  4.27s/it] 11%|█▏        | 430/3753 [33:01<4:06:52,  4.46s/it]{'loss': 81.5251, 'grad_norm': 1753.8751220703125, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 2.0327954292297363, 'weight_rejected': 0.27125170826911926, 'kl_term_chosen': -1.46917724609375, 'epoch': 0.1145902731512325}
                                                    {'loss': 81.5251, 'grad_norm': 1753.8751220703125, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 2.0327954292297363, 'weight_rejected': 0.27125170826911926, 'kl_term_chosen': -1.46917724609375, 'epoch': 0.11}
 11%|█▏        | 430/3753 [33:01<4:06:52,  4.46s/it] 11%|█▏        | 431/3753 [33:05<3:53:45,  4.22s/it] 12%|█▏        | 432/3753 [33:13<5:08:06,  5.57s/it] 12%|█▏        | 433/3753 [33:17<4:41:59,  5.10s/it] 12%|█▏        | 434/3753 [33:22<4:25:30,  4.80s/it] 12%|█▏        | 435/3753 [33:25<4:08:21,  4.49s/it] 12%|█▏        | 436/3753 [33:30<4:06:04,  4.45s/it] 12%|█▏        | 437/3753 [33:34<4:05:29,  4.44s/it] 12%|█▏        | 438/3753 [33:39<4:13:15,  4.58s/it] 12%|█▏        | 439/3753 [33:43<4:10:05,  4.53s/it] 12%|█▏        | 440/3753 [33:48<4:03:19,  4.41s/it]{'loss': 118.5314, 'grad_norm': 16170.09765625, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -3.6749911308288574, 'weight_rejected': 0.048136770725250244, 'kl_term_chosen': 4.629638671875, 'epoch': 0.11725516322451698}
                                                    {'loss': 118.5314, 'grad_norm': 16170.09765625, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -3.6749911308288574, 'weight_rejected': 0.048136770725250244, 'kl_term_chosen': 4.629638671875, 'epoch': 0.12}
 12%|█▏        | 440/3753 [33:48<4:03:19,  4.41s/it] 12%|█▏        | 441/3753 [33:53<4:25:26,  4.81s/it] 12%|█▏        | 442/3753 [33:58<4:21:30,  4.74s/it] 12%|█▏        | 443/3753 [34:01<3:54:48,  4.26s/it] 12%|█▏        | 444/3753 [34:06<4:06:14,  4.46s/it] 12%|█▏        | 445/3753 [34:10<3:54:48,  4.26s/it] 12%|█▏        | 446/3753 [34:14<3:59:44,  4.35s/it] 12%|█▏        | 447/3753 [34:19<3:59:46,  4.35s/it] 12%|█▏        | 448/3753 [34:22<3:41:24,  4.02s/it] 12%|█▏        | 449/3753 [34:27<4:02:29,  4.40s/it] 12%|█▏        | 450/3753 [34:31<3:59:59,  4.36s/it]{'loss': 150.97, 'grad_norm': 1342.4466552734375, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.5224528908729553, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 1.4157623052597046, 'epoch': 0.11992005329780146}
                                                    {'loss': 150.97, 'grad_norm': 1342.4466552734375, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -0.5224528908729553, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 1.4157623052597046, 'epoch': 0.12}
 12%|█▏        | 450/3753 [34:32<3:59:59,  4.36s/it] 12%|█▏        | 451/3753 [34:36<4:03:15,  4.42s/it] 12%|█▏        | 452/3753 [34:41<4:14:53,  4.63s/it] 12%|█▏        | 453/3753 [34:45<3:55:59,  4.29s/it] 12%|█▏        | 454/3753 [34:50<4:15:47,  4.65s/it] 12%|█▏        | 455/3753 [34:55<4:15:44,  4.65s/it] 12%|█▏        | 456/3753 [35:01<4:40:47,  5.11s/it] 12%|█▏        | 457/3753 [35:05<4:24:19,  4.81s/it] 12%|█▏        | 458/3753 [35:09<4:08:28,  4.52s/it] 12%|█▏        | 459/3753 [35:13<4:03:39,  4.44s/it] 12%|█▏        | 460/3753 [35:19<4:21:22,  4.76s/it]{'loss': 176.7116, 'grad_norm': 18.60958480834961, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -6.514674186706543, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': 7.433154582977295, 'epoch': 0.12258494337108594}
                                                    {'loss': 176.7116, 'grad_norm': 18.60958480834961, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -6.514674186706543, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': 7.433154582977295, 'epoch': 0.12}
 12%|█▏        | 460/3753 [35:19<4:21:22,  4.76s/it] 12%|█▏        | 461/3753 [35:22<4:06:19,  4.49s/it] 12%|█▏        | 462/3753 [35:25<3:41:04,  4.03s/it] 12%|█▏        | 463/3753 [35:30<3:45:29,  4.11s/it] 12%|█▏        | 464/3753 [35:34<3:46:47,  4.14s/it] 12%|█▏        | 465/3753 [35:38<3:45:59,  4.12s/it] 12%|█▏        | 466/3753 [35:42<3:47:52,  4.16s/it] 12%|█▏        | 467/3753 [35:47<3:54:41,  4.29s/it] 12%|█▏        | 468/3753 [35:55<4:51:39,  5.33s/it] 12%|█▏        | 469/3753 [36:00<4:53:37,  5.36s/it] 13%|█▎        | 470/3753 [36:06<5:05:11,  5.58s/it]{'loss': 223.5877, 'grad_norm': 2712.517333984375, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -9.978565216064453, 'weight_rejected': 0.08151976019144058, 'kl_term_chosen': 10.92356014251709, 'epoch': 0.1252498334443704}
                                                    {'loss': 223.5877, 'grad_norm': 2712.517333984375, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -9.978565216064453, 'weight_rejected': 0.08151976019144058, 'kl_term_chosen': 10.92356014251709, 'epoch': 0.13}
 13%|█▎        | 470/3753 [36:06<5:05:11,  5.58s/it] 13%|█▎        | 471/3753 [36:12<5:08:10,  5.63s/it] 13%|█▎        | 472/3753 [36:15<4:33:58,  5.01s/it] 13%|█▎        | 473/3753 [36:19<4:02:11,  4.43s/it] 13%|█▎        | 474/3753 [36:23<4:02:55,  4.45s/it] 13%|█▎        | 475/3753 [36:28<4:04:56,  4.48s/it] 13%|█▎        | 476/3753 [36:31<3:53:59,  4.28s/it] 13%|█▎        | 477/3753 [36:36<3:57:39,  4.35s/it] 13%|█▎        | 478/3753 [36:40<3:55:45,  4.32s/it] 13%|█▎        | 479/3753 [36:46<4:20:06,  4.77s/it] 13%|█▎        | 480/3753 [36:51<4:18:53,  4.75s/it]{'loss': 200.4969, 'grad_norm': 3389.288818359375, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 1.112473487854004, 'weight_rejected': 0.23792988061904907, 'kl_term_chosen': -0.535931408405304, 'epoch': 0.1279147235176549}
                                                    {'loss': 200.4969, 'grad_norm': 3389.288818359375, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 1.112473487854004, 'weight_rejected': 0.23792988061904907, 'kl_term_chosen': -0.535931408405304, 'epoch': 0.13}
 13%|█▎        | 480/3753 [36:51<4:18:53,  4.75s/it] 13%|█▎        | 481/3753 [36:56<4:22:12,  4.81s/it] 13%|█▎        | 482/3753 [37:00<4:08:43,  4.56s/it] 13%|█▎        | 483/3753 [37:04<3:58:30,  4.38s/it] 13%|█▎        | 484/3753 [37:08<3:52:06,  4.26s/it] 13%|█▎        | 485/3753 [37:11<3:41:39,  4.07s/it] 13%|█▎        | 486/3753 [37:16<3:57:52,  4.37s/it] 13%|█▎        | 487/3753 [37:21<4:04:55,  4.50s/it] 13%|█▎        | 488/3753 [37:25<3:52:32,  4.27s/it] 13%|█▎        | 489/3753 [37:30<4:04:20,  4.49s/it] 13%|█▎        | 490/3753 [37:35<4:18:09,  4.75s/it]{'loss': 145.1268, 'grad_norm': 29.165647506713867, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -1.8732593059539795, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': 2.8174362182617188, 'epoch': 0.13057961359093936}
                                                    {'loss': 145.1268, 'grad_norm': 29.165647506713867, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -1.8732593059539795, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': 2.8174362182617188, 'epoch': 0.13}
 13%|█▎        | 490/3753 [37:35<4:18:09,  4.75s/it] 13%|█▎        | 491/3753 [37:40<4:20:43,  4.80s/it] 13%|█▎        | 492/3753 [37:44<4:03:52,  4.49s/it] 13%|█▎        | 493/3753 [37:54<5:30:10,  6.08s/it] 13%|█▎        | 494/3753 [37:58<4:58:05,  5.49s/it] 13%|█▎        | 495/3753 [38:01<4:23:06,  4.85s/it] 13%|█▎        | 496/3753 [38:06<4:23:26,  4.85s/it] 13%|█▎        | 497/3753 [38:10<4:03:53,  4.49s/it] 13%|█▎        | 498/3753 [38:18<4:59:40,  5.52s/it] 13%|█▎        | 499/3753 [38:24<5:10:18,  5.72s/it] 13%|█▎        | 500/3753 [38:29<4:59:25,  5.52s/it]{'loss': 200.5594, 'grad_norm': 7379.431640625, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 0.0174156092107296, 'weight_chosen': -0.02030867338180542, 'weight_rejected': 0.22270013391971588, 'kl_term_chosen': 0.6627411246299744, 'epoch': 0.13324450366422386}
                                                    {'loss': 200.5594, 'grad_norm': 7379.431640625, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 0.0174156092107296, 'weight_chosen': -0.02030867338180542, 'weight_rejected': 0.22270013391971588, 'kl_term_chosen': 0.6627411246299744, 'epoch': 0.13}
 13%|█▎        | 500/3753 [38:29<4:59:25,  5.52s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 13%|█▎        | 501/3753 [39:30<20:12:24, 22.37s/it] 13%|█▎        | 502/3753 [39:38<16:16:40, 18.03s/it] 13%|█▎        | 503/3753 [39:43<12:35:23, 13.95s/it] 13%|█▎        | 504/3753 [39:46<9:48:48, 10.87s/it]  13%|█▎        | 505/3753 [39:50<7:50:43,  8.70s/it] 13%|█▎        | 506/3753 [39:54<6:33:49,  7.28s/it] 14%|█▎        | 507/3753 [40:00<6:04:47,  6.74s/it] 14%|█▎        | 508/3753 [40:05<5:39:26,  6.28s/it] 14%|█▎        | 509/3753 [40:09<5:02:01,  5.59s/it] 14%|█▎        | 510/3753 [40:13<4:41:51,  5.21s/it]{'loss': 259.403, 'grad_norm': 328.8316345214844, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -3.0944948196411133, 'weight_rejected': 0.03358950838446617, 'kl_term_chosen': 4.05047607421875, 'epoch': 0.13590939373750832}
                                                    {'loss': 259.403, 'grad_norm': 328.8316345214844, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 99.48430633544922, 'mean_ratio_rejected': 99.48430633544922, 'weight_chosen': -3.0944948196411133, 'weight_rejected': 0.03358950838446617, 'kl_term_chosen': 4.05047607421875, 'epoch': 0.14}
 14%|█▎        | 510/3753 [40:13<4:41:51,  5.21s/it] 14%|█▎        | 511/3753 [40:17<4:27:32,  4.95s/it]W1109 07:28:48.298000 23355 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
W1109 07:28:48.302000 23355 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 23458 closing signal SIGTERM
W1109 07:28:48.304000 23355 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 23459 closing signal SIGTERM
W1109 07:28:48.304000 23355 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 23460 closing signal SIGTERM
W1109 07:28:48.305000 23355 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 23461 closing signal SIGTERM
Traceback (most recent call last):
  File "/root/miniconda3/envs/advan/bin/accelerate", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/launch.py", line 1222, in launch_command
    multi_gpu_launcher(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/launch.py", line 853, in multi_gpu_launcher
    distrib_run.run(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py", line 138, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 715, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 879, in _invoke_run
    time.sleep(monitor_interval)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 23355 got signal: 15
