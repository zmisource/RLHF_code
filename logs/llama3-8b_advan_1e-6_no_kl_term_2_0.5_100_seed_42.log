nohup: ignoring input
[W1109 05:43:33.678027469 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 82.77it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 89.91it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.39it/s]
加载作为参考的SFT模型 (Reference Model)...
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 85.79it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 83.18it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.70it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 90.64it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 85.81it/s]
[W1109 05:43:38.287767222 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1109 05:43:38.303132064 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1109 05:43:38.310528413 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1109 05:43:38.313354693 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
/rlhf_code/code/implement_final_v3_no_kl_term2.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /root/wandb/offline-run-20251109_054348-8m4n94e5
  0%|          | 0/3753 [00:00<?, ?it/s]--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -199.0
Sample 0 - pi_logp_chosen:  -198.81076049804688
Sample 0 - Difference (pi - ref): 0.189239501953125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -100.5
Sample 0 - pi_logp_chosen:  -100.34402465820312
Sample 0 - Difference (pi - ref): 0.155975341796875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -122.0
Sample 0 - pi_logp_chosen:  -121.57272338867188
Sample 0 - Difference (pi - ref): 0.427276611328125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -234.0
Sample 0 - pi_logp_chosen:  -233.57894897460938
Sample 0 - Difference (pi - ref): 0.421051025390625
---------------------------------
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -227.0
Sample 0 - pi_logp_chosen:  -227.50088500976562
Sample 0 - Difference (pi - ref): -0.500885009765625
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---Sample 0 - ref_logp_chosen: -248.0
Sample 0 - pi_logp_chosen:  -248.47735595703125

Sample 0 - Difference (pi - ref): -0.47735595703125
---------------------------------
Sample 0 - ref_logp_chosen: -209.0
Sample 0 - pi_logp_chosen:  -208.26136779785156
Sample 0 - Difference (pi - ref): 0.7386322021484375
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -728.0
Sample 0 - pi_logp_chosen:  -730.50390625
Sample 0 - Difference (pi - ref): -2.50390625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -240.0
Sample 0 - pi_logp_chosen:  -240.2412567138672
Sample 0 - Difference (pi - ref): -0.2412567138671875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -253.0
Sample 0 - pi_logp_chosen:  -253.00314331054688
Sample 0 - Difference (pi - ref): -0.003143310546875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -350.0
Sample 0 - pi_logp_chosen:  -349.3069152832031
Sample 0 - Difference (pi - ref): 0.693084716796875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -452.0
Sample 0 - pi_logp_chosen:  -453.64239501953125
Sample 0 - Difference (pi - ref): -1.64239501953125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -127.5
Sample 0 - pi_logp_chosen:  -127.59747314453125
Sample 0 - Difference (pi - ref): -0.09747314453125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -98.5
Sample 0 - pi_logp_chosen:  -98.78225708007812
Sample 0 - Difference (pi - ref): -0.282257080078125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -251.0
Sample 0 - pi_logp_chosen:  -249.6898956298828
Sample 0 - Difference (pi - ref): 1.3101043701171875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -516.0
Sample 0 - pi_logp_chosen:  -514.2531127929688
Sample 0 - Difference (pi - ref): 1.74688720703125
---------------------------------
  0%|          | 1/3753 [00:04<4:56:38,  4.74s/it]{'loss': -0.1746, 'grad_norm': 2037.3673095703125, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 6.590037822723389, 'weight_chosen': 0.2668696641921997, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 0.6550521850585938, 'epoch': 0.0002664890073284477}
                                                  {'loss': -0.1746, 'grad_norm': 2037.3673095703125, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 6.590037822723389, 'weight_chosen': 0.2668696641921997, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 0.6550521850585938, 'epoch': 0.0}
  0%|          | 1/3753 [00:04<4:56:38,  4.74s/it]  0%|          | 2/3753 [00:10<5:18:39,  5.10s/it]  0%|          | 3/3753 [00:14<5:07:21,  4.92s/it]  0%|          | 4/3753 [00:18<4:42:57,  4.53s/it]  0%|          | 5/3753 [00:22<4:36:21,  4.42s/it]  0%|          | 6/3753 [00:28<4:59:11,  4.79s/it]  0%|          | 7/3753 [00:32<4:46:37,  4.59s/it]  0%|          | 8/3753 [00:37<4:43:33,  4.54s/it]  0%|          | 9/3753 [00:40<4:25:19,  4.25s/it]  0%|          | 10/3753 [00:44<4:20:24,  4.17s/it]{'loss': -0.3044, 'grad_norm': 3400.607177734375, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 1.0305633544921875, 'mean_ratio_rejected': 0.9331270456314087, 'weight_chosen': 0.23003220558166504, 'weight_rejected': 0.4163219630718231, 'kl_term_chosen': 0.01505279541015625, 'epoch': 0.002664890073284477}
                                                   {'loss': -0.3044, 'grad_norm': 3400.607177734375, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 1.0305633544921875, 'mean_ratio_rejected': 0.9331270456314087, 'weight_chosen': 0.23003220558166504, 'weight_rejected': 0.4163219630718231, 'kl_term_chosen': 0.01505279541015625, 'epoch': 0.0}
  0%|          | 10/3753 [00:44<4:20:24,  4.17s/it]  0%|          | 11/3753 [00:49<4:26:34,  4.27s/it]  0%|          | 12/3753 [00:54<4:39:06,  4.48s/it]  0%|          | 13/3753 [00:58<4:35:49,  4.42s/it]  0%|          | 14/3753 [01:02<4:28:54,  4.32s/it]  0%|          | 15/3753 [01:06<4:18:08,  4.14s/it]  0%|          | 16/3753 [01:10<4:17:24,  4.13s/it]  0%|          | 17/3753 [01:14<4:09:41,  4.01s/it]  0%|          | 18/3753 [01:18<4:25:14,  4.26s/it]  1%|          | 19/3753 [01:22<4:08:07,  3.99s/it]  1%|          | 20/3753 [01:26<4:05:56,  3.95s/it]{'loss': -0.0843, 'grad_norm': 24898.64453125, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 1.5520063638687134, 'mean_ratio_rejected': 1.1870492696762085, 'weight_chosen': 0.5128175616264343, 'weight_rejected': 0.29665425419807434, 'kl_term_chosen': 0.2197742462158203, 'epoch': 0.005329780146568954}
                                                   {'loss': -0.0843, 'grad_norm': 24898.64453125, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 1.5520063638687134, 'mean_ratio_rejected': 1.1870492696762085, 'weight_chosen': 0.5128175616264343, 'weight_rejected': 0.29665425419807434, 'kl_term_chosen': 0.2197742462158203, 'epoch': 0.01}
  1%|          | 20/3753 [01:26<4:05:56,  3.95s/it]  1%|          | 21/3753 [01:30<4:10:12,  4.02s/it]  1%|          | 22/3753 [01:38<5:20:40,  5.16s/it]  1%|          | 23/3753 [01:43<5:17:29,  5.11s/it]  1%|          | 24/3753 [01:46<4:43:25,  4.56s/it]  1%|          | 25/3753 [01:50<4:37:07,  4.46s/it]  1%|          | 26/3753 [01:53<4:10:39,  4.04s/it]  1%|          | 27/3753 [01:57<4:11:50,  4.06s/it]  1%|          | 28/3753 [02:01<4:13:17,  4.08s/it]  1%|          | 29/3753 [02:05<4:08:46,  4.01s/it]  1%|          | 30/3753 [02:09<4:11:37,  4.06s/it]{'loss': 0.0374, 'grad_norm': 17957.8125, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 0.9277781844139099, 'mean_ratio_rejected': 1.1833916902542114, 'weight_chosen': 0.6654325127601624, 'weight_rejected': 0.5987815260887146, 'kl_term_chosen': -0.03748130798339844, 'epoch': 0.007994670219853431}
                                                   {'loss': 0.0374, 'grad_norm': 17957.8125, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 0.9277781844139099, 'mean_ratio_rejected': 1.1833916902542114, 'weight_chosen': 0.6654325127601624, 'weight_rejected': 0.5987815260887146, 'kl_term_chosen': -0.03748130798339844, 'epoch': 0.01}
  1%|          | 30/3753 [02:10<4:11:37,  4.06s/it]  1%|          | 31/3753 [02:15<4:33:58,  4.42s/it]  1%|          | 32/3753 [02:18<4:21:04,  4.21s/it]  1%|          | 33/3753 [02:22<4:12:47,  4.08s/it]  1%|          | 34/3753 [02:29<5:01:25,  4.86s/it]  1%|          | 35/3753 [02:34<5:14:19,  5.07s/it]  1%|          | 36/3753 [02:41<5:34:30,  5.40s/it]  1%|          | 37/3753 [02:46<5:39:39,  5.48s/it]  1%|          | 38/3753 [02:51<5:19:19,  5.16s/it]  1%|          | 39/3753 [02:59<6:20:04,  6.14s/it]  1%|          | 40/3753 [03:03<5:40:50,  5.51s/it]{'loss': 2.0304, 'grad_norm': 2456.40234375, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 0.4931209683418274, 'mean_ratio_rejected': 1.6898553371429443, 'weight_chosen': 1.1112947463989258, 'weight_rejected': 0.1276526302099228, 'kl_term_chosen': -0.3535003662109375, 'epoch': 0.010659560293137908}
                                                   {'loss': 2.0304, 'grad_norm': 2456.40234375, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 0.4931209683418274, 'mean_ratio_rejected': 1.6898553371429443, 'weight_chosen': 1.1112947463989258, 'weight_rejected': 0.1276526302099228, 'kl_term_chosen': -0.3535003662109375, 'epoch': 0.01}
  1%|          | 40/3753 [03:03<5:40:50,  5.51s/it]  1%|          | 41/3753 [03:10<6:00:45,  5.83s/it]  1%|          | 42/3753 [03:13<5:09:36,  5.01s/it]  1%|          | 43/3753 [03:18<5:05:28,  4.94s/it]  1%|          | 44/3753 [03:22<4:49:48,  4.69s/it]  1%|          | 45/3753 [03:27<4:58:01,  4.82s/it]  1%|          | 46/3753 [03:32<5:01:00,  4.87s/it]  1%|▏         | 47/3753 [03:35<4:25:17,  4.30s/it]  1%|▏         | 48/3753 [03:39<4:20:46,  4.22s/it]  1%|▏         | 49/3753 [03:43<4:26:36,  4.32s/it]  1%|▏         | 50/3753 [03:47<4:22:31,  4.25s/it]{'loss': -0.0286, 'grad_norm': 2337.4541015625, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 3.896730661392212, 'mean_ratio_rejected': 3.9186134338378906, 'weight_chosen': 0.18332266807556152, 'weight_rejected': 0.6851073503494263, 'kl_term_chosen': 0.6800689697265625, 'epoch': 0.013324450366422385}
                                                   {'loss': -0.0286, 'grad_norm': 2337.4541015625, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 3.896730661392212, 'mean_ratio_rejected': 3.9186134338378906, 'weight_chosen': 0.18332266807556152, 'weight_rejected': 0.6851073503494263, 'kl_term_chosen': 0.6800689697265625, 'epoch': 0.01}
  1%|▏         | 50/3753 [03:48<4:22:31,  4.25s/it]  1%|▏         | 51/3753 [03:52<4:20:36,  4.22s/it]  1%|▏         | 52/3753 [03:56<4:29:22,  4.37s/it]  1%|▏         | 53/3753 [04:02<4:56:24,  4.81s/it]  1%|▏         | 54/3753 [04:06<4:31:54,  4.41s/it]  1%|▏         | 55/3753 [04:14<5:41:34,  5.54s/it]  1%|▏         | 56/3753 [04:22<6:27:12,  6.28s/it]  2%|▏         | 57/3753 [04:27<5:58:13,  5.82s/it]  2%|▏         | 58/3753 [04:30<5:14:43,  5.11s/it]  2%|▏         | 59/3753 [04:38<6:00:16,  5.85s/it]  2%|▏         | 60/3753 [04:41<5:10:37,  5.05s/it]{'loss': 0.4927, 'grad_norm': 11371.9560546875, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 1.320884108543396, 'mean_ratio_rejected': 1.1657427549362183, 'weight_chosen': -0.10893601179122925, 'weight_rejected': 0.937210738658905, 'kl_term_chosen': 0.13915061950683594, 'epoch': 0.015989340439706862}
                                                   {'loss': 0.4927, 'grad_norm': 11371.9560546875, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 1.320884108543396, 'mean_ratio_rejected': 1.1657427549362183, 'weight_chosen': -0.10893601179122925, 'weight_rejected': 0.937210738658905, 'kl_term_chosen': 0.13915061950683594, 'epoch': 0.02}
  2%|▏         | 60/3753 [04:41<5:10:37,  5.05s/it]  2%|▏         | 61/3753 [04:47<5:25:06,  5.28s/it]  2%|▏         | 62/3753 [04:51<5:07:19,  5.00s/it]  2%|▏         | 63/3753 [04:55<4:56:26,  4.82s/it]  2%|▏         | 64/3753 [05:01<5:03:50,  4.94s/it]  2%|▏         | 65/3753 [05:04<4:44:47,  4.63s/it]  2%|▏         | 66/3753 [05:10<4:56:47,  4.83s/it]  2%|▏         | 67/3753 [05:14<4:52:34,  4.76s/it]  2%|▏         | 68/3753 [05:18<4:33:28,  4.45s/it]  2%|▏         | 69/3753 [05:23<4:35:35,  4.49s/it]  2%|▏         | 70/3753 [05:26<4:21:05,  4.25s/it]{'loss': 0.0712, 'grad_norm': 8236.947265625, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 21.065526962280273, 'mean_ratio_rejected': 5.645537853240967, 'weight_chosen': -0.5605884194374084, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 1.5238189697265625, 'epoch': 0.018654230512991338}
                                                   {'loss': 0.0712, 'grad_norm': 8236.947265625, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 21.065526962280273, 'mean_ratio_rejected': 5.645537853240967, 'weight_chosen': -0.5605884194374084, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 1.5238189697265625, 'epoch': 0.02}
  2%|▏         | 70/3753 [05:26<4:21:05,  4.25s/it]  2%|▏         | 71/3753 [05:31<4:31:10,  4.42s/it]  2%|▏         | 72/3753 [05:36<4:39:42,  4.56s/it]  2%|▏         | 73/3753 [05:40<4:27:35,  4.36s/it]  2%|▏         | 74/3753 [05:44<4:16:03,  4.18s/it]  2%|▏         | 75/3753 [05:47<4:06:49,  4.03s/it]  2%|▏         | 76/3753 [05:53<4:38:29,  4.54s/it]  2%|▏         | 77/3753 [05:57<4:16:39,  4.19s/it]  2%|▏         | 78/3753 [06:02<4:36:55,  4.52s/it]  2%|▏         | 79/3753 [06:06<4:33:30,  4.47s/it]  2%|▏         | 80/3753 [06:11<4:41:49,  4.60s/it]{'loss': 0.3004, 'grad_norm': 3025.4052734375, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 0.9480531215667725, 'mean_ratio_rejected': 2.168658971786499, 'weight_chosen': 0.9550811648368835, 'weight_rejected': 0.10230471193790436, 'kl_term_chosen': -0.02667236328125, 'epoch': 0.021319120586275817}
                                                   {'loss': 0.3004, 'grad_norm': 3025.4052734375, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 0.9480531215667725, 'mean_ratio_rejected': 2.168658971786499, 'weight_chosen': 0.9550811648368835, 'weight_rejected': 0.10230471193790436, 'kl_term_chosen': -0.02667236328125, 'epoch': 0.02}
  2%|▏         | 80/3753 [06:11<4:41:49,  4.60s/it]  2%|▏         | 81/3753 [06:16<4:44:42,  4.65s/it]  2%|▏         | 82/3753 [06:20<4:29:08,  4.40s/it]  2%|▏         | 83/3753 [06:27<5:16:44,  5.18s/it]  2%|▏         | 84/3753 [06:32<5:11:37,  5.10s/it]  2%|▏         | 85/3753 [06:35<4:44:27,  4.65s/it]  2%|▏         | 86/3753 [06:39<4:20:59,  4.27s/it]  2%|▏         | 87/3753 [06:46<5:10:18,  5.08s/it]  2%|▏         | 88/3753 [06:49<4:46:36,  4.69s/it]  2%|▏         | 89/3753 [06:54<4:45:31,  4.68s/it]  2%|▏         | 90/3753 [06:58<4:37:10,  4.54s/it]{'loss': 0.134, 'grad_norm': 16657.423828125, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 22.618640899658203, 'mean_ratio_rejected': 58.71486282348633, 'weight_chosen': -0.7701535224914551, 'weight_rejected': 0.15002880990505219, 'kl_term_chosen': 1.55938720703125, 'epoch': 0.023984010659560292}
                                                   {'loss': 0.134, 'grad_norm': 16657.423828125, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 22.618640899658203, 'mean_ratio_rejected': 58.71486282348633, 'weight_chosen': -0.7701535224914551, 'weight_rejected': 0.15002880990505219, 'kl_term_chosen': 1.55938720703125, 'epoch': 0.02}
  2%|▏         | 90/3753 [06:58<4:37:10,  4.54s/it]  2%|▏         | 91/3753 [07:01<4:14:43,  4.17s/it]  2%|▏         | 92/3753 [07:05<4:10:52,  4.11s/it]  2%|▏         | 93/3753 [07:11<4:36:23,  4.53s/it]  3%|▎         | 94/3753 [07:15<4:29:43,  4.42s/it]  3%|▎         | 95/3753 [07:22<5:11:39,  5.11s/it]  3%|▎         | 96/3753 [07:26<4:52:06,  4.79s/it]  3%|▎         | 97/3753 [07:30<4:42:22,  4.63s/it]  3%|▎         | 98/3753 [07:36<5:03:34,  4.98s/it]  3%|▎         | 99/3753 [07:39<4:35:31,  4.52s/it]  3%|▎         | 100/3753 [07:44<4:28:33,  4.41s/it]{'loss': 1.3259, 'grad_norm': 4894.07177734375, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 1.3740522861480713, 'mean_ratio_rejected': 1.6610757112503052, 'weight_chosen': 0.46906906366348267, 'weight_rejected': 0.14414885640144348, 'kl_term_chosen': 0.15888214111328125, 'epoch': 0.02664890073284477}
                                                    {'loss': 1.3259, 'grad_norm': 4894.07177734375, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 1.3740522861480713, 'mean_ratio_rejected': 1.6610757112503052, 'weight_chosen': 0.46906906366348267, 'weight_rejected': 0.14414885640144348, 'kl_term_chosen': 0.15888214111328125, 'epoch': 0.03}
  3%|▎         | 100/3753 [07:44<4:28:33,  4.41s/it]  3%|▎         | 101/3753 [07:48<4:32:49,  4.48s/it]  3%|▎         | 102/3753 [07:52<4:27:14,  4.39s/it]  3%|▎         | 103/3753 [07:56<4:16:15,  4.21s/it]  3%|▎         | 104/3753 [08:02<4:42:14,  4.64s/it]  3%|▎         | 105/3753 [08:06<4:38:03,  4.57s/it]  3%|▎         | 106/3753 [08:12<4:56:15,  4.87s/it]  3%|▎         | 107/3753 [08:16<4:52:07,  4.81s/it]  3%|▎         | 108/3753 [08:20<4:37:29,  4.57s/it]  3%|▎         | 109/3753 [08:24<4:26:53,  4.39s/it]  3%|▎         | 110/3753 [08:28<4:19:03,  4.27s/it]{'loss': 0.1893, 'grad_norm': 14869.2763671875, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 14.153520584106445, 'mean_ratio_rejected': 1.7404935359954834, 'weight_chosen': -0.41130518913269043, 'weight_rejected': 0.04146226868033409, 'kl_term_chosen': 1.324981689453125, 'epoch': 0.029313790806129246}
                                                    {'loss': 0.1893, 'grad_norm': 14869.2763671875, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 14.153520584106445, 'mean_ratio_rejected': 1.7404935359954834, 'weight_chosen': -0.41130518913269043, 'weight_rejected': 0.04146226868033409, 'kl_term_chosen': 1.324981689453125, 'epoch': 0.03}
  3%|▎         | 110/3753 [08:29<4:19:03,  4.27s/it]  3%|▎         | 111/3753 [08:34<4:49:21,  4.77s/it]  3%|▎         | 112/3753 [08:38<4:30:55,  4.46s/it]  3%|▎         | 113/3753 [08:41<4:09:58,  4.12s/it]  3%|▎         | 114/3753 [08:45<3:59:57,  3.96s/it]  3%|▎         | 115/3753 [08:49<3:57:26,  3.92s/it]  3%|▎         | 116/3753 [08:54<4:14:31,  4.20s/it]  3%|▎         | 117/3753 [08:58<4:13:18,  4.18s/it]  3%|▎         | 118/3753 [09:02<4:16:32,  4.23s/it]  3%|▎         | 119/3753 [09:10<5:24:39,  5.36s/it]  3%|▎         | 120/3753 [09:15<5:07:48,  5.08s/it]{'loss': 0.2952, 'grad_norm': 6961.4287109375, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 0.4868556559085846, 'mean_ratio_rejected': 0.5471735596656799, 'weight_chosen': 1.1964483261108398, 'weight_rejected': 0.49502578377723694, 'kl_term_chosen': -0.359893798828125, 'epoch': 0.031978680879413725}
                                                    {'loss': 0.2952, 'grad_norm': 6961.4287109375, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 0.4868556559085846, 'mean_ratio_rejected': 0.5471735596656799, 'weight_chosen': 1.1964483261108398, 'weight_rejected': 0.49502578377723694, 'kl_term_chosen': -0.359893798828125, 'epoch': 0.03}
  3%|▎         | 120/3753 [09:15<5:07:48,  5.08s/it]  3%|▎         | 121/3753 [09:19<4:53:15,  4.84s/it]  3%|▎         | 122/3753 [09:24<4:53:05,  4.84s/it]  3%|▎         | 123/3753 [09:28<4:42:38,  4.67s/it]  3%|▎         | 124/3753 [09:32<4:26:48,  4.41s/it]  3%|▎         | 125/3753 [09:37<4:33:57,  4.53s/it]  3%|▎         | 126/3753 [09:42<4:41:40,  4.66s/it]  3%|▎         | 127/3753 [09:45<4:23:01,  4.35s/it]  3%|▎         | 128/3753 [09:50<4:34:04,  4.54s/it]  3%|▎         | 129/3753 [09:56<4:55:56,  4.90s/it]  3%|▎         | 130/3753 [10:01<4:49:38,  4.80s/it]{'loss': 1.3927, 'grad_norm': 4694.90625, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 2.9012887477874756, 'mean_ratio_rejected': 0.6570981740951538, 'weight_chosen': -0.23510760068893433, 'weight_rejected': 0.10970578342676163, 'kl_term_chosen': 0.5325775146484375, 'epoch': 0.034643570952698204}
                                                    {'loss': 1.3927, 'grad_norm': 4694.90625, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 2.9012887477874756, 'mean_ratio_rejected': 0.6570981740951538, 'weight_chosen': -0.23510760068893433, 'weight_rejected': 0.10970578342676163, 'kl_term_chosen': 0.5325775146484375, 'epoch': 0.03}
  3%|▎         | 130/3753 [10:01<4:49:38,  4.80s/it]  3%|▎         | 131/3753 [10:04<4:33:40,  4.53s/it]  4%|▎         | 132/3753 [10:08<4:11:39,  4.17s/it]  4%|▎         | 133/3753 [10:13<4:24:24,  4.38s/it]  4%|▎         | 134/3753 [10:17<4:27:48,  4.44s/it]  4%|▎         | 135/3753 [10:21<4:15:22,  4.23s/it]  4%|▎         | 136/3753 [10:24<4:02:44,  4.03s/it]  4%|▎         | 137/3753 [10:28<3:57:07,  3.93s/it]  4%|▎         | 138/3753 [10:33<4:11:51,  4.18s/it]  4%|▎         | 139/3753 [10:37<4:05:49,  4.08s/it]  4%|▎         | 140/3753 [10:42<4:22:12,  4.35s/it]{'loss': 0.2846, 'grad_norm': 5075.28271484375, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 3.4047062397003174, 'mean_ratio_rejected': 1.964848279953003, 'weight_chosen': 0.247084379196167, 'weight_rejected': 0.14706450700759888, 'kl_term_chosen': 0.612579345703125, 'epoch': 0.037308461025982675}
                                                    {'loss': 0.2846, 'grad_norm': 5075.28271484375, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 3.4047062397003174, 'mean_ratio_rejected': 1.964848279953003, 'weight_chosen': 0.247084379196167, 'weight_rejected': 0.14706450700759888, 'kl_term_chosen': 0.612579345703125, 'epoch': 0.04}
  4%|▎         | 140/3753 [10:42<4:22:12,  4.35s/it]  4%|▍         | 141/3753 [10:46<4:13:21,  4.21s/it]  4%|▍         | 142/3753 [10:52<4:55:31,  4.91s/it]  4%|▍         | 143/3753 [10:56<4:40:50,  4.67s/it]  4%|▍         | 144/3753 [11:02<5:05:28,  5.08s/it]  4%|▍         | 145/3753 [11:10<5:46:54,  5.77s/it]  4%|▍         | 146/3753 [11:15<5:39:14,  5.64s/it]  4%|▍         | 147/3753 [11:22<6:02:54,  6.04s/it]  4%|▍         | 148/3753 [11:27<5:45:16,  5.75s/it]  4%|▍         | 149/3753 [11:31<5:15:33,  5.25s/it]  4%|▍         | 150/3753 [11:38<5:47:45,  5.79s/it]{'loss': 0.329, 'grad_norm': 2001.2138671875, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 0.5081691145896912, 'mean_ratio_rejected': 0.12817980349063873, 'weight_chosen': 0.6739301681518555, 'weight_rejected': 0.5903069972991943, 'kl_term_chosen': -0.338470458984375, 'epoch': 0.039973351099267154}
                                                    {'loss': 0.329, 'grad_norm': 2001.2138671875, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 0.5081691145896912, 'mean_ratio_rejected': 0.12817980349063873, 'weight_chosen': 0.6739301681518555, 'weight_rejected': 0.5903069972991943, 'kl_term_chosen': -0.338470458984375, 'epoch': 0.04}
  4%|▍         | 150/3753 [11:39<5:47:45,  5.79s/it]  4%|▍         | 151/3753 [11:44<5:40:57,  5.68s/it]  4%|▍         | 152/3753 [11:48<5:08:52,  5.15s/it]  4%|▍         | 153/3753 [11:52<5:03:55,  5.07s/it]  4%|▍         | 154/3753 [11:57<4:51:15,  4.86s/it]  4%|▍         | 155/3753 [12:01<4:46:51,  4.78s/it]  4%|▍         | 156/3753 [12:06<4:40:24,  4.68s/it]  4%|▍         | 157/3753 [12:10<4:24:43,  4.42s/it]  4%|▍         | 158/3753 [12:14<4:30:03,  4.51s/it]  4%|▍         | 159/3753 [12:18<4:21:51,  4.37s/it]  4%|▍         | 160/3753 [12:23<4:25:24,  4.43s/it]{'loss': 0.9846, 'grad_norm': 2880.821044921875, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 0.2753104269504547, 'mean_ratio_rejected': 7.210623741149902, 'weight_chosen': 1.324957251548767, 'weight_rejected': 0.3372035324573517, 'kl_term_chosen': -0.644927978515625, 'epoch': 0.04263824117255163}
                                                    {'loss': 0.9846, 'grad_norm': 2880.821044921875, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 0.2753104269504547, 'mean_ratio_rejected': 7.210623741149902, 'weight_chosen': 1.324957251548767, 'weight_rejected': 0.3372035324573517, 'kl_term_chosen': -0.644927978515625, 'epoch': 0.04}
  4%|▍         | 160/3753 [12:23<4:25:24,  4.43s/it]  4%|▍         | 161/3753 [12:27<4:21:04,  4.36s/it]  4%|▍         | 162/3753 [12:32<4:19:43,  4.34s/it]  4%|▍         | 163/3753 [12:35<4:02:35,  4.05s/it]  4%|▍         | 164/3753 [12:42<4:51:05,  4.87s/it]  4%|▍         | 165/3753 [12:48<5:23:59,  5.42s/it]  4%|▍         | 166/3753 [12:52<4:53:01,  4.90s/it]  4%|▍         | 167/3753 [12:57<4:54:26,  4.93s/it]  4%|▍         | 168/3753 [13:02<5:02:07,  5.06s/it]  5%|▍         | 169/3753 [13:06<4:33:43,  4.58s/it]  5%|▍         | 170/3753 [13:09<4:10:39,  4.20s/it]{'loss': 3.0677, 'grad_norm': 98667.90625, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 2.4543020725250244, 'mean_ratio_rejected': 12.238762855529785, 'weight_chosen': 0.42342615127563477, 'weight_rejected': 0.13568955659866333, 'kl_term_chosen': 0.44892120361328125, 'epoch': 0.04530313124583611}
                                                    {'loss': 3.0677, 'grad_norm': 98667.90625, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 2.4543020725250244, 'mean_ratio_rejected': 12.238762855529785, 'weight_chosen': 0.42342615127563477, 'weight_rejected': 0.13568955659866333, 'kl_term_chosen': 0.44892120361328125, 'epoch': 0.05}
  5%|▍         | 170/3753 [13:09<4:10:39,  4.20s/it]  5%|▍         | 171/3753 [13:14<4:17:11,  4.31s/it]  5%|▍         | 172/3753 [13:23<5:41:11,  5.72s/it]  5%|▍         | 173/3753 [13:26<5:05:07,  5.11s/it]  5%|▍         | 174/3753 [13:31<4:53:49,  4.93s/it]  5%|▍         | 175/3753 [13:35<4:44:48,  4.78s/it]  5%|▍         | 176/3753 [13:39<4:26:06,  4.46s/it]  5%|▍         | 177/3753 [13:44<4:28:31,  4.51s/it]  5%|▍         | 178/3753 [13:49<4:35:45,  4.63s/it]  5%|▍         | 179/3753 [13:52<4:19:51,  4.36s/it]  5%|▍         | 180/3753 [13:57<4:18:19,  4.34s/it]{'loss': 3.305, 'grad_norm': 52753.66796875, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 37.38755416870117, 'mean_ratio_rejected': 15.813021659851074, 'weight_chosen': -0.8753224611282349, 'weight_rejected': 0.09268777817487717, 'kl_term_chosen': 1.8106689453125, 'epoch': 0.047968021319120584}
                                                    {'loss': 3.305, 'grad_norm': 52753.66796875, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 37.38755416870117, 'mean_ratio_rejected': 15.813021659851074, 'weight_chosen': -0.8753224611282349, 'weight_rejected': 0.09268777817487717, 'kl_term_chosen': 1.8106689453125, 'epoch': 0.05}
  5%|▍         | 180/3753 [13:57<4:18:19,  4.34s/it]  5%|▍         | 181/3753 [14:01<4:22:00,  4.40s/it]  5%|▍         | 182/3753 [14:09<5:14:06,  5.28s/it]  5%|▍         | 183/3753 [14:13<5:02:05,  5.08s/it]  5%|▍         | 184/3753 [14:19<5:08:38,  5.19s/it]  5%|▍         | 185/3753 [14:24<5:05:29,  5.14s/it]  5%|▍         | 186/3753 [14:28<4:45:53,  4.81s/it]  5%|▍         | 187/3753 [14:32<4:30:58,  4.56s/it]  5%|▌         | 188/3753 [14:36<4:27:55,  4.51s/it]  5%|▌         | 189/3753 [14:43<5:12:47,  5.27s/it]  5%|▌         | 190/3753 [14:48<4:58:28,  5.03s/it]{'loss': 0.4168, 'grad_norm': 1627.2318115234375, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 1.3963508605957031, 'mean_ratio_rejected': 1.3139137029647827, 'weight_chosen': 0.7138659358024597, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 0.16693115234375, 'epoch': 0.05063291139240506}
                                                    {'loss': 0.4168, 'grad_norm': 1627.2318115234375, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 1.3963508605957031, 'mean_ratio_rejected': 1.3139137029647827, 'weight_chosen': 0.7138659358024597, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 0.16693115234375, 'epoch': 0.05}
  5%|▌         | 190/3753 [14:48<4:58:28,  5.03s/it]  5%|▌         | 191/3753 [14:51<4:34:37,  4.63s/it]  5%|▌         | 192/3753 [14:59<5:25:05,  5.48s/it]  5%|▌         | 193/3753 [15:03<5:06:50,  5.17s/it]  5%|▌         | 194/3753 [15:08<5:07:39,  5.19s/it]  5%|▌         | 195/3753 [15:13<4:50:29,  4.90s/it]  5%|▌         | 196/3753 [15:16<4:28:09,  4.52s/it]  5%|▌         | 197/3753 [15:25<5:43:15,  5.79s/it]  5%|▌         | 198/3753 [15:29<5:11:28,  5.26s/it]  5%|▌         | 199/3753 [15:35<5:22:09,  5.44s/it]  5%|▌         | 200/3753 [15:39<5:00:55,  5.08s/it]{'loss': 5.1705, 'grad_norm': 5334.8193359375, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 2.496415615081787, 'mean_ratio_rejected': 1.4772504568099976, 'weight_chosen': 0.4859195947647095, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 0.457427978515625, 'epoch': 0.05329780146568954}
                                                    {'loss': 5.1705, 'grad_norm': 5334.8193359375, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 2.496415615081787, 'mean_ratio_rejected': 1.4772504568099976, 'weight_chosen': 0.4859195947647095, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 0.457427978515625, 'epoch': 0.05}
  5%|▌         | 200/3753 [15:39<5:00:55,  5.08s/it]  5%|▌         | 201/3753 [15:46<5:26:44,  5.52s/it]  5%|▌         | 202/3753 [15:50<5:02:27,  5.11s/it]  5%|▌         | 203/3753 [15:55<5:00:40,  5.08s/it]  5%|▌         | 204/3753 [15:58<4:35:19,  4.65s/it]  5%|▌         | 205/3753 [16:03<4:29:19,  4.55s/it]  5%|▌         | 206/3753 [16:09<4:59:46,  5.07s/it]  6%|▌         | 207/3753 [16:13<4:44:38,  4.82s/it]  6%|▌         | 208/3753 [16:19<4:51:47,  4.94s/it]  6%|▌         | 209/3753 [16:23<4:50:14,  4.91s/it]  6%|▌         | 210/3753 [16:28<4:45:50,  4.84s/it]{'loss': 0.2798, 'grad_norm': 1550.3262939453125, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 0.26966431736946106, 'mean_ratio_rejected': 1.6755539178848267, 'weight_chosen': 1.4740254878997803, 'weight_rejected': 0.15304215252399445, 'kl_term_chosen': -0.6552886962890625, 'epoch': 0.05596269153897402}
                                                    {'loss': 0.2798, 'grad_norm': 1550.3262939453125, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 0.26966431736946106, 'mean_ratio_rejected': 1.6755539178848267, 'weight_chosen': 1.4740254878997803, 'weight_rejected': 0.15304215252399445, 'kl_term_chosen': -0.6552886962890625, 'epoch': 0.06}
  6%|▌         | 210/3753 [16:28<4:45:50,  4.84s/it]  6%|▌         | 211/3753 [16:34<4:58:52,  5.06s/it]  6%|▌         | 212/3753 [16:37<4:29:38,  4.57s/it]  6%|▌         | 213/3753 [16:42<4:32:28,  4.62s/it]  6%|▌         | 214/3753 [16:47<4:50:32,  4.93s/it]  6%|▌         | 215/3753 [16:51<4:34:44,  4.66s/it]  6%|▌         | 216/3753 [16:56<4:34:41,  4.66s/it]  6%|▌         | 217/3753 [17:00<4:19:18,  4.40s/it]  6%|▌         | 218/3753 [17:04<4:21:38,  4.44s/it]  6%|▌         | 219/3753 [17:08<4:11:42,  4.27s/it]  6%|▌         | 220/3753 [17:12<4:02:35,  4.12s/it]{'loss': 1.0, 'grad_norm': 1296.9620361328125, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 0.6515271067619324, 'mean_ratio_rejected': 0.1541573405265808, 'weight_chosen': 0.8959449529647827, 'weight_rejected': 0.1200256198644638, 'kl_term_chosen': -0.2142181396484375, 'epoch': 0.05862758161225849}
                                                    {'loss': 1.0, 'grad_norm': 1296.9620361328125, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 0.6515271067619324, 'mean_ratio_rejected': 0.1541573405265808, 'weight_chosen': 0.8959449529647827, 'weight_rejected': 0.1200256198644638, 'kl_term_chosen': -0.2142181396484375, 'epoch': 0.06}
  6%|▌         | 220/3753 [17:12<4:02:35,  4.12s/it]  6%|▌         | 221/3753 [17:16<3:55:09,  3.99s/it]  6%|▌         | 222/3753 [17:20<4:06:22,  4.19s/it]  6%|▌         | 223/3753 [17:24<3:52:38,  3.95s/it]  6%|▌         | 224/3753 [17:28<3:55:18,  4.00s/it]  6%|▌         | 225/3753 [17:32<3:58:42,  4.06s/it]  6%|▌         | 226/3753 [17:36<3:56:07,  4.02s/it]  6%|▌         | 227/3753 [17:41<4:20:53,  4.44s/it]  6%|▌         | 228/3753 [17:45<4:03:52,  4.15s/it]  6%|▌         | 229/3753 [17:50<4:13:57,  4.32s/it]  6%|▌         | 230/3753 [17:56<4:55:55,  5.04s/it]{'loss': 1.6387, 'grad_norm': 2037.7108154296875, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 0.4656396210193634, 'mean_ratio_rejected': 2.3730268478393555, 'weight_chosen': 1.3193824291229248, 'weight_rejected': 0.1490352898836136, 'kl_term_chosen': -0.382171630859375, 'epoch': 0.06129247168554297}
                                                    {'loss': 1.6387, 'grad_norm': 2037.7108154296875, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 0.4656396210193634, 'mean_ratio_rejected': 2.3730268478393555, 'weight_chosen': 1.3193824291229248, 'weight_rejected': 0.1490352898836136, 'kl_term_chosen': -0.382171630859375, 'epoch': 0.06}
  6%|▌         | 230/3753 [17:56<4:55:55,  5.04s/it]  6%|▌         | 231/3753 [18:02<5:07:09,  5.23s/it]  6%|▌         | 232/3753 [18:06<4:52:03,  4.98s/it]  6%|▌         | 233/3753 [18:11<4:52:28,  4.99s/it]  6%|▌         | 234/3753 [18:17<4:56:45,  5.06s/it]  6%|▋         | 235/3753 [18:25<5:54:20,  6.04s/it]  6%|▋         | 236/3753 [18:29<5:25:00,  5.54s/it]  6%|▋         | 237/3753 [18:33<4:48:09,  4.92s/it]  6%|▋         | 238/3753 [18:38<4:45:58,  4.88s/it]  6%|▋         | 239/3753 [18:42<4:44:51,  4.86s/it]  6%|▋         | 240/3753 [18:47<4:37:53,  4.75s/it]{'loss': 2.0579, 'grad_norm': 1377.391845703125, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.2789214849472046, 'weight_chosen': 6.83475923538208, 'weight_rejected': 0.17781086266040802, 'kl_term_chosen': -6.0036163330078125, 'epoch': 0.06395736175882745}
                                                    {'loss': 2.0579, 'grad_norm': 1377.391845703125, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.2789214849472046, 'weight_chosen': 6.83475923538208, 'weight_rejected': 0.17781086266040802, 'kl_term_chosen': -6.0036163330078125, 'epoch': 0.06}
  6%|▋         | 240/3753 [18:47<4:37:53,  4.75s/it]  6%|▋         | 241/3753 [18:51<4:28:18,  4.58s/it]  6%|▋         | 242/3753 [18:55<4:20:04,  4.44s/it]  6%|▋         | 243/3753 [19:00<4:24:29,  4.52s/it]  7%|▋         | 244/3753 [19:06<4:49:16,  4.95s/it]  7%|▋         | 245/3753 [19:10<4:42:40,  4.83s/it]  7%|▋         | 246/3753 [19:14<4:23:16,  4.50s/it]  7%|▋         | 247/3753 [19:21<5:06:32,  5.25s/it]  7%|▋         | 248/3753 [19:26<5:00:53,  5.15s/it]  7%|▋         | 249/3753 [19:32<5:08:52,  5.29s/it]  7%|▋         | 250/3753 [19:37<5:05:58,  5.24s/it]{'loss': 0.3554, 'grad_norm': 1801.01220703125, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 0.2583935260772705, 'mean_ratio_rejected': 0.22368241846561432, 'weight_chosen': 1.571425199508667, 'weight_rejected': 0.14804719388484955, 'kl_term_chosen': -0.6766357421875, 'epoch': 0.06662225183211193}
                                                    {'loss': 0.3554, 'grad_norm': 1801.01220703125, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 0.2583935260772705, 'mean_ratio_rejected': 0.22368241846561432, 'weight_chosen': 1.571425199508667, 'weight_rejected': 0.14804719388484955, 'kl_term_chosen': -0.6766357421875, 'epoch': 0.07}
  7%|▋         | 250/3753 [19:37<5:05:58,  5.24s/it]  7%|▋         | 251/3753 [19:44<5:30:19,  5.66s/it]  7%|▋         | 252/3753 [19:49<5:24:19,  5.56s/it]  7%|▋         | 253/3753 [19:54<5:08:56,  5.30s/it]  7%|▋         | 254/3753 [19:57<4:37:56,  4.77s/it]  7%|▋         | 255/3753 [20:01<4:29:00,  4.61s/it]  7%|▋         | 256/3753 [20:05<4:11:32,  4.32s/it]  7%|▋         | 257/3753 [20:09<4:13:48,  4.36s/it]  7%|▋         | 258/3753 [20:13<4:09:01,  4.28s/it]  7%|▋         | 259/3753 [20:17<3:56:02,  4.05s/it]  7%|▋         | 260/3753 [20:22<4:09:51,  4.29s/it]{'loss': 2.5206, 'grad_norm': 2015.5172119140625, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.3013054430484772, 'weight_chosen': 4.565785884857178, 'weight_rejected': 0.13386748731136322, 'kl_term_chosen': -3.6785812377929688, 'epoch': 0.06928714190539641}
                                                    {'loss': 2.5206, 'grad_norm': 2015.5172119140625, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.3013054430484772, 'weight_chosen': 4.565785884857178, 'weight_rejected': 0.13386748731136322, 'kl_term_chosen': -3.6785812377929688, 'epoch': 0.07}
  7%|▋         | 260/3753 [20:22<4:09:51,  4.29s/it]  7%|▋         | 261/3753 [20:26<4:14:06,  4.37s/it]  7%|▋         | 262/3753 [20:31<4:16:29,  4.41s/it]  7%|▋         | 263/3753 [20:36<4:20:12,  4.47s/it]  7%|▋         | 264/3753 [20:40<4:14:39,  4.38s/it]  7%|▋         | 265/3753 [20:44<4:13:20,  4.36s/it]  7%|▋         | 266/3753 [20:48<4:04:49,  4.21s/it]  7%|▋         | 267/3753 [20:52<3:59:42,  4.13s/it]  7%|▋         | 268/3753 [20:57<4:13:55,  4.37s/it]  7%|▋         | 269/3753 [21:00<3:55:03,  4.05s/it]  7%|▋         | 270/3753 [21:05<4:05:47,  4.23s/it]{'loss': 0.1677, 'grad_norm': 1791.0224609375, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.11693363636732101, 'weight_chosen': 7.601919651031494, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': -6.6263427734375, 'epoch': 0.07195203197868089}
                                                    {'loss': 0.1677, 'grad_norm': 1791.0224609375, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.11693363636732101, 'weight_chosen': 7.601919651031494, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': -6.6263427734375, 'epoch': 0.07}
  7%|▋         | 270/3753 [21:05<4:05:47,  4.23s/it]  7%|▋         | 271/3753 [21:09<4:15:07,  4.40s/it]  7%|▋         | 272/3753 [21:14<4:17:05,  4.43s/it]  7%|▋         | 273/3753 [21:18<4:03:42,  4.20s/it]  7%|▋         | 274/3753 [21:21<3:55:43,  4.07s/it]  7%|▋         | 275/3753 [21:26<3:57:58,  4.11s/it]  7%|▋         | 276/3753 [21:29<3:49:15,  3.96s/it]  7%|▋         | 277/3753 [21:35<4:13:03,  4.37s/it]  7%|▋         | 278/3753 [21:38<3:58:51,  4.12s/it]  7%|▋         | 279/3753 [21:43<4:08:49,  4.30s/it]  7%|▋         | 280/3753 [21:48<4:16:45,  4.44s/it]{'loss': 0.3278, 'grad_norm': 6888.361328125, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.2633150517940521, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 1.5976603031158447, 'weight_rejected': 0.07263670116662979, 'kl_term_chosen': -0.6672019958496094, 'epoch': 0.07461692205196535}
                                                    {'loss': 0.3278, 'grad_norm': 6888.361328125, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.2633150517940521, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 1.5976603031158447, 'weight_rejected': 0.07263670116662979, 'kl_term_chosen': -0.6672019958496094, 'epoch': 0.07}
  7%|▋         | 280/3753 [21:48<4:16:45,  4.44s/it]  7%|▋         | 281/3753 [21:52<4:13:46,  4.39s/it]  8%|▊         | 282/3753 [21:58<4:46:54,  4.96s/it]  8%|▊         | 283/3753 [22:03<4:37:18,  4.79s/it]  8%|▊         | 284/3753 [22:07<4:27:02,  4.62s/it]  8%|▊         | 285/3753 [22:14<5:14:20,  5.44s/it]  8%|▊         | 286/3753 [22:18<4:45:31,  4.94s/it]  8%|▊         | 287/3753 [22:22<4:32:23,  4.72s/it]  8%|▊         | 288/3753 [22:31<5:46:21,  6.00s/it]  8%|▊         | 289/3753 [22:36<5:28:14,  5.69s/it]  8%|▊         | 290/3753 [22:45<6:19:31,  6.58s/it]{'loss': 0.4169, 'grad_norm': 29984.85546875, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 0.7530679702758789, 'mean_ratio_rejected': 2.169651746749878, 'weight_chosen': 0.895266592502594, 'weight_rejected': 0.20946967601776123, 'kl_term_chosen': -0.1417999267578125, 'epoch': 0.07728181212524983}
                                                    {'loss': 0.4169, 'grad_norm': 29984.85546875, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 0.7530679702758789, 'mean_ratio_rejected': 2.169651746749878, 'weight_chosen': 0.895266592502594, 'weight_rejected': 0.20946967601776123, 'kl_term_chosen': -0.1417999267578125, 'epoch': 0.08}
  8%|▊         | 290/3753 [22:45<6:19:31,  6.58s/it]  8%|▊         | 291/3753 [22:48<5:29:55,  5.72s/it]  8%|▊         | 292/3753 [22:54<5:36:56,  5.84s/it]  8%|▊         | 293/3753 [22:58<5:04:12,  5.28s/it]  8%|▊         | 294/3753 [23:03<4:43:28,  4.92s/it]  8%|▊         | 295/3753 [23:08<4:45:23,  4.95s/it]  8%|▊         | 296/3753 [23:12<4:28:59,  4.67s/it]  8%|▊         | 297/3753 [23:16<4:25:29,  4.61s/it]  8%|▊         | 298/3753 [23:22<4:49:09,  5.02s/it]  8%|▊         | 299/3753 [23:27<4:41:15,  4.89s/it]  8%|▊         | 300/3753 [23:31<4:30:07,  4.69s/it]{'loss': 11.471, 'grad_norm': 512.0653686523438, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 0.023034032434225082, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 2.80953311920166, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': -1.8853912353515625, 'epoch': 0.07994670219853431}
                                                    {'loss': 11.471, 'grad_norm': 512.0653686523438, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 0.023034032434225082, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 2.80953311920166, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': -1.8853912353515625, 'epoch': 0.08}
  8%|▊         | 300/3753 [23:31<4:30:07,  4.69s/it]  8%|▊         | 301/3753 [23:35<4:25:00,  4.61s/it]  8%|▊         | 302/3753 [23:40<4:30:17,  4.70s/it]  8%|▊         | 303/3753 [23:45<4:33:56,  4.76s/it]  8%|▊         | 304/3753 [23:48<4:10:17,  4.35s/it]  8%|▊         | 305/3753 [23:52<4:02:53,  4.23s/it]  8%|▊         | 306/3753 [23:56<3:59:51,  4.17s/it]  8%|▊         | 307/3753 [24:01<4:11:30,  4.38s/it]  8%|▊         | 308/3753 [24:07<4:36:41,  4.82s/it]  8%|▊         | 309/3753 [24:12<4:31:34,  4.73s/it]  8%|▊         | 310/3753 [24:16<4:27:36,  4.66s/it]{'loss': 25.826, 'grad_norm': 7808.7021484375, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.1317582130432129, 'weight_chosen': 2.995898485183716, 'weight_rejected': 0.22815649211406708, 'kl_term_chosen': -2.3322296142578125, 'epoch': 0.08261159227181879}
                                                    {'loss': 25.826, 'grad_norm': 7808.7021484375, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.1317582130432129, 'weight_chosen': 2.995898485183716, 'weight_rejected': 0.22815649211406708, 'kl_term_chosen': -2.3322296142578125, 'epoch': 0.08}
  8%|▊         | 310/3753 [24:16<4:27:36,  4.66s/it]  8%|▊         | 311/3753 [24:21<4:21:58,  4.57s/it]  8%|▊         | 312/3753 [24:25<4:15:22,  4.45s/it]  8%|▊         | 313/3753 [24:29<4:12:26,  4.40s/it]  8%|▊         | 314/3753 [24:36<5:00:37,  5.24s/it]  8%|▊         | 315/3753 [24:40<4:38:07,  4.85s/it]  8%|▊         | 316/3753 [24:44<4:23:04,  4.59s/it]  8%|▊         | 317/3753 [24:48<4:11:22,  4.39s/it]  8%|▊         | 318/3753 [24:53<4:16:32,  4.48s/it]  8%|▊         | 319/3753 [24:57<4:11:00,  4.39s/it]  9%|▊         | 320/3753 [25:02<4:18:28,  4.52s/it]{'loss': 41.9448, 'grad_norm': 112.69312286376953, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 0.04725266993045807, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 2.46333384513855, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': -1.526123046875, 'epoch': 0.08527648234510327}
                                                    {'loss': 41.9448, 'grad_norm': 112.69312286376953, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 0.04725266993045807, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 2.46333384513855, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': -1.526123046875, 'epoch': 0.09}
  9%|▊         | 320/3753 [25:02<4:18:28,  4.52s/it]  9%|▊         | 321/3753 [25:07<4:23:22,  4.60s/it]  9%|▊         | 322/3753 [25:11<4:14:08,  4.44s/it]  9%|▊         | 323/3753 [25:14<3:55:16,  4.12s/it]  9%|▊         | 324/3753 [25:21<4:49:16,  5.06s/it]  9%|▊         | 325/3753 [25:26<4:39:43,  4.90s/it]  9%|▊         | 326/3753 [25:29<4:17:12,  4.50s/it]  9%|▊         | 327/3753 [25:34<4:18:23,  4.53s/it]  9%|▊         | 328/3753 [25:38<4:06:10,  4.31s/it]  9%|▉         | 329/3753 [25:42<4:11:52,  4.41s/it]  9%|▉         | 330/3753 [25:47<4:19:56,  4.56s/it]{'loss': 43.0726, 'grad_norm': 33597.65234375, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 9.170886039733887, 'mean_ratio_rejected': 0.1764243245124817, 'weight_chosen': -0.24647873640060425, 'weight_rejected': 0.22135066986083984, 'kl_term_chosen': 1.1080169677734375, 'epoch': 0.08794137241838774}
                                                    {'loss': 43.0726, 'grad_norm': 33597.65234375, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 9.170886039733887, 'mean_ratio_rejected': 0.1764243245124817, 'weight_chosen': -0.24647873640060425, 'weight_rejected': 0.22135066986083984, 'kl_term_chosen': 1.1080169677734375, 'epoch': 0.09}
  9%|▉         | 330/3753 [25:47<4:19:56,  4.56s/it]  9%|▉         | 331/3753 [25:52<4:16:10,  4.49s/it]  9%|▉         | 332/3753 [25:55<4:05:40,  4.31s/it]  9%|▉         | 333/3753 [26:00<4:10:38,  4.40s/it]  9%|▉         | 334/3753 [26:08<5:15:25,  5.54s/it]  9%|▉         | 335/3753 [26:13<5:01:53,  5.30s/it]  9%|▉         | 336/3753 [26:16<4:29:02,  4.72s/it]  9%|▉         | 337/3753 [26:21<4:34:31,  4.82s/it]  9%|▉         | 338/3753 [26:25<4:10:24,  4.40s/it]  9%|▉         | 339/3753 [26:29<3:58:26,  4.19s/it]  9%|▉         | 340/3753 [26:33<4:04:09,  4.29s/it]{'loss': 15.5968, 'grad_norm': 432.27960205078125, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.016972897574305534, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 2.2817111015319824, 'weight_rejected': 0.7826625108718872, 'kl_term_chosen': -2.0380687713623047, 'epoch': 0.09060626249167222}
                                                    {'loss': 15.5968, 'grad_norm': 432.27960205078125, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.016972897574305534, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 2.2817111015319824, 'weight_rejected': 0.7826625108718872, 'kl_term_chosen': -2.0380687713623047, 'epoch': 0.09}
  9%|▉         | 340/3753 [26:33<4:04:09,  4.29s/it]  9%|▉         | 341/3753 [26:37<3:53:38,  4.11s/it]  9%|▉         | 342/3753 [26:41<3:50:12,  4.05s/it]  9%|▉         | 343/3753 [26:45<4:01:52,  4.26s/it]  9%|▉         | 344/3753 [26:49<3:54:15,  4.12s/it]  9%|▉         | 345/3753 [26:55<4:24:47,  4.66s/it]  9%|▉         | 346/3753 [26:59<4:14:09,  4.48s/it]  9%|▉         | 347/3753 [27:04<4:14:14,  4.48s/it]  9%|▉         | 348/3753 [27:09<4:34:34,  4.84s/it]  9%|▉         | 349/3753 [27:13<4:12:21,  4.45s/it]  9%|▉         | 350/3753 [27:18<4:21:24,  4.61s/it]{'loss': 3.5616, 'grad_norm': 1540.5418701171875, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 3.2530593872070312, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 0.24460887908935547, 'weight_rejected': 0.2186693549156189, 'kl_term_chosen': 0.5897979736328125, 'epoch': 0.09327115256495669}
                                                    {'loss': 3.5616, 'grad_norm': 1540.5418701171875, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 3.2530593872070312, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 0.24460887908935547, 'weight_rejected': 0.2186693549156189, 'kl_term_chosen': 0.5897979736328125, 'epoch': 0.09}
  9%|▉         | 350/3753 [27:18<4:21:24,  4.61s/it]  9%|▉         | 351/3753 [27:22<4:09:30,  4.40s/it]  9%|▉         | 352/3753 [27:25<3:50:35,  4.07s/it]  9%|▉         | 353/3753 [27:29<3:51:21,  4.08s/it]  9%|▉         | 354/3753 [27:34<4:01:38,  4.27s/it]  9%|▉         | 355/3753 [27:40<4:31:01,  4.79s/it]  9%|▉         | 356/3753 [27:44<4:25:05,  4.68s/it] 10%|▉         | 357/3753 [27:49<4:16:10,  4.53s/it] 10%|▉         | 358/3753 [27:53<4:15:07,  4.51s/it] 10%|▉         | 359/3753 [27:57<4:14:15,  4.49s/it] 10%|▉         | 360/3753 [28:01<3:58:38,  4.22s/it]{'loss': 0.795, 'grad_norm': 612.406494140625, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 10.900396347045898, 'weight_rejected': 0.16667540371418, 'kl_term_chosen': -10.3560791015625, 'epoch': 0.09593604263824117}
                                                    {'loss': 0.795, 'grad_norm': 612.406494140625, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 10.900396347045898, 'weight_rejected': 0.16667540371418, 'kl_term_chosen': -10.3560791015625, 'epoch': 0.1}
 10%|▉         | 360/3753 [28:01<3:58:38,  4.22s/it] 10%|▉         | 361/3753 [28:06<4:11:18,  4.45s/it] 10%|▉         | 362/3753 [28:10<4:08:13,  4.39s/it] 10%|▉         | 363/3753 [28:14<4:03:45,  4.31s/it] 10%|▉         | 364/3753 [28:19<4:06:43,  4.37s/it] 10%|▉         | 365/3753 [28:23<3:55:11,  4.17s/it] 10%|▉         | 366/3753 [28:26<3:45:02,  3.99s/it] 10%|▉         | 367/3753 [28:30<3:48:46,  4.05s/it] 10%|▉         | 368/3753 [28:35<4:01:29,  4.28s/it] 10%|▉         | 369/3753 [28:40<4:04:44,  4.34s/it] 10%|▉         | 370/3753 [28:44<4:03:12,  4.31s/it]{'loss': 6.0499, 'grad_norm': 44278.078125, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 3.246405839920044, 'weight_rejected': 0.20561504364013672, 'kl_term_chosen': -2.3820953369140625, 'epoch': 0.09860093271152565}
                                                    {'loss': 6.0499, 'grad_norm': 44278.078125, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 3.246405839920044, 'weight_rejected': 0.20561504364013672, 'kl_term_chosen': -2.3820953369140625, 'epoch': 0.1}
 10%|▉         | 370/3753 [28:44<4:03:12,  4.31s/it] 10%|▉         | 371/3753 [28:48<3:53:27,  4.14s/it] 10%|▉         | 372/3753 [28:52<4:03:12,  4.32s/it] 10%|▉         | 373/3753 [28:56<3:58:04,  4.23s/it] 10%|▉         | 374/3753 [29:04<4:47:02,  5.10s/it] 10%|▉         | 375/3753 [29:09<4:53:03,  5.21s/it] 10%|█         | 376/3753 [29:18<5:56:36,  6.34s/it] 10%|█         | 377/3753 [29:25<6:00:58,  6.42s/it] 10%|█         | 378/3753 [29:28<5:15:57,  5.62s/it] 10%|█         | 379/3753 [29:32<4:44:09,  5.05s/it] 10%|█         | 380/3753 [29:37<4:38:17,  4.95s/it]{'loss': 3.694, 'grad_norm': 25390.857421875, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 5.408389568328857, 'weight_rejected': 0.02595735713839531, 'kl_term_chosen': -4.448028564453125, 'epoch': 0.10126582278481013}
                                                    {'loss': 3.694, 'grad_norm': 25390.857421875, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 5.408389568328857, 'weight_rejected': 0.02595735713839531, 'kl_term_chosen': -4.448028564453125, 'epoch': 0.1}
 10%|█         | 380/3753 [29:37<4:38:17,  4.95s/it] 10%|█         | 381/3753 [29:41<4:23:24,  4.69s/it] 10%|█         | 382/3753 [29:46<4:24:50,  4.71s/it] 10%|█         | 383/3753 [29:50<4:13:41,  4.52s/it] 10%|█         | 384/3753 [29:55<4:26:44,  4.75s/it] 10%|█         | 385/3753 [30:05<5:53:23,  6.30s/it] 10%|█         | 386/3753 [30:09<5:10:04,  5.53s/it] 10%|█         | 387/3753 [30:13<4:52:47,  5.22s/it] 10%|█         | 388/3753 [30:17<4:39:00,  4.98s/it] 10%|█         | 389/3753 [30:22<4:36:25,  4.93s/it] 10%|█         | 390/3753 [30:28<4:52:19,  5.22s/it]{'loss': 5.8555, 'grad_norm': 0.0, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 5.216142177581787, 'weight_rejected': 0.8164063692092896, 'kl_term_chosen': -4.577306747436523, 'epoch': 0.1039307128580946}
                                                    {'loss': 5.8555, 'grad_norm': 0.0, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 5.216142177581787, 'weight_rejected': 0.8164063692092896, 'kl_term_chosen': -4.577306747436523, 'epoch': 0.1}
 10%|█         | 390/3753 [30:28<4:52:19,  5.22s/it] 10%|█         | 391/3753 [30:33<4:38:10,  4.96s/it] 10%|█         | 392/3753 [30:37<4:23:45,  4.71s/it] 10%|█         | 393/3753 [30:41<4:23:46,  4.71s/it] 10%|█         | 394/3753 [30:46<4:18:29,  4.62s/it] 11%|█         | 395/3753 [30:51<4:20:38,  4.66s/it] 11%|█         | 396/3753 [30:59<5:26:53,  5.84s/it] 11%|█         | 397/3753 [31:03<4:46:18,  5.12s/it] 11%|█         | 398/3753 [31:09<5:01:41,  5.40s/it] 11%|█         | 399/3753 [31:14<4:58:10,  5.33s/it] 11%|█         | 400/3753 [31:18<4:39:25,  5.00s/it]{'loss': -0.079, 'grad_norm': 0.0, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 9.665643692016602, 'weight_rejected': 0.25091278553009033, 'kl_term_chosen': -8.970512390136719, 'epoch': 0.10659560293137908}
                                                    {'loss': -0.079, 'grad_norm': 0.0, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 9.665643692016602, 'weight_rejected': 0.25091278553009033, 'kl_term_chosen': -8.970512390136719, 'epoch': 0.11}
 11%|█         | 400/3753 [31:18<4:39:25,  5.00s/it] 11%|█         | 401/3753 [31:22<4:22:50,  4.70s/it] 11%|█         | 402/3753 [31:27<4:23:20,  4.72s/it] 11%|█         | 403/3753 [31:31<4:06:33,  4.42s/it] 11%|█         | 404/3753 [31:35<4:00:44,  4.31s/it] 11%|█         | 405/3753 [31:40<4:13:26,  4.54s/it] 11%|█         | 406/3753 [31:44<4:13:40,  4.55s/it] 11%|█         | 407/3753 [31:48<4:01:45,  4.34s/it] 11%|█         | 408/3753 [31:53<4:10:45,  4.50s/it] 11%|█         | 409/3753 [31:57<4:11:16,  4.51s/it] 11%|█         | 410/3753 [32:02<4:09:55,  4.49s/it]{'loss': -0.1621, 'grad_norm': 0.0, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 19.2455997467041, 'weight_rejected': 0.28776782751083374, 'kl_term_chosen': -18.59869384765625, 'epoch': 0.10926049300466356}
                                                    {'loss': -0.1621, 'grad_norm': 0.0, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 19.2455997467041, 'weight_rejected': 0.28776782751083374, 'kl_term_chosen': -18.59869384765625, 'epoch': 0.11}
 11%|█         | 410/3753 [32:02<4:09:55,  4.49s/it] 11%|█         | 411/3753 [32:07<4:18:24,  4.64s/it] 11%|█         | 412/3753 [32:11<4:08:45,  4.47s/it] 11%|█         | 413/3753 [32:16<4:25:51,  4.78s/it] 11%|█         | 414/3753 [32:21<4:26:20,  4.79s/it] 11%|█         | 415/3753 [32:26<4:20:18,  4.68s/it] 11%|█         | 416/3753 [32:30<4:13:22,  4.56s/it] 11%|█         | 417/3753 [32:34<4:07:51,  4.46s/it] 11%|█         | 418/3753 [32:38<3:59:01,  4.30s/it] 11%|█         | 419/3753 [32:42<3:53:01,  4.19s/it] 11%|█         | 420/3753 [32:46<3:54:29,  4.22s/it]{'loss': -0.1775, 'grad_norm': 0.0, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 20.493915557861328, 'weight_rejected': 0.2727987766265869, 'kl_term_chosen': -19.842559814453125, 'epoch': 0.11192538307794804}
                                                    {'loss': -0.1775, 'grad_norm': 0.0, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 20.493915557861328, 'weight_rejected': 0.2727987766265869, 'kl_term_chosen': -19.842559814453125, 'epoch': 0.11}
 11%|█         | 420/3753 [32:46<3:54:29,  4.22s/it] 11%|█         | 421/3753 [32:51<3:57:13,  4.27s/it] 11%|█         | 422/3753 [32:55<3:52:41,  4.19s/it] 11%|█▏        | 423/3753 [32:59<3:48:44,  4.12s/it] 11%|█▏        | 424/3753 [33:02<3:31:29,  3.81s/it] 11%|█▏        | 425/3753 [33:06<3:38:00,  3.93s/it] 11%|█▏        | 426/3753 [33:11<3:49:14,  4.13s/it] 11%|█▏        | 427/3753 [33:15<3:54:40,  4.23s/it] 11%|█▏        | 428/3753 [33:20<4:02:43,  4.38s/it] 11%|█▏        | 429/3753 [33:24<3:57:16,  4.28s/it] 11%|█▏        | 430/3753 [33:29<4:07:27,  4.47s/it]{'loss': -0.1692, 'grad_norm': 0.0, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 31.383319854736328, 'weight_rejected': 0.27125170826911926, 'kl_term_chosen': -30.8197021484375, 'epoch': 0.1145902731512325}
                                                    {'loss': -0.1692, 'grad_norm': 0.0, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 31.383319854736328, 'weight_rejected': 0.27125170826911926, 'kl_term_chosen': -30.8197021484375, 'epoch': 0.11}
 11%|█▏        | 430/3753 [33:29<4:07:27,  4.47s/it] 11%|█▏        | 431/3753 [33:32<3:54:05,  4.23s/it] 12%|█▏        | 432/3753 [33:41<5:10:19,  5.61s/it] 12%|█▏        | 433/3753 [33:45<4:43:32,  5.12s/it] 12%|█▏        | 434/3753 [33:49<4:26:41,  4.82s/it] 12%|█▏        | 435/3753 [33:53<4:09:02,  4.50s/it] 12%|█▏        | 436/3753 [33:57<4:06:22,  4.46s/it] 12%|█▏        | 437/3753 [34:02<4:08:22,  4.49s/it] 12%|█▏        | 438/3753 [34:07<4:14:58,  4.61s/it] 12%|█▏        | 439/3753 [34:11<4:11:36,  4.56s/it] 12%|█▏        | 440/3753 [34:16<4:04:40,  4.43s/it]{'loss': -0.1765, 'grad_norm': 0.0, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 27.417537689208984, 'weight_rejected': 0.048136770725250244, 'kl_term_chosen': -26.462890625, 'epoch': 0.11725516322451698}
                                                    {'loss': -0.1765, 'grad_norm': 0.0, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 27.417537689208984, 'weight_rejected': 0.048136770725250244, 'kl_term_chosen': -26.462890625, 'epoch': 0.12}
 12%|█▏        | 440/3753 [34:16<4:04:40,  4.43s/it] 12%|█▏        | 441/3753 [34:21<4:28:55,  4.87s/it] 12%|█▏        | 442/3753 [34:26<4:24:01,  4.78s/it] 12%|█▏        | 443/3753 [34:29<4:02:36,  4.40s/it] 12%|█▏        | 444/3753 [34:34<4:11:20,  4.56s/it] 12%|█▏        | 445/3753 [34:38<3:58:49,  4.33s/it] 12%|█▏        | 446/3753 [34:43<4:02:28,  4.40s/it] 12%|█▏        | 447/3753 [34:47<4:01:33,  4.38s/it] 12%|█▏        | 448/3753 [34:50<3:42:38,  4.04s/it] 12%|█▏        | 449/3753 [34:56<4:06:25,  4.48s/it] 12%|█▏        | 450/3753 [35:00<4:03:56,  4.43s/it]{'loss': -0.1819, 'grad_norm': 0.0, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 10.925047874450684, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': -10.03173828125, 'epoch': 0.11992005329780146}
                                                    {'loss': -0.1819, 'grad_norm': 0.0, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 10.925047874450684, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': -10.03173828125, 'epoch': 0.12}
 12%|█▏        | 450/3753 [35:00<4:03:56,  4.43s/it] 12%|█▏        | 451/3753 [35:05<4:06:27,  4.48s/it] 12%|█▏        | 452/3753 [35:10<4:16:58,  4.67s/it] 12%|█▏        | 453/3753 [35:13<3:57:32,  4.32s/it] 12%|█▏        | 454/3753 [35:19<4:19:15,  4.72s/it] 12%|█▏        | 455/3753 [35:24<4:18:29,  4.70s/it] 12%|█▏        | 456/3753 [35:30<4:41:52,  5.13s/it] 12%|█▏        | 457/3753 [35:34<4:24:49,  4.82s/it] 12%|█▏        | 458/3753 [35:38<4:08:35,  4.53s/it] 12%|█▏        | 459/3753 [35:42<4:03:40,  4.44s/it] 12%|█▏        | 460/3753 [35:48<4:23:39,  4.80s/it]{'loss': -0.1696, 'grad_norm': 0.0, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 31.195457458496094, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': -30.2769775390625, 'epoch': 0.12258494337108594}
                                                    {'loss': -0.1696, 'grad_norm': 0.0, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 31.195457458496094, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': -30.2769775390625, 'epoch': 0.12}
 12%|█▏        | 460/3753 [35:48<4:23:39,  4.80s/it] 12%|█▏        | 461/3753 [35:52<4:08:26,  4.53s/it] 12%|█▏        | 462/3753 [35:55<3:43:48,  4.08s/it] 12%|█▏        | 463/3753 [35:59<3:47:11,  4.14s/it] 12%|█▏        | 464/3753 [36:03<3:47:45,  4.15s/it] 12%|█▏        | 465/3753 [36:07<3:47:23,  4.15s/it] 12%|█▏        | 466/3753 [36:12<3:50:54,  4.21s/it] 12%|█▏        | 467/3753 [36:16<3:57:04,  4.33s/it] 12%|█▏        | 468/3753 [36:24<4:53:30,  5.36s/it] 12%|█▏        | 469/3753 [36:29<4:55:06,  5.39s/it] 13%|█▎        | 470/3753 [36:36<5:08:44,  5.64s/it]{'loss': -0.1753, 'grad_norm': 0.0, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 33.49879837036133, 'weight_rejected': 0.08151976019144058, 'kl_term_chosen': -32.553802490234375, 'epoch': 0.1252498334443704}
                                                    {'loss': -0.1753, 'grad_norm': 0.0, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 33.49879837036133, 'weight_rejected': 0.08151976019144058, 'kl_term_chosen': -32.553802490234375, 'epoch': 0.13}
 13%|█▎        | 470/3753 [36:36<5:08:44,  5.64s/it] 13%|█▎        | 471/3753 [36:41<5:10:39,  5.68s/it] 13%|█▎        | 472/3753 [36:45<4:35:36,  5.04s/it] 13%|█▎        | 473/3753 [36:48<4:04:05,  4.47s/it] 13%|█▎        | 474/3753 [36:53<4:04:02,  4.47s/it] 13%|█▎        | 475/3753 [36:57<4:05:33,  4.49s/it] 13%|█▎        | 476/3753 [37:01<3:55:58,  4.32s/it] 13%|█▎        | 477/3753 [37:06<3:59:25,  4.39s/it] 13%|█▎        | 478/3753 [37:10<3:56:35,  4.33s/it] 13%|█▎        | 479/3753 [37:16<4:20:26,  4.77s/it] 13%|█▎        | 480/3753 [37:20<4:18:41,  4.74s/it]{'loss': -0.177, 'grad_norm': 0.0, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 30.712100982666016, 'weight_rejected': 0.23792988061904907, 'kl_term_chosen': -30.13555908203125, 'epoch': 0.1279147235176549}
                                                    {'loss': -0.177, 'grad_norm': 0.0, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 30.712100982666016, 'weight_rejected': 0.23792988061904907, 'kl_term_chosen': -30.13555908203125, 'epoch': 0.13}
 13%|█▎        | 480/3753 [37:20<4:18:41,  4.74s/it] 13%|█▎        | 481/3753 [37:25<4:21:49,  4.80s/it] 13%|█▎        | 482/3753 [37:29<4:10:55,  4.60s/it] 13%|█▎        | 483/3753 [37:33<4:01:41,  4.43s/it] 13%|█▎        | 484/3753 [37:37<3:54:03,  4.30s/it] 13%|█▎        | 485/3753 [37:41<3:42:55,  4.09s/it] 13%|█▎        | 486/3753 [37:46<3:59:44,  4.40s/it] 13%|█▎        | 487/3753 [37:51<4:06:06,  4.52s/it] 13%|█▎        | 488/3753 [37:55<3:56:25,  4.34s/it] 13%|█▎        | 489/3753 [38:00<4:06:55,  4.54s/it] 13%|█▎        | 490/3753 [38:05<4:19:45,  4.78s/it]{'loss': -0.1838, 'grad_norm': 0.0, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 17.76006507873535, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': -16.815887451171875, 'epoch': 0.13057961359093936}
                                                    {'loss': -0.1838, 'grad_norm': 0.0, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 17.76006507873535, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': -16.815887451171875, 'epoch': 0.13}
 13%|█▎        | 490/3753 [38:05<4:19:45,  4.78s/it] 13%|█▎        | 491/3753 [38:10<4:21:43,  4.81s/it] 13%|█▎        | 492/3753 [38:14<4:04:28,  4.50s/it] 13%|█▎        | 493/3753 [38:24<5:32:35,  6.12s/it] 13%|█▎        | 494/3753 [38:28<5:01:04,  5.54s/it] 13%|█▎        | 495/3753 [38:31<4:25:22,  4.89s/it] 13%|█▎        | 496/3753 [38:36<4:24:40,  4.88s/it] 13%|█▎        | 497/3753 [38:40<4:04:29,  4.51s/it] 13%|█▎        | 498/3753 [38:48<4:59:43,  5.52s/it] 13%|█▎        | 499/3753 [38:54<5:12:45,  5.77s/it] 13%|█▎        | 500/3753 [38:59<5:01:29,  5.56s/it]{'loss': -0.1828, 'grad_norm': 2.1242496967315674, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 11.702898979187012, 'weight_rejected': 0.22270013391971588, 'kl_term_chosen': -11.060466766357422, 'epoch': 0.13324450366422386}
                                                    {'loss': -0.1828, 'grad_norm': 2.1242496967315674, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 11.702898979187012, 'weight_rejected': 0.22270013391971588, 'kl_term_chosen': -11.060466766357422, 'epoch': 0.13}
 13%|█▎        | 500/3753 [38:59<5:01:29,  5.56s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 13%|█▎        | 501/3753 [40:00<19:55:40, 22.06s/it] 13%|█▎        | 502/3753 [40:08<16:05:22, 17.82s/it] 13%|█▎        | 503/3753 [40:12<12:27:01, 13.79s/it] 13%|█▎        | 504/3753 [40:16<9:43:03, 10.77s/it]  13%|█▎        | 505/3753 [40:19<7:46:41,  8.62s/it] 13%|█▎        | 506/3753 [40:23<6:31:27,  7.23s/it] 14%|█▎        | 507/3753 [40:29<6:03:42,  6.72s/it] 14%|█▎        | 508/3753 [40:34<5:38:42,  6.26s/it] 14%|█▎        | 509/3753 [40:38<5:01:37,  5.58s/it] 14%|█▎        | 510/3753 [40:42<4:41:31,  5.21s/it]{'loss': -0.1943, 'grad_norm': 0.0, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 30.85245132446289, 'weight_rejected': 0.03358950838446617, 'kl_term_chosen': -29.896469116210938, 'epoch': 0.13590939373750832}
                                                    {'loss': -0.1943, 'grad_norm': 0.0, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 0.010051836259663105, 'mean_ratio_rejected': 0.010051836259663105, 'weight_chosen': 30.85245132446289, 'weight_rejected': 0.03358950838446617, 'kl_term_chosen': -29.896469116210938, 'epoch': 0.14}
 14%|█▎        | 510/3753 [40:42<4:41:31,  5.21s/it] 14%|█▎        | 511/3753 [40:47<4:27:26,  4.95s/it]W1109 06:24:38.664000 9594 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
W1109 06:24:38.667000 9594 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 9702 closing signal SIGTERM
W1109 06:24:38.667000 9594 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 9703 closing signal SIGTERM
W1109 06:24:38.671000 9594 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 9704 closing signal SIGTERM
W1109 06:24:38.672000 9594 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 9705 closing signal SIGTERM
Traceback (most recent call last):
  File "/root/miniconda3/envs/advan/bin/accelerate", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/launch.py", line 1222, in launch_command
    multi_gpu_launcher(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/launch.py", line 853, in multi_gpu_launcher
    distrib_run.run(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py", line 138, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 715, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 879, in _invoke_run
    time.sleep(monitor_interval)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 9594 got signal: 15
