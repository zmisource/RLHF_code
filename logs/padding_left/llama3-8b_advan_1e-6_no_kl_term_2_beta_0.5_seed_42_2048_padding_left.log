nohup: ignoring input
[W1201 11:07:53.879396994 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
⚙️  Running in WANDB offline mode⚙️  Running in WANDB offline mode

⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 98.74it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.22it/s]
加载作为参考的SFT模型 (Reference Model)...
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.74it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.50it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 98.65it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 98.69it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.95it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.00it/s]
[W1201 11:07:58.254880046 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1201 11:07:58.259638580 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1201 11:07:58.263325587 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1201 11:07:58.263776264 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...初始化 CustomSymPOTrainer...

/rlhf_code/code/implement_final_v3_no_kl_term2.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
/rlhf_code/code/implement_final_v3_no_kl_term2.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /wandb/offline-run-20251201_110806-qfslrsbe
  0%|          | 0/3753 [00:00<?, ?it/s]--- Sanity Check at Step 0 ------ Sanity Check at Step 0 ---

--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -44.5
Sample 0 - pi_logp_chosen:  -44.146331787109375
Difference: 0.353668212890625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -100.5
Sample 0 - pi_logp_chosen:  -100.34402465820312
Difference: 0.155975341796875
---------------------------------
Sample 0 - ref_logp_chosen: -112.0
Sample 0 - pi_logp_chosen:  -111.70196533203125
Difference: 0.29803466796875
---------------------------------
Sample 0 - ref_logp_chosen: -234.0
Sample 0 - pi_logp_chosen:  -233.57894897460938
Difference: 0.421051025390625
---------------------------------
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -65.5
Sample 0 - pi_logp_chosen:  -65.91077423095703
Difference: -0.41077423095703125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -246.0
Sample 0 - pi_logp_chosen:  -246.4385986328125
Difference: -0.4385986328125
---------------------------------
Sample 0 - ref_logp_chosen: -209.0
Sample 0 - pi_logp_chosen:  -208.26136779785156
Difference: 0.7386322021484375
---------------------------------
Sample 0 - ref_logp_chosen: -380.0
Sample 0 - pi_logp_chosen:  -381.313720703125
Difference: -1.313720703125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -70.0
Sample 0 - pi_logp_chosen:  -70.18619537353516
Difference: -0.18619537353515625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -167.0
Sample 0 - pi_logp_chosen:  -167.149169921875
Difference: -0.149169921875
---------------------------------
Sample 0 - ref_logp_chosen: -350.0
Sample 0 - pi_logp_chosen:  -349.3069152832031
Difference: 0.693084716796875
---------------------------------
Sample 0 - ref_logp_chosen: -452.0
Sample 0 - pi_logp_chosen:  -453.64239501953125
Difference: -1.64239501953125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -81.5
Sample 0 - pi_logp_chosen:  -81.75975036621094
Difference: -0.2597503662109375
---------------------------------
Sample 0 - ref_logp_chosen: -98.5
Sample 0 - pi_logp_chosen:  -98.78225708007812
Difference: -0.282257080078125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -251.0
Sample 0 - pi_logp_chosen:  -249.6898956298828
Difference: 1.3101043701171875
---------------------------------
Sample 0 - ref_logp_chosen: -242.0
Sample 0 - pi_logp_chosen:  -241.97824096679688
Difference: 0.021759033203125
---------------------------------
  0%|          | 1/3753 [00:04<4:54:51,  4.72s/it]{'loss': -0.3531, 'grad_norm': 1999.294677734375, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 2.1782100200653076, 'weight_chosen': 0.2668696641921997, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 0.6550521850585938, 'epoch': 0.0002664890073284477}
                                                  {'loss': -0.3531, 'grad_norm': 1999.294677734375, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 2.1782100200653076, 'weight_chosen': 0.2668696641921997, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 0.6550521850585938, 'epoch': 0.0}
  0%|          | 1/3753 [00:04<4:54:51,  4.72s/it]  0%|          | 2/3753 [00:10<5:17:37,  5.08s/it]  0%|          | 3/3753 [00:14<5:06:03,  4.90s/it]  0%|          | 4/3753 [00:18<4:42:06,  4.52s/it]  0%|          | 5/3753 [00:22<4:33:45,  4.38s/it]  0%|          | 6/3753 [00:28<4:53:51,  4.71s/it]  0%|          | 7/3753 [00:32<4:42:20,  4.52s/it]  0%|          | 8/3753 [00:36<4:41:00,  4.50s/it]  0%|          | 9/3753 [00:40<4:23:20,  4.22s/it]  0%|          | 10/3753 [00:44<4:13:40,  4.07s/it]{'loss': -0.442, 'grad_norm': 2175.144775390625, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 0.7462674379348755, 'mean_ratio_rejected': 0.6779412031173706, 'weight_chosen': 0.3914206027984619, 'weight_rejected': 0.4163219630718231, 'kl_term_chosen': -0.14633560180664062, 'epoch': 0.002664890073284477}
                                                   {'loss': -0.442, 'grad_norm': 2175.144775390625, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 0.7462674379348755, 'mean_ratio_rejected': 0.6779412031173706, 'weight_chosen': 0.3914206027984619, 'weight_rejected': 0.4163219630718231, 'kl_term_chosen': -0.14633560180664062, 'epoch': 0.0}
  0%|          | 10/3753 [00:44<4:13:40,  4.07s/it]  0%|          | 11/3753 [00:48<4:21:26,  4.19s/it]  0%|          | 12/3753 [00:53<4:34:43,  4.41s/it]  0%|          | 13/3753 [00:57<4:32:37,  4.37s/it]  0%|          | 14/3753 [01:01<4:26:27,  4.28s/it]  0%|          | 15/3753 [01:05<4:16:26,  4.12s/it]  0%|          | 16/3753 [01:09<4:10:54,  4.03s/it]  0%|          | 17/3753 [01:13<4:05:33,  3.94s/it]  0%|          | 18/3753 [01:17<4:22:40,  4.22s/it]  1%|          | 19/3753 [01:21<4:06:24,  3.96s/it]  1%|          | 20/3753 [01:25<4:04:47,  3.93s/it]{'loss': -0.295, 'grad_norm': 1815.107421875, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 1.1193488836288452, 'mean_ratio_rejected': 0.9007921814918518, 'weight_chosen': 0.6762182116508484, 'weight_rejected': 0.29665425419807434, 'kl_term_chosen': 0.05637359619140625, 'epoch': 0.005329780146568954}
                                                   {'loss': -0.295, 'grad_norm': 1815.107421875, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 1.1193488836288452, 'mean_ratio_rejected': 0.9007921814918518, 'weight_chosen': 0.6762182116508484, 'weight_rejected': 0.29665425419807434, 'kl_term_chosen': 0.05637359619140625, 'epoch': 0.01}
  1%|          | 20/3753 [01:25<4:04:47,  3.93s/it]  1%|          | 21/3753 [01:29<4:07:42,  3.98s/it]  1%|          | 22/3753 [01:36<5:00:38,  4.83s/it]  1%|          | 23/3753 [01:41<5:02:59,  4.87s/it]  1%|          | 24/3753 [01:44<4:33:15,  4.40s/it]  1%|          | 25/3753 [01:48<4:29:45,  4.34s/it]  1%|          | 26/3753 [01:51<4:05:00,  3.94s/it]  1%|          | 27/3753 [01:55<4:05:56,  3.96s/it]  1%|          | 28/3753 [01:59<4:03:03,  3.91s/it]  1%|          | 29/3753 [02:03<4:01:13,  3.89s/it]  1%|          | 30/3753 [02:07<4:06:15,  3.97s/it]{'loss': -0.1266, 'grad_norm': 1966.6837158203125, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 2.5000083446502686, 'mean_ratio_rejected': 1.8132959604263306, 'weight_chosen': 0.1698041558265686, 'weight_rejected': 0.5987815260887146, 'kl_term_chosen': 0.4581470489501953, 'epoch': 0.007994670219853431}
                                                   {'loss': -0.1266, 'grad_norm': 1966.6837158203125, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 2.5000083446502686, 'mean_ratio_rejected': 1.8132959604263306, 'weight_chosen': 0.1698041558265686, 'weight_rejected': 0.5987815260887146, 'kl_term_chosen': 0.4581470489501953, 'epoch': 0.01}
  1%|          | 30/3753 [02:07<4:06:15,  3.97s/it]  1%|          | 31/3753 [02:12<4:29:41,  4.35s/it]  1%|          | 32/3753 [02:16<4:15:58,  4.13s/it]  1%|          | 33/3753 [02:19<4:03:36,  3.93s/it]  1%|          | 34/3753 [02:24<4:20:54,  4.21s/it]  1%|          | 35/3753 [02:29<4:39:51,  4.52s/it]  1%|          | 36/3753 [02:34<4:50:22,  4.69s/it]  1%|          | 37/3753 [02:40<5:09:29,  5.00s/it]  1%|          | 38/3753 [02:44<4:55:56,  4.78s/it]  1%|          | 39/3753 [02:50<5:07:34,  4.97s/it]  1%|          | 40/3753 [02:54<4:49:36,  4.68s/it]{'loss': 1.1043, 'grad_norm': 2801.17333984375, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 2.0086522102355957, 'mean_ratio_rejected': 2.46099591255188, 'weight_chosen': 0.40906238555908203, 'weight_rejected': 0.1276526302099228, 'kl_term_chosen': 0.34873199462890625, 'epoch': 0.010659560293137908}
                                                   {'loss': 1.1043, 'grad_norm': 2801.17333984375, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 2.0086522102355957, 'mean_ratio_rejected': 2.46099591255188, 'weight_chosen': 0.40906238555908203, 'weight_rejected': 0.1276526302099228, 'kl_term_chosen': 0.34873199462890625, 'epoch': 0.01}
  1%|          | 40/3753 [02:54<4:49:36,  4.68s/it]  1%|          | 41/3753 [02:58<4:46:14,  4.63s/it]  1%|          | 42/3753 [03:01<4:15:25,  4.13s/it]  1%|          | 43/3753 [03:06<4:22:50,  4.25s/it]  1%|          | 44/3753 [03:10<4:17:59,  4.17s/it]  1%|          | 45/3753 [03:15<4:32:59,  4.42s/it]  1%|          | 46/3753 [03:20<4:43:13,  4.58s/it]  1%|▏         | 47/3753 [03:23<4:12:35,  4.09s/it]  1%|▏         | 48/3753 [03:27<4:11:30,  4.07s/it]  1%|▏         | 49/3753 [03:31<4:13:29,  4.11s/it]  1%|▏         | 50/3753 [03:35<4:10:42,  4.06s/it]{'loss': 0.2163, 'grad_norm': 1291.424560546875, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 1.0841820240020752, 'mean_ratio_rejected': 2.0125794410705566, 'weight_chosen': 0.8229787349700928, 'weight_rejected': 0.6851073503494263, 'kl_term_chosen': 0.04041290283203125, 'epoch': 0.013324450366422385}
                                                   {'loss': 0.2163, 'grad_norm': 1291.424560546875, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 1.0841820240020752, 'mean_ratio_rejected': 2.0125794410705566, 'weight_chosen': 0.8229787349700928, 'weight_rejected': 0.6851073503494263, 'kl_term_chosen': 0.04041290283203125, 'epoch': 0.01}
  1%|▏         | 50/3753 [03:35<4:10:42,  4.06s/it]  1%|▏         | 51/3753 [03:39<4:12:06,  4.09s/it]  1%|▏         | 52/3753 [03:44<4:23:21,  4.27s/it]  1%|▏         | 53/3753 [03:50<4:52:42,  4.75s/it]  1%|▏         | 54/3753 [03:53<4:28:55,  4.36s/it]  1%|▏         | 55/3753 [03:59<5:00:59,  4.88s/it]  1%|▏         | 56/3753 [04:04<5:01:25,  4.89s/it]  2%|▏         | 57/3753 [04:09<4:58:29,  4.85s/it]  2%|▏         | 58/3753 [04:12<4:32:45,  4.43s/it]  2%|▏         | 59/3753 [04:17<4:42:52,  4.59s/it]  2%|▏         | 60/3753 [04:20<4:15:56,  4.16s/it]{'loss': 0.3621, 'grad_norm': 2198.220947265625, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 0.9718989729881287, 'mean_ratio_rejected': 1.0729743242263794, 'weight_chosen': 0.04446631669998169, 'weight_rejected': 0.937210738658905, 'kl_term_chosen': -0.014251708984375, 'epoch': 0.015989340439706862}
                                                   {'loss': 0.3621, 'grad_norm': 2198.220947265625, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 0.9718989729881287, 'mean_ratio_rejected': 1.0729743242263794, 'weight_chosen': 0.04446631669998169, 'weight_rejected': 0.937210738658905, 'kl_term_chosen': -0.014251708984375, 'epoch': 0.02}
  2%|▏         | 60/3753 [04:20<4:15:56,  4.16s/it]  2%|▏         | 61/3753 [04:25<4:31:53,  4.42s/it]  2%|▏         | 62/3753 [04:30<4:32:23,  4.43s/it]  2%|▏         | 63/3753 [04:34<4:28:48,  4.37s/it]  2%|▏         | 64/3753 [04:39<4:30:04,  4.39s/it]  2%|▏         | 65/3753 [04:42<4:20:58,  4.25s/it]  2%|▏         | 66/3753 [04:47<4:31:04,  4.41s/it]  2%|▏         | 67/3753 [04:52<4:34:44,  4.47s/it]  2%|▏         | 68/3753 [04:56<4:20:53,  4.25s/it]  2%|▏         | 69/3753 [05:00<4:26:45,  4.34s/it]  2%|▏         | 70/3753 [05:04<4:14:36,  4.15s/it]{'loss': 0.7143, 'grad_norm': 2489.154541015625, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 3.4534714221954346, 'weight_chosen': -0.868587076663971, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 1.831817626953125, 'epoch': 0.018654230512991338}
                                                   {'loss': 0.7143, 'grad_norm': 2489.154541015625, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 3.4534714221954346, 'weight_chosen': -0.868587076663971, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 1.831817626953125, 'epoch': 0.02}
  2%|▏         | 70/3753 [05:04<4:14:36,  4.15s/it]  2%|▏         | 71/3753 [05:08<4:22:55,  4.28s/it]  2%|▏         | 72/3753 [05:13<4:26:31,  4.34s/it]  2%|▏         | 73/3753 [05:17<4:17:51,  4.20s/it]  2%|▏         | 74/3753 [05:21<4:09:12,  4.06s/it]  2%|▏         | 75/3753 [05:24<4:01:29,  3.94s/it]  2%|▏         | 76/3753 [05:29<4:23:49,  4.31s/it]  2%|▏         | 77/3753 [05:32<4:00:44,  3.93s/it]  2%|▏         | 78/3753 [05:37<4:21:48,  4.27s/it]  2%|▏         | 79/3753 [05:42<4:22:27,  4.29s/it]  2%|▏         | 80/3753 [05:47<4:30:56,  4.43s/it]{'loss': 0.5737, 'grad_norm': 1655.61181640625, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 1.6827536821365356, 'mean_ratio_rejected': 2.639497756958008, 'weight_chosen': 0.6681930422782898, 'weight_rejected': 0.10230471193790436, 'kl_term_chosen': 0.26021575927734375, 'epoch': 0.021319120586275817}
                                                   {'loss': 0.5737, 'grad_norm': 1655.61181640625, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 1.6827536821365356, 'mean_ratio_rejected': 2.639497756958008, 'weight_chosen': 0.6681930422782898, 'weight_rejected': 0.10230471193790436, 'kl_term_chosen': 0.26021575927734375, 'epoch': 0.02}
  2%|▏         | 80/3753 [05:47<4:30:56,  4.43s/it]  2%|▏         | 81/3753 [05:51<4:36:33,  4.52s/it]  2%|▏         | 82/3753 [05:55<4:23:22,  4.30s/it]  2%|▏         | 83/3753 [06:01<4:46:27,  4.68s/it]  2%|▏         | 84/3753 [06:05<4:49:19,  4.73s/it]  2%|▏         | 85/3753 [06:09<4:26:43,  4.36s/it]  2%|▏         | 86/3753 [06:12<4:08:13,  4.06s/it]  2%|▏         | 87/3753 [06:18<4:35:41,  4.51s/it]  2%|▏         | 88/3753 [06:22<4:23:20,  4.31s/it]  2%|▏         | 89/3753 [06:26<4:24:39,  4.33s/it]  2%|▏         | 90/3753 [06:30<4:18:51,  4.24s/it]{'loss': 0.8797, 'grad_norm': 1783.7755126953125, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.129960775375366, 'weight_chosen': -1.705700397491455, 'weight_rejected': 0.15002880990505219, 'kl_term_chosen': 2.49493408203125, 'epoch': 0.023984010659560292}
                                                   {'loss': 0.8797, 'grad_norm': 1783.7755126953125, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.129960775375366, 'weight_chosen': -1.705700397491455, 'weight_rejected': 0.15002880990505219, 'kl_term_chosen': 2.49493408203125, 'epoch': 0.02}
  2%|▏         | 90/3753 [06:30<4:18:51,  4.24s/it]  2%|▏         | 91/3753 [06:33<4:01:40,  3.96s/it]  2%|▏         | 92/3753 [06:37<4:01:22,  3.96s/it]  2%|▏         | 93/3753 [06:42<4:12:14,  4.13s/it]  3%|▎         | 94/3753 [06:46<4:04:40,  4.01s/it]  3%|▎         | 95/3753 [06:52<4:50:50,  4.77s/it]  3%|▎         | 96/3753 [06:56<4:39:31,  4.59s/it]  3%|▎         | 97/3753 [07:01<4:33:04,  4.48s/it]  3%|▎         | 98/3753 [07:06<4:56:58,  4.88s/it]  3%|▎         | 99/3753 [07:10<4:30:31,  4.44s/it]  3%|▎         | 100/3753 [07:13<4:13:27,  4.16s/it]{'loss': 0.8951, 'grad_norm': 1212.7547607421875, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 1.215681552886963, 'mean_ratio_rejected': 0.6013791561126709, 'weight_chosen': 0.5302987694740295, 'weight_rejected': 0.14414885640144348, 'kl_term_chosen': 0.09765243530273438, 'epoch': 0.02664890073284477}
                                                    {'loss': 0.8951, 'grad_norm': 1212.7547607421875, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 1.215681552886963, 'mean_ratio_rejected': 0.6013791561126709, 'weight_chosen': 0.5302987694740295, 'weight_rejected': 0.14414885640144348, 'kl_term_chosen': 0.09765243530273438, 'epoch': 0.03}
  3%|▎         | 100/3753 [07:13<4:13:27,  4.16s/it]  3%|▎         | 101/3753 [07:18<4:21:04,  4.29s/it]  3%|▎         | 102/3753 [07:22<4:18:09,  4.24s/it]  3%|▎         | 103/3753 [07:26<4:08:40,  4.09s/it]  3%|▎         | 104/3753 [07:31<4:37:14,  4.56s/it]  3%|▎         | 105/3753 [07:35<4:26:44,  4.39s/it]  3%|▎         | 106/3753 [07:41<4:45:54,  4.70s/it]  3%|▎         | 107/3753 [07:45<4:44:27,  4.68s/it]  3%|▎         | 108/3753 [07:50<4:32:05,  4.48s/it]  3%|▎         | 109/3753 [07:53<4:22:00,  4.31s/it]  3%|▎         | 110/3753 [07:57<4:15:07,  4.20s/it]{'loss': 0.1695, 'grad_norm': 2077.639404296875, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 6.1184563636779785, 'weight_chosen': -0.5084578990936279, 'weight_rejected': 0.04146226868033409, 'kl_term_chosen': 1.4221343994140625, 'epoch': 0.029313790806129246}
                                                    {'loss': 0.1695, 'grad_norm': 2077.639404296875, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 6.1184563636779785, 'weight_chosen': -0.5084578990936279, 'weight_rejected': 0.04146226868033409, 'kl_term_chosen': 1.4221343994140625, 'epoch': 0.03}
  3%|▎         | 110/3753 [07:57<4:15:07,  4.20s/it]  3%|▎         | 111/3753 [08:03<4:33:39,  4.51s/it]  3%|▎         | 112/3753 [08:06<4:22:05,  4.32s/it]  3%|▎         | 113/3753 [08:10<4:03:33,  4.01s/it]  3%|▎         | 114/3753 [08:13<3:55:25,  3.88s/it]  3%|▎         | 115/3753 [08:17<3:54:10,  3.86s/it]  3%|▎         | 116/3753 [08:22<4:06:04,  4.06s/it]  3%|▎         | 117/3753 [08:26<4:04:46,  4.04s/it]  3%|▎         | 118/3753 [08:30<4:12:41,  4.17s/it]  3%|▎         | 119/3753 [08:35<4:21:17,  4.31s/it]  3%|▎         | 120/3753 [08:39<4:24:49,  4.37s/it]{'loss': 0.8709, 'grad_norm': 2372.954345703125, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 0.5931158065795898, 'mean_ratio_rejected': 0.2095586210489273, 'weight_chosen': 1.0977373123168945, 'weight_rejected': 0.49502578377723694, 'kl_term_chosen': -0.2611827850341797, 'epoch': 0.031978680879413725}
                                                    {'loss': 0.8709, 'grad_norm': 2372.954345703125, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 0.5931158065795898, 'mean_ratio_rejected': 0.2095586210489273, 'weight_chosen': 1.0977373123168945, 'weight_rejected': 0.49502578377723694, 'kl_term_chosen': -0.2611827850341797, 'epoch': 0.03}
  3%|▎         | 120/3753 [08:39<4:24:49,  4.37s/it]  3%|▎         | 121/3753 [08:44<4:23:02,  4.35s/it]  3%|▎         | 122/3753 [08:48<4:29:53,  4.46s/it]  3%|▎         | 123/3753 [08:53<4:27:50,  4.43s/it]  3%|▎         | 124/3753 [08:56<4:16:28,  4.24s/it]  3%|▎         | 125/3753 [09:01<4:21:02,  4.32s/it]  3%|▎         | 126/3753 [09:06<4:27:54,  4.43s/it]  3%|▎         | 127/3753 [09:09<4:12:58,  4.19s/it]  3%|▎         | 128/3753 [09:14<4:17:15,  4.26s/it]  3%|▎         | 129/3753 [09:19<4:42:01,  4.67s/it]  3%|▎         | 130/3753 [09:24<4:39:42,  4.63s/it]{'loss': 1.0946, 'grad_norm': 2253.557861328125, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.658623993396759, 'weight_chosen': -1.021698236465454, 'weight_rejected': 0.10970578342676163, 'kl_term_chosen': 1.3191680908203125, 'epoch': 0.034643570952698204}
                                                    {'loss': 1.0946, 'grad_norm': 2253.557861328125, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.658623993396759, 'weight_chosen': -1.021698236465454, 'weight_rejected': 0.10970578342676163, 'kl_term_chosen': 1.3191680908203125, 'epoch': 0.03}
  3%|▎         | 130/3753 [09:24<4:39:42,  4.63s/it]  3%|▎         | 131/3753 [09:28<4:26:18,  4.41s/it]  4%|▎         | 132/3753 [09:31<4:05:51,  4.07s/it]  4%|▎         | 133/3753 [09:36<4:14:16,  4.21s/it]  4%|▎         | 134/3753 [09:40<4:17:27,  4.27s/it]  4%|▎         | 135/3753 [09:44<4:07:20,  4.10s/it]  4%|▎         | 136/3753 [09:47<3:57:08,  3.93s/it]  4%|▎         | 137/3753 [09:51<3:53:30,  3.87s/it]  4%|▎         | 138/3753 [09:56<4:05:12,  4.07s/it]  4%|▎         | 139/3753 [09:59<4:03:08,  4.04s/it]  4%|▎         | 140/3753 [10:04<4:14:29,  4.23s/it]{'loss': 0.9303, 'grad_norm': 1187.4996337890625, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 4.892669677734375, 'mean_ratio_rejected': 6.599497318267822, 'weight_chosen': 0.06579470634460449, 'weight_rejected': 0.14706450700759888, 'kl_term_chosen': 0.7938690185546875, 'epoch': 0.037308461025982675}
                                                    {'loss': 0.9303, 'grad_norm': 1187.4996337890625, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 4.892669677734375, 'mean_ratio_rejected': 6.599497318267822, 'weight_chosen': 0.06579470634460449, 'weight_rejected': 0.14706450700759888, 'kl_term_chosen': 0.7938690185546875, 'epoch': 0.04}
  4%|▎         | 140/3753 [10:04<4:14:29,  4.23s/it]  4%|▍         | 141/3753 [10:08<4:07:34,  4.11s/it]  4%|▍         | 142/3753 [10:14<4:38:52,  4.63s/it]  4%|▍         | 143/3753 [10:18<4:29:23,  4.48s/it]  4%|▍         | 144/3753 [10:24<4:49:09,  4.81s/it]  4%|▍         | 145/3753 [10:28<4:49:27,  4.81s/it]  4%|▍         | 146/3753 [10:33<4:52:09,  4.86s/it]  4%|▍         | 147/3753 [10:37<4:31:47,  4.52s/it]  4%|▍         | 148/3753 [10:42<4:38:30,  4.64s/it]  4%|▍         | 149/3753 [10:46<4:23:36,  4.39s/it]  4%|▍         | 150/3753 [10:51<4:31:41,  4.52s/it]{'loss': 1.2116, 'grad_norm': 1891.13330078125, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 0.21098479628562927, 'mean_ratio_rejected': 0.1961769014596939, 'weight_chosen': 1.1134443283081055, 'weight_rejected': 0.5903069972991943, 'kl_term_chosen': -0.777984619140625, 'epoch': 0.039973351099267154}
                                                    {'loss': 1.2116, 'grad_norm': 1891.13330078125, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 0.21098479628562927, 'mean_ratio_rejected': 0.1961769014596939, 'weight_chosen': 1.1134443283081055, 'weight_rejected': 0.5903069972991943, 'kl_term_chosen': -0.777984619140625, 'epoch': 0.04}
  4%|▍         | 150/3753 [10:51<4:31:41,  4.52s/it]  4%|▍         | 151/3753 [10:56<4:40:19,  4.67s/it]  4%|▍         | 152/3753 [11:00<4:26:24,  4.44s/it]  4%|▍         | 153/3753 [11:04<4:30:22,  4.51s/it]  4%|▍         | 154/3753 [11:09<4:27:08,  4.45s/it]  4%|▍         | 155/3753 [11:13<4:20:10,  4.34s/it]  4%|▍         | 156/3753 [11:17<4:20:59,  4.35s/it]  4%|▍         | 157/3753 [11:21<4:10:44,  4.18s/it]  4%|▍         | 158/3753 [11:25<4:17:49,  4.30s/it]  4%|▍         | 159/3753 [11:29<4:13:08,  4.23s/it]  4%|▍         | 160/3753 [11:34<4:16:21,  4.28s/it]{'loss': 1.0835, 'grad_norm': 1796.119140625, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 1.240964651107788, 'mean_ratio_rejected': 2.07735276222229, 'weight_chosen': 0.5720847845077515, 'weight_rejected': 0.3372035324573517, 'kl_term_chosen': 0.10794448852539062, 'epoch': 0.04263824117255163}
                                                    {'loss': 1.0835, 'grad_norm': 1796.119140625, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 1.240964651107788, 'mean_ratio_rejected': 2.07735276222229, 'weight_chosen': 0.5720847845077515, 'weight_rejected': 0.3372035324573517, 'kl_term_chosen': 0.10794448852539062, 'epoch': 0.04}
  4%|▍         | 160/3753 [11:34<4:16:21,  4.28s/it]  4%|▍         | 161/3753 [11:38<4:07:51,  4.14s/it]  4%|▍         | 162/3753 [11:42<4:09:16,  4.16s/it]  4%|▍         | 163/3753 [11:45<3:55:15,  3.93s/it]  4%|▍         | 164/3753 [11:51<4:33:54,  4.58s/it]  4%|▍         | 165/3753 [11:56<4:29:41,  4.51s/it]  4%|▍         | 166/3753 [11:59<4:09:32,  4.17s/it]  4%|▍         | 167/3753 [12:04<4:24:11,  4.42s/it]  4%|▍         | 168/3753 [12:09<4:36:24,  4.63s/it]  5%|▍         | 169/3753 [12:13<4:15:35,  4.28s/it]  5%|▍         | 170/3753 [12:16<3:57:58,  3.99s/it]{'loss': 1.2147, 'grad_norm': 1601.6514892578125, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 4.530160903930664, 'mean_ratio_rejected': 8.029438972473145, 'weight_chosen': 0.11696863174438477, 'weight_rejected': 0.13568955659866333, 'kl_term_chosen': 0.7553787231445312, 'epoch': 0.04530313124583611}
                                                    {'loss': 1.2147, 'grad_norm': 1601.6514892578125, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 4.530160903930664, 'mean_ratio_rejected': 8.029438972473145, 'weight_chosen': 0.11696863174438477, 'weight_rejected': 0.13568955659866333, 'kl_term_chosen': 0.7553787231445312, 'epoch': 0.05}
  5%|▍         | 170/3753 [12:16<3:57:58,  3.99s/it]  5%|▍         | 171/3753 [12:20<4:07:47,  4.15s/it]  5%|▍         | 172/3753 [12:26<4:35:06,  4.61s/it]  5%|▍         | 173/3753 [12:30<4:21:11,  4.38s/it]  5%|▍         | 174/3753 [12:34<4:20:30,  4.37s/it]  5%|▍         | 175/3753 [12:39<4:21:25,  4.38s/it]  5%|▍         | 176/3753 [12:42<4:05:23,  4.12s/it]  5%|▍         | 177/3753 [12:47<4:10:01,  4.20s/it]  5%|▍         | 178/3753 [12:51<4:20:43,  4.38s/it]  5%|▍         | 179/3753 [12:55<4:07:57,  4.16s/it]  5%|▍         | 180/3753 [12:59<4:05:38,  4.13s/it]{'loss': 1.6329, 'grad_norm': 4170.482421875, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.2130070924758911, 'weight_rejected': 0.09268777817487717, 'kl_term_chosen': 2.1483535766601562, 'epoch': 0.047968021319120584}
                                                    {'loss': 1.6329, 'grad_norm': 4170.482421875, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.2130070924758911, 'weight_rejected': 0.09268777817487717, 'kl_term_chosen': 2.1483535766601562, 'epoch': 0.05}
  5%|▍         | 180/3753 [12:59<4:05:38,  4.13s/it]  5%|▍         | 181/3753 [13:04<4:13:01,  4.25s/it]  5%|▍         | 182/3753 [13:10<4:45:15,  4.79s/it]  5%|▍         | 183/3753 [13:14<4:41:13,  4.73s/it]  5%|▍         | 184/3753 [13:20<4:50:43,  4.89s/it]  5%|▍         | 185/3753 [13:24<4:49:55,  4.88s/it]  5%|▍         | 186/3753 [13:28<4:34:50,  4.62s/it]  5%|▍         | 187/3753 [13:32<4:22:48,  4.42s/it]  5%|▌         | 188/3753 [13:36<4:13:31,  4.27s/it]  5%|▌         | 189/3753 [13:43<4:54:25,  4.96s/it]  5%|▌         | 190/3753 [13:47<4:42:33,  4.76s/it]{'loss': 1.391, 'grad_norm': 1169.811767578125, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 0.8748013377189636, 'mean_ratio_rejected': 1.7143465280532837, 'weight_chosen': 0.9476763606071472, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': -0.0668792724609375, 'epoch': 0.05063291139240506}
                                                    {'loss': 1.391, 'grad_norm': 1169.811767578125, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 0.8748013377189636, 'mean_ratio_rejected': 1.7143465280532837, 'weight_chosen': 0.9476763606071472, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': -0.0668792724609375, 'epoch': 0.05}
  5%|▌         | 190/3753 [13:47<4:42:33,  4.76s/it]  5%|▌         | 191/3753 [13:51<4:24:45,  4.46s/it]  5%|▌         | 192/3753 [13:55<4:21:42,  4.41s/it]  5%|▌         | 193/3753 [13:59<4:15:29,  4.31s/it]  5%|▌         | 194/3753 [14:04<4:27:12,  4.50s/it]  5%|▌         | 195/3753 [14:08<4:20:53,  4.40s/it]  5%|▌         | 196/3753 [14:12<4:04:17,  4.12s/it]  5%|▌         | 197/3753 [14:18<4:34:37,  4.63s/it]  5%|▌         | 198/3753 [14:22<4:21:29,  4.41s/it]  5%|▌         | 199/3753 [14:27<4:34:01,  4.63s/it]  5%|▌         | 200/3753 [14:31<4:29:21,  4.55s/it]{'loss': 1.8274, 'grad_norm': 1238.47412109375, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 3.246464490890503, 'weight_chosen': -1.3374751806259155, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 2.28082275390625, 'epoch': 0.05329780146568954}
                                                    {'loss': 1.8274, 'grad_norm': 1238.47412109375, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 3.246464490890503, 'weight_chosen': -1.3374751806259155, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 2.28082275390625, 'epoch': 0.05}
  5%|▌         | 200/3753 [14:31<4:29:21,  4.55s/it]  5%|▌         | 201/3753 [14:35<4:24:42,  4.47s/it]  5%|▌         | 202/3753 [14:39<4:14:39,  4.30s/it]  5%|▌         | 203/3753 [14:43<4:12:26,  4.27s/it]  5%|▌         | 204/3753 [14:47<4:01:08,  4.08s/it]  5%|▌         | 205/3753 [14:51<3:56:11,  3.99s/it]  5%|▌         | 206/3753 [14:56<4:22:07,  4.43s/it]  6%|▌         | 207/3753 [15:00<4:16:34,  4.34s/it]  6%|▌         | 208/3753 [15:05<4:27:12,  4.52s/it]  6%|▌         | 209/3753 [15:10<4:30:30,  4.58s/it]  6%|▌         | 210/3753 [15:15<4:28:19,  4.54s/it]{'loss': 1.4559, 'grad_norm': 1339.912109375, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 3.7350900173187256, 'mean_ratio_rejected': 1.7502943277359009, 'weight_chosen': 0.1598508358001709, 'weight_rejected': 0.15304215252399445, 'kl_term_chosen': 0.6588859558105469, 'epoch': 0.05596269153897402}
                                                    {'loss': 1.4559, 'grad_norm': 1339.912109375, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 3.7350900173187256, 'mean_ratio_rejected': 1.7502943277359009, 'weight_chosen': 0.1598508358001709, 'weight_rejected': 0.15304215252399445, 'kl_term_chosen': 0.6588859558105469, 'epoch': 0.06}
  6%|▌         | 210/3753 [15:15<4:28:19,  4.54s/it]  6%|▌         | 211/3753 [15:20<4:41:38,  4.77s/it]  6%|▌         | 212/3753 [15:24<4:22:08,  4.44s/it]  6%|▌         | 213/3753 [15:28<4:24:40,  4.49s/it]  6%|▌         | 214/3753 [15:34<4:45:08,  4.83s/it]  6%|▌         | 215/3753 [15:38<4:30:48,  4.59s/it]  6%|▌         | 216/3753 [15:42<4:24:06,  4.48s/it]  6%|▌         | 217/3753 [15:46<4:13:58,  4.31s/it]  6%|▌         | 218/3753 [15:51<4:22:01,  4.45s/it]  6%|▌         | 219/3753 [15:54<4:06:51,  4.19s/it]  6%|▌         | 220/3753 [15:58<3:59:18,  4.06s/it]{'loss': 1.1751, 'grad_norm': 2699.898193359375, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 9.620984077453613, 'mean_ratio_rejected': 2.4972727298736572, 'weight_chosen': -0.4502464532852173, 'weight_rejected': 0.1200256198644638, 'kl_term_chosen': 1.1319732666015625, 'epoch': 0.05862758161225849}
                                                    {'loss': 1.1751, 'grad_norm': 2699.898193359375, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 9.620984077453613, 'mean_ratio_rejected': 2.4972727298736572, 'weight_chosen': -0.4502464532852173, 'weight_rejected': 0.1200256198644638, 'kl_term_chosen': 1.1319732666015625, 'epoch': 0.06}
  6%|▌         | 220/3753 [15:58<3:59:18,  4.06s/it]  6%|▌         | 221/3753 [16:02<3:52:26,  3.95s/it]  6%|▌         | 222/3753 [16:06<3:55:19,  4.00s/it]  6%|▌         | 223/3753 [16:09<3:46:45,  3.85s/it]  6%|▌         | 224/3753 [16:13<3:48:01,  3.88s/it]  6%|▌         | 225/3753 [16:18<3:53:38,  3.97s/it]  6%|▌         | 226/3753 [16:21<3:49:06,  3.90s/it]  6%|▌         | 227/3753 [16:27<4:14:13,  4.33s/it]  6%|▌         | 228/3753 [16:30<3:59:07,  4.07s/it]  6%|▌         | 229/3753 [16:35<4:12:43,  4.30s/it]  6%|▌         | 230/3753 [16:41<4:42:44,  4.82s/it]{'loss': 1.456, 'grad_norm': 1835.2894287109375, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 2.8174800872802734, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.41928935050964355, 'weight_rejected': 0.1490352898836136, 'kl_term_chosen': 0.5179214477539062, 'epoch': 0.06129247168554297}
                                                    {'loss': 1.456, 'grad_norm': 1835.2894287109375, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 2.8174800872802734, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.41928935050964355, 'weight_rejected': 0.1490352898836136, 'kl_term_chosen': 0.5179214477539062, 'epoch': 0.06}
  6%|▌         | 230/3753 [16:41<4:42:44,  4.82s/it]  6%|▌         | 231/3753 [16:46<4:47:02,  4.89s/it]  6%|▌         | 232/3753 [16:50<4:34:04,  4.67s/it]  6%|▌         | 233/3753 [16:55<4:37:24,  4.73s/it]  6%|▌         | 234/3753 [17:00<4:47:53,  4.91s/it]  6%|▋         | 235/3753 [17:06<4:58:19,  5.09s/it]  6%|▋         | 236/3753 [17:10<4:40:43,  4.79s/it]  6%|▋         | 237/3753 [17:13<4:17:25,  4.39s/it]  6%|▋         | 238/3753 [17:18<4:14:24,  4.34s/it]  6%|▋         | 239/3753 [17:23<4:24:36,  4.52s/it]  6%|▋         | 240/3753 [17:27<4:26:00,  4.54s/it]{'loss': 1.3474, 'grad_norm': 1678.6263427734375, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.4786839485168457, 'weight_rejected': 0.17781086266040802, 'kl_term_chosen': -1.6475410461425781, 'epoch': 0.06395736175882745}
                                                    {'loss': 1.3474, 'grad_norm': 1678.6263427734375, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.4786839485168457, 'weight_rejected': 0.17781086266040802, 'kl_term_chosen': -1.6475410461425781, 'epoch': 0.06}
  6%|▋         | 240/3753 [17:27<4:26:00,  4.54s/it]  6%|▋         | 241/3753 [17:31<4:17:15,  4.39s/it]  6%|▋         | 242/3753 [17:35<4:12:39,  4.32s/it]  6%|▋         | 243/3753 [17:40<4:14:25,  4.35s/it]  7%|▋         | 244/3753 [17:44<4:20:04,  4.45s/it]  7%|▋         | 245/3753 [17:49<4:18:03,  4.41s/it]  7%|▋         | 246/3753 [17:52<4:04:07,  4.18s/it]  7%|▋         | 247/3753 [17:57<4:16:52,  4.40s/it]  7%|▋         | 248/3753 [18:01<4:10:20,  4.29s/it]  7%|▋         | 249/3753 [18:06<4:19:58,  4.45s/it]  7%|▋         | 250/3753 [18:11<4:33:30,  4.68s/it]{'loss': 2.9729, 'grad_norm': 1830.16650390625, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 5.07524299621582, 'mean_ratio_rejected': 1.5903087854385376, 'weight_chosen': 0.08260226249694824, 'weight_rejected': 0.14804719388484955, 'kl_term_chosen': 0.8121871948242188, 'epoch': 0.06662225183211193}
                                                    {'loss': 2.9729, 'grad_norm': 1830.16650390625, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 5.07524299621582, 'mean_ratio_rejected': 1.5903087854385376, 'weight_chosen': 0.08260226249694824, 'weight_rejected': 0.14804719388484955, 'kl_term_chosen': 0.8121871948242188, 'epoch': 0.07}
  7%|▋         | 250/3753 [18:12<4:33:30,  4.68s/it]  7%|▋         | 251/3753 [18:17<4:54:41,  5.05s/it]  7%|▋         | 252/3753 [18:22<4:56:20,  5.08s/it]  7%|▋         | 253/3753 [18:27<4:49:11,  4.96s/it]  7%|▋         | 254/3753 [18:31<4:23:11,  4.51s/it]  7%|▋         | 255/3753 [18:34<4:09:51,  4.29s/it]  7%|▋         | 256/3753 [18:38<3:59:48,  4.11s/it]  7%|▋         | 257/3753 [18:43<4:09:28,  4.28s/it]  7%|▋         | 258/3753 [18:46<3:59:38,  4.11s/it]  7%|▋         | 259/3753 [18:50<3:49:12,  3.94s/it]  7%|▋         | 260/3753 [18:55<4:00:20,  4.13s/it]{'loss': 6.2457, 'grad_norm': 942.8822021484375, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 0.34265026450157166, 'mean_ratio_rejected': 1.6174243688583374, 'weight_chosen': 1.422727108001709, 'weight_rejected': 0.13386748731136322, 'kl_term_chosen': -0.5355224609375, 'epoch': 0.06928714190539641}
                                                    {'loss': 6.2457, 'grad_norm': 942.8822021484375, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 0.34265026450157166, 'mean_ratio_rejected': 1.6174243688583374, 'weight_chosen': 1.422727108001709, 'weight_rejected': 0.13386748731136322, 'kl_term_chosen': -0.5355224609375, 'epoch': 0.07}
  7%|▋         | 260/3753 [18:55<4:00:20,  4.13s/it]  7%|▋         | 261/3753 [18:59<4:07:58,  4.26s/it]  7%|▋         | 262/3753 [19:04<4:10:30,  4.31s/it]  7%|▋         | 263/3753 [19:08<4:17:45,  4.43s/it]  7%|▋         | 264/3753 [19:12<4:07:14,  4.25s/it]  7%|▋         | 265/3753 [19:16<4:03:17,  4.19s/it]  7%|▋         | 266/3753 [19:20<3:55:07,  4.05s/it]  7%|▋         | 267/3753 [19:24<3:52:27,  4.00s/it]  7%|▋         | 268/3753 [19:29<4:08:22,  4.28s/it]  7%|▋         | 269/3753 [19:32<3:54:25,  4.04s/it]  7%|▋         | 270/3753 [19:37<4:02:19,  4.17s/it]{'loss': 2.1233, 'grad_norm': 1221.123779296875, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.5517058372497559, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': 2.52728271484375, 'epoch': 0.07195203197868089}
                                                    {'loss': 2.1233, 'grad_norm': 1221.123779296875, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.5517058372497559, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': 2.52728271484375, 'epoch': 0.07}
  7%|▋         | 270/3753 [19:37<4:02:19,  4.17s/it]  7%|▋         | 271/3753 [19:41<4:08:02,  4.27s/it]  7%|▋         | 272/3753 [19:46<4:09:57,  4.31s/it]  7%|▋         | 273/3753 [19:49<3:58:32,  4.11s/it]  7%|▋         | 274/3753 [19:53<3:56:19,  4.08s/it]  7%|▋         | 275/3753 [19:57<3:52:58,  4.02s/it]  7%|▋         | 276/3753 [20:01<3:45:24,  3.89s/it]  7%|▋         | 277/3753 [20:06<4:04:41,  4.22s/it]  7%|▋         | 278/3753 [20:09<3:48:31,  3.95s/it]  7%|▋         | 279/3753 [20:14<4:00:41,  4.16s/it]  7%|▋         | 280/3753 [20:19<4:14:44,  4.40s/it]{'loss': 5.2442, 'grad_norm': 1139.158203125, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.5712082386016846, 'mean_ratio_rejected': 0.405351847410202, 'weight_chosen': 1.2104589939117432, 'weight_rejected': 0.07263670116662979, 'kl_term_chosen': -0.2800006866455078, 'epoch': 0.07461692205196535}
                                                    {'loss': 5.2442, 'grad_norm': 1139.158203125, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 0.5712082386016846, 'mean_ratio_rejected': 0.405351847410202, 'weight_chosen': 1.2104589939117432, 'weight_rejected': 0.07263670116662979, 'kl_term_chosen': -0.2800006866455078, 'epoch': 0.07}
  7%|▋         | 280/3753 [20:19<4:14:44,  4.40s/it]  7%|▋         | 281/3753 [20:23<4:07:35,  4.28s/it]  8%|▊         | 282/3753 [20:28<4:24:22,  4.57s/it]  8%|▊         | 283/3753 [20:32<4:19:47,  4.49s/it]  8%|▊         | 284/3753 [20:36<4:14:17,  4.40s/it]  8%|▊         | 285/3753 [20:42<4:37:11,  4.80s/it]  8%|▊         | 286/3753 [20:46<4:20:04,  4.50s/it]  8%|▊         | 287/3753 [20:50<4:06:22,  4.26s/it]  8%|▊         | 288/3753 [20:55<4:29:19,  4.66s/it]  8%|▊         | 289/3753 [21:00<4:30:49,  4.69s/it]  8%|▊         | 290/3753 [21:06<4:50:14,  5.03s/it]{'loss': 4.3045, 'grad_norm': 3946.4326171875, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.2632524967193604, 'weight_chosen': -0.8619202971458435, 'weight_rejected': 0.20946967601776123, 'kl_term_chosen': 1.615386962890625, 'epoch': 0.07728181212524983}
                                                    {'loss': 4.3045, 'grad_norm': 3946.4326171875, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.2632524967193604, 'weight_chosen': -0.8619202971458435, 'weight_rejected': 0.20946967601776123, 'kl_term_chosen': 1.615386962890625, 'epoch': 0.08}
  8%|▊         | 290/3753 [21:06<4:50:14,  5.03s/it]  8%|▊         | 291/3753 [21:10<4:31:00,  4.70s/it]  8%|▊         | 292/3753 [21:15<4:41:07,  4.87s/it]  8%|▊         | 293/3753 [21:19<4:19:29,  4.50s/it]  8%|▊         | 294/3753 [21:23<4:13:22,  4.39s/it]  8%|▊         | 295/3753 [21:28<4:20:39,  4.52s/it]  8%|▊         | 296/3753 [21:32<4:11:37,  4.37s/it]  8%|▊         | 297/3753 [21:36<4:15:17,  4.43s/it]  8%|▊         | 298/3753 [21:42<4:32:35,  4.73s/it]  8%|▊         | 299/3753 [21:46<4:25:13,  4.61s/it]  8%|▊         | 300/3753 [21:50<4:17:52,  4.48s/it]{'loss': 4.0017, 'grad_norm': 986.4439086914062, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 7.863929271697998, 'weight_chosen': -0.2851172089576721, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 1.209259033203125, 'epoch': 0.07994670219853431}
                                                    {'loss': 4.0017, 'grad_norm': 986.4439086914062, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 7.863929271697998, 'weight_chosen': -0.2851172089576721, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 1.209259033203125, 'epoch': 0.08}
  8%|▊         | 300/3753 [21:50<4:17:52,  4.48s/it]  8%|▊         | 301/3753 [21:54<4:14:00,  4.41s/it]  8%|▊         | 302/3753 [21:59<4:24:58,  4.61s/it]  8%|▊         | 303/3753 [22:04<4:26:37,  4.64s/it]  8%|▊         | 304/3753 [22:07<3:59:12,  4.16s/it]  8%|▊         | 305/3753 [22:11<3:57:06,  4.13s/it]  8%|▊         | 306/3753 [22:15<3:51:55,  4.04s/it]  8%|▊         | 307/3753 [22:20<4:01:19,  4.20s/it]  8%|▊         | 308/3753 [22:25<4:21:44,  4.56s/it]  8%|▊         | 309/3753 [22:29<4:20:36,  4.54s/it]  8%|▊         | 310/3753 [22:33<4:11:22,  4.38s/it]{'loss': 4.4059, 'grad_norm': 877.8466796875, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 1.4199589490890503, 'mean_ratio_rejected': 0.29704180359840393, 'weight_chosen': 0.48835498094558716, 'weight_rejected': 0.22815649211406708, 'kl_term_chosen': 0.17531394958496094, 'epoch': 0.08261159227181879}
                                                    {'loss': 4.4059, 'grad_norm': 877.8466796875, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 1.4199589490890503, 'mean_ratio_rejected': 0.29704180359840393, 'weight_chosen': 0.48835498094558716, 'weight_rejected': 0.22815649211406708, 'kl_term_chosen': 0.17531394958496094, 'epoch': 0.08}
  8%|▊         | 310/3753 [22:34<4:11:22,  4.38s/it]  8%|▊         | 311/3753 [22:38<4:12:25,  4.40s/it]  8%|▊         | 312/3753 [22:42<4:05:59,  4.29s/it]  8%|▊         | 313/3753 [22:46<4:07:57,  4.32s/it]  8%|▊         | 314/3753 [22:51<4:19:51,  4.53s/it]  8%|▊         | 315/3753 [22:55<4:03:28,  4.25s/it]  8%|▊         | 316/3753 [22:59<3:52:25,  4.06s/it]  8%|▊         | 317/3753 [23:03<3:52:25,  4.06s/it]  8%|▊         | 318/3753 [23:07<4:02:25,  4.23s/it]  8%|▊         | 319/3753 [23:11<4:01:08,  4.21s/it]  9%|▊         | 320/3753 [23:16<4:08:25,  4.34s/it]{'loss': 5.4032, 'grad_norm': 1340.0989990234375, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 9.939117431640625, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.2110283374786377, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': 1.1482391357421875, 'epoch': 0.08527648234510327}
                                                    {'loss': 5.4032, 'grad_norm': 1340.0989990234375, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 9.939117431640625, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.2110283374786377, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': 1.1482391357421875, 'epoch': 0.09}
  9%|▊         | 320/3753 [23:16<4:08:25,  4.34s/it]  9%|▊         | 321/3753 [23:21<4:11:12,  4.39s/it]  9%|▊         | 322/3753 [23:24<4:02:00,  4.23s/it]  9%|▊         | 323/3753 [23:28<3:46:42,  3.97s/it]  9%|▊         | 324/3753 [23:34<4:28:46,  4.70s/it]  9%|▊         | 325/3753 [23:39<4:21:41,  4.58s/it]  9%|▊         | 326/3753 [23:42<4:04:23,  4.28s/it]  9%|▊         | 327/3753 [23:46<4:02:06,  4.24s/it]  9%|▊         | 328/3753 [23:50<3:54:43,  4.11s/it]  9%|▉         | 329/3753 [23:55<4:00:44,  4.22s/it]  9%|▉         | 330/3753 [24:00<4:14:15,  4.46s/it]{'loss': 8.6865, 'grad_norm': 1162.5308837890625, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 1.0158406496047974, 'mean_ratio_rejected': 7.820491790771484, 'weight_chosen': 0.8536799550056458, 'weight_rejected': 0.22135066986083984, 'kl_term_chosen': 0.0078582763671875, 'epoch': 0.08794137241838774}
                                                    {'loss': 8.6865, 'grad_norm': 1162.5308837890625, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 1.0158406496047974, 'mean_ratio_rejected': 7.820491790771484, 'weight_chosen': 0.8536799550056458, 'weight_rejected': 0.22135066986083984, 'kl_term_chosen': 0.0078582763671875, 'epoch': 0.09}
  9%|▉         | 330/3753 [24:00<4:14:15,  4.46s/it]  9%|▉         | 331/3753 [24:03<4:05:25,  4.30s/it]  9%|▉         | 332/3753 [24:07<3:57:32,  4.17s/it]  9%|▉         | 333/3753 [24:12<3:59:40,  4.20s/it]  9%|▉         | 334/3753 [24:17<4:17:38,  4.52s/it]  9%|▉         | 335/3753 [24:22<4:23:31,  4.63s/it]  9%|▉         | 336/3753 [24:25<4:01:11,  4.24s/it]  9%|▉         | 337/3753 [24:30<4:06:52,  4.34s/it]  9%|▉         | 338/3753 [24:33<3:53:02,  4.09s/it]  9%|▉         | 339/3753 [24:37<3:41:50,  3.90s/it]  9%|▉         | 340/3753 [24:41<3:49:39,  4.04s/it]{'loss': 5.9676, 'grad_norm': 613.9815673828125, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.490686058998108, 'weight_rejected': 0.7826625108718872, 'kl_term_chosen': -1.2470436096191406, 'epoch': 0.09060626249167222}
                                                    {'loss': 5.9676, 'grad_norm': 613.9815673828125, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.490686058998108, 'weight_rejected': 0.7826625108718872, 'kl_term_chosen': -1.2470436096191406, 'epoch': 0.09}
  9%|▉         | 340/3753 [24:41<3:49:39,  4.04s/it]  9%|▉         | 341/3753 [24:45<3:45:48,  3.97s/it]  9%|▉         | 342/3753 [24:49<3:44:26,  3.95s/it]  9%|▉         | 343/3753 [24:53<3:54:48,  4.13s/it]  9%|▉         | 344/3753 [24:57<3:51:19,  4.07s/it]  9%|▉         | 345/3753 [25:03<4:14:17,  4.48s/it]  9%|▉         | 346/3753 [25:07<4:08:18,  4.37s/it]  9%|▉         | 347/3753 [25:11<4:10:15,  4.41s/it]  9%|▉         | 348/3753 [25:17<4:24:37,  4.66s/it]  9%|▉         | 349/3753 [25:20<4:05:26,  4.33s/it]  9%|▉         | 350/3753 [25:25<4:10:50,  4.42s/it]{'loss': 6.8426, 'grad_norm': 705.4271240234375, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.32166430354118347, 'weight_chosen': -1.1416215896606445, 'weight_rejected': 0.2186693549156189, 'kl_term_chosen': 1.9760284423828125, 'epoch': 0.09327115256495669}
                                                    {'loss': 6.8426, 'grad_norm': 705.4271240234375, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.32166430354118347, 'weight_chosen': -1.1416215896606445, 'weight_rejected': 0.2186693549156189, 'kl_term_chosen': 1.9760284423828125, 'epoch': 0.09}
  9%|▉         | 350/3753 [25:25<4:10:50,  4.42s/it]  9%|▉         | 351/3753 [25:29<4:02:10,  4.27s/it]  9%|▉         | 352/3753 [25:32<3:46:47,  4.00s/it]  9%|▉         | 353/3753 [25:36<3:48:31,  4.03s/it]  9%|▉         | 354/3753 [25:40<3:54:11,  4.13s/it]  9%|▉         | 355/3753 [25:45<4:02:50,  4.29s/it]  9%|▉         | 356/3753 [25:49<4:04:28,  4.32s/it] 10%|▉         | 357/3753 [25:54<4:01:43,  4.27s/it] 10%|▉         | 358/3753 [25:58<4:07:13,  4.37s/it] 10%|▉         | 359/3753 [26:02<4:00:12,  4.25s/it] 10%|▉         | 360/3753 [26:06<3:51:13,  4.09s/it]{'loss': 5.6985, 'grad_norm': 704.1294555664062, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 0.2535988390445709, 'mean_ratio_rejected': 0.30425766110420227, 'weight_chosen': 1.2303178310394287, 'weight_rejected': 0.16667540371418, 'kl_term_chosen': -0.6860008239746094, 'epoch': 0.09593604263824117}
                                                    {'loss': 5.6985, 'grad_norm': 704.1294555664062, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 0.2535988390445709, 'mean_ratio_rejected': 0.30425766110420227, 'weight_chosen': 1.2303178310394287, 'weight_rejected': 0.16667540371418, 'kl_term_chosen': -0.6860008239746094, 'epoch': 0.1}
 10%|▉         | 360/3753 [26:06<3:51:13,  4.09s/it] 10%|▉         | 361/3753 [26:11<3:59:42,  4.24s/it] 10%|▉         | 362/3753 [26:15<4:01:47,  4.28s/it] 10%|▉         | 363/3753 [26:19<4:00:45,  4.26s/it] 10%|▉         | 364/3753 [26:24<4:04:20,  4.33s/it] 10%|▉         | 365/3753 [26:27<3:45:59,  4.00s/it] 10%|▉         | 366/3753 [26:30<3:36:35,  3.84s/it] 10%|▉         | 367/3753 [26:34<3:41:12,  3.92s/it] 10%|▉         | 368/3753 [26:39<3:55:53,  4.18s/it] 10%|▉         | 369/3753 [26:44<4:02:24,  4.30s/it] 10%|▉         | 370/3753 [26:48<3:57:55,  4.22s/it]{'loss': 6.1148, 'grad_norm': 1014.4618530273438, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.7983712553977966, 'weight_chosen': 2.5900604724884033, 'weight_rejected': 0.20561504364013672, 'kl_term_chosen': -1.7257499694824219, 'epoch': 0.09860093271152565}
                                                    {'loss': 6.1148, 'grad_norm': 1014.4618530273438, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.7983712553977966, 'weight_chosen': 2.5900604724884033, 'weight_rejected': 0.20561504364013672, 'kl_term_chosen': -1.7257499694824219, 'epoch': 0.1}
 10%|▉         | 370/3753 [26:48<3:57:55,  4.22s/it] 10%|▉         | 371/3753 [26:51<3:47:37,  4.04s/it] 10%|▉         | 372/3753 [26:56<3:56:30,  4.20s/it] 10%|▉         | 373/3753 [27:00<3:51:37,  4.11s/it] 10%|▉         | 374/3753 [27:04<3:53:48,  4.15s/it] 10%|▉         | 375/3753 [27:10<4:16:19,  4.55s/it] 10%|█         | 376/3753 [27:16<4:38:46,  4.95s/it] 10%|█         | 377/3753 [27:21<4:42:06,  5.01s/it] 10%|█         | 378/3753 [27:24<4:17:12,  4.57s/it] 10%|█         | 379/3753 [27:28<3:56:46,  4.21s/it] 10%|█         | 380/3753 [27:32<4:04:20,  4.35s/it]{'loss': 12.0048, 'grad_norm': 587.89453125, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.23905611038208, 'weight_rejected': 0.02595735713839531, 'kl_term_chosen': 5.1994171142578125, 'epoch': 0.10126582278481013}
                                                    {'loss': 12.0048, 'grad_norm': 587.89453125, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.23905611038208, 'weight_rejected': 0.02595735713839531, 'kl_term_chosen': 5.1994171142578125, 'epoch': 0.1}
 10%|█         | 380/3753 [27:32<4:04:20,  4.35s/it] 10%|█         | 381/3753 [27:36<3:59:36,  4.26s/it] 10%|█         | 382/3753 [27:41<4:00:14,  4.28s/it] 10%|█         | 383/3753 [27:45<3:54:12,  4.17s/it] 10%|█         | 384/3753 [27:50<4:13:10,  4.51s/it] 10%|█         | 385/3753 [27:56<4:36:28,  4.93s/it] 10%|█         | 386/3753 [27:59<4:14:09,  4.53s/it] 10%|█         | 387/3753 [28:04<4:09:05,  4.44s/it] 10%|█         | 388/3753 [28:08<4:09:38,  4.45s/it] 10%|█         | 389/3753 [28:13<4:11:21,  4.48s/it] 10%|█         | 390/3753 [28:17<4:14:50,  4.55s/it]{'loss': 10.092, 'grad_norm': 761.4966430664062, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.2565353512763977, 'mean_ratio_rejected': 0.2125130593776703, 'weight_chosen': 1.3190797567367554, 'weight_rejected': 0.8164063692092896, 'kl_term_chosen': -0.6802444458007812, 'epoch': 0.1039307128580946}
                                                    {'loss': 10.092, 'grad_norm': 761.4966430664062, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.2565353512763977, 'mean_ratio_rejected': 0.2125130593776703, 'weight_chosen': 1.3190797567367554, 'weight_rejected': 0.8164063692092896, 'kl_term_chosen': -0.6802444458007812, 'epoch': 0.1}
 10%|█         | 390/3753 [28:17<4:14:50,  4.55s/it] 10%|█         | 391/3753 [28:22<4:11:39,  4.49s/it] 10%|█         | 392/3753 [28:26<4:02:01,  4.32s/it] 10%|█         | 393/3753 [28:30<4:04:13,  4.36s/it] 10%|█         | 394/3753 [28:34<4:02:54,  4.34s/it] 11%|█         | 395/3753 [28:39<4:09:48,  4.46s/it] 11%|█         | 396/3753 [28:45<4:32:36,  4.87s/it] 11%|█         | 397/3753 [28:48<4:08:27,  4.44s/it] 11%|█         | 398/3753 [28:53<4:03:51,  4.36s/it] 11%|█         | 399/3753 [28:57<4:09:54,  4.47s/it] 11%|█         | 400/3753 [29:01<4:00:58,  4.31s/it]{'loss': 5.5542, 'grad_norm': 832.4564208984375, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 0.5385609865188599, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.0045583248138428, 'weight_rejected': 0.25091278553009033, 'kl_term_chosen': -0.30942726135253906, 'epoch': 0.10659560293137908}
                                                    {'loss': 5.5542, 'grad_norm': 832.4564208984375, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 0.5385609865188599, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.0045583248138428, 'weight_rejected': 0.25091278553009033, 'kl_term_chosen': -0.30942726135253906, 'epoch': 0.11}
 11%|█         | 400/3753 [29:01<4:00:58,  4.31s/it] 11%|█         | 401/3753 [29:05<3:55:48,  4.22s/it] 11%|█         | 402/3753 [29:10<4:06:29,  4.41s/it] 11%|█         | 403/3753 [29:13<3:43:42,  4.01s/it] 11%|█         | 404/3753 [29:17<3:46:45,  4.06s/it] 11%|█         | 405/3753 [29:22<3:56:28,  4.24s/it] 11%|█         | 406/3753 [29:26<3:55:55,  4.23s/it] 11%|█         | 407/3753 [29:30<3:48:43,  4.10s/it] 11%|█         | 408/3753 [29:35<4:01:30,  4.33s/it] 11%|█         | 409/3753 [29:39<3:57:19,  4.26s/it] 11%|█         | 410/3753 [29:43<4:00:18,  4.31s/it]{'loss': 10.9633, 'grad_norm': 179.88282775878906, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.5078110694885254, 'weight_rejected': 0.28776782751083374, 'kl_term_chosen': -1.8609046936035156, 'epoch': 0.10926049300466356}
                                                    {'loss': 10.9633, 'grad_norm': 179.88282775878906, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.5078110694885254, 'weight_rejected': 0.28776782751083374, 'kl_term_chosen': -1.8609046936035156, 'epoch': 0.11}
 11%|█         | 410/3753 [29:43<4:00:18,  4.31s/it] 11%|█         | 411/3753 [29:48<4:09:30,  4.48s/it] 11%|█         | 412/3753 [29:52<3:59:54,  4.31s/it] 11%|█         | 413/3753 [29:58<4:19:28,  4.66s/it] 11%|█         | 414/3753 [30:03<4:23:55,  4.74s/it] 11%|█         | 415/3753 [30:07<4:11:22,  4.52s/it] 11%|█         | 416/3753 [30:11<4:08:39,  4.47s/it] 11%|█         | 417/3753 [30:15<4:00:01,  4.32s/it] 11%|█         | 418/3753 [30:19<3:53:30,  4.20s/it] 11%|█         | 419/3753 [30:23<3:51:30,  4.17s/it] 11%|█         | 420/3753 [30:27<3:43:57,  4.03s/it]{'loss': 6.7723, 'grad_norm': 413.50579833984375, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.06210994720459, 'weight_rejected': 0.2727987766265869, 'kl_term_chosen': -2.410755157470703, 'epoch': 0.11192538307794804}
                                                    {'loss': 6.7723, 'grad_norm': 413.50579833984375, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.06210994720459, 'weight_rejected': 0.2727987766265869, 'kl_term_chosen': -2.410755157470703, 'epoch': 0.11}
 11%|█         | 420/3753 [30:27<3:43:57,  4.03s/it] 11%|█         | 421/3753 [30:31<3:51:40,  4.17s/it] 11%|█         | 422/3753 [30:35<3:50:51,  4.16s/it] 11%|█▏        | 423/3753 [30:39<3:45:08,  4.06s/it] 11%|█▏        | 424/3753 [30:42<3:31:03,  3.80s/it] 11%|█▏        | 425/3753 [30:46<3:37:43,  3.93s/it] 11%|█▏        | 426/3753 [30:51<3:45:28,  4.07s/it] 11%|█▏        | 427/3753 [30:55<3:51:37,  4.18s/it] 11%|█▏        | 428/3753 [31:00<3:56:59,  4.28s/it] 11%|█▏        | 429/3753 [31:04<3:53:00,  4.21s/it] 11%|█▏        | 430/3753 [31:09<4:02:06,  4.37s/it]{'loss': 11.0429, 'grad_norm': 421.3566589355469, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.36189427971839905, 'weight_chosen': 3.1070446968078613, 'weight_rejected': 0.27125170826911926, 'kl_term_chosen': -2.543426513671875, 'epoch': 0.1145902731512325}
                                                    {'loss': 11.0429, 'grad_norm': 421.3566589355469, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.36189427971839905, 'weight_chosen': 3.1070446968078613, 'weight_rejected': 0.27125170826911926, 'kl_term_chosen': -2.543426513671875, 'epoch': 0.11}
 11%|█▏        | 430/3753 [31:09<4:02:06,  4.37s/it] 11%|█▏        | 431/3753 [31:12<3:50:13,  4.16s/it] 12%|█▏        | 432/3753 [31:18<4:20:19,  4.70s/it] 12%|█▏        | 433/3753 [31:22<4:07:29,  4.47s/it] 12%|█▏        | 434/3753 [31:26<3:57:34,  4.29s/it] 12%|█▏        | 435/3753 [31:30<3:50:51,  4.17s/it] 12%|█▏        | 436/3753 [31:34<3:53:25,  4.22s/it] 12%|█▏        | 437/3753 [31:38<3:50:30,  4.17s/it] 12%|█▏        | 438/3753 [31:43<4:03:59,  4.42s/it] 12%|█▏        | 439/3753 [31:48<4:00:03,  4.35s/it] 12%|█▏        | 440/3753 [31:52<3:56:04,  4.28s/it]{'loss': 20.2821, 'grad_norm': 172.7850799560547, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.29427719116211, 'weight_rejected': 0.048136770725250244, 'kl_term_chosen': 9.248924255371094, 'epoch': 0.11725516322451698}
                                                    {'loss': 20.2821, 'grad_norm': 172.7850799560547, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.29427719116211, 'weight_rejected': 0.048136770725250244, 'kl_term_chosen': 9.248924255371094, 'epoch': 0.12}
 12%|█▏        | 440/3753 [31:52<3:56:04,  4.28s/it] 12%|█▏        | 441/3753 [31:56<4:00:01,  4.35s/it] 12%|█▏        | 442/3753 [32:00<3:59:59,  4.35s/it] 12%|█▏        | 443/3753 [32:03<3:30:26,  3.81s/it] 12%|█▏        | 444/3753 [32:08<3:48:47,  4.15s/it] 12%|█▏        | 445/3753 [32:11<3:37:57,  3.95s/it] 12%|█▏        | 446/3753 [32:16<3:49:33,  4.16s/it] 12%|█▏        | 447/3753 [32:21<3:52:47,  4.23s/it] 12%|█▏        | 448/3753 [32:24<3:38:31,  3.97s/it] 12%|█▏        | 449/3753 [32:29<3:52:07,  4.22s/it] 12%|█▏        | 450/3753 [32:33<3:52:09,  4.22s/it]{'loss': 45.6763, 'grad_norm': 1211.9871826171875, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.830880165100098, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 6.724189758300781, 'epoch': 0.11992005329780146}
                                                    {'loss': 45.6763, 'grad_norm': 1211.9871826171875, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.830880165100098, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 6.724189758300781, 'epoch': 0.12}
 12%|█▏        | 450/3753 [32:33<3:52:09,  4.22s/it] 12%|█▏        | 451/3753 [32:37<3:53:41,  4.25s/it] 12%|█▏        | 452/3753 [32:42<4:04:39,  4.45s/it] 12%|█▏        | 453/3753 [32:46<3:50:45,  4.20s/it] 12%|█▏        | 454/3753 [32:51<4:11:44,  4.58s/it] 12%|█▏        | 455/3753 [32:55<4:04:49,  4.45s/it] 12%|█▏        | 456/3753 [33:00<4:11:27,  4.58s/it] 12%|█▏        | 457/3753 [33:04<4:03:13,  4.43s/it] 12%|█▏        | 458/3753 [33:08<3:55:21,  4.29s/it] 12%|█▏        | 459/3753 [33:13<3:56:15,  4.30s/it] 12%|█▏        | 460/3753 [33:18<4:16:08,  4.67s/it]{'loss': 23.297, 'grad_norm': 1045.7406005859375, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.2989275455474854, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': -1.3804473876953125, 'epoch': 0.12258494337108594}
                                                    {'loss': 23.297, 'grad_norm': 1045.7406005859375, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.2989275455474854, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': -1.3804473876953125, 'epoch': 0.12}
 12%|█▏        | 460/3753 [33:18<4:16:08,  4.67s/it] 12%|█▏        | 461/3753 [33:22<3:56:54,  4.32s/it] 12%|█▏        | 462/3753 [33:24<3:31:49,  3.86s/it] 12%|█▏        | 463/3753 [33:29<3:41:05,  4.03s/it] 12%|█▏        | 464/3753 [33:33<3:43:16,  4.07s/it] 12%|█▏        | 465/3753 [33:37<3:41:58,  4.05s/it] 12%|█▏        | 466/3753 [33:41<3:47:10,  4.15s/it] 12%|█▏        | 467/3753 [33:46<3:48:20,  4.17s/it] 12%|█▏        | 468/3753 [33:51<4:00:14,  4.39s/it] 12%|█▏        | 469/3753 [33:56<4:16:56,  4.69s/it] 13%|█▎        | 470/3753 [34:02<4:32:43,  4.98s/it]{'loss': 5.9281, 'grad_norm': 751.1595458984375, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.9756648540496826, 'weight_rejected': 0.08151976019144058, 'kl_term_chosen': -2.030670166015625, 'epoch': 0.1252498334443704}
                                                    {'loss': 5.9281, 'grad_norm': 751.1595458984375, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.9756648540496826, 'weight_rejected': 0.08151976019144058, 'kl_term_chosen': -2.030670166015625, 'epoch': 0.13}
 13%|█▎        | 470/3753 [34:02<4:32:43,  4.98s/it] 13%|█▎        | 471/3753 [34:07<4:44:43,  5.21s/it] 13%|█▎        | 472/3753 [34:11<4:17:02,  4.70s/it] 13%|█▎        | 473/3753 [34:14<3:45:58,  4.13s/it] 13%|█▎        | 474/3753 [34:18<3:52:49,  4.26s/it] 13%|█▎        | 475/3753 [34:23<3:57:14,  4.34s/it] 13%|█▎        | 476/3753 [34:27<3:51:59,  4.25s/it] 13%|█▎        | 477/3753 [34:31<3:52:50,  4.26s/it] 13%|█▎        | 478/3753 [34:35<3:46:33,  4.15s/it] 13%|█▎        | 479/3753 [34:40<4:09:13,  4.57s/it] 13%|█▎        | 480/3753 [34:45<4:12:53,  4.64s/it]{'loss': 11.1706, 'grad_norm': 251.6110076904297, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.711799621582031, 'weight_rejected': 0.23792988061904907, 'kl_term_chosen': -4.135257720947266, 'epoch': 0.1279147235176549}
                                                    {'loss': 11.1706, 'grad_norm': 251.6110076904297, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.711799621582031, 'weight_rejected': 0.23792988061904907, 'kl_term_chosen': -4.135257720947266, 'epoch': 0.13}
 13%|█▎        | 480/3753 [34:45<4:12:53,  4.64s/it] 13%|█▎        | 481/3753 [34:50<4:17:59,  4.73s/it] 13%|█▎        | 482/3753 [34:54<4:02:55,  4.46s/it] 13%|█▎        | 483/3753 [34:58<3:53:13,  4.28s/it] 13%|█▎        | 484/3753 [35:02<3:46:00,  4.15s/it] 13%|█▎        | 485/3753 [35:06<3:40:30,  4.05s/it] 13%|█▎        | 486/3753 [35:10<3:49:47,  4.22s/it] 13%|█▎        | 487/3753 [35:15<4:01:09,  4.43s/it] 13%|█▎        | 488/3753 [35:19<3:46:46,  4.17s/it] 13%|█▎        | 489/3753 [35:23<3:56:20,  4.34s/it] 13%|█▎        | 490/3753 [35:29<4:10:05,  4.60s/it]{'loss': 16.5048, 'grad_norm': 510.92449951171875, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -4.63083553314209, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': 5.57501220703125, 'epoch': 0.13057961359093936}
                                                    {'loss': 16.5048, 'grad_norm': 510.92449951171875, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -4.63083553314209, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': 5.57501220703125, 'epoch': 0.13}
 13%|█▎        | 490/3753 [35:29<4:10:05,  4.60s/it] 13%|█▎        | 491/3753 [35:34<4:18:05,  4.75s/it] 13%|█▎        | 492/3753 [35:37<4:01:59,  4.45s/it] 13%|█▎        | 493/3753 [35:45<4:46:49,  5.28s/it] 13%|█▎        | 494/3753 [35:48<4:22:21,  4.83s/it] 13%|█▎        | 495/3753 [35:52<3:58:01,  4.38s/it] 13%|█▎        | 496/3753 [35:57<4:05:38,  4.53s/it] 13%|█▎        | 497/3753 [36:01<3:54:37,  4.32s/it] 13%|█▎        | 498/3753 [36:06<4:07:37,  4.56s/it] 13%|█▎        | 499/3753 [36:11<4:21:58,  4.83s/it] 13%|█▎        | 500/3753 [36:16<4:17:47,  4.75s/it]{'loss': 28.6305, 'grad_norm': 153.68621826171875, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.48953914642334, 'weight_rejected': 0.22270013391971588, 'kl_term_chosen': -10.84710693359375, 'epoch': 0.13324450366422386}
                                                    {'loss': 28.6305, 'grad_norm': 153.68621826171875, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.48953914642334, 'weight_rejected': 0.22270013391971588, 'kl_term_chosen': -10.84710693359375, 'epoch': 0.13}
 13%|█▎        | 500/3753 [36:16<4:17:47,  4.75s/it] 13%|█▎        | 501/3753 [36:20<4:12:22,  4.66s/it] 13%|█▎        | 502/3753 [36:25<4:16:24,  4.73s/it] 13%|█▎        | 503/3753 [36:29<4:09:26,  4.61s/it] 13%|█▎        | 504/3753 [36:33<3:55:01,  4.34s/it] 13%|█▎        | 505/3753 [36:37<3:46:44,  4.19s/it] 13%|█▎        | 506/3753 [36:41<3:41:32,  4.09s/it] 14%|█▎        | 507/3753 [36:46<3:55:14,  4.35s/it] 14%|█▎        | 508/3753 [36:51<4:08:29,  4.59s/it] 14%|█▎        | 509/3753 [36:55<3:58:10,  4.41s/it] 14%|█▎        | 510/3753 [36:59<4:00:28,  4.45s/it]{'loss': 29.5942, 'grad_norm': 1514.5062255859375, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.514132499694824, 'weight_rejected': 0.03358950838446617, 'kl_term_chosen': -5.5581512451171875, 'epoch': 0.13590939373750832}
                                                    {'loss': 29.5942, 'grad_norm': 1514.5062255859375, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.514132499694824, 'weight_rejected': 0.03358950838446617, 'kl_term_chosen': -5.5581512451171875, 'epoch': 0.14}
 14%|█▎        | 510/3753 [36:59<4:00:28,  4.45s/it] 14%|█▎        | 511/3753 [37:04<4:00:16,  4.45s/it] 14%|█▎        | 512/3753 [37:08<3:47:54,  4.22s/it] 14%|█▎        | 513/3753 [37:12<3:56:26,  4.38s/it] 14%|█▎        | 514/3753 [37:17<4:03:21,  4.51s/it] 14%|█▎        | 515/3753 [37:22<4:11:52,  4.67s/it] 14%|█▎        | 516/3753 [37:26<4:06:17,  4.57s/it] 14%|█▍        | 517/3753 [37:30<3:52:09,  4.30s/it] 14%|█▍        | 518/3753 [37:34<3:45:30,  4.18s/it] 14%|█▍        | 519/3753 [37:39<3:59:16,  4.44s/it] 14%|█▍        | 520/3753 [37:44<4:12:45,  4.69s/it]{'loss': 7.7384, 'grad_norm': 1039.03271484375, 'learning_rate': 9.955821687527552e-07, 'mean_ratio_chosen': 0.5343189239501953, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.2364203929901123, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': -0.3133811950683594, 'epoch': 0.13857428381079281}
                                                    {'loss': 7.7384, 'grad_norm': 1039.03271484375, 'learning_rate': 9.955821687527552e-07, 'mean_ratio_chosen': 0.5343189239501953, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.2364203929901123, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': -0.3133811950683594, 'epoch': 0.14}
 14%|█▍        | 520/3753 [37:44<4:12:45,  4.69s/it] 14%|█▍        | 521/3753 [37:49<4:06:52,  4.58s/it] 14%|█▍        | 522/3753 [37:53<4:05:58,  4.57s/it] 14%|█▍        | 523/3753 [37:58<4:13:44,  4.71s/it] 14%|█▍        | 524/3753 [38:03<4:11:48,  4.68s/it] 14%|█▍        | 525/3753 [38:07<4:00:05,  4.46s/it] 14%|█▍        | 526/3753 [38:10<3:39:41,  4.08s/it] 14%|█▍        | 527/3753 [38:14<3:34:07,  3.98s/it] 14%|█▍        | 528/3753 [38:18<3:45:14,  4.19s/it] 14%|█▍        | 529/3753 [38:22<3:35:09,  4.00s/it] 14%|█▍        | 530/3753 [38:26<3:37:23,  4.05s/it]{'loss': 11.4366, 'grad_norm': 699.5916137695312, 'learning_rate': 9.94943765952491e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 14.29202651977539, 'weight_rejected': 0.332852303981781, 'kl_term_chosen': -13.856124877929688, 'epoch': 0.14123917388407728}
                                                    {'loss': 11.4366, 'grad_norm': 699.5916137695312, 'learning_rate': 9.94943765952491e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 14.29202651977539, 'weight_rejected': 0.332852303981781, 'kl_term_chosen': -13.856124877929688, 'epoch': 0.14}
 14%|█▍        | 530/3753 [38:26<3:37:23,  4.05s/it] 14%|█▍        | 531/3753 [38:30<3:27:08,  3.86s/it] 14%|█▍        | 532/3753 [38:34<3:38:58,  4.08s/it] 14%|█▍        | 533/3753 [38:39<3:47:18,  4.24s/it] 14%|█▍        | 534/3753 [38:42<3:37:09,  4.05s/it] 14%|█▍        | 535/3753 [38:47<3:45:19,  4.20s/it] 14%|█▍        | 536/3753 [38:51<3:50:39,  4.30s/it] 14%|█▍        | 537/3753 [38:56<4:00:02,  4.48s/it] 14%|█▍        | 538/3753 [39:00<3:42:21,  4.15s/it] 14%|█▍        | 539/3753 [39:03<3:31:06,  3.94s/it] 14%|█▍        | 540/3753 [39:06<3:19:05,  3.72s/it]{'loss': 20.5748, 'grad_norm': 610.494140625, 'learning_rate': 9.942625289827702e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.8760159015655518, 'weight_chosen': -4.176331520080566, 'weight_rejected': 0.1233656257390976, 'kl_term_chosen': 5.104740142822266, 'epoch': 0.14390406395736177}
                                                    {'loss': 20.5748, 'grad_norm': 610.494140625, 'learning_rate': 9.942625289827702e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.8760159015655518, 'weight_chosen': -4.176331520080566, 'weight_rejected': 0.1233656257390976, 'kl_term_chosen': 5.104740142822266, 'epoch': 0.14}
 14%|█▍        | 540/3753 [39:06<3:19:05,  3.72s/it] 14%|█▍        | 541/3753 [39:10<3:20:27,  3.74s/it] 14%|█▍        | 542/3753 [39:14<3:23:28,  3.80s/it] 14%|█▍        | 543/3753 [39:17<3:14:42,  3.64s/it] 14%|█▍        | 544/3753 [39:22<3:29:29,  3.92s/it] 15%|█▍        | 545/3753 [39:26<3:28:26,  3.90s/it] 15%|█▍        | 546/3753 [39:29<3:24:03,  3.82s/it] 15%|█▍        | 547/3753 [39:34<3:35:08,  4.03s/it] 15%|█▍        | 548/3753 [39:40<4:04:21,  4.57s/it] 15%|█▍        | 549/3753 [39:44<3:52:29,  4.35s/it] 15%|█▍        | 550/3753 [39:49<4:02:45,  4.55s/it]{'loss': 32.2468, 'grad_norm': 699.7396240234375, 'learning_rate': 9.935385168002298e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -15.892984390258789, 'weight_rejected': 0.07585817575454712, 'kl_term_chosen': 16.829269409179688, 'epoch': 0.14656895403064624}
                                                    {'loss': 32.2468, 'grad_norm': 699.7396240234375, 'learning_rate': 9.935385168002298e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -15.892984390258789, 'weight_rejected': 0.07585817575454712, 'kl_term_chosen': 16.829269409179688, 'epoch': 0.15}
 15%|█▍        | 550/3753 [39:49<4:02:45,  4.55s/it] 15%|█▍        | 551/3753 [39:53<4:00:56,  4.51s/it] 15%|█▍        | 552/3753 [39:57<3:44:31,  4.21s/it] 15%|█▍        | 553/3753 [40:00<3:39:32,  4.12s/it] 15%|█▍        | 554/3753 [40:05<3:46:08,  4.24s/it] 15%|█▍        | 555/3753 [40:09<3:49:20,  4.30s/it] 15%|█▍        | 556/3753 [40:13<3:43:22,  4.19s/it] 15%|█▍        | 557/3753 [40:18<3:51:25,  4.34s/it] 15%|█▍        | 558/3753 [40:22<3:48:54,  4.30s/it] 15%|█▍        | 559/3753 [40:26<3:46:20,  4.25s/it] 15%|█▍        | 560/3753 [40:30<3:40:58,  4.15s/it]{'loss': 25.5497, 'grad_norm': 166.82603454589844, 'learning_rate': 9.927717920634233e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.731808662414551, 'weight_rejected': 0.18713268637657166, 'kl_term_chosen': 7.6101226806640625, 'epoch': 0.1492338441039307}
                                                    {'loss': 25.5497, 'grad_norm': 166.82603454589844, 'learning_rate': 9.927717920634233e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.731808662414551, 'weight_rejected': 0.18713268637657166, 'kl_term_chosen': 7.6101226806640625, 'epoch': 0.15}
 15%|█▍        | 560/3753 [40:30<3:40:58,  4.15s/it] 15%|█▍        | 561/3753 [40:34<3:32:46,  4.00s/it] 15%|█▍        | 562/3753 [40:39<3:47:17,  4.27s/it] 15%|█▌        | 563/3753 [40:43<3:47:55,  4.29s/it] 15%|█▌        | 564/3753 [40:47<3:43:22,  4.20s/it] 15%|█▌        | 565/3753 [40:52<3:53:56,  4.40s/it] 15%|█▌        | 566/3753 [40:57<3:54:38,  4.42s/it] 15%|█▌        | 567/3753 [41:01<3:58:38,  4.49s/it] 15%|█▌        | 568/3753 [41:06<4:04:39,  4.61s/it] 15%|█▌        | 569/3753 [41:10<4:00:09,  4.53s/it] 15%|█▌        | 570/3753 [41:14<3:41:56,  4.18s/it]{'loss': 39.6283, 'grad_norm': 99.01322937011719, 'learning_rate': 9.919624211273986e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.336541086435318, 'weight_chosen': -3.762908935546875, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': 4.7335968017578125, 'epoch': 0.1518987341772152}
                                                    {'loss': 39.6283, 'grad_norm': 99.01322937011719, 'learning_rate': 9.919624211273986e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.336541086435318, 'weight_chosen': -3.762908935546875, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': 4.7335968017578125, 'epoch': 0.15}
 15%|█▌        | 570/3753 [41:14<3:41:56,  4.18s/it] 15%|█▌        | 571/3753 [41:19<3:58:23,  4.50s/it] 15%|█▌        | 572/3753 [41:22<3:40:59,  4.17s/it] 15%|█▌        | 573/3753 [41:26<3:33:56,  4.04s/it] 15%|█▌        | 574/3753 [41:30<3:35:26,  4.07s/it] 15%|█▌        | 575/3753 [41:35<3:51:11,  4.36s/it] 15%|█▌        | 576/3753 [41:40<3:51:37,  4.37s/it] 15%|█▌        | 577/3753 [41:45<3:57:27,  4.49s/it] 15%|█▌        | 578/3753 [41:49<3:55:00,  4.44s/it] 15%|█▌        | 579/3753 [41:52<3:34:55,  4.06s/it] 15%|█▌        | 580/3753 [41:57<3:43:12,  4.22s/it]{'loss': 66.9706, 'grad_norm': 887.4140014648438, 'learning_rate': 9.911104740379551e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 8.547762870788574, 'weight_rejected': 0.8499711751937866, 'kl_term_chosen': -8.438056945800781, 'epoch': 0.15456362425049966}
                                                    {'loss': 66.9706, 'grad_norm': 887.4140014648438, 'learning_rate': 9.911104740379551e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 8.547762870788574, 'weight_rejected': 0.8499711751937866, 'kl_term_chosen': -8.438056945800781, 'epoch': 0.15}
 15%|█▌        | 580/3753 [41:57<3:43:12,  4.22s/it] 15%|█▌        | 581/3753 [42:00<3:37:30,  4.11s/it] 16%|█▌        | 582/3753 [42:05<3:40:04,  4.16s/it] 16%|█▌        | 583/3753 [42:09<3:33:45,  4.05s/it] 16%|█▌        | 584/3753 [42:12<3:20:12,  3.79s/it] 16%|█▌        | 585/3753 [42:16<3:23:08,  3.85s/it] 16%|█▌        | 586/3753 [42:20<3:23:32,  3.86s/it] 16%|█▌        | 587/3753 [42:24<3:36:14,  4.10s/it] 16%|█▌        | 588/3753 [42:29<3:47:28,  4.31s/it] 16%|█▌        | 589/3753 [42:34<4:04:35,  4.64s/it] 16%|█▌        | 590/3753 [42:38<3:46:01,  4.29s/it]{'loss': 70.521, 'grad_norm': 360.4507751464844, 'learning_rate': 9.902160245255826e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -15.351737976074219, 'weight_rejected': 0.12592275440692902, 'kl_term_chosen': 16.225814819335938, 'epoch': 0.15722851432378415}
                                                    {'loss': 70.521, 'grad_norm': 360.4507751464844, 'learning_rate': 9.902160245255826e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -15.351737976074219, 'weight_rejected': 0.12592275440692902, 'kl_term_chosen': 16.225814819335938, 'epoch': 0.16}
 16%|█▌        | 590/3753 [42:38<3:46:01,  4.29s/it] 16%|█▌        | 591/3753 [42:42<3:48:29,  4.34s/it] 16%|█▌        | 592/3753 [42:46<3:39:33,  4.17s/it] 16%|█▌        | 593/3753 [42:52<4:00:51,  4.57s/it] 16%|█▌        | 594/3753 [42:56<3:55:13,  4.47s/it] 16%|█▌        | 595/3753 [42:59<3:36:15,  4.11s/it] 16%|█▌        | 596/3753 [43:03<3:33:56,  4.07s/it] 16%|█▌        | 597/3753 [43:07<3:30:28,  4.00s/it] 16%|█▌        | 598/3753 [43:11<3:35:22,  4.10s/it] 16%|█▌        | 599/3753 [43:16<3:47:22,  4.33s/it] 16%|█▌        | 600/3753 [43:21<3:58:34,  4.54s/it]{'loss': 41.3144, 'grad_norm': 596.8921508789062, 'learning_rate': 9.892791499990784e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.5729968547821045, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 4.5345306396484375, 'epoch': 0.15989340439706862}
                                                    {'loss': 41.3144, 'grad_norm': 596.8921508789062, 'learning_rate': 9.892791499990784e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.5729968547821045, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 4.5345306396484375, 'epoch': 0.16}
 16%|█▌        | 600/3753 [43:21<3:58:34,  4.54s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 16%|█▌        | 601/3753 [44:21<18:32:33, 21.18s/it] 16%|█▌        | 602/3753 [44:25<14:04:48, 16.09s/it] 16%|█▌        | 603/3753 [44:30<11:09:10, 12.75s/it] 16%|█▌        | 604/3753 [44:34<8:51:33, 10.13s/it]  16%|█▌        | 605/3753 [44:38<7:15:34,  8.30s/it] 16%|█▌        | 606/3753 [44:43<6:11:24,  7.08s/it] 16%|█▌        | 607/3753 [44:46<5:10:46,  5.93s/it] 16%|█▌        | 608/3753 [44:50<4:42:30,  5.39s/it] 16%|█▌        | 609/3753 [44:55<4:36:05,  5.27s/it] 16%|█▋        | 610/3753 [44:58<4:06:09,  4.70s/it]{'loss': 9.7087, 'grad_norm': 801.8839721679688, 'learning_rate': 9.882999315388504e-07, 'mean_ratio_chosen': 0.15849119424819946, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.758648157119751, 'weight_rejected': 0.14033624529838562, 'kl_term_chosen': -0.9210281372070312, 'epoch': 0.1625582944703531}
                                                    {'loss': 9.7087, 'grad_norm': 801.8839721679688, 'learning_rate': 9.882999315388504e-07, 'mean_ratio_chosen': 0.15849119424819946, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.758648157119751, 'weight_rejected': 0.14033624529838562, 'kl_term_chosen': -0.9210281372070312, 'epoch': 0.16}
 16%|█▋        | 610/3753 [44:58<4:06:09,  4.70s/it] 16%|█▋        | 611/3753 [45:01<3:40:04,  4.20s/it] 16%|█▋        | 612/3753 [45:07<4:03:58,  4.66s/it] 16%|█▋        | 613/3753 [45:11<3:44:19,  4.29s/it] 16%|█▋        | 614/3753 [45:16<4:02:57,  4.64s/it] 16%|█▋        | 615/3753 [45:20<3:54:27,  4.48s/it] 16%|█▋        | 616/3753 [45:25<3:54:00,  4.48s/it] 16%|█▋        | 617/3753 [45:28<3:44:29,  4.30s/it] 16%|█▋        | 618/3753 [45:32<3:31:28,  4.05s/it] 16%|█▋        | 619/3753 [45:35<3:14:14,  3.72s/it] 17%|█▋        | 620/3753 [45:41<3:48:48,  4.38s/it]{'loss': 35.3477, 'grad_norm': 139.2036895751953, 'learning_rate': 9.872784538898985e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.3890700340270996, 'weight_rejected': 0.46295860409736633, 'kl_term_chosen': 2.7297744750976562, 'epoch': 0.16522318454363757}
                                                    {'loss': 35.3477, 'grad_norm': 139.2036895751953, 'learning_rate': 9.872784538898985e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -2.3890700340270996, 'weight_rejected': 0.46295860409736633, 'kl_term_chosen': 2.7297744750976562, 'epoch': 0.17}
 17%|█▋        | 620/3753 [45:41<3:48:48,  4.38s/it] 17%|█▋        | 621/3753 [45:46<3:58:13,  4.56s/it] 17%|█▋        | 622/3753 [45:49<3:43:33,  4.28s/it] 17%|█▋        | 623/3753 [45:53<3:36:44,  4.15s/it] 17%|█▋        | 624/3753 [45:57<3:37:02,  4.16s/it] 17%|█▋        | 625/3753 [46:01<3:32:27,  4.08s/it] 17%|█▋        | 626/3753 [46:05<3:32:30,  4.08s/it] 17%|█▋        | 627/3753 [46:10<3:46:28,  4.35s/it] 17%|█▋        | 628/3753 [46:15<3:51:55,  4.45s/it] 17%|█▋        | 629/3753 [46:20<3:56:09,  4.54s/it] 17%|█▋        | 630/3753 [46:24<3:56:06,  4.54s/it]{'loss': 41.2188, 'grad_norm': 705.7044067382812, 'learning_rate': 9.86214805454481e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.5809962749481201, 'weight_rejected': 0.14033624529838562, 'kl_term_chosen': -1.4712905883789062, 'epoch': 0.16788807461692204}
                                                    {'loss': 41.2188, 'grad_norm': 705.7044067382812, 'learning_rate': 9.86214805454481e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.5809962749481201, 'weight_rejected': 0.14033624529838562, 'kl_term_chosen': -1.4712905883789062, 'epoch': 0.17}
 17%|█▋        | 630/3753 [46:25<3:56:06,  4.54s/it] 17%|█▋        | 631/3753 [46:29<3:59:48,  4.61s/it] 17%|█▋        | 632/3753 [46:33<3:49:38,  4.41s/it] 17%|█▋        | 633/3753 [46:38<4:01:24,  4.64s/it] 17%|█▋        | 634/3753 [46:43<4:00:22,  4.62s/it] 17%|█▋        | 635/3753 [46:46<3:43:16,  4.30s/it] 17%|█▋        | 636/3753 [46:51<3:42:56,  4.29s/it] 17%|█▋        | 637/3753 [46:55<3:35:47,  4.16s/it] 17%|█▋        | 638/3753 [46:58<3:28:07,  4.01s/it] 17%|█▋        | 639/3753 [47:04<4:00:04,  4.63s/it] 17%|█▋        | 640/3753 [47:08<3:51:39,  4.46s/it]{'loss': 19.5013, 'grad_norm': 963.720703125, 'learning_rate': 9.851090782844644e-07, 'mean_ratio_chosen': 9.22203540802002, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.16745030879974365, 'weight_rejected': 0.07696083933115005, 'kl_term_chosen': 1.1107978820800781, 'epoch': 0.17055296469020653}
                                                    {'loss': 19.5013, 'grad_norm': 963.720703125, 'learning_rate': 9.851090782844644e-07, 'mean_ratio_chosen': 9.22203540802002, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.16745030879974365, 'weight_rejected': 0.07696083933115005, 'kl_term_chosen': 1.1107978820800781, 'epoch': 0.17}
 17%|█▋        | 640/3753 [47:08<3:51:39,  4.46s/it] 17%|█▋        | 641/3753 [47:13<3:53:08,  4.50s/it] 17%|█▋        | 642/3753 [47:18<4:01:46,  4.66s/it] 17%|█▋        | 643/3753 [47:22<3:57:33,  4.58s/it] 17%|█▋        | 644/3753 [47:27<3:51:25,  4.47s/it] 17%|█▋        | 645/3753 [47:31<3:51:21,  4.47s/it] 17%|█▋        | 646/3753 [47:35<3:40:23,  4.26s/it] 17%|█▋        | 647/3753 [47:39<3:36:47,  4.19s/it] 17%|█▋        | 648/3753 [47:42<3:17:28,  3.82s/it] 17%|█▋        | 649/3753 [47:46<3:26:34,  3.99s/it] 17%|█▋        | 650/3753 [47:50<3:21:45,  3.90s/it]{'loss': 10.2842, 'grad_norm': 0.0, 'learning_rate': 9.839613680733559e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 22.711933135986328, 'weight_rejected': 0.33982762694358826, 'kl_term_chosen': -21.958465576171875, 'epoch': 0.173217854763491}
                                                    {'loss': 10.2842, 'grad_norm': 0.0, 'learning_rate': 9.839613680733559e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 22.711933135986328, 'weight_rejected': 0.33982762694358826, 'kl_term_chosen': -21.958465576171875, 'epoch': 0.17}
 17%|█▋        | 650/3753 [47:50<3:21:45,  3.90s/it] 17%|█▋        | 651/3753 [47:56<3:55:49,  4.56s/it] 17%|█▋        | 652/3753 [48:00<3:47:31,  4.40s/it] 17%|█▋        | 653/3753 [48:05<3:53:10,  4.51s/it] 17%|█▋        | 654/3753 [48:11<4:22:06,  5.07s/it]