nohup: ignoring input
[W1105 06:59:40.933059287 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
从磁盘加载数据集...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 91.86it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 90.46it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 91.24it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.90it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 91.40it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 90.95it/s]
[W1105 06:59:48.113680965 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 92.85it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.11it/s]
[W1105 06:59:48.140373159 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1105 06:59:48.162037161 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1105 06:59:48.165901632 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
WARNING:accelerate.utils.other:Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /wandb/offline-run-20251105_065957-vfssiy2g
  0%|          | 0/3753 [00:00<?, ?it/s]--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -199.0
Sample 0 - pi_logp_chosen:  -198.81076049804688
Sample 0 - Difference (pi - ref): 0.189239501953125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -100.5
Sample 0 - pi_logp_chosen:  -100.34402465820312
Sample 0 - Difference (pi - ref): 0.155975341796875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -122.0
Sample 0 - pi_logp_chosen:  -121.57272338867188
Sample 0 - Difference (pi - ref): 0.427276611328125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -234.0
Sample 0 - pi_logp_chosen:  -233.57894897460938
Sample 0 - Difference (pi - ref): 0.421051025390625
---------------------------------
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -227.0
Sample 0 - pi_logp_chosen:  -227.50088500976562
Sample 0 - Difference (pi - ref): -0.500885009765625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -248.0
Sample 0 - pi_logp_chosen:  -248.47735595703125
Sample 0 - Difference (pi - ref): -0.47735595703125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -209.0
Sample 0 - pi_logp_chosen:  -208.26136779785156
Sample 0 - Difference (pi - ref): 0.7386322021484375
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -728.0
Sample 0 - pi_logp_chosen:  -730.50390625
Sample 0 - Difference (pi - ref): -2.50390625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -240.0
Sample 0 - pi_logp_chosen:  -240.2412567138672
Sample 0 - Difference (pi - ref): -0.2412567138671875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -253.0
Sample 0 - pi_logp_chosen:  -253.00314331054688
Sample 0 - Difference (pi - ref): -0.003143310546875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -350.0
Sample 0 - pi_logp_chosen:  -349.3069152832031
Sample 0 - Difference (pi - ref): 0.693084716796875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -452.0
Sample 0 - pi_logp_chosen:  -453.64239501953125
Sample 0 - Difference (pi - ref): -1.64239501953125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -127.5
Sample 0 - pi_logp_chosen:  -127.59747314453125
Sample 0 - Difference (pi - ref): -0.09747314453125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -98.5
Sample 0 - pi_logp_chosen:  -98.78225708007812
Sample 0 - Difference (pi - ref): -0.282257080078125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -251.0
Sample 0 - pi_logp_chosen:  -249.6898956298828
Sample 0 - Difference (pi - ref): 1.3101043701171875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -516.0
Sample 0 - pi_logp_chosen:  -514.2531127929688
Sample 0 - Difference (pi - ref): 1.74688720703125
---------------------------------
  0%|          | 1/3753 [00:04<4:55:39,  4.73s/it]{'loss': 0.7762, 'grad_norm': 9654.1123046875, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 6.590037822723389, 'weight_chosen': 0.2668696641921997, 'weight_rejected': 0.9874604344367981, 'kl_term_chosen': 0.6550521850585938, 'epoch': 0.0002664890073284477}
                                                  {'loss': 0.7762, 'grad_norm': 9654.1123046875, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 6.590037822723389, 'weight_chosen': 0.2668696641921997, 'weight_rejected': 0.9874604344367981, 'kl_term_chosen': 0.6550521850585938, 'epoch': 0.0}
  0%|          | 1/3753 [00:04<4:55:39,  4.73s/it]  0%|          | 2/3753 [00:10<5:15:55,  5.05s/it]  0%|          | 3/3753 [00:14<5:05:54,  4.89s/it]  0%|          | 4/3753 [00:18<4:42:08,  4.52s/it]  0%|          | 5/3753 [00:22<4:30:12,  4.33s/it]  0%|          | 6/3753 [00:27<4:43:21,  4.54s/it]  0%|          | 7/3753 [00:31<4:35:42,  4.42s/it]  0%|          | 8/3753 [00:36<4:41:39,  4.51s/it]  0%|          | 9/3753 [00:40<4:41:33,  4.51s/it]  0%|          | 10/3753 [00:44<4:21:51,  4.20s/it]{'loss': 0.2225, 'grad_norm': 2530.68212890625, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 0.8426885604858398, 'mean_ratio_rejected': 2.5861358642578125, 'weight_chosen': 0.33066391944885254, 'weight_rejected': 0.891404390335083, 'kl_term_chosen': -0.08557891845703125, 'epoch': 0.002664890073284477}
                                                   {'loss': 0.2225, 'grad_norm': 2530.68212890625, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 0.8426885604858398, 'mean_ratio_rejected': 2.5861358642578125, 'weight_chosen': 0.33066391944885254, 'weight_rejected': 0.891404390335083, 'kl_term_chosen': -0.08557891845703125, 'epoch': 0.0}
  0%|          | 10/3753 [00:44<4:21:51,  4.20s/it]  0%|          | 11/3753 [00:48<4:23:33,  4.23s/it]  0%|          | 12/3753 [00:53<4:35:01,  4.41s/it]  0%|          | 13/3753 [00:57<4:33:03,  4.38s/it]  0%|          | 14/3753 [01:01<4:26:50,  4.28s/it]  0%|          | 15/3753 [01:05<4:16:48,  4.12s/it]  0%|          | 16/3753 [01:09<4:05:07,  3.94s/it]  0%|          | 17/3753 [01:13<4:09:38,  4.01s/it]  0%|          | 18/3753 [01:18<4:31:53,  4.37s/it]  1%|          | 19/3753 [01:21<4:12:43,  4.06s/it]  1%|          | 20/3753 [01:25<4:09:04,  4.00s/it]{'loss': 0.3229, 'grad_norm': 2139.438232421875, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 1.038285732269287, 'mean_ratio_rejected': 0.8499038815498352, 'weight_chosen': 0.7138063311576843, 'weight_rejected': 0.21533825993537903, 'kl_term_chosen': 0.018785476684570312, 'epoch': 0.005329780146568954}
                                                   {'loss': 0.3229, 'grad_norm': 2139.438232421875, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 1.038285732269287, 'mean_ratio_rejected': 0.8499038815498352, 'weight_chosen': 0.7138063311576843, 'weight_rejected': 0.21533825993537903, 'kl_term_chosen': 0.018785476684570312, 'epoch': 0.01}
  1%|          | 20/3753 [01:25<4:09:04,  4.00s/it]  1%|          | 21/3753 [01:29<4:08:37,  4.00s/it]  1%|          | 22/3753 [01:37<5:12:31,  5.03s/it]  1%|          | 23/3753 [01:42<5:10:06,  4.99s/it]  1%|          | 24/3753 [01:45<4:38:27,  4.48s/it]  1%|          | 25/3753 [01:49<4:33:39,  4.40s/it]  1%|          | 26/3753 [01:52<4:12:16,  4.06s/it]  1%|          | 27/3753 [01:57<4:26:13,  4.29s/it]  1%|          | 28/3753 [02:01<4:12:46,  4.07s/it]  1%|          | 29/3753 [02:05<4:08:19,  4.00s/it]  1%|          | 30/3753 [02:09<4:11:18,  4.05s/it]{'loss': -0.005, 'grad_norm': 4133.22216796875, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 1.348576307296753, 'mean_ratio_rejected': 1.1570371389389038, 'weight_chosen': 0.4784265160560608, 'weight_rejected': 0.6717128157615662, 'kl_term_chosen': 0.14952468872070312, 'epoch': 0.007994670219853431}
                                                   {'loss': -0.005, 'grad_norm': 4133.22216796875, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 1.348576307296753, 'mean_ratio_rejected': 1.1570371389389038, 'weight_chosen': 0.4784265160560608, 'weight_rejected': 0.6717128157615662, 'kl_term_chosen': 0.14952468872070312, 'epoch': 0.01}
  1%|          | 30/3753 [02:09<4:11:18,  4.05s/it]  1%|          | 31/3753 [02:14<4:33:40,  4.41s/it]  1%|          | 32/3753 [02:18<4:16:48,  4.14s/it]  1%|          | 33/3753 [02:21<4:04:18,  3.94s/it]  1%|          | 34/3753 [02:28<4:52:57,  4.73s/it]  1%|          | 35/3753 [02:34<5:18:41,  5.14s/it]  1%|          | 36/3753 [02:40<5:46:07,  5.59s/it]  1%|          | 37/3753 [02:46<5:48:56,  5.63s/it]  1%|          | 38/3753 [02:50<5:21:57,  5.20s/it]  1%|          | 39/3753 [02:58<6:10:35,  5.99s/it]  1%|          | 40/3753 [03:02<5:33:30,  5.39s/it]{'loss': 0.9606, 'grad_norm': 12013.763671875, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 0.3604448735713959, 'mean_ratio_rejected': 1.4969804286956787, 'weight_chosen': 1.2680025100708008, 'weight_rejected': 0.3293776512145996, 'kl_term_chosen': -0.5102081298828125, 'epoch': 0.010659560293137908}
                                                   {'loss': 0.9606, 'grad_norm': 12013.763671875, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 0.3604448735713959, 'mean_ratio_rejected': 1.4969804286956787, 'weight_chosen': 1.2680025100708008, 'weight_rejected': 0.3293776512145996, 'kl_term_chosen': -0.5102081298828125, 'epoch': 0.01}
  1%|          | 40/3753 [03:02<5:33:30,  5.39s/it]  1%|          | 41/3753 [03:09<5:55:45,  5.75s/it]  1%|          | 42/3753 [03:12<5:05:11,  4.93s/it]  1%|          | 43/3753 [03:17<5:06:24,  4.96s/it]  1%|          | 44/3753 [03:21<4:50:00,  4.69s/it]  1%|          | 45/3753 [03:26<4:55:09,  4.78s/it]  1%|          | 46/3753 [03:31<4:58:46,  4.84s/it]  1%|▏         | 47/3753 [03:34<4:23:28,  4.27s/it]  1%|▏         | 48/3753 [03:38<4:19:15,  4.20s/it]  1%|▏         | 49/3753 [03:42<4:17:16,  4.17s/it]  1%|▏         | 50/3753 [03:45<4:05:52,  3.98s/it]{'loss': 0.2037, 'grad_norm': 2014.557861328125, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 4.7518439292907715, 'mean_ratio_rejected': 2.1618857383728027, 'weight_chosen': 0.08412528038024902, 'weight_rejected': 1.070597767829895, 'kl_term_chosen': 0.779266357421875, 'epoch': 0.013324450366422385}
                                                   {'loss': 0.2037, 'grad_norm': 2014.557861328125, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 4.7518439292907715, 'mean_ratio_rejected': 2.1618857383728027, 'weight_chosen': 0.08412528038024902, 'weight_rejected': 1.070597767829895, 'kl_term_chosen': 0.779266357421875, 'epoch': 0.01}
  1%|▏         | 50/3753 [03:45<4:05:52,  3.98s/it]  1%|▏         | 51/3753 [03:50<4:08:55,  4.03s/it]  1%|▏         | 52/3753 [03:55<4:30:48,  4.39s/it]  1%|▏         | 53/3753 [04:01<5:07:34,  4.99s/it]  1%|▏         | 54/3753 [04:05<4:39:48,  4.54s/it]  1%|▏         | 55/3753 [04:12<5:38:58,  5.50s/it]  1%|▏         | 56/3753 [04:20<6:16:19,  6.11s/it]  2%|▏         | 57/3753 [04:25<5:51:02,  5.70s/it]  2%|▏         | 58/3753 [04:28<5:09:42,  5.03s/it]  2%|▏         | 59/3753 [04:36<5:56:50,  5.80s/it]  2%|▏         | 60/3753 [04:39<5:08:04,  5.01s/it]{'loss': 0.3155, 'grad_norm': 3693.09912109375, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 0.9236042499542236, 'mean_ratio_rejected': 0.917245626449585, 'weight_chosen': 0.0699504017829895, 'weight_rejected': 0.8940207362174988, 'kl_term_chosen': -0.03973579406738281, 'epoch': 0.015989340439706862}
                                                   {'loss': 0.3155, 'grad_norm': 3693.09912109375, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 0.9236042499542236, 'mean_ratio_rejected': 0.917245626449585, 'weight_chosen': 0.0699504017829895, 'weight_rejected': 0.8940207362174988, 'kl_term_chosen': -0.03973579406738281, 'epoch': 0.02}
  2%|▏         | 60/3753 [04:39<5:08:04,  5.01s/it]  2%|▏         | 61/3753 [04:44<5:16:01,  5.14s/it]  2%|▏         | 62/3753 [04:49<5:11:30,  5.06s/it]  2%|▏         | 63/3753 [04:54<4:59:38,  4.87s/it]  2%|▏         | 64/3753 [04:59<5:06:28,  4.98s/it]  2%|▏         | 65/3753 [05:03<4:46:46,  4.67s/it]  2%|▏         | 66/3753 [05:07<4:44:41,  4.63s/it]  2%|▏         | 67/3753 [05:12<4:40:20,  4.56s/it]  2%|▏         | 68/3753 [05:15<4:25:00,  4.32s/it]  2%|▏         | 69/3753 [05:20<4:29:37,  4.39s/it]  2%|▏         | 70/3753 [05:24<4:30:05,  4.40s/it]{'loss': 0.3636, 'grad_norm': 2526.329833984375, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 3.120903491973877, 'mean_ratio_rejected': 1.0005494356155396, 'weight_chosen': 0.39416927099227905, 'weight_rejected': 0.044955525547266006, 'kl_term_chosen': 0.569061279296875, 'epoch': 0.018654230512991338}
                                                   {'loss': 0.3636, 'grad_norm': 2526.329833984375, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 3.120903491973877, 'mean_ratio_rejected': 1.0005494356155396, 'weight_chosen': 0.39416927099227905, 'weight_rejected': 0.044955525547266006, 'kl_term_chosen': 0.569061279296875, 'epoch': 0.02}
  2%|▏         | 70/3753 [05:25<4:30:05,  4.40s/it]  2%|▏         | 71/3753 [05:29<4:40:18,  4.57s/it]  2%|▏         | 72/3753 [05:34<4:34:25,  4.47s/it]  2%|▏         | 73/3753 [05:37<4:19:17,  4.23s/it]  2%|▏         | 74/3753 [05:41<4:10:37,  4.09s/it]  2%|▏         | 75/3753 [05:45<4:02:40,  3.96s/it]  2%|▏         | 76/3753 [05:50<4:34:48,  4.48s/it]  2%|▏         | 77/3753 [05:54<4:08:45,  4.06s/it]  2%|▏         | 78/3753 [05:59<4:27:18,  4.36s/it]  2%|▏         | 79/3753 [06:03<4:36:29,  4.52s/it]  2%|▏         | 80/3753 [06:08<4:42:59,  4.62s/it]{'loss': 0.2416, 'grad_norm': 3399.10546875, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 0.806495189666748, 'mean_ratio_rejected': 1.162376880645752, 'weight_chosen': 1.0359375476837158, 'weight_rejected': 0.1775381714105606, 'kl_term_chosen': -0.1075286865234375, 'epoch': 0.021319120586275817}
                                                   {'loss': 0.2416, 'grad_norm': 3399.10546875, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 0.806495189666748, 'mean_ratio_rejected': 1.162376880645752, 'weight_chosen': 1.0359375476837158, 'weight_rejected': 0.1775381714105606, 'kl_term_chosen': -0.1075286865234375, 'epoch': 0.02}
  2%|▏         | 80/3753 [06:08<4:42:59,  4.62s/it]  2%|▏         | 81/3753 [06:13<4:45:39,  4.67s/it]  2%|▏         | 82/3753 [06:17<4:30:12,  4.42s/it]  2%|▏         | 83/3753 [06:23<5:08:10,  5.04s/it]  2%|▏         | 84/3753 [06:28<4:59:50,  4.90s/it]  2%|▏         | 85/3753 [06:32<4:34:37,  4.49s/it]  2%|▏         | 86/3753 [06:35<4:14:13,  4.16s/it]  2%|▏         | 87/3753 [06:42<5:04:47,  4.99s/it]  2%|▏         | 88/3753 [06:47<5:03:09,  4.96s/it]  2%|▏         | 89/3753 [06:51<4:46:19,  4.69s/it]  2%|▏         | 90/3753 [06:55<4:32:09,  4.46s/it]{'loss': 0.6238, 'grad_norm': 3854.2236328125, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 5.657093048095703, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.07722139358520508, 'weight_rejected': 1.9772993326187134, 'kl_term_chosen': 0.866455078125, 'epoch': 0.023984010659560292}
                                                   {'loss': 0.6238, 'grad_norm': 3854.2236328125, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 5.657093048095703, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.07722139358520508, 'weight_rejected': 1.9772993326187134, 'kl_term_chosen': 0.866455078125, 'epoch': 0.02}
  2%|▏         | 90/3753 [06:55<4:32:09,  4.46s/it]  2%|▏         | 91/3753 [06:58<4:11:24,  4.12s/it]  2%|▏         | 92/3753 [07:02<4:08:23,  4.07s/it]  2%|▏         | 93/3753 [07:07<4:34:24,  4.50s/it]  3%|▎         | 94/3753 [07:11<4:18:18,  4.24s/it]  3%|▎         | 95/3753 [07:18<4:58:45,  4.90s/it]  3%|▎         | 96/3753 [07:22<4:55:34,  4.85s/it]  3%|▎         | 97/3753 [07:27<4:51:33,  4.78s/it]  3%|▎         | 98/3753 [07:33<5:10:42,  5.10s/it]  3%|▎         | 99/3753 [07:36<4:40:30,  4.61s/it]  3%|▎         | 100/3753 [07:40<4:16:17,  4.21s/it]{'loss': 0.2443, 'grad_norm': 2492.291748046875, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 1.3424067497253418, 'mean_ratio_rejected': 1.177551031112671, 'weight_chosen': 0.4807191491127014, 'weight_rejected': 0.22586730122566223, 'kl_term_chosen': 0.1472320556640625, 'epoch': 0.02664890073284477}
                                                    {'loss': 0.2443, 'grad_norm': 2492.291748046875, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 1.3424067497253418, 'mean_ratio_rejected': 1.177551031112671, 'weight_chosen': 0.4807191491127014, 'weight_rejected': 0.22586730122566223, 'kl_term_chosen': 0.1472320556640625, 'epoch': 0.03}
  3%|▎         | 100/3753 [07:40<4:16:17,  4.21s/it]  3%|▎         | 101/3753 [07:44<4:19:21,  4.26s/it]  3%|▎         | 102/3753 [07:48<4:17:08,  4.23s/it]  3%|▎         | 103/3753 [07:52<4:08:15,  4.08s/it]  3%|▎         | 104/3753 [07:58<4:42:54,  4.65s/it]  3%|▎         | 105/3753 [08:02<4:28:59,  4.42s/it]  3%|▎         | 106/3753 [08:07<4:51:37,  4.80s/it]  3%|▎         | 107/3753 [08:12<4:48:37,  4.75s/it]  3%|▎         | 108/3753 [08:16<4:35:01,  4.53s/it]  3%|▎         | 109/3753 [08:20<4:24:22,  4.35s/it]  3%|▎         | 110/3753 [08:24<4:17:04,  4.23s/it]{'loss': 0.9111, 'grad_norm': 9680.779296875, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 8.490229606628418, 'mean_ratio_rejected': 0.8303458094596863, 'weight_chosen': -0.15578150749206543, 'weight_rejected': -0.05149427428841591, 'kl_term_chosen': 1.0694580078125, 'epoch': 0.029313790806129246}
                                                    {'loss': 0.9111, 'grad_norm': 9680.779296875, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 8.490229606628418, 'mean_ratio_rejected': 0.8303458094596863, 'weight_chosen': -0.15578150749206543, 'weight_rejected': -0.05149427428841591, 'kl_term_chosen': 1.0694580078125, 'epoch': 0.03}
  3%|▎         | 110/3753 [08:24<4:17:04,  4.23s/it]  3%|▎         | 111/3753 [08:29<4:37:21,  4.57s/it]  3%|▎         | 112/3753 [08:33<4:18:00,  4.25s/it]  3%|▎         | 113/3753 [08:36<4:06:53,  4.07s/it]  3%|▎         | 114/3753 [08:41<4:12:37,  4.17s/it]  3%|▎         | 115/3753 [08:45<4:06:41,  4.07s/it]  3%|▎         | 116/3753 [08:49<4:12:55,  4.17s/it]  3%|▎         | 117/3753 [08:53<4:05:06,  4.04s/it]  3%|▎         | 118/3753 [08:57<4:10:59,  4.14s/it]  3%|▎         | 119/3753 [09:05<5:18:17,  5.26s/it]  3%|▎         | 120/3753 [09:09<5:03:48,  5.02s/it]{'loss': 0.1599, 'grad_norm': 6263.13916015625, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 0.3106754720211029, 'mean_ratio_rejected': 0.7589280009269714, 'weight_chosen': 1.4210577011108398, 'weight_rejected': 0.35710158944129944, 'kl_term_chosen': -0.584503173828125, 'epoch': 0.031978680879413725}
                                                    {'loss': 0.1599, 'grad_norm': 6263.13916015625, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 0.3106754720211029, 'mean_ratio_rejected': 0.7589280009269714, 'weight_chosen': 1.4210577011108398, 'weight_rejected': 0.35710158944129944, 'kl_term_chosen': -0.584503173828125, 'epoch': 0.03}
  3%|▎         | 120/3753 [09:10<5:03:48,  5.02s/it]  3%|▎         | 121/3753 [09:14<4:50:48,  4.80s/it]  3%|▎         | 122/3753 [09:19<4:55:09,  4.88s/it]  3%|▎         | 123/3753 [09:23<4:47:36,  4.75s/it]  3%|▎         | 124/3753 [09:27<4:34:44,  4.54s/it]  3%|▎         | 125/3753 [09:32<4:39:49,  4.63s/it]  3%|▎         | 126/3753 [09:37<4:44:48,  4.71s/it]  3%|▎         | 127/3753 [09:41<4:25:13,  4.39s/it]  3%|▎         | 128/3753 [09:45<4:20:17,  4.31s/it]  3%|▎         | 129/3753 [09:51<4:47:40,  4.76s/it]  3%|▎         | 130/3753 [09:56<4:49:44,  4.80s/it]{'loss': 0.2944, 'grad_norm': 4276.1240234375, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 3.120712995529175, 'mean_ratio_rejected': 0.7226508855819702, 'weight_chosen': -0.2715608477592468, 'weight_rejected': -0.05270876735448837, 'kl_term_chosen': 0.56903076171875, 'epoch': 0.034643570952698204}
                                                    {'loss': 0.2944, 'grad_norm': 4276.1240234375, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 3.120712995529175, 'mean_ratio_rejected': 0.7226508855819702, 'weight_chosen': -0.2715608477592468, 'weight_rejected': -0.05270876735448837, 'kl_term_chosen': 0.56903076171875, 'epoch': 0.03}
  3%|▎         | 130/3753 [09:56<4:49:44,  4.80s/it]  3%|▎         | 131/3753 [10:00<4:40:02,  4.64s/it]  4%|▎         | 132/3753 [10:03<4:19:57,  4.31s/it]  4%|▎         | 133/3753 [10:08<4:25:06,  4.39s/it]  4%|▎         | 134/3753 [10:12<4:22:59,  4.36s/it]  4%|▎         | 135/3753 [10:16<4:11:36,  4.17s/it]  4%|▎         | 136/3753 [10:19<4:00:18,  3.99s/it]  4%|▎         | 137/3753 [10:23<3:55:59,  3.92s/it]  4%|▎         | 138/3753 [10:28<4:07:02,  4.10s/it]  4%|▎         | 139/3753 [10:32<4:04:03,  4.05s/it]  4%|▎         | 140/3753 [10:37<4:23:13,  4.37s/it]{'loss': 0.9176, 'grad_norm': 4683.77880859375, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 1.0508091449737549, 'mean_ratio_rejected': 0.7909203171730042, 'weight_chosen': 0.834883451461792, 'weight_rejected': 0.029785454273223877, 'kl_term_chosen': 0.0247802734375, 'epoch': 0.037308461025982675}
                                                    {'loss': 0.9176, 'grad_norm': 4683.77880859375, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 1.0508091449737549, 'mean_ratio_rejected': 0.7909203171730042, 'weight_chosen': 0.834883451461792, 'weight_rejected': 0.029785454273223877, 'kl_term_chosen': 0.0247802734375, 'epoch': 0.04}
  4%|▎         | 140/3753 [10:37<4:23:13,  4.37s/it]  4%|▍         | 141/3753 [10:41<4:21:57,  4.35s/it]  4%|▍         | 142/3753 [10:48<5:00:00,  4.98s/it]  4%|▍         | 143/3753 [10:52<4:44:12,  4.72s/it]  4%|▍         | 144/3753 [10:58<5:04:07,  5.06s/it]  4%|▍         | 145/3753 [11:05<5:40:48,  5.67s/it]  4%|▍         | 146/3753 [11:10<5:36:36,  5.60s/it]  4%|▍         | 147/3753 [11:17<6:01:17,  6.01s/it]  4%|▍         | 148/3753 [11:23<5:54:42,  5.90s/it]  4%|▍         | 149/3753 [11:27<5:17:09,  5.28s/it]  4%|▍         | 150/3753 [11:33<5:44:31,  5.74s/it]{'loss': 0.7853, 'grad_norm': 10171.3935546875, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 0.31909289956092834, 'mean_ratio_rejected': 0.14034472405910492, 'weight_chosen': 0.9065961837768555, 'weight_rejected': -0.39151978492736816, 'kl_term_chosen': -0.571136474609375, 'epoch': 0.039973351099267154}
                                                    {'loss': 0.7853, 'grad_norm': 10171.3935546875, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 0.31909289956092834, 'mean_ratio_rejected': 0.14034472405910492, 'weight_chosen': 0.9065961837768555, 'weight_rejected': -0.39151978492736816, 'kl_term_chosen': -0.571136474609375, 'epoch': 0.04}
  4%|▍         | 150/3753 [11:34<5:44:31,  5.74s/it]  4%|▍         | 151/3753 [11:38<5:33:31,  5.56s/it]  4%|▍         | 152/3753 [11:42<5:03:51,  5.06s/it]  4%|▍         | 153/3753 [11:47<5:00:48,  5.01s/it]  4%|▍         | 154/3753 [11:52<4:48:53,  4.82s/it]  4%|▍         | 155/3753 [11:56<4:41:51,  4.70s/it]  4%|▍         | 156/3753 [12:00<4:29:55,  4.50s/it]  4%|▍         | 157/3753 [12:04<4:22:43,  4.38s/it]  4%|▍         | 158/3753 [12:09<4:33:50,  4.57s/it]  4%|▍         | 159/3753 [12:13<4:28:32,  4.48s/it]  4%|▍         | 160/3753 [12:18<4:30:46,  4.52s/it]{'loss': 1.1256, 'grad_norm': 5405.34716796875, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 0.27284303307533264, 'mean_ratio_rejected': 1.4117976427078247, 'weight_chosen': 1.3294585943222046, 'weight_rejected': 0.5096354484558105, 'kl_term_chosen': -0.6494293212890625, 'epoch': 0.04263824117255163}
                                                    {'loss': 1.1256, 'grad_norm': 5405.34716796875, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 0.27284303307533264, 'mean_ratio_rejected': 1.4117976427078247, 'weight_chosen': 1.3294585943222046, 'weight_rejected': 0.5096354484558105, 'kl_term_chosen': -0.6494293212890625, 'epoch': 0.04}
  4%|▍         | 160/3753 [12:18<4:30:46,  4.52s/it]  4%|▍         | 161/3753 [12:22<4:16:03,  4.28s/it]  4%|▍         | 162/3753 [12:26<4:08:31,  4.15s/it]  4%|▍         | 163/3753 [12:29<3:54:53,  3.93s/it]  4%|▍         | 164/3753 [12:36<4:51:01,  4.87s/it]  4%|▍         | 165/3753 [12:43<5:24:05,  5.42s/it]  4%|▍         | 166/3753 [12:47<4:55:33,  4.94s/it]  4%|▍         | 167/3753 [12:52<4:57:39,  4.98s/it]  4%|▍         | 168/3753 [12:57<5:02:59,  5.07s/it]  5%|▍         | 169/3753 [13:00<4:34:04,  4.59s/it]  5%|▍         | 170/3753 [13:04<4:10:57,  4.20s/it]{'loss': 0.8645, 'grad_norm': 1846.7196044921875, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 0.7116317749023438, 'mean_ratio_rejected': 2.2448177337646484, 'weight_chosen': 1.0424447059631348, 'weight_rejected': 0.5400016903877258, 'kl_term_chosen': -0.17009735107421875, 'epoch': 0.04530313124583611}
                                                    {'loss': 0.8645, 'grad_norm': 1846.7196044921875, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 0.7116317749023438, 'mean_ratio_rejected': 2.2448177337646484, 'weight_chosen': 1.0424447059631348, 'weight_rejected': 0.5400016903877258, 'kl_term_chosen': -0.17009735107421875, 'epoch': 0.05}
  5%|▍         | 170/3753 [13:04<4:10:57,  4.20s/it]  5%|▍         | 171/3753 [13:08<4:16:55,  4.30s/it]  5%|▍         | 172/3753 [13:17<5:29:00,  5.51s/it]  5%|▍         | 173/3753 [13:20<4:56:43,  4.97s/it]  5%|▍         | 174/3753 [13:25<4:53:07,  4.91s/it]  5%|▍         | 175/3753 [13:30<4:44:52,  4.78s/it]  5%|▍         | 176/3753 [13:34<4:32:34,  4.57s/it]  5%|▍         | 177/3753 [13:38<4:29:17,  4.52s/it]  5%|▍         | 178/3753 [13:43<4:30:02,  4.53s/it]  5%|▍         | 179/3753 [13:46<4:10:18,  4.20s/it]  5%|▍         | 180/3753 [13:50<4:12:14,  4.24s/it]{'loss': 0.8366, 'grad_norm': 2855.921142578125, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 1.498065710067749, 'mean_ratio_rejected': 0.6874570846557617, 'weight_chosen': 0.7332590818405151, 'weight_rejected': -0.09469015151262283, 'kl_term_chosen': 0.20208740234375, 'epoch': 0.047968021319120584}
                                                    {'loss': 0.8366, 'grad_norm': 2855.921142578125, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 1.498065710067749, 'mean_ratio_rejected': 0.6874570846557617, 'weight_chosen': 0.7332590818405151, 'weight_rejected': -0.09469015151262283, 'kl_term_chosen': 0.20208740234375, 'epoch': 0.05}
  5%|▍         | 180/3753 [13:51<4:12:14,  4.24s/it]  5%|▍         | 181/3753 [13:55<4:18:10,  4.34s/it]  5%|▍         | 182/3753 [14:02<5:03:57,  5.11s/it]  5%|▍         | 183/3753 [14:07<5:05:35,  5.14s/it]  5%|▍         | 184/3753 [14:13<5:10:51,  5.23s/it]  5%|▍         | 185/3753 [14:17<5:06:15,  5.15s/it]  5%|▍         | 186/3753 [14:22<4:46:25,  4.82s/it]  5%|▍         | 187/3753 [14:25<4:30:52,  4.56s/it]  5%|▌         | 188/3753 [14:29<4:19:30,  4.37s/it]  5%|▌         | 189/3753 [14:36<5:03:55,  5.12s/it]  5%|▌         | 190/3753 [14:40<4:47:03,  4.83s/it]{'loss': 1.3477, 'grad_norm': 2589.7412109375, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 0.39503854513168335, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.3451831340789795, 'weight_rejected': -1.1914207935333252, 'kl_term_chosen': -0.464385986328125, 'epoch': 0.05063291139240506}
                                                    {'loss': 1.3477, 'grad_norm': 2589.7412109375, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 0.39503854513168335, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.3451831340789795, 'weight_rejected': -1.1914207935333252, 'kl_term_chosen': -0.464385986328125, 'epoch': 0.05}
  5%|▌         | 190/3753 [14:41<4:47:03,  4.83s/it]  5%|▌         | 191/3753 [14:44<4:32:59,  4.60s/it]  5%|▌         | 192/3753 [14:52<5:29:03,  5.54s/it]  5%|▌         | 193/3753 [14:57<5:09:42,  5.22s/it]  5%|▌         | 194/3753 [15:02<5:07:27,  5.18s/it]  5%|▌         | 195/3753 [15:06<4:46:50,  4.84s/it]  5%|▌         | 196/3753 [15:09<4:20:35,  4.40s/it]  5%|▌         | 197/3753 [15:18<5:35:17,  5.66s/it]  5%|▌         | 198/3753 [15:22<5:05:32,  5.16s/it]  5%|▌         | 199/3753 [15:27<5:08:42,  5.21s/it]  5%|▌         | 200/3753 [15:32<4:57:34,  5.03s/it]{'loss': 2.0131, 'grad_norm': 3941.45556640625, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.6946696639060974, 'weight_chosen': -0.6934932470321655, 'weight_rejected': -0.12633627653121948, 'kl_term_chosen': 1.6368408203125, 'epoch': 0.05329780146568954}
                                                    {'loss': 2.0131, 'grad_norm': 3941.45556640625, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.6946696639060974, 'weight_chosen': -0.6934932470321655, 'weight_rejected': -0.12633627653121948, 'kl_term_chosen': 1.6368408203125, 'epoch': 0.05}
  5%|▌         | 200/3753 [15:32<4:57:34,  5.03s/it]  5%|▌         | 201/3753 [15:39<5:34:50,  5.66s/it]  5%|▌         | 202/3753 [15:43<5:06:32,  5.18s/it]  5%|▌         | 203/3753 [15:48<5:03:25,  5.13s/it]  5%|▌         | 204/3753 [15:52<4:37:08,  4.69s/it]  5%|▌         | 205/3753 [15:55<4:19:28,  4.39s/it]  5%|▌         | 206/3753 [16:02<4:52:40,  4.95s/it]  6%|▌         | 207/3753 [16:06<4:35:57,  4.67s/it]  6%|▌         | 208/3753 [16:11<4:44:21,  4.81s/it]  6%|▌         | 209/3753 [16:16<4:54:12,  4.98s/it]  6%|▌         | 210/3753 [16:21<4:54:56,  4.99s/it]{'loss': 1.9789, 'grad_norm': 6383.95849609375, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 5.863626956939697, 'mean_ratio_rejected': 9.359830856323242, 'weight_chosen': -0.06564736366271973, 'weight_rejected': 1.2712558507919312, 'kl_term_chosen': 0.8843841552734375, 'epoch': 0.05596269153897402}
                                                    {'loss': 1.9789, 'grad_norm': 6383.95849609375, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 5.863626956939697, 'mean_ratio_rejected': 9.359830856323242, 'weight_chosen': -0.06564736366271973, 'weight_rejected': 1.2712558507919312, 'kl_term_chosen': 0.8843841552734375, 'epoch': 0.06}
  6%|▌         | 210/3753 [16:21<4:54:56,  4.99s/it]  6%|▌         | 211/3753 [16:26<4:58:48,  5.06s/it]  6%|▌         | 212/3753 [16:30<4:29:41,  4.57s/it]  6%|▌         | 213/3753 [16:34<4:28:04,  4.54s/it]  6%|▌         | 214/3753 [16:40<4:47:43,  4.88s/it]  6%|▌         | 215/3753 [16:44<4:32:53,  4.63s/it]  6%|▌         | 216/3753 [16:48<4:25:29,  4.50s/it]  6%|▌         | 217/3753 [16:52<4:10:20,  4.25s/it]  6%|▌         | 218/3753 [16:57<4:24:47,  4.49s/it]  6%|▌         | 219/3753 [17:01<4:15:44,  4.34s/it]  6%|▌         | 220/3753 [17:05<4:05:16,  4.17s/it]{'loss': 1.6341, 'grad_norm': 2970.424560546875, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 5.020939350128174, 'mean_ratio_rejected': 2.9675538539886475, 'weight_chosen': -0.12508165836334229, 'weight_rejected': 0.6638946533203125, 'kl_term_chosen': 0.8068084716796875, 'epoch': 0.05862758161225849}
                                                    {'loss': 1.6341, 'grad_norm': 2970.424560546875, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 5.020939350128174, 'mean_ratio_rejected': 2.9675538539886475, 'weight_chosen': -0.12508165836334229, 'weight_rejected': 0.6638946533203125, 'kl_term_chosen': 0.8068084716796875, 'epoch': 0.06}
  6%|▌         | 220/3753 [17:05<4:05:16,  4.17s/it]  6%|▌         | 221/3753 [17:08<3:56:48,  4.02s/it]  6%|▌         | 222/3753 [17:12<3:58:23,  4.05s/it]  6%|▌         | 223/3753 [17:16<3:44:37,  3.82s/it]  6%|▌         | 224/3753 [17:19<3:44:30,  3.82s/it]  6%|▌         | 225/3753 [17:24<3:51:15,  3.93s/it]  6%|▌         | 226/3753 [17:28<3:51:32,  3.94s/it]  6%|▌         | 227/3753 [17:33<4:18:45,  4.40s/it]  6%|▌         | 228/3753 [17:37<4:06:06,  4.19s/it]  6%|▌         | 229/3753 [17:42<4:15:01,  4.34s/it]  6%|▌         | 230/3753 [17:48<4:49:49,  4.94s/it]{'loss': 2.5228, 'grad_norm': 2176.88916015625, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 0.15914306044578552, 'mean_ratio_rejected': 3.560270071029663, 'weight_chosen': 1.8561866283416748, 'weight_rejected': 0.7839534878730774, 'kl_term_chosen': -0.918975830078125, 'epoch': 0.06129247168554297}
                                                    {'loss': 2.5228, 'grad_norm': 2176.88916015625, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 0.15914306044578552, 'mean_ratio_rejected': 3.560270071029663, 'weight_chosen': 1.8561866283416748, 'weight_rejected': 0.7839534878730774, 'kl_term_chosen': -0.918975830078125, 'epoch': 0.06}
  6%|▌         | 230/3753 [17:48<4:49:49,  4.94s/it]  6%|▌         | 231/3753 [17:53<5:02:21,  5.15s/it]  6%|▌         | 232/3753 [17:58<4:44:32,  4.85s/it]  6%|▌         | 233/3753 [18:02<4:42:50,  4.82s/it]  6%|▌         | 234/3753 [18:08<4:51:43,  4.97s/it]  6%|▋         | 235/3753 [18:16<5:55:42,  6.07s/it]  6%|▋         | 236/3753 [18:20<5:21:14,  5.48s/it]  6%|▋         | 237/3753 [18:25<4:57:26,  5.08s/it]  6%|▋         | 238/3753 [18:29<4:46:30,  4.89s/it]  6%|▋         | 239/3753 [18:34<4:43:02,  4.83s/it]  6%|▋         | 240/3753 [18:38<4:36:41,  4.73s/it]{'loss': 2.9234, 'grad_norm': 2800.22216796875, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.21615135669708252, 'weight_chosen': -1.1096223592758179, 'weight_rejected': -0.5880773663520813, 'kl_term_chosen': 1.940765380859375, 'epoch': 0.06395736175882745}
                                                    {'loss': 2.9234, 'grad_norm': 2800.22216796875, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.21615135669708252, 'weight_chosen': -1.1096223592758179, 'weight_rejected': -0.5880773663520813, 'kl_term_chosen': 1.940765380859375, 'epoch': 0.06}
  6%|▋         | 240/3753 [18:38<4:36:41,  4.73s/it]  6%|▋         | 241/3753 [18:42<4:22:24,  4.48s/it]  6%|▋         | 242/3753 [18:46<4:16:23,  4.38s/it]  6%|▋         | 243/3753 [18:51<4:17:13,  4.40s/it]  7%|▋         | 244/3753 [18:57<4:47:08,  4.91s/it]  7%|▋         | 245/3753 [19:02<4:45:01,  4.87s/it]  7%|▋         | 246/3753 [19:05<4:24:44,  4.53s/it]  7%|▋         | 247/3753 [19:12<5:08:43,  5.28s/it]  7%|▋         | 248/3753 [19:17<5:02:42,  5.18s/it]  7%|▋         | 249/3753 [19:22<5:01:35,  5.16s/it]  7%|▋         | 250/3753 [19:28<5:00:56,  5.15s/it]{'loss': 1.1634, 'grad_norm': 4304.306640625, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 3.7811081409454346, 'weight_chosen': -0.695908784866333, 'weight_rejected': 0.8130557537078857, 'kl_term_chosen': 1.5906982421875, 'epoch': 0.06662225183211193}
                                                    {'loss': 1.1634, 'grad_norm': 4304.306640625, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 3.7811081409454346, 'weight_chosen': -0.695908784866333, 'weight_rejected': 0.8130557537078857, 'kl_term_chosen': 1.5906982421875, 'epoch': 0.07}
  7%|▋         | 250/3753 [19:28<5:00:56,  5.15s/it]  7%|▋         | 251/3753 [19:34<5:25:52,  5.58s/it]  7%|▋         | 252/3753 [19:39<5:14:09,  5.38s/it]  7%|▋         | 253/3753 [19:45<5:15:13,  5.40s/it]  7%|▋         | 254/3753 [19:48<4:41:22,  4.83s/it]  7%|▋         | 255/3753 [19:52<4:27:40,  4.59s/it]  7%|▋         | 256/3753 [19:56<4:10:32,  4.30s/it]  7%|▋         | 257/3753 [20:00<4:11:23,  4.31s/it]  7%|▋         | 258/3753 [20:04<4:01:38,  4.15s/it]  7%|▋         | 259/3753 [20:07<3:50:46,  3.96s/it]  7%|▋         | 260/3753 [20:12<4:01:25,  4.15s/it]{'loss': 1.491, 'grad_norm': 2932.7939453125, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.9747207760810852, 'weight_chosen': 2.0851798057556152, 'weight_rejected': 0.12106536328792572, 'kl_term_chosen': -1.1979751586914062, 'epoch': 0.06928714190539641}
                                                    {'loss': 1.491, 'grad_norm': 2932.7939453125, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.9747207760810852, 'weight_chosen': 2.0851798057556152, 'weight_rejected': 0.12106536328792572, 'kl_term_chosen': -1.1979751586914062, 'epoch': 0.07}
  7%|▋         | 260/3753 [20:12<4:01:25,  4.15s/it]  7%|▋         | 261/3753 [20:17<4:10:29,  4.30s/it]  7%|▋         | 262/3753 [20:21<4:21:10,  4.49s/it]  7%|▋         | 263/3753 [20:26<4:22:56,  4.52s/it]  7%|▋         | 264/3753 [20:30<4:16:47,  4.42s/it]  7%|▋         | 265/3753 [20:34<4:09:53,  4.30s/it]  7%|▋         | 266/3753 [20:38<3:57:41,  4.09s/it]  7%|▋         | 267/3753 [20:42<3:52:18,  4.00s/it]  7%|▋         | 268/3753 [20:47<4:08:32,  4.28s/it]  7%|▋         | 269/3753 [20:50<3:51:23,  3.98s/it]  7%|▋         | 270/3753 [20:55<4:03:53,  4.20s/it]{'loss': 0.4927, 'grad_norm': 1624.134033203125, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 1.2422434091567993, 'mean_ratio_rejected': 0.8555020093917847, 'weight_chosen': 0.8671174645423889, 'weight_rejected': -0.02770281583070755, 'kl_term_chosen': 0.10845947265625, 'epoch': 0.07195203197868089}
                                                    {'loss': 0.4927, 'grad_norm': 1624.134033203125, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 1.2422434091567993, 'mean_ratio_rejected': 0.8555020093917847, 'weight_chosen': 0.8671174645423889, 'weight_rejected': -0.02770281583070755, 'kl_term_chosen': 0.10845947265625, 'epoch': 0.07}
  7%|▋         | 270/3753 [20:55<4:03:53,  4.20s/it]  7%|▋         | 271/3753 [20:59<4:15:41,  4.41s/it]  7%|▋         | 272/3753 [21:04<4:13:25,  4.37s/it]  7%|▋         | 273/3753 [21:08<4:04:22,  4.21s/it]  7%|▋         | 274/3753 [21:11<3:56:26,  4.08s/it]  7%|▋         | 275/3753 [21:15<3:53:18,  4.02s/it]  7%|▋         | 276/3753 [21:19<3:45:57,  3.90s/it]  7%|▋         | 277/3753 [21:24<4:08:16,  4.29s/it]  7%|▋         | 278/3753 [21:28<3:55:10,  4.06s/it]  7%|▋         | 279/3753 [21:32<4:05:38,  4.24s/it]  7%|▋         | 280/3753 [21:37<4:22:29,  4.53s/it]{'loss': 5.6919, 'grad_norm': 2455.882080078125, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 1.3640044927597046, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.7752458453178406, 'weight_rejected': -2.4134016036987305, 'kl_term_chosen': 0.15521240234375, 'epoch': 0.07461692205196535}
                                                    {'loss': 5.6919, 'grad_norm': 2455.882080078125, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 1.3640044927597046, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.7752458453178406, 'weight_rejected': -2.4134016036987305, 'kl_term_chosen': 0.15521240234375, 'epoch': 0.07}
  7%|▋         | 280/3753 [21:38<4:22:29,  4.53s/it]  7%|▋         | 281/3753 [21:42<4:19:00,  4.48s/it]  8%|▊         | 282/3753 [21:48<4:45:16,  4.93s/it]  8%|▊         | 283/3753 [21:52<4:32:49,  4.72s/it]  8%|▊         | 284/3753 [21:56<4:21:15,  4.52s/it]  8%|▊         | 285/3753 [22:03<5:10:47,  5.38s/it]  8%|▊         | 286/3753 [22:07<4:43:12,  4.90s/it]  8%|▊         | 287/3753 [22:11<4:26:02,  4.61s/it]  8%|▊         | 288/3753 [22:20<5:44:19,  5.96s/it]  8%|▊         | 289/3753 [22:26<5:31:23,  5.74s/it]  8%|▊         | 290/3753 [22:34<6:21:16,  6.61s/it]{'loss': 5.0345, 'grad_norm': 2007.3177490234375, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 0.7306784391403198, 'mean_ratio_rejected': 0.1335240602493286, 'weight_chosen': 0.9103575348854065, 'weight_rejected': -0.7972670793533325, 'kl_term_chosen': -0.156890869140625, 'epoch': 0.07728181212524983}
                                                    {'loss': 5.0345, 'grad_norm': 2007.3177490234375, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 0.7306784391403198, 'mean_ratio_rejected': 0.1335240602493286, 'weight_chosen': 0.9103575348854065, 'weight_rejected': -0.7972670793533325, 'kl_term_chosen': -0.156890869140625, 'epoch': 0.08}
  8%|▊         | 290/3753 [22:34<6:21:16,  6.61s/it]  8%|▊         | 291/3753 [22:38<5:31:16,  5.74s/it]  8%|▊         | 292/3753 [22:44<5:33:17,  5.78s/it]  8%|▊         | 293/3753 [22:47<4:56:42,  5.15s/it]  8%|▊         | 294/3753 [22:51<4:38:03,  4.82s/it]  8%|▊         | 295/3753 [22:56<4:37:47,  4.82s/it]  8%|▊         | 296/3753 [23:00<4:23:20,  4.57s/it]  8%|▊         | 297/3753 [23:05<4:25:28,  4.61s/it]  8%|▊         | 298/3753 [23:11<4:48:27,  5.01s/it]  8%|▊         | 299/3753 [23:16<4:41:54,  4.90s/it]  8%|▊         | 300/3753 [23:20<4:27:32,  4.65s/it]{'loss': 5.1462, 'grad_norm': 1233.750732421875, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.9603415131568909, 'weight_rejected': -1.4149408340454102, 'kl_term_chosen': 1.8844833374023438, 'epoch': 0.07994670219853431}
                                                    {'loss': 5.1462, 'grad_norm': 1233.750732421875, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.9603415131568909, 'weight_rejected': -1.4149408340454102, 'kl_term_chosen': 1.8844833374023438, 'epoch': 0.08}
  8%|▊         | 300/3753 [23:20<4:27:32,  4.65s/it]  8%|▊         | 301/3753 [23:24<4:18:59,  4.50s/it]  8%|▊         | 302/3753 [23:29<4:26:33,  4.63s/it]  8%|▊         | 303/3753 [23:33<4:25:56,  4.63s/it]  8%|▊         | 304/3753 [23:36<3:59:02,  4.16s/it]  8%|▊         | 305/3753 [23:41<3:58:39,  4.15s/it]  8%|▊         | 306/3753 [23:45<3:59:13,  4.16s/it]  8%|▊         | 307/3753 [23:49<4:06:27,  4.29s/it]  8%|▊         | 308/3753 [23:55<4:34:50,  4.79s/it]  8%|▊         | 309/3753 [24:00<4:30:12,  4.71s/it]  8%|▊         | 310/3753 [24:04<4:18:25,  4.50s/it]{'loss': 1.7178, 'grad_norm': 1419.0743408203125, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 0.7070209383964539, 'mean_ratio_rejected': 0.4453175961971283, 'weight_chosen': 0.8370164036750793, 'weight_rejected': -0.17632730305194855, 'kl_term_chosen': -0.17334747314453125, 'epoch': 0.08261159227181879}
                                                    {'loss': 1.7178, 'grad_norm': 1419.0743408203125, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 0.7070209383964539, 'mean_ratio_rejected': 0.4453175961971283, 'weight_chosen': 0.8370164036750793, 'weight_rejected': -0.17632730305194855, 'kl_term_chosen': -0.17334747314453125, 'epoch': 0.08}
  8%|▊         | 310/3753 [24:04<4:18:25,  4.50s/it]  8%|▊         | 311/3753 [24:08<4:15:26,  4.45s/it]  8%|▊         | 312/3753 [24:12<4:06:04,  4.29s/it]  8%|▊         | 313/3753 [24:16<4:05:59,  4.29s/it]  8%|▊         | 314/3753 [24:24<4:57:10,  5.18s/it]  8%|▊         | 315/3753 [24:28<4:38:28,  4.86s/it]  8%|▊         | 316/3753 [24:32<4:24:54,  4.62s/it]  8%|▊         | 317/3753 [24:36<4:13:03,  4.42s/it]  8%|▊         | 318/3753 [24:40<4:13:23,  4.43s/it]  8%|▊         | 319/3753 [24:44<4:08:53,  4.35s/it]  9%|▊         | 320/3753 [24:49<4:12:13,  4.41s/it]{'loss': 5.6275, 'grad_norm': 1687.7852783203125, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 3.212022066116333, 'mean_ratio_rejected': 0.15207333862781525, 'weight_chosen': 0.3537604808807373, 'weight_rejected': -0.9008504748344421, 'kl_term_chosen': 0.5834503173828125, 'epoch': 0.08527648234510327}
                                                    {'loss': 5.6275, 'grad_norm': 1687.7852783203125, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 3.212022066116333, 'mean_ratio_rejected': 0.15207333862781525, 'weight_chosen': 0.3537604808807373, 'weight_rejected': -0.9008504748344421, 'kl_term_chosen': 0.5834503173828125, 'epoch': 0.09}
  9%|▊         | 320/3753 [24:49<4:12:13,  4.41s/it]  9%|▊         | 321/3753 [24:53<4:14:21,  4.45s/it]  9%|▊         | 322/3753 [24:57<4:03:58,  4.27s/it]  9%|▊         | 323/3753 [25:01<3:56:03,  4.13s/it]  9%|▊         | 324/3753 [25:09<4:53:19,  5.13s/it]  9%|▊         | 325/3753 [25:13<4:37:24,  4.86s/it]  9%|▊         | 326/3753 [25:16<4:15:26,  4.47s/it]  9%|▊         | 327/3753 [25:20<4:07:58,  4.34s/it]  9%|▊         | 328/3753 [25:24<3:59:08,  4.19s/it]  9%|▉         | 329/3753 [25:29<4:02:04,  4.24s/it]  9%|▉         | 330/3753 [25:33<4:13:19,  4.44s/it]{'loss': 7.9829, 'grad_norm': 9328.734375, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 0.9858343005180359, 'mean_ratio_rejected': 9.291458129882812, 'weight_chosen': 0.868671715259552, 'weight_rejected': 1.3358983993530273, 'kl_term_chosen': -0.00713348388671875, 'epoch': 0.08794137241838774}
                                                    {'loss': 7.9829, 'grad_norm': 9328.734375, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 0.9858343005180359, 'mean_ratio_rejected': 9.291458129882812, 'weight_chosen': 0.868671715259552, 'weight_rejected': 1.3358983993530273, 'kl_term_chosen': -0.00713348388671875, 'epoch': 0.09}
  9%|▉         | 330/3753 [25:34<4:13:19,  4.44s/it]  9%|▉         | 331/3753 [25:37<4:02:55,  4.26s/it]  9%|▉         | 332/3753 [25:42<4:01:49,  4.24s/it]  9%|▉         | 333/3753 [25:46<4:12:38,  4.43s/it]  9%|▉         | 334/3753 [25:54<5:12:21,  5.48s/it]  9%|▉         | 335/3753 [25:59<5:00:04,  5.27s/it]  9%|▉         | 336/3753 [26:02<4:26:55,  4.69s/it]  9%|▉         | 337/3753 [26:07<4:24:41,  4.65s/it]  9%|▉         | 338/3753 [26:10<4:03:33,  4.28s/it]  9%|▉         | 339/3753 [26:14<3:49:21,  4.03s/it]  9%|▉         | 340/3753 [26:18<3:56:56,  4.17s/it]{'loss': 7.3595, 'grad_norm': 1099.4620361328125, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.006293773651123, 'weight_rejected': -8.271849632263184, 'kl_term_chosen': -5.762651443481445, 'epoch': 0.09060626249167222}
                                                    {'loss': 7.3595, 'grad_norm': 1099.4620361328125, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 6.006293773651123, 'weight_rejected': -8.271849632263184, 'kl_term_chosen': -5.762651443481445, 'epoch': 0.09}
  9%|▉         | 340/3753 [26:18<3:56:56,  4.17s/it]  9%|▉         | 341/3753 [26:23<3:57:47,  4.18s/it]  9%|▉         | 342/3753 [26:27<3:57:11,  4.17s/it]  9%|▉         | 343/3753 [26:31<4:02:22,  4.26s/it]  9%|▉         | 344/3753 [26:35<3:54:38,  4.13s/it]  9%|▉         | 345/3753 [26:40<4:16:52,  4.52s/it]  9%|▉         | 346/3753 [26:44<4:08:24,  4.37s/it]  9%|▉         | 347/3753 [26:49<4:10:18,  4.41s/it]  9%|▉         | 348/3753 [26:54<4:23:29,  4.64s/it]  9%|▉         | 349/3753 [26:58<4:08:29,  4.38s/it]  9%|▉         | 350/3753 [27:03<4:19:14,  4.57s/it]{'loss': 19.1124, 'grad_norm': 5753.626953125, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 2.4769885540008545, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.38088512420654297, 'weight_rejected': 3.6584582328796387, 'kl_term_chosen': 0.453521728515625, 'epoch': 0.09327115256495669}
                                                    {'loss': 19.1124, 'grad_norm': 5753.626953125, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 2.4769885540008545, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.38088512420654297, 'weight_rejected': 3.6584582328796387, 'kl_term_chosen': 0.453521728515625, 'epoch': 0.09}
  9%|▉         | 350/3753 [27:03<4:19:14,  4.57s/it]  9%|▉         | 351/3753 [27:07<4:13:59,  4.48s/it]  9%|▉         | 352/3753 [27:10<3:53:09,  4.11s/it]  9%|▉         | 353/3753 [27:15<3:53:08,  4.11s/it]  9%|▉         | 354/3753 [27:19<3:55:34,  4.16s/it]  9%|▉         | 355/3753 [27:25<4:21:31,  4.62s/it]  9%|▉         | 356/3753 [27:29<4:18:37,  4.57s/it] 10%|▉         | 357/3753 [27:33<4:15:19,  4.51s/it] 10%|▉         | 358/3753 [27:38<4:24:31,  4.68s/it] 10%|▉         | 359/3753 [27:43<4:15:58,  4.53s/it] 10%|▉         | 360/3753 [27:47<4:05:34,  4.34s/it]{'loss': 5.7964, 'grad_norm': 667.3031616210938, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 3.306607961654663, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.053644418716430664, 'weight_rejected': -1.2823907136917114, 'kl_term_chosen': 0.59796142578125, 'epoch': 0.09593604263824117}
                                                    {'loss': 5.7964, 'grad_norm': 667.3031616210938, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 3.306607961654663, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -0.053644418716430664, 'weight_rejected': -1.2823907136917114, 'kl_term_chosen': 0.59796142578125, 'epoch': 0.1}
 10%|▉         | 360/3753 [27:47<4:05:34,  4.34s/it] 10%|▉         | 361/3753 [27:51<4:07:45,  4.38s/it] 10%|▉         | 362/3753 [27:55<4:05:42,  4.35s/it] 10%|▉         | 363/3753 [27:59<4:01:37,  4.28s/it] 10%|▉         | 364/3753 [28:04<4:04:48,  4.33s/it] 10%|▉         | 365/3753 [28:07<3:44:09,  3.97s/it] 10%|▉         | 366/3753 [28:11<3:37:01,  3.84s/it] 10%|▉         | 367/3753 [28:15<3:45:07,  3.99s/it] 10%|▉         | 368/3753 [28:20<4:09:59,  4.43s/it] 10%|▉         | 369/3753 [28:25<4:10:40,  4.44s/it] 10%|▉         | 370/3753 [28:29<4:03:23,  4.32s/it]{'loss': 6.1952, 'grad_norm': 7379.74267578125, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 4.0031633377075195, 'mean_ratio_rejected': 0.1908387690782547, 'weight_chosen': 0.17076796293258667, 'weight_rejected': -0.6225481033325195, 'kl_term_chosen': 0.69354248046875, 'epoch': 0.09860093271152565}
                                                    {'loss': 6.1952, 'grad_norm': 7379.74267578125, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 4.0031633377075195, 'mean_ratio_rejected': 0.1908387690782547, 'weight_chosen': 0.17076796293258667, 'weight_rejected': -0.6225481033325195, 'kl_term_chosen': 0.69354248046875, 'epoch': 0.1}
 10%|▉         | 370/3753 [28:29<4:03:23,  4.32s/it] 10%|▉         | 371/3753 [28:32<3:49:08,  4.07s/it] 10%|▉         | 372/3753 [28:37<3:57:08,  4.21s/it] 10%|▉         | 373/3753 [28:41<3:49:59,  4.08s/it] 10%|▉         | 374/3753 [28:48<4:48:21,  5.12s/it] 10%|▉         | 375/3753 [28:54<4:55:06,  5.24s/it] 10%|█         | 376/3753 [29:03<6:02:42,  6.44s/it] 10%|█         | 377/3753 [29:09<6:00:28,  6.41s/it] 10%|█         | 378/3753 [29:13<5:19:32,  5.68s/it] 10%|█         | 379/3753 [29:17<4:46:00,  5.09s/it] 10%|█         | 380/3753 [29:22<4:39:58,  4.98s/it]{'loss': 3.1796, 'grad_norm': 782.8258056640625, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.7399938106536865, 'weight_rejected': -1.7445504665374756, 'kl_term_chosen': -2.779632568359375, 'epoch': 0.10126582278481013}
                                                    {'loss': 3.1796, 'grad_norm': 782.8258056640625, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.7399938106536865, 'weight_rejected': -1.7445504665374756, 'kl_term_chosen': -2.779632568359375, 'epoch': 0.1}
 10%|█         | 380/3753 [29:22<4:39:58,  4.98s/it] 10%|█         | 381/3753 [29:26<4:24:35,  4.71s/it] 10%|█         | 382/3753 [29:30<4:20:00,  4.63s/it] 10%|█         | 383/3753 [29:35<4:15:43,  4.55s/it] 10%|█         | 384/3753 [29:40<4:26:02,  4.74s/it] 10%|█         | 385/3753 [29:50<5:56:31,  6.35s/it] 10%|█         | 386/3753 [29:54<5:16:12,  5.63s/it] 10%|█         | 387/3753 [29:58<4:52:33,  5.21s/it] 10%|█         | 388/3753 [30:02<4:38:58,  4.97s/it] 10%|█         | 389/3753 [30:07<4:29:58,  4.82s/it] 10%|█         | 390/3753 [30:13<4:50:03,  5.18s/it]{'loss': 2.0213, 'grad_norm': 1004.91015625, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.276183605194092, 'weight_rejected': -1.604160189628601, 'kl_term_chosen': -2.637348175048828, 'epoch': 0.1039307128580946}
                                                    {'loss': 2.0213, 'grad_norm': 1004.91015625, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 3.276183605194092, 'weight_rejected': -1.604160189628601, 'kl_term_chosen': -2.637348175048828, 'epoch': 0.1}
 10%|█         | 390/3753 [30:13<4:50:03,  5.18s/it] 10%|█         | 391/3753 [30:17<4:36:25,  4.93s/it] 10%|█         | 392/3753 [30:21<4:20:33,  4.65s/it] 10%|█         | 393/3753 [30:26<4:23:51,  4.71s/it] 10%|█         | 394/3753 [30:30<4:18:13,  4.61s/it] 11%|█         | 395/3753 [30:35<4:24:09,  4.72s/it] 11%|█         | 396/3753 [30:44<5:29:30,  5.89s/it] 11%|█         | 397/3753 [30:48<4:48:04,  5.15s/it] 11%|█         | 398/3753 [30:53<4:53:13,  5.24s/it] 11%|█         | 399/3753 [30:58<4:52:14,  5.23s/it] 11%|█         | 400/3753 [31:02<4:33:16,  4.89s/it]{'loss': 5.8569, 'grad_norm': 738.5506591796875, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 0.3949601948261261, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.159616231918335, 'weight_rejected': -1.2864140272140503, 'kl_term_chosen': -0.46448516845703125, 'epoch': 0.10659560293137908}
                                                    {'loss': 5.8569, 'grad_norm': 738.5506591796875, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 0.3949601948261261, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.159616231918335, 'weight_rejected': -1.2864140272140503, 'kl_term_chosen': -0.46448516845703125, 'epoch': 0.11}
 11%|█         | 400/3753 [31:02<4:33:16,  4.89s/it] 11%|█         | 401/3753 [31:07<4:24:13,  4.73s/it] 11%|█         | 402/3753 [31:11<4:24:16,  4.73s/it] 11%|█         | 403/3753 [31:15<4:05:47,  4.40s/it] 11%|█         | 404/3753 [31:19<4:00:23,  4.31s/it] 11%|█         | 405/3753 [31:24<4:13:09,  4.54s/it] 11%|█         | 406/3753 [31:28<4:07:20,  4.43s/it] 11%|█         | 407/3753 [31:32<3:56:58,  4.25s/it] 11%|█         | 408/3753 [31:37<4:11:03,  4.50s/it] 11%|█         | 409/3753 [31:41<4:02:19,  4.35s/it] 11%|█         | 410/3753 [31:46<4:10:56,  4.50s/it]{'loss': 4.7567, 'grad_norm': 1108.3233642578125, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.770754337310791, 'weight_rejected': -9.339670181274414, 'kl_term_chosen': -5.123847961425781, 'epoch': 0.10926049300466356}
                                                    {'loss': 4.7567, 'grad_norm': 1108.3233642578125, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.770754337310791, 'weight_rejected': -9.339670181274414, 'kl_term_chosen': -5.123847961425781, 'epoch': 0.11}
 11%|█         | 410/3753 [31:46<4:10:56,  4.50s/it] 11%|█         | 411/3753 [31:51<4:15:26,  4.59s/it] 11%|█         | 412/3753 [31:55<4:06:59,  4.44s/it] 11%|█         | 413/3753 [32:01<4:29:39,  4.84s/it] 11%|█         | 414/3753 [32:06<4:29:13,  4.84s/it] 11%|█         | 415/3753 [32:09<4:13:12,  4.55s/it] 11%|█         | 416/3753 [32:14<4:08:17,  4.46s/it] 11%|█         | 417/3753 [32:18<3:58:06,  4.28s/it] 11%|█         | 418/3753 [32:22<3:55:52,  4.24s/it] 11%|█         | 419/3753 [32:26<3:56:26,  4.26s/it] 11%|█         | 420/3753 [32:30<3:47:42,  4.10s/it]{'loss': 2.6006, 'grad_norm': 0.0, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.824481010437012, 'weight_rejected': -5.005704879760742, 'kl_term_chosen': -4.173126220703125, 'epoch': 0.11192538307794804}
                                                    {'loss': 2.6006, 'grad_norm': 0.0, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.824481010437012, 'weight_rejected': -5.005704879760742, 'kl_term_chosen': -4.173126220703125, 'epoch': 0.11}
 11%|█         | 420/3753 [32:30<3:47:42,  4.10s/it] 11%|█         | 421/3753 [32:34<3:57:39,  4.28s/it] 11%|█         | 422/3753 [32:39<3:56:14,  4.26s/it] 11%|█▏        | 423/3753 [32:42<3:46:44,  4.09s/it] 11%|█▏        | 424/3753 [32:45<3:30:10,  3.79s/it] 11%|█▏        | 425/3753 [32:50<3:37:04,  3.91s/it] 11%|█▏        | 426/3753 [32:54<3:44:16,  4.04s/it] 11%|█▏        | 427/3753 [32:59<3:56:43,  4.27s/it] 11%|█▏        | 428/3753 [33:03<3:58:44,  4.31s/it] 11%|█▏        | 429/3753 [33:08<3:59:43,  4.33s/it] 11%|█▏        | 430/3753 [33:13<4:12:49,  4.56s/it]{'loss': 14.3076, 'grad_norm': 25.673879623413086, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 19.065311431884766, 'weight_rejected': -11.519878387451172, 'kl_term_chosen': -18.501693725585938, 'epoch': 0.1145902731512325}
                                                    {'loss': 14.3076, 'grad_norm': 25.673879623413086, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 19.065311431884766, 'weight_rejected': -11.519878387451172, 'kl_term_chosen': -18.501693725585938, 'epoch': 0.11}
 11%|█▏        | 430/3753 [33:13<4:12:49,  4.56s/it] 11%|█▏        | 431/3753 [33:16<3:57:44,  4.29s/it] 12%|█▏        | 432/3753 [33:25<5:04:46,  5.51s/it] 12%|█▏        | 433/3753 [33:29<4:39:38,  5.05s/it] 12%|█▏        | 434/3753 [33:33<4:22:28,  4.74s/it] 12%|█▏        | 435/3753 [33:37<4:11:44,  4.55s/it] 12%|█▏        | 436/3753 [33:41<4:08:24,  4.49s/it] 12%|█▏        | 437/3753 [33:45<4:01:00,  4.36s/it] 12%|█▏        | 438/3753 [33:50<4:15:36,  4.63s/it] 12%|█▏        | 439/3753 [33:55<4:12:05,  4.56s/it] 12%|█▏        | 440/3753 [33:59<4:02:33,  4.39s/it]{'loss': 49.6569, 'grad_norm': 1133.855712890625, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.48475980758667, 'weight_rejected': 1.464961051940918, 'kl_term_chosen': 8.439407348632812, 'epoch': 0.11725516322451698}
                                                    {'loss': 49.6569, 'grad_norm': 1133.855712890625, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.48475980758667, 'weight_rejected': 1.464961051940918, 'kl_term_chosen': 8.439407348632812, 'epoch': 0.12}
 12%|█▏        | 440/3753 [33:59<4:02:33,  4.39s/it] 12%|█▏        | 441/3753 [34:05<4:27:43,  4.85s/it] 12%|█▏        | 442/3753 [34:09<4:23:28,  4.77s/it] 12%|█▏        | 443/3753 [34:12<3:55:30,  4.27s/it] 12%|█▏        | 444/3753 [34:17<4:06:28,  4.47s/it] 12%|█▏        | 445/3753 [34:21<3:55:20,  4.27s/it] 12%|█▏        | 446/3753 [34:26<4:00:13,  4.36s/it] 12%|█▏        | 447/3753 [34:30<4:05:39,  4.46s/it] 12%|█▏        | 448/3753 [34:34<3:49:16,  4.16s/it] 12%|█▏        | 449/3753 [34:39<4:01:21,  4.38s/it] 12%|█▏        | 450/3753 [34:43<3:58:45,  4.34s/it]{'loss': 38.2972, 'grad_norm': 1586.421875, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 8.55799388885498, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.18012350797653198, 'weight_rejected': 12.876944541931152, 'kl_term_chosen': 1.0734329223632812, 'epoch': 0.11992005329780146}
                                                    {'loss': 38.2972, 'grad_norm': 1586.421875, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 8.55799388885498, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.18012350797653198, 'weight_rejected': 12.876944541931152, 'kl_term_chosen': 1.0734329223632812, 'epoch': 0.12}
 12%|█▏        | 450/3753 [34:43<3:58:45,  4.34s/it] 12%|█▏        | 451/3753 [34:47<3:56:27,  4.30s/it] 12%|█▏        | 452/3753 [34:52<4:10:07,  4.55s/it] 12%|█▏        | 453/3753 [34:56<4:01:57,  4.40s/it] 12%|█▏        | 454/3753 [35:02<4:18:18,  4.70s/it] 12%|█▏        | 455/3753 [35:06<4:09:29,  4.54s/it] 12%|█▏        | 456/3753 [35:12<4:34:11,  4.99s/it] 12%|█▏        | 457/3753 [35:17<4:28:19,  4.88s/it] 12%|█▏        | 458/3753 [35:21<4:11:11,  4.57s/it] 12%|█▏        | 459/3753 [35:25<4:05:46,  4.48s/it] 12%|█▏        | 460/3753 [35:30<4:20:52,  4.75s/it]{'loss': 80.9157, 'grad_norm': 5422.20849609375, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -17.11481475830078, 'weight_rejected': -4.878717422485352, 'kl_term_chosen': 18.033294677734375, 'epoch': 0.12258494337108594}
                                                    {'loss': 80.9157, 'grad_norm': 5422.20849609375, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -17.11481475830078, 'weight_rejected': -4.878717422485352, 'kl_term_chosen': 18.033294677734375, 'epoch': 0.12}
 12%|█▏        | 460/3753 [35:30<4:20:52,  4.75s/it] 12%|█▏        | 461/3753 [35:34<4:07:26,  4.51s/it] 12%|█▏        | 462/3753 [35:37<3:39:26,  4.00s/it] 12%|█▏        | 463/3753 [35:41<3:44:36,  4.10s/it] 12%|█▏        | 464/3753 [35:45<3:45:52,  4.12s/it] 12%|█▏        | 465/3753 [35:50<3:47:09,  4.15s/it] 12%|█▏        | 466/3753 [35:54<3:47:11,  4.15s/it] 12%|█▏        | 467/3753 [35:58<3:48:29,  4.17s/it] 12%|█▏        | 468/3753 [36:06<4:47:51,  5.26s/it] 12%|█▏        | 469/3753 [36:11<4:50:31,  5.31s/it] 13%|█▎        | 470/3753 [36:18<5:07:51,  5.63s/it]{'loss': 79.383, 'grad_norm': 2067.428955078125, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -28.25599479675293, 'weight_rejected': -6.727501392364502, 'kl_term_chosen': 29.20098876953125, 'epoch': 0.1252498334443704}
                                                    {'loss': 79.383, 'grad_norm': 2067.428955078125, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -28.25599479675293, 'weight_rejected': -6.727501392364502, 'kl_term_chosen': 29.20098876953125, 'epoch': 0.13}
 13%|█▎        | 470/3753 [36:18<5:07:51,  5.63s/it] 13%|█▎        | 471/3753 [36:23<5:05:49,  5.59s/it] 13%|█▎        | 472/3753 [36:27<4:30:14,  4.94s/it] 13%|█▎        | 473/3753 [36:30<4:01:09,  4.41s/it] 13%|█▎        | 474/3753 [36:34<4:02:04,  4.43s/it] 13%|█▎        | 475/3753 [36:39<4:07:25,  4.53s/it] 13%|█▎        | 476/3753 [36:43<3:55:45,  4.32s/it] 13%|█▎        | 477/3753 [36:47<3:55:43,  4.32s/it] 13%|█▎        | 478/3753 [36:51<3:52:22,  4.26s/it] 13%|█▎        | 479/3753 [36:57<4:23:21,  4.83s/it] 13%|█▎        | 480/3753 [37:02<4:20:50,  4.78s/it]{'loss': 58.778, 'grad_norm': 0.0, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 21.928958892822266, 'weight_rejected': -7.416721820831299, 'kl_term_chosen': -21.3524169921875, 'epoch': 0.1279147235176549}
                                                    {'loss': 58.778, 'grad_norm': 0.0, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 21.928958892822266, 'weight_rejected': -7.416721820831299, 'kl_term_chosen': -21.3524169921875, 'epoch': 0.13}
 13%|█▎        | 480/3753 [37:02<4:20:50,  4.78s/it] 13%|█▎        | 481/3753 [37:07<4:23:31,  4.83s/it] 13%|█▎        | 482/3753 [37:11<4:09:09,  4.57s/it] 13%|█▎        | 483/3753 [37:15<3:57:38,  4.36s/it] 13%|█▎        | 484/3753 [37:19<3:49:10,  4.21s/it] 13%|█▎        | 485/3753 [37:22<3:39:31,  4.03s/it] 13%|█▎        | 486/3753 [37:27<3:55:49,  4.33s/it] 13%|█▎        | 487/3753 [37:32<4:03:33,  4.47s/it] 13%|█▎        | 488/3753 [37:36<3:54:47,  4.31s/it] 13%|█▎        | 489/3753 [37:41<4:02:03,  4.45s/it] 13%|█▎        | 490/3753 [37:46<4:16:12,  4.71s/it]{'loss': 55.279, 'grad_norm': 518.7125854492188, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.0237414836883545, 'weight_rejected': 8.149809837341309, 'kl_term_chosen': 3.9679183959960938, 'epoch': 0.13057961359093936}
                                                    {'loss': 55.279, 'grad_norm': 518.7125854492188, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -3.0237414836883545, 'weight_rejected': 8.149809837341309, 'kl_term_chosen': 3.9679183959960938, 'epoch': 0.13}
 13%|█▎        | 490/3753 [37:46<4:16:12,  4.71s/it] 13%|█▎        | 491/3753 [37:51<4:24:39,  4.87s/it] 13%|█▎        | 492/3753 [37:55<4:06:36,  4.54s/it] 13%|█▎        | 493/3753 [38:05<5:29:47,  6.07s/it] 13%|█▎        | 494/3753 [38:08<4:50:38,  5.35s/it] 13%|█▎        | 495/3753 [38:12<4:17:50,  4.75s/it] 13%|█▎        | 496/3753 [38:17<4:22:33,  4.84s/it] 13%|█▎        | 497/3753 [38:21<4:08:10,  4.57s/it] 13%|█▎        | 498/3753 [38:29<5:02:23,  5.57s/it] 13%|█▎        | 499/3753 [38:35<5:11:08,  5.74s/it] 13%|█▎        | 500/3753 [38:40<4:55:17,  5.45s/it]{'loss': 38.1311, 'grad_norm': 0.0, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 13.758246421813965, 'weight_rejected': -16.628480911254883, 'kl_term_chosen': -13.115814208984375, 'epoch': 0.13324450366422386}
                                                    {'loss': 38.1311, 'grad_norm': 0.0, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 13.758246421813965, 'weight_rejected': -16.628480911254883, 'kl_term_chosen': -13.115814208984375, 'epoch': 0.13}
 13%|█▎        | 500/3753 [38:40<4:55:17,  5.45s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:634: UserWarning: Detected an existing checkpoint in /train/output_model/llama3-8b-sympo-1e-6_0.1_/checkpoint-500/pytorch_model_fsdp_0/.metadata, overwriting since self.overwrite=True. Past version 2.5 of PyTorch, `overwrite` will default to False. Set this variable to True to maintain this functionality or False to raise when an existing checkpoint is found.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:634: UserWarning: Detected an existing checkpoint in /train/output_model/llama3-8b-sympo-1e-6_0.1_/checkpoint-500/pytorch_model_fsdp_0/.metadata, overwriting since self.overwrite=True. Past version 2.5 of PyTorch, `overwrite` will default to False. Set this variable to True to maintain this functionality or False to raise when an existing checkpoint is found.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:634: UserWarning: Detected an existing checkpoint in /train/output_model/llama3-8b-sympo-1e-6_0.1_/checkpoint-500/pytorch_model_fsdp_0/.metadata, overwriting since self.overwrite=True. Past version 2.5 of PyTorch, `overwrite` will default to False. Set this variable to True to maintain this functionality or False to raise when an existing checkpoint is found.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:634: UserWarning: Detected an existing checkpoint in /train/output_model/llama3-8b-sympo-1e-6_0.1_/checkpoint-500/pytorch_model_fsdp_0/.metadata, overwriting since self.overwrite=True. Past version 2.5 of PyTorch, `overwrite` will default to False. Set this variable to True to maintain this functionality or False to raise when an existing checkpoint is found.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:634: UserWarning: Detected an existing checkpoint in /train/output_model/llama3-8b-sympo-1e-6_0.1_/checkpoint-500/optimizer_0/.metadata, overwriting since self.overwrite=True. Past version 2.5 of PyTorch, `overwrite` will default to False. Set this variable to True to maintain this functionality or False to raise when an existing checkpoint is found.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:634: UserWarning: Detected an existing checkpoint in /train/output_model/llama3-8b-sympo-1e-6_0.1_/checkpoint-500/optimizer_0/.metadata, overwriting since self.overwrite=True. Past version 2.5 of PyTorch, `overwrite` will default to False. Set this variable to True to maintain this functionality or False to raise when an existing checkpoint is found.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:634: UserWarning: Detected an existing checkpoint in /train/output_model/llama3-8b-sympo-1e-6_0.1_/checkpoint-500/optimizer_0/.metadata, overwriting since self.overwrite=True. Past version 2.5 of PyTorch, `overwrite` will default to False. Set this variable to True to maintain this functionality or False to raise when an existing checkpoint is found.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/filesystem.py:634: UserWarning: Detected an existing checkpoint in /train/output_model/llama3-8b-sympo-1e-6_0.1_/checkpoint-500/optimizer_0/.metadata, overwriting since self.overwrite=True. Past version 2.5 of PyTorch, `overwrite` will default to False. Set this variable to True to maintain this functionality or False to raise when an existing checkpoint is found.
  warnings.warn(
 13%|█▎        | 501/3753 [39:33<17:49:11, 19.73s/it] 13%|█▎        | 502/3753 [39:40<14:34:11, 16.13s/it] 13%|█▎        | 503/3753 [39:45<11:25:18, 12.65s/it] 13%|█▎        | 504/3753 [39:49<9:03:17, 10.03s/it]  13%|█▎        | 505/3753 [39:53<7:22:30,  8.17s/it] 13%|█▎        | 506/3753 [39:56<6:10:27,  6.85s/it] 14%|█▎        | 507/3753 [40:01<5:40:03,  6.29s/it] 14%|█▎        | 508/3753 [40:07<5:21:50,  5.95s/it] 14%|█▎        | 509/3753 [40:11<4:54:43,  5.45s/it] 14%|█▎        | 510/3753 [40:15<4:36:41,  5.12s/it]{'loss': 10.1509, 'grad_norm': 102.6153564453125, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.057909965515137, 'weight_rejected': -8.859232902526855, 'kl_term_chosen': -4.1019287109375, 'epoch': 0.13590939373750832}
                                                    {'loss': 10.1509, 'grad_norm': 102.6153564453125, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.057909965515137, 'weight_rejected': -8.859232902526855, 'kl_term_chosen': -4.1019287109375, 'epoch': 0.14}
 14%|█▎        | 510/3753 [40:15<4:36:41,  5.12s/it] 14%|█▎        | 511/3753 [40:20<4:24:03,  4.89s/it]W1105 07:40:19.790000 40916 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
W1105 07:40:19.796000 40916 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 41095 closing signal SIGTERM
W1105 07:40:19.799000 40916 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 41096 closing signal SIGTERM
W1105 07:40:19.805000 40916 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 41097 closing signal SIGTERM
W1105 07:40:19.809000 40916 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 41098 closing signal SIGTERM
Traceback (most recent call last):
  File "/root/miniconda3/envs/advan/bin/accelerate", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/launch.py", line 1222, in launch_command
    multi_gpu_launcher(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/launch.py", line 853, in multi_gpu_launcher
    distrib_run.run(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py", line 138, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 715, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 879, in _invoke_run
    time.sleep(monitor_interval)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 40916 got signal: 15
