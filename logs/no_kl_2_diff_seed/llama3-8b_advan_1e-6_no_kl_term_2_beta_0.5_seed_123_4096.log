nohup: ignoring input
[W1119 04:53:21.016028990 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 123
设置随机种子为: 123
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.59it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.27it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 97.08it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.51it/s]
⚙️  Running in WANDB offline mode⚙️  Running in WANDB offline mode

设置随机种子为: 123设置随机种子为: 123

[W1119 04:53:26.289453697 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1119 04:53:26.293107569 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 59.34it/s]
加载作为参考的SFT模型 (Reference Model)...Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 59.41it/s]

加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 59.19it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 59.00it/s]
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
[W1119 04:53:27.238218997 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
[W1119 04:53:27.248229495 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /wandb/offline-run-20251119_045335-uap57a2f
  0%|          | 0/3753 [00:00<?, ?it/s]--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -199.0
Sample 0 - pi_logp_chosen:  -198.81076049804688
Sample 0 - Difference (pi - ref): 0.189239501953125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -100.5
Sample 0 - pi_logp_chosen:  -100.34402465820312
Sample 0 - Difference (pi - ref): 0.155975341796875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -122.0
Sample 0 - pi_logp_chosen:  -121.57272338867188
Sample 0 - Difference (pi - ref): 0.427276611328125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -234.0
Sample 0 - pi_logp_chosen:  -233.57894897460938
Sample 0 - Difference (pi - ref): 0.421051025390625
---------------------------------
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -227.0
Sample 0 - pi_logp_chosen:  -227.50088500976562
Sample 0 - Difference (pi - ref): -0.500885009765625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -248.0
Sample 0 - pi_logp_chosen:  -248.47735595703125
Sample 0 - Difference (pi - ref): -0.47735595703125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -209.0
Sample 0 - pi_logp_chosen:  -208.26136779785156
Sample 0 - Difference (pi - ref): 0.7386322021484375
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -728.0
Sample 0 - pi_logp_chosen:  -730.50390625
Sample 0 - Difference (pi - ref): -2.50390625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -240.0
Sample 0 - pi_logp_chosen:  -240.2412567138672
Sample 0 - Difference (pi - ref): -0.2412567138671875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -253.0
Sample 0 - pi_logp_chosen:  -253.00314331054688
Sample 0 - Difference (pi - ref): -0.003143310546875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -350.0
Sample 0 - pi_logp_chosen:  -349.3069152832031
Sample 0 - Difference (pi - ref): 0.693084716796875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -452.0
Sample 0 - pi_logp_chosen:  -453.64239501953125
Sample 0 - Difference (pi - ref): -1.64239501953125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -127.5
Sample 0 - pi_logp_chosen:  -127.59747314453125
Sample 0 - Difference (pi - ref): -0.09747314453125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -98.5
Sample 0 - pi_logp_chosen:  -98.78225708007812
Sample 0 - Difference (pi - ref): -0.282257080078125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -251.0
Sample 0 - pi_logp_chosen:  -249.6898956298828
Sample 0 - Difference (pi - ref): 1.3101043701171875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -516.0
Sample 0 - pi_logp_chosen:  -514.2531127929688
Sample 0 - Difference (pi - ref): 1.74688720703125
---------------------------------
  0%|          | 1/3753 [00:04<4:56:20,  4.74s/it]{'loss': -0.1771, 'grad_norm': 2052.312744140625, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 6.590037822723389, 'weight_chosen': 0.2668696641921997, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 0.6550521850585938, 'epoch': 0.0002664890073284477}
                                                  {'loss': -0.1771, 'grad_norm': 2052.312744140625, 'learning_rate': 0.0, 'mean_ratio_chosen': 3.7065606117248535, 'mean_ratio_rejected': 6.590037822723389, 'weight_chosen': 0.2668696641921997, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 0.6550521850585938, 'epoch': 0.0}
  0%|          | 1/3753 [00:04<4:56:20,  4.74s/it]  0%|          | 2/3753 [00:10<5:18:30,  5.09s/it]  0%|          | 3/3753 [00:14<5:07:21,  4.92s/it]  0%|          | 4/3753 [00:18<4:43:15,  4.53s/it]  0%|          | 5/3753 [00:22<4:34:08,  4.39s/it]  0%|          | 6/3753 [00:28<4:54:59,  4.72s/it]  0%|          | 7/3753 [00:32<4:43:38,  4.54s/it]  0%|          | 8/3753 [00:36<4:41:59,  4.52s/it]  0%|          | 9/3753 [00:40<4:24:08,  4.23s/it]  0%|          | 10/3753 [00:44<4:14:52,  4.09s/it]{'loss': -0.3849, 'grad_norm': 2965.656982421875, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 0.7454537749290466, 'mean_ratio_rejected': 1.1797270774841309, 'weight_chosen': 0.3919661045074463, 'weight_rejected': 0.4163219630718231, 'kl_term_chosen': -0.146881103515625, 'epoch': 0.002664890073284477}
                                                   {'loss': -0.3849, 'grad_norm': 2965.656982421875, 'learning_rate': 2.3936170212765956e-08, 'mean_ratio_chosen': 0.7454537749290466, 'mean_ratio_rejected': 1.1797270774841309, 'weight_chosen': 0.3919661045074463, 'weight_rejected': 0.4163219630718231, 'kl_term_chosen': -0.146881103515625, 'epoch': 0.0}
  0%|          | 10/3753 [00:44<4:14:52,  4.09s/it]  0%|          | 11/3753 [00:48<4:22:37,  4.21s/it]  0%|          | 12/3753 [00:53<4:36:20,  4.43s/it]  0%|          | 13/3753 [00:57<4:34:02,  4.40s/it]  0%|          | 14/3753 [01:02<4:27:35,  4.29s/it]  0%|          | 15/3753 [01:05<4:17:07,  4.13s/it]  0%|          | 16/3753 [01:09<4:12:36,  4.06s/it]  0%|          | 17/3753 [01:13<4:07:07,  3.97s/it]  0%|          | 18/3753 [01:18<4:23:30,  4.23s/it]  1%|          | 19/3753 [01:21<4:06:58,  3.97s/it]  1%|          | 20/3753 [01:25<4:05:05,  3.94s/it]{'loss': -0.18, 'grad_norm': 2644.728515625, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 1.4253315925598145, 'mean_ratio_rejected': 0.804792582988739, 'weight_chosen': 0.5553895831108093, 'weight_rejected': 0.29665425419807434, 'kl_term_chosen': 0.1772022247314453, 'epoch': 0.005329780146568954}
                                                   {'loss': -0.18, 'grad_norm': 2644.728515625, 'learning_rate': 5.053191489361702e-08, 'mean_ratio_chosen': 1.4253315925598145, 'mean_ratio_rejected': 0.804792582988739, 'weight_chosen': 0.5553895831108093, 'weight_rejected': 0.29665425419807434, 'kl_term_chosen': 0.1772022247314453, 'epoch': 0.01}
  1%|          | 20/3753 [01:25<4:05:05,  3.94s/it]  1%|          | 21/3753 [01:29<4:07:50,  3.98s/it]  1%|          | 22/3753 [01:37<5:16:37,  5.09s/it]  1%|          | 23/3753 [01:42<5:15:57,  5.08s/it]  1%|          | 24/3753 [01:45<4:42:07,  4.54s/it]  1%|          | 25/3753 [01:49<4:36:04,  4.44s/it]  1%|          | 26/3753 [01:52<4:09:45,  4.02s/it]  1%|          | 27/3753 [01:56<4:09:31,  4.02s/it]  1%|          | 28/3753 [02:00<4:06:29,  3.97s/it]  1%|          | 29/3753 [02:04<4:03:56,  3.93s/it]  1%|          | 30/3753 [02:08<4:08:16,  4.00s/it]{'loss': 0.2454, 'grad_norm': 1844.7677001953125, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 1.5821822881698608, 'mean_ratio_rejected': 1.3767963647842407, 'weight_chosen': 0.3985486626625061, 'weight_rejected': 0.5987815260887146, 'kl_term_chosen': 0.2294025421142578, 'epoch': 0.007994670219853431}
                                                   {'loss': 0.2454, 'grad_norm': 1844.7677001953125, 'learning_rate': 7.712765957446808e-08, 'mean_ratio_chosen': 1.5821822881698608, 'mean_ratio_rejected': 1.3767963647842407, 'weight_chosen': 0.3985486626625061, 'weight_rejected': 0.5987815260887146, 'kl_term_chosen': 0.2294025421142578, 'epoch': 0.01}
  1%|          | 30/3753 [02:08<4:08:16,  4.00s/it]  1%|          | 31/3753 [02:14<4:31:50,  4.38s/it]  1%|          | 32/3753 [02:17<4:17:48,  4.16s/it]  1%|          | 33/3753 [02:21<4:07:36,  3.99s/it]  1%|          | 34/3753 [02:27<4:57:09,  4.79s/it]  1%|          | 35/3753 [02:33<5:11:04,  5.02s/it]  1%|          | 36/3753 [02:39<5:34:00,  5.39s/it]  1%|          | 37/3753 [02:45<5:40:15,  5.49s/it]  1%|          | 38/3753 [02:49<5:18:03,  5.14s/it]  1%|          | 39/3753 [02:57<6:13:06,  6.03s/it]  1%|          | 40/3753 [03:01<5:37:39,  5.46s/it]{'loss': 1.5936, 'grad_norm': 2265.391357421875, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 1.7127777338027954, 'mean_ratio_rejected': 1.9393807649612427, 'weight_chosen': 0.4887361526489258, 'weight_rejected': 0.1276526302099228, 'kl_term_chosen': 0.2690582275390625, 'epoch': 0.010659560293137908}
                                                   {'loss': 1.5936, 'grad_norm': 2265.391357421875, 'learning_rate': 1.0372340425531915e-07, 'mean_ratio_chosen': 1.7127777338027954, 'mean_ratio_rejected': 1.9393807649612427, 'weight_chosen': 0.4887361526489258, 'weight_rejected': 0.1276526302099228, 'kl_term_chosen': 0.2690582275390625, 'epoch': 0.01}
  1%|          | 40/3753 [03:02<5:37:39,  5.46s/it]  1%|          | 41/3753 [03:08<5:59:33,  5.81s/it]  1%|          | 42/3753 [03:11<5:08:08,  4.98s/it]  1%|          | 43/3753 [03:16<5:04:35,  4.93s/it]  1%|          | 44/3753 [03:20<4:47:43,  4.65s/it]  1%|          | 45/3753 [03:25<4:52:49,  4.74s/it]  1%|          | 46/3753 [03:30<4:57:06,  4.81s/it]  1%|▏         | 47/3753 [03:33<4:22:10,  4.24s/it]  1%|▏         | 48/3753 [03:37<4:18:32,  4.19s/it]  1%|▏         | 49/3753 [03:41<4:20:59,  4.23s/it]  1%|▏         | 50/3753 [03:45<4:13:56,  4.11s/it]{'loss': 1.7218, 'grad_norm': 1800.370361328125, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 1.7968389987945557, 'mean_ratio_rejected': 2.1670875549316406, 'weight_chosen': 0.5703771114349365, 'weight_rejected': 0.6851073503494263, 'kl_term_chosen': 0.2930145263671875, 'epoch': 0.013324450366422385}
                                                   {'loss': 1.7218, 'grad_norm': 1800.370361328125, 'learning_rate': 1.3031914893617022e-07, 'mean_ratio_chosen': 1.7968389987945557, 'mean_ratio_rejected': 2.1670875549316406, 'weight_chosen': 0.5703771114349365, 'weight_rejected': 0.6851073503494263, 'kl_term_chosen': 0.2930145263671875, 'epoch': 0.01}
  1%|▏         | 50/3753 [03:45<4:13:56,  4.11s/it]  1%|▏         | 51/3753 [03:49<4:14:37,  4.13s/it]  1%|▏         | 52/3753 [03:54<4:25:18,  4.30s/it]  1%|▏         | 53/3753 [04:00<4:53:57,  4.77s/it]  1%|▏         | 54/3753 [04:03<4:29:52,  4.38s/it]  1%|▏         | 55/3753 [04:11<5:35:12,  5.44s/it]  1%|▏         | 56/3753 [04:19<6:19:38,  6.16s/it]  2%|▏         | 57/3753 [04:24<5:52:52,  5.73s/it]  2%|▏         | 58/3753 [04:27<5:11:00,  5.05s/it]  2%|▏         | 59/3753 [04:35<5:57:07,  5.80s/it]  2%|▏         | 60/3753 [04:38<5:08:15,  5.01s/it]{'loss': 1.4345, 'grad_norm': 6106.46875, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 0.9641884565353394, 'mean_ratio_rejected': 1.0133249759674072, 'weight_chosen': 0.04844886064529419, 'weight_rejected': 0.937210738658905, 'kl_term_chosen': -0.0182342529296875, 'epoch': 0.015989340439706862}
                                                   {'loss': 1.4345, 'grad_norm': 6106.46875, 'learning_rate': 1.5691489361702126e-07, 'mean_ratio_chosen': 0.9641884565353394, 'mean_ratio_rejected': 1.0133249759674072, 'weight_chosen': 0.04844886064529419, 'weight_rejected': 0.937210738658905, 'kl_term_chosen': -0.0182342529296875, 'epoch': 0.02}
  2%|▏         | 60/3753 [04:38<5:08:15,  5.01s/it]  2%|▏         | 61/3753 [04:43<5:16:28,  5.14s/it]  2%|▏         | 62/3753 [04:48<5:01:09,  4.90s/it]  2%|▏         | 63/3753 [04:52<4:52:50,  4.76s/it]  2%|▏         | 64/3753 [04:57<5:01:18,  4.90s/it]  2%|▏         | 65/3753 [05:01<4:42:51,  4.60s/it]  2%|▏         | 66/3753 [05:06<4:49:47,  4.72s/it]  2%|▏         | 67/3753 [05:11<4:46:19,  4.66s/it]  2%|▏         | 68/3753 [05:14<4:28:39,  4.37s/it]  2%|▏         | 69/3753 [05:19<4:32:30,  4.44s/it]  2%|▏         | 70/3753 [05:23<4:18:47,  4.22s/it]{'loss': 1.0439, 'grad_norm': 2488.03857421875, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.019685745239258, 'weight_chosen': -0.911616861820221, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 1.874847412109375, 'epoch': 0.018654230512991338}
                                                   {'loss': 1.0439, 'grad_norm': 2488.03857421875, 'learning_rate': 1.8351063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.019685745239258, 'weight_chosen': -0.911616861820221, 'weight_rejected': 0.044680867344141006, 'kl_term_chosen': 1.874847412109375, 'epoch': 0.02}
  2%|▏         | 70/3753 [05:23<4:18:47,  4.22s/it]  2%|▏         | 71/3753 [05:27<4:27:52,  4.37s/it]  2%|▏         | 72/3753 [05:32<4:31:38,  4.43s/it]  2%|▏         | 73/3753 [05:36<4:20:01,  4.24s/it]  2%|▏         | 74/3753 [05:40<4:10:48,  4.09s/it]  2%|▏         | 75/3753 [05:43<4:02:42,  3.96s/it]  2%|▏         | 76/3753 [05:49<4:35:42,  4.50s/it]  2%|▏         | 77/3753 [05:52<4:12:19,  4.12s/it]  2%|▏         | 78/3753 [05:57<4:28:50,  4.39s/it]  2%|▏         | 79/3753 [06:02<4:27:26,  4.37s/it]  2%|▏         | 80/3753 [06:07<4:37:54,  4.54s/it]{'loss': 0.5805, 'grad_norm': 2338.305419921875, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 2.868800640106201, 'mean_ratio_rejected': 3.6478989124298096, 'weight_chosen': 0.40146178007125854, 'weight_rejected': 0.10230471193790436, 'kl_term_chosen': 0.526947021484375, 'epoch': 0.021319120586275817}
                                                   {'loss': 0.5805, 'grad_norm': 2338.305419921875, 'learning_rate': 2.101063829787234e-07, 'mean_ratio_chosen': 2.868800640106201, 'mean_ratio_rejected': 3.6478989124298096, 'weight_chosen': 0.40146178007125854, 'weight_rejected': 0.10230471193790436, 'kl_term_chosen': 0.526947021484375, 'epoch': 0.02}
  2%|▏         | 80/3753 [06:07<4:37:54,  4.54s/it]  2%|▏         | 81/3753 [06:11<4:41:50,  4.61s/it]  2%|▏         | 82/3753 [06:15<4:27:04,  4.37s/it]  2%|▏         | 83/3753 [06:22<5:08:45,  5.05s/it]  2%|▏         | 84/3753 [06:26<5:03:04,  4.96s/it]  2%|▏         | 85/3753 [06:30<4:36:30,  4.52s/it]  2%|▏         | 86/3753 [06:33<4:15:03,  4.17s/it]  2%|▏         | 87/3753 [06:40<5:07:26,  5.03s/it]  2%|▏         | 88/3753 [06:44<4:44:35,  4.66s/it]  2%|▏         | 89/3753 [06:48<4:37:54,  4.55s/it]  2%|▏         | 90/3753 [06:52<4:28:42,  4.40s/it]{'loss': 1.0005, 'grad_norm': 2332.637939453125, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.5304684638977051, 'weight_rejected': 0.15002880990505219, 'kl_term_chosen': 1.3197021484375, 'epoch': 0.023984010659560292}
                                                   {'loss': 1.0005, 'grad_norm': 2332.637939453125, 'learning_rate': 2.3670212765957445e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.5304684638977051, 'weight_rejected': 0.15002880990505219, 'kl_term_chosen': 1.3197021484375, 'epoch': 0.02}
  2%|▏         | 90/3753 [06:53<4:28:42,  4.40s/it]  2%|▏         | 91/3753 [06:56<4:08:41,  4.07s/it]  2%|▏         | 92/3753 [07:00<4:06:30,  4.04s/it]  2%|▏         | 93/3753 [07:05<4:33:12,  4.48s/it]  3%|▎         | 94/3753 [07:09<4:22:57,  4.31s/it]  3%|▎         | 95/3753 [07:16<5:04:22,  4.99s/it]  3%|▎         | 96/3753 [07:20<4:46:30,  4.70s/it]  3%|▎         | 97/3753 [07:24<4:38:12,  4.57s/it]  3%|▎         | 98/3753 [07:30<5:01:28,  4.95s/it]  3%|▎         | 99/3753 [07:33<4:33:54,  4.50s/it]  3%|▎         | 100/3753 [07:37<4:19:17,  4.26s/it]{'loss': 2.2799, 'grad_norm': 1566.7110595703125, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 1.2893656492233276, 'mean_ratio_rejected': 1.6407655477523804, 'weight_chosen': 0.5008760094642639, 'weight_rejected': 0.14414885640144348, 'kl_term_chosen': 0.1270751953125, 'epoch': 0.02664890073284477}
                                                    {'loss': 2.2799, 'grad_norm': 1566.7110595703125, 'learning_rate': 2.632978723404255e-07, 'mean_ratio_chosen': 1.2893656492233276, 'mean_ratio_rejected': 1.6407655477523804, 'weight_chosen': 0.5008760094642639, 'weight_rejected': 0.14414885640144348, 'kl_term_chosen': 0.1270751953125, 'epoch': 0.03}
  3%|▎         | 100/3753 [07:37<4:19:17,  4.26s/it]  3%|▎         | 101/3753 [07:42<4:23:08,  4.32s/it]  3%|▎         | 102/3753 [07:46<4:19:36,  4.27s/it]  3%|▎         | 103/3753 [07:49<4:09:38,  4.10s/it]  3%|▎         | 104/3753 [07:55<4:38:06,  4.57s/it]  3%|▎         | 105/3753 [07:59<4:30:54,  4.46s/it]  3%|▎         | 106/3753 [08:05<4:46:50,  4.72s/it]  3%|▎         | 107/3753 [08:09<4:45:20,  4.70s/it]  3%|▎         | 108/3753 [08:13<4:32:46,  4.49s/it]  3%|▎         | 109/3753 [08:17<4:22:33,  4.32s/it]  3%|▎         | 110/3753 [08:21<4:15:19,  4.21s/it]{'loss': 0.9857, 'grad_norm': 1383.0955810546875, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 5.430668830871582, 'weight_chosen': -0.7412917613983154, 'weight_rejected': 0.04146226868033409, 'kl_term_chosen': 1.65496826171875, 'epoch': 0.029313790806129246}
                                                    {'loss': 0.9857, 'grad_norm': 1383.0955810546875, 'learning_rate': 2.8989361702127657e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 5.430668830871582, 'weight_chosen': -0.7412917613983154, 'weight_rejected': 0.04146226868033409, 'kl_term_chosen': 1.65496826171875, 'epoch': 0.03}
  3%|▎         | 110/3753 [08:21<4:15:19,  4.21s/it]  3%|▎         | 111/3753 [08:27<4:41:26,  4.64s/it]  3%|▎         | 112/3753 [08:30<4:23:11,  4.34s/it]  3%|▎         | 113/3753 [08:34<4:04:24,  4.03s/it]  3%|▎         | 114/3753 [08:37<3:55:50,  3.89s/it]  3%|▎         | 115/3753 [08:41<3:54:05,  3.86s/it]  3%|▎         | 116/3753 [08:46<4:08:25,  4.10s/it]  3%|▎         | 117/3753 [08:50<4:07:14,  4.08s/it]  3%|▎         | 118/3753 [08:54<4:12:21,  4.17s/it]  3%|▎         | 119/3753 [09:02<5:22:26,  5.32s/it]  3%|▎         | 120/3753 [09:07<5:06:25,  5.06s/it]{'loss': 2.187, 'grad_norm': 1154.80712890625, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 5.999748706817627, 'mean_ratio_rejected': 0.36500823497772217, 'weight_chosen': -0.059304237365722656, 'weight_rejected': 0.49502578377723694, 'kl_term_chosen': 0.8958587646484375, 'epoch': 0.031978680879413725}
                                                    {'loss': 2.187, 'grad_norm': 1154.80712890625, 'learning_rate': 3.1648936170212764e-07, 'mean_ratio_chosen': 5.999748706817627, 'mean_ratio_rejected': 0.36500823497772217, 'weight_chosen': -0.059304237365722656, 'weight_rejected': 0.49502578377723694, 'kl_term_chosen': 0.8958587646484375, 'epoch': 0.03}
  3%|▎         | 120/3753 [09:07<5:06:25,  5.06s/it]  3%|▎         | 121/3753 [09:11<4:52:26,  4.83s/it]  3%|▎         | 122/3753 [09:15<4:49:02,  4.78s/it]  3%|▎         | 123/3753 [09:20<4:38:47,  4.61s/it]  3%|▎         | 124/3753 [09:24<4:24:06,  4.37s/it]  3%|▎         | 125/3753 [09:28<4:32:02,  4.50s/it]  3%|▎         | 126/3753 [09:33<4:39:00,  4.62s/it]  3%|▎         | 127/3753 [09:37<4:21:07,  4.32s/it]  3%|▎         | 128/3753 [09:41<4:27:09,  4.42s/it]  3%|▎         | 129/3753 [09:47<4:50:54,  4.82s/it]  3%|▎         | 130/3753 [09:52<4:45:39,  4.73s/it]{'loss': 0.7313, 'grad_norm': 3700.037109375, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.22315742075443268, 'weight_chosen': -1.0055086612701416, 'weight_rejected': 0.10970578342676163, 'kl_term_chosen': 1.302978515625, 'epoch': 0.034643570952698204}
                                                    {'loss': 0.7313, 'grad_norm': 3700.037109375, 'learning_rate': 3.430851063829787e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.22315742075443268, 'weight_chosen': -1.0055086612701416, 'weight_rejected': 0.10970578342676163, 'kl_term_chosen': 1.302978515625, 'epoch': 0.03}
  3%|▎         | 130/3753 [09:52<4:45:39,  4.73s/it]  3%|▎         | 131/3753 [09:56<4:30:54,  4.49s/it]  4%|▎         | 132/3753 [09:59<4:10:10,  4.15s/it]  4%|▎         | 133/3753 [10:04<4:20:16,  4.31s/it]  4%|▎         | 134/3753 [10:08<4:22:22,  4.35s/it]  4%|▎         | 135/3753 [10:12<4:11:12,  4.17s/it]  4%|▎         | 136/3753 [10:15<3:59:50,  3.98s/it]  4%|▎         | 137/3753 [10:19<3:55:22,  3.91s/it]  4%|▎         | 138/3753 [10:24<4:08:55,  4.13s/it]  4%|▎         | 139/3753 [10:28<4:02:34,  4.03s/it]  4%|▎         | 140/3753 [10:32<4:17:01,  4.27s/it]{'loss': 2.5565, 'grad_norm': 1973.3798828125, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 4.634124755859375, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.09294009208679199, 'weight_rejected': 0.14706450700759888, 'kl_term_chosen': 0.7667236328125, 'epoch': 0.037308461025982675}
                                                    {'loss': 2.5565, 'grad_norm': 1973.3798828125, 'learning_rate': 3.696808510638298e-07, 'mean_ratio_chosen': 4.634124755859375, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.09294009208679199, 'weight_rejected': 0.14706450700759888, 'kl_term_chosen': 0.7667236328125, 'epoch': 0.04}
  4%|▎         | 140/3753 [10:33<4:17:01,  4.27s/it]  4%|▍         | 141/3753 [10:36<4:09:56,  4.15s/it]  4%|▍         | 142/3753 [10:43<4:53:16,  4.87s/it]  4%|▍         | 143/3753 [10:47<4:39:24,  4.64s/it]  4%|▍         | 144/3753 [10:53<5:02:24,  5.03s/it]  4%|▍         | 145/3753 [11:00<5:41:44,  5.68s/it]  4%|▍         | 146/3753 [11:05<5:33:29,  5.55s/it]  4%|▍         | 147/3753 [11:12<5:59:59,  5.99s/it]  4%|▍         | 148/3753 [11:18<5:44:09,  5.73s/it]  4%|▍         | 149/3753 [11:21<5:12:34,  5.20s/it]  4%|▍         | 150/3753 [11:28<5:41:40,  5.69s/it]{'loss': 0.9618, 'grad_norm': 2045.8499755859375, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 0.6469206809997559, 'mean_ratio_rejected': 0.23770937323570251, 'weight_chosen': 0.5532255172729492, 'weight_rejected': 0.5903069972991943, 'kl_term_chosen': -0.21776580810546875, 'epoch': 0.039973351099267154}
                                                    {'loss': 0.9618, 'grad_norm': 2045.8499755859375, 'learning_rate': 3.962765957446808e-07, 'mean_ratio_chosen': 0.6469206809997559, 'mean_ratio_rejected': 0.23770937323570251, 'weight_chosen': 0.5532255172729492, 'weight_rejected': 0.5903069972991943, 'kl_term_chosen': -0.21776580810546875, 'epoch': 0.04}
  4%|▍         | 150/3753 [11:29<5:41:40,  5.69s/it]  4%|▍         | 151/3753 [11:34<5:34:06,  5.57s/it]  4%|▍         | 152/3753 [11:37<5:03:50,  5.06s/it]  4%|▍         | 153/3753 [11:42<5:00:45,  5.01s/it]  4%|▍         | 154/3753 [11:47<4:49:15,  4.82s/it]  4%|▍         | 155/3753 [11:51<4:41:44,  4.70s/it]  4%|▍         | 156/3753 [11:55<4:34:44,  4.58s/it]  4%|▍         | 157/3753 [11:59<4:20:54,  4.35s/it]  4%|▍         | 158/3753 [12:04<4:28:44,  4.49s/it]  4%|▍         | 159/3753 [12:08<4:21:04,  4.36s/it]  4%|▍         | 160/3753 [12:13<4:25:34,  4.43s/it]{'loss': 1.7825, 'grad_norm': 2500.8828125, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 0.48206549882888794, 'mean_ratio_rejected': 2.1290509700775146, 'weight_chosen': 1.044866919517517, 'weight_rejected': 0.3372035324573517, 'kl_term_chosen': -0.364837646484375, 'epoch': 0.04263824117255163}
                                                    {'loss': 1.7825, 'grad_norm': 2500.8828125, 'learning_rate': 4.228723404255319e-07, 'mean_ratio_chosen': 0.48206549882888794, 'mean_ratio_rejected': 2.1290509700775146, 'weight_chosen': 1.044866919517517, 'weight_rejected': 0.3372035324573517, 'kl_term_chosen': -0.364837646484375, 'epoch': 0.04}
  4%|▍         | 160/3753 [12:13<4:25:34,  4.43s/it]  4%|▍         | 161/3753 [12:17<4:18:11,  4.31s/it]  4%|▍         | 162/3753 [12:21<4:15:53,  4.28s/it]  4%|▍         | 163/3753 [12:24<3:59:53,  4.01s/it]  4%|▍         | 164/3753 [12:31<4:49:09,  4.83s/it]  4%|▍         | 165/3753 [12:38<5:20:28,  5.36s/it]  4%|▍         | 166/3753 [12:41<4:48:58,  4.83s/it]  4%|▍         | 167/3753 [12:46<4:50:19,  4.86s/it]  4%|▍         | 168/3753 [12:51<4:55:35,  4.95s/it]  5%|▍         | 169/3753 [12:55<4:28:39,  4.50s/it]  5%|▍         | 170/3753 [12:58<4:06:51,  4.13s/it]{'loss': 7.9363, 'grad_norm': 880.879150390625, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 5.555552959442139, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.014948368072509766, 'weight_rejected': 0.13568955659866333, 'kl_term_chosen': 0.8573989868164062, 'epoch': 0.04530313124583611}
                                                    {'loss': 7.9363, 'grad_norm': 880.879150390625, 'learning_rate': 4.4946808510638295e-07, 'mean_ratio_chosen': 5.555552959442139, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 0.014948368072509766, 'weight_rejected': 0.13568955659866333, 'kl_term_chosen': 0.8573989868164062, 'epoch': 0.05}
  5%|▍         | 170/3753 [12:58<4:06:51,  4.13s/it]  5%|▍         | 171/3753 [13:03<4:13:52,  4.25s/it]  5%|▍         | 172/3753 [13:11<5:34:56,  5.61s/it]  5%|▍         | 173/3753 [13:15<4:59:59,  5.03s/it]  5%|▍         | 174/3753 [13:19<4:47:50,  4.83s/it]  5%|▍         | 175/3753 [13:24<4:40:42,  4.71s/it]  5%|▍         | 176/3753 [13:28<4:21:45,  4.39s/it]  5%|▍         | 177/3753 [13:32<4:24:17,  4.43s/it]  5%|▍         | 178/3753 [13:37<4:30:43,  4.54s/it]  5%|▍         | 179/3753 [13:40<4:12:59,  4.25s/it]  5%|▍         | 180/3753 [13:45<4:11:43,  4.23s/it]{'loss': 14.4468, 'grad_norm': 3626.477783203125, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.1625539064407349, 'weight_rejected': 0.09268777817487717, 'kl_term_chosen': 2.097900390625, 'epoch': 0.047968021319120584}
                                                    {'loss': 14.4468, 'grad_norm': 3626.477783203125, 'learning_rate': 4.76063829787234e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -1.1625539064407349, 'weight_rejected': 0.09268777817487717, 'kl_term_chosen': 2.097900390625, 'epoch': 0.05}
  5%|▍         | 180/3753 [13:45<4:11:43,  4.23s/it]  5%|▍         | 181/3753 [13:49<4:17:38,  4.33s/it]  5%|▍         | 182/3753 [13:56<5:08:30,  5.18s/it]  5%|▍         | 183/3753 [14:01<4:57:26,  5.00s/it]  5%|▍         | 184/3753 [14:06<5:05:03,  5.13s/it]  5%|▍         | 185/3753 [14:11<5:00:36,  5.06s/it]  5%|▍         | 186/3753 [14:15<4:42:11,  4.75s/it]  5%|▍         | 187/3753 [14:19<4:27:50,  4.51s/it]  5%|▌         | 188/3753 [14:23<4:22:38,  4.42s/it]  5%|▌         | 189/3753 [14:30<5:08:53,  5.20s/it]  5%|▌         | 190/3753 [14:35<4:53:07,  4.94s/it]{'loss': 10.4806, 'grad_norm': 819.0878295898438, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.9102603197097778, 'weight_chosen': -2.3796398639678955, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 3.26043701171875, 'epoch': 0.05063291139240506}
                                                    {'loss': 10.4806, 'grad_norm': 819.0878295898438, 'learning_rate': 5.026595744680851e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.9102603197097778, 'weight_chosen': -2.3796398639678955, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 3.26043701171875, 'epoch': 0.05}
  5%|▌         | 190/3753 [14:35<4:53:07,  4.94s/it]  5%|▌         | 191/3753 [14:38<4:30:52,  4.56s/it]  5%|▌         | 192/3753 [14:46<5:21:40,  5.42s/it]  5%|▌         | 193/3753 [14:50<5:02:36,  5.10s/it]  5%|▌         | 194/3753 [14:55<5:03:24,  5.12s/it]  5%|▌         | 195/3753 [15:00<4:45:55,  4.82s/it]  5%|▌         | 196/3753 [15:03<4:22:14,  4.42s/it]  5%|▌         | 197/3753 [15:12<5:37:39,  5.70s/it]  5%|▌         | 198/3753 [15:16<5:06:35,  5.17s/it]  5%|▌         | 199/3753 [15:21<5:14:18,  5.31s/it]  5%|▌         | 200/3753 [15:25<4:55:26,  4.99s/it]{'loss': 11.9473, 'grad_norm': 723.9896240234375, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.6972979307174683, 'weight_chosen': -4.32035493850708, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 5.263702392578125, 'epoch': 0.05329780146568954}
                                                    {'loss': 11.9473, 'grad_norm': 723.9896240234375, 'learning_rate': 5.292553191489362e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.6972979307174683, 'weight_chosen': -4.32035493850708, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': 5.263702392578125, 'epoch': 0.05}
  5%|▌         | 200/3753 [15:26<4:55:26,  4.99s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
  5%|▌         | 201/3753 [16:27<21:45:17, 22.05s/it]  5%|▌         | 202/3753 [16:31<16:18:30, 16.53s/it]  5%|▌         | 203/3753 [16:36<12:50:46, 13.03s/it]  5%|▌         | 204/3753 [16:40<10:07:02, 10.26s/it]  5%|▌         | 205/3753 [16:44<8:12:55,  8.34s/it]   5%|▌         | 206/3753 [16:51<7:50:19,  7.96s/it]  6%|▌         | 207/3753 [16:55<6:39:30,  6.76s/it]  6%|▌         | 208/3753 [17:00<6:14:36,  6.34s/it]  6%|▌         | 209/3753 [17:05<5:53:22,  5.98s/it]  6%|▌         | 210/3753 [17:10<5:26:23,  5.53s/it]{'loss': 9.6528, 'grad_norm': 1271.21875, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 7.969749450683594, 'mean_ratio_rejected': 6.425407886505127, 'weight_chosen': -0.21908974647521973, 'weight_rejected': 0.15304215252399445, 'kl_term_chosen': 1.0378265380859375, 'epoch': 0.05596269153897402}
                                                    {'loss': 9.6528, 'grad_norm': 1271.21875, 'learning_rate': 5.558510638297872e-07, 'mean_ratio_chosen': 7.969749450683594, 'mean_ratio_rejected': 6.425407886505127, 'weight_chosen': -0.21908974647521973, 'weight_rejected': 0.15304215252399445, 'kl_term_chosen': 1.0378265380859375, 'epoch': 0.06}
  6%|▌         | 210/3753 [17:10<5:26:23,  5.53s/it]  6%|▌         | 211/3753 [17:15<5:24:03,  5.49s/it]  6%|▌         | 212/3753 [17:19<4:52:21,  4.95s/it]  6%|▌         | 213/3753 [17:23<4:45:27,  4.84s/it]  6%|▌         | 214/3753 [17:29<4:59:55,  5.09s/it]  6%|▌         | 215/3753 [17:33<4:44:32,  4.83s/it]  6%|▌         | 216/3753 [17:37<4:37:03,  4.70s/it]  6%|▌         | 217/3753 [17:41<4:18:29,  4.39s/it]  6%|▌         | 218/3753 [17:46<4:29:14,  4.57s/it]  6%|▌         | 219/3753 [17:50<4:12:07,  4.28s/it]  6%|▌         | 220/3753 [17:54<4:02:49,  4.12s/it]{'loss': 10.0801, 'grad_norm': 2394.1640625, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 3.6926732063293457, 'mean_ratio_rejected': 1.816078782081604, 'weight_chosen': 0.028551459312438965, 'weight_rejected': 0.1200256198644638, 'kl_term_chosen': 0.6531753540039062, 'epoch': 0.05862758161225849}
                                                    {'loss': 10.0801, 'grad_norm': 2394.1640625, 'learning_rate': 5.824468085106384e-07, 'mean_ratio_chosen': 3.6926732063293457, 'mean_ratio_rejected': 1.816078782081604, 'weight_chosen': 0.028551459312438965, 'weight_rejected': 0.1200256198644638, 'kl_term_chosen': 0.6531753540039062, 'epoch': 0.06}
  6%|▌         | 220/3753 [17:54<4:02:49,  4.12s/it]  6%|▌         | 221/3753 [17:57<3:59:13,  4.06s/it]  6%|▌         | 222/3753 [18:02<4:02:38,  4.12s/it]  6%|▌         | 223/3753 [18:05<3:55:57,  4.01s/it]  6%|▌         | 224/3753 [18:09<3:52:23,  3.95s/it]  6%|▌         | 225/3753 [18:13<3:56:51,  4.03s/it]  6%|▌         | 226/3753 [18:17<3:54:40,  3.99s/it]  6%|▌         | 227/3753 [18:23<4:20:23,  4.43s/it]  6%|▌         | 228/3753 [18:26<4:01:13,  4.11s/it]  6%|▌         | 229/3753 [18:31<4:20:16,  4.43s/it]  6%|▌         | 230/3753 [18:38<4:59:22,  5.10s/it]{'loss': 10.185, 'grad_norm': 757.6350708007812, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.066237449645996, 'weight_rejected': 0.1490352898836136, 'kl_term_chosen': 5.003448486328125, 'epoch': 0.06129247168554297}
                                                    {'loss': 10.185, 'grad_norm': 757.6350708007812, 'learning_rate': 6.090425531914894e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.066237449645996, 'weight_rejected': 0.1490352898836136, 'kl_term_chosen': 5.003448486328125, 'epoch': 0.06}
  6%|▌         | 230/3753 [18:38<4:59:22,  5.10s/it]  6%|▌         | 231/3753 [18:44<5:09:21,  5.27s/it]  6%|▌         | 232/3753 [18:48<4:52:12,  4.98s/it]  6%|▌         | 233/3753 [18:53<4:51:20,  4.97s/it]  6%|▌         | 234/3753 [18:58<5:01:44,  5.14s/it]  6%|▋         | 235/3753 [19:07<5:56:23,  6.08s/it]  6%|▋         | 236/3753 [19:11<5:21:32,  5.49s/it]  6%|▋         | 237/3753 [19:14<4:45:56,  4.88s/it]  6%|▋         | 238/3753 [19:19<4:38:53,  4.76s/it]  6%|▋         | 239/3753 [19:24<4:41:23,  4.80s/it]  6%|▋         | 240/3753 [19:29<4:44:39,  4.86s/it]{'loss': 10.6306, 'grad_norm': 1257.616943359375, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -4.341891765594482, 'weight_rejected': 0.17781086266040802, 'kl_term_chosen': 5.17303466796875, 'epoch': 0.06395736175882745}
                                                    {'loss': 10.6306, 'grad_norm': 1257.616943359375, 'learning_rate': 6.356382978723404e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -4.341891765594482, 'weight_rejected': 0.17781086266040802, 'kl_term_chosen': 5.17303466796875, 'epoch': 0.06}
  6%|▋         | 240/3753 [19:29<4:44:39,  4.86s/it]  6%|▋         | 241/3753 [19:33<4:30:14,  4.62s/it]  6%|▋         | 242/3753 [19:37<4:21:37,  4.47s/it]  6%|▋         | 243/3753 [19:41<4:21:06,  4.46s/it]  7%|▋         | 244/3753 [19:47<4:47:50,  4.92s/it]  7%|▋         | 245/3753 [19:51<4:33:15,  4.67s/it]  7%|▋         | 246/3753 [19:55<4:20:28,  4.46s/it]  7%|▋         | 247/3753 [20:02<5:02:42,  5.18s/it]  7%|▋         | 248/3753 [20:07<4:59:46,  5.13s/it]  7%|▋         | 249/3753 [20:12<4:59:30,  5.13s/it]  7%|▋         | 250/3753 [20:18<5:05:35,  5.23s/it]{'loss': 11.8902, 'grad_norm': 1449.1619873046875, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.196500062942505, 'weight_chosen': -0.419968843460083, 'weight_rejected': 0.14804719388484955, 'kl_term_chosen': 1.31475830078125, 'epoch': 0.06662225183211193}
                                                    {'loss': 11.8902, 'grad_norm': 1449.1619873046875, 'learning_rate': 6.622340425531915e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 2.196500062942505, 'weight_chosen': -0.419968843460083, 'weight_rejected': 0.14804719388484955, 'kl_term_chosen': 1.31475830078125, 'epoch': 0.07}
  7%|▋         | 250/3753 [20:18<5:05:35,  5.23s/it]  7%|▋         | 251/3753 [20:24<5:29:13,  5.64s/it]  7%|▋         | 252/3753 [20:30<5:21:04,  5.50s/it]  7%|▋         | 253/3753 [20:34<5:06:54,  5.26s/it]  7%|▋         | 254/3753 [20:38<4:35:36,  4.73s/it]  7%|▋         | 255/3753 [20:42<4:24:55,  4.54s/it]  7%|▋         | 256/3753 [20:46<4:08:31,  4.26s/it]  7%|▋         | 257/3753 [20:50<4:18:10,  4.43s/it]  7%|▋         | 258/3753 [20:54<4:06:19,  4.23s/it]  7%|▋         | 259/3753 [20:58<3:54:21,  4.02s/it]  7%|▋         | 260/3753 [21:02<4:04:29,  4.20s/it]{'loss': 18.52, 'grad_norm': 844.487548828125, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 0.19556421041488647, 'mean_ratio_rejected': 0.29992246627807617, 'weight_chosen': 1.7031378746032715, 'weight_rejected': 0.13386748731136322, 'kl_term_chosen': -0.8159332275390625, 'epoch': 0.06928714190539641}
                                                    {'loss': 18.52, 'grad_norm': 844.487548828125, 'learning_rate': 6.888297872340425e-07, 'mean_ratio_chosen': 0.19556421041488647, 'mean_ratio_rejected': 0.29992246627807617, 'weight_chosen': 1.7031378746032715, 'weight_rejected': 0.13386748731136322, 'kl_term_chosen': -0.8159332275390625, 'epoch': 0.07}
  7%|▋         | 260/3753 [21:02<4:04:29,  4.20s/it]  7%|▋         | 261/3753 [21:07<4:11:48,  4.33s/it]  7%|▋         | 262/3753 [21:11<4:14:04,  4.37s/it]  7%|▋         | 263/3753 [21:16<4:20:47,  4.48s/it]  7%|▋         | 264/3753 [21:20<4:09:54,  4.30s/it]  7%|▋         | 265/3753 [21:24<4:05:20,  4.22s/it]  7%|▋         | 266/3753 [21:28<3:57:21,  4.08s/it]  7%|▋         | 267/3753 [21:32<3:56:20,  4.07s/it]  7%|▋         | 268/3753 [21:37<4:14:45,  4.39s/it]  7%|▋         | 269/3753 [21:40<3:59:38,  4.13s/it]  7%|▋         | 270/3753 [21:45<4:05:52,  4.24s/it]{'loss': 5.6853, 'grad_norm': 1257.4979248046875, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 0.5347062945365906, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.2885956764221191, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': -0.313018798828125, 'epoch': 0.07195203197868089}
                                                    {'loss': 5.6853, 'grad_norm': 1257.4979248046875, 'learning_rate': 7.154255319148937e-07, 'mean_ratio_chosen': 0.5347062945365906, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 1.2885956764221191, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': -0.313018798828125, 'epoch': 0.07}
  7%|▋         | 270/3753 [21:45<4:05:52,  4.24s/it]  7%|▋         | 271/3753 [21:49<4:10:40,  4.32s/it]  7%|▋         | 272/3753 [21:54<4:12:21,  4.35s/it]  7%|▋         | 273/3753 [21:58<4:05:17,  4.23s/it]  7%|▋         | 274/3753 [22:02<4:00:44,  4.15s/it]  7%|▋         | 275/3753 [22:06<3:56:13,  4.08s/it]  7%|▋         | 276/3753 [22:09<3:47:45,  3.93s/it]  7%|▋         | 277/3753 [22:14<4:09:32,  4.31s/it]  7%|▋         | 278/3753 [22:18<3:56:40,  4.09s/it]  7%|▋         | 279/3753 [22:23<4:10:06,  4.32s/it]  7%|▋         | 280/3753 [22:28<4:21:42,  4.52s/it]{'loss': 7.2341, 'grad_norm': 1232.1624755859375, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 8.198931694030762, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.12154370546340942, 'weight_rejected': 0.07263670116662979, 'kl_term_chosen': 1.052001953125, 'epoch': 0.07461692205196535}
                                                    {'loss': 7.2341, 'grad_norm': 1232.1624755859375, 'learning_rate': 7.420212765957447e-07, 'mean_ratio_chosen': 8.198931694030762, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -0.12154370546340942, 'weight_rejected': 0.07263670116662979, 'kl_term_chosen': 1.052001953125, 'epoch': 0.07}
  7%|▋         | 280/3753 [22:28<4:21:42,  4.52s/it]  7%|▋         | 281/3753 [22:32<4:12:31,  4.36s/it]  8%|▊         | 282/3753 [22:38<4:38:14,  4.81s/it]  8%|▊         | 283/3753 [22:42<4:29:50,  4.67s/it]  8%|▊         | 284/3753 [22:47<4:26:59,  4.62s/it]  8%|▊         | 285/3753 [22:54<5:15:20,  5.46s/it]  8%|▊         | 286/3753 [22:58<4:49:02,  5.00s/it]  8%|▊         | 287/3753 [23:02<4:29:50,  4.67s/it]  8%|▊         | 288/3753 [23:11<5:40:17,  5.89s/it]  8%|▊         | 289/3753 [23:16<5:25:46,  5.64s/it]  8%|▊         | 290/3753 [23:24<6:20:28,  6.59s/it]{'loss': 6.6102, 'grad_norm': 1863.6885986328125, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 9.057820320129395, 'mean_ratio_rejected': 0.24628260731697083, 'weight_chosen': -0.34834760427474976, 'weight_rejected': 0.20946967601776123, 'kl_term_chosen': 1.1018142700195312, 'epoch': 0.07728181212524983}
                                                    {'loss': 6.6102, 'grad_norm': 1863.6885986328125, 'learning_rate': 7.686170212765957e-07, 'mean_ratio_chosen': 9.057820320129395, 'mean_ratio_rejected': 0.24628260731697083, 'weight_chosen': -0.34834760427474976, 'weight_rejected': 0.20946967601776123, 'kl_term_chosen': 1.1018142700195312, 'epoch': 0.08}
  8%|▊         | 290/3753 [23:25<6:20:28,  6.59s/it]  8%|▊         | 291/3753 [23:28<5:34:33,  5.80s/it]  8%|▊         | 292/3753 [23:34<5:37:49,  5.86s/it]  8%|▊         | 293/3753 [23:38<4:59:36,  5.20s/it]  8%|▊         | 294/3753 [23:42<4:39:31,  4.85s/it]  8%|▊         | 295/3753 [23:47<4:45:04,  4.95s/it]  8%|▊         | 296/3753 [23:51<4:27:44,  4.65s/it]  8%|▊         | 297/3753 [23:56<4:28:26,  4.66s/it]  8%|▊         | 298/3753 [24:02<4:46:06,  4.97s/it]  8%|▊         | 299/3753 [24:06<4:34:27,  4.77s/it]  8%|▊         | 300/3753 [24:10<4:24:30,  4.60s/it]{'loss': 10.0292, 'grad_norm': 1122.18701171875, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.314887046813965, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 5.2390289306640625, 'epoch': 0.07994670219853431}
                                                    {'loss': 10.0292, 'grad_norm': 1122.18701171875, 'learning_rate': 7.952127659574468e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.314887046813965, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 5.2390289306640625, 'epoch': 0.08}
  8%|▊         | 300/3753 [24:10<4:24:30,  4.60s/it]  8%|▊         | 301/3753 [24:14<4:19:45,  4.51s/it]  8%|▊         | 302/3753 [24:20<4:30:46,  4.71s/it]  8%|▊         | 303/3753 [24:24<4:30:09,  4.70s/it]  8%|▊         | 304/3753 [24:27<4:02:08,  4.21s/it]  8%|▊         | 305/3753 [24:31<3:57:04,  4.13s/it]  8%|▊         | 306/3753 [24:35<3:58:01,  4.14s/it]  8%|▊         | 307/3753 [24:40<4:09:31,  4.34s/it]  8%|▊         | 308/3753 [24:46<4:35:30,  4.80s/it]  8%|▊         | 309/3753 [24:51<4:30:18,  4.71s/it]  8%|▊         | 310/3753 [24:55<4:18:02,  4.50s/it]{'loss': 15.2161, 'grad_norm': 681.5027465820312, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.275477886199951, 'weight_rejected': 0.22815649211406708, 'kl_term_chosen': -3.6118087768554688, 'epoch': 0.08261159227181879}
                                                    {'loss': 15.2161, 'grad_norm': 681.5027465820312, 'learning_rate': 8.218085106382978e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.275477886199951, 'weight_rejected': 0.22815649211406708, 'kl_term_chosen': -3.6118087768554688, 'epoch': 0.08}
  8%|▊         | 310/3753 [24:55<4:18:02,  4.50s/it]  8%|▊         | 311/3753 [24:59<4:14:57,  4.44s/it]  8%|▊         | 312/3753 [25:03<4:11:58,  4.39s/it]  8%|▊         | 313/3753 [25:08<4:13:50,  4.43s/it]  8%|▊         | 314/3753 [25:15<5:02:07,  5.27s/it]  8%|▊         | 315/3753 [25:19<4:34:24,  4.79s/it]  8%|▊         | 316/3753 [25:22<4:14:16,  4.44s/it]  8%|▊         | 317/3753 [25:26<4:07:49,  4.33s/it]  8%|▊         | 318/3753 [25:31<4:16:42,  4.48s/it]  8%|▊         | 319/3753 [25:35<4:11:14,  4.39s/it]  9%|▊         | 320/3753 [25:40<4:17:53,  4.51s/it]{'loss': 20.4178, 'grad_norm': 332.6126708984375, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.341689348220825, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': 3.278900146484375, 'epoch': 0.08527648234510327}
                                                    {'loss': 20.4178, 'grad_norm': 332.6126708984375, 'learning_rate': 8.48404255319149e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -2.341689348220825, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': 3.278900146484375, 'epoch': 0.09}
  9%|▊         | 320/3753 [25:40<4:17:53,  4.51s/it]  9%|▊         | 321/3753 [25:45<4:19:20,  4.53s/it]  9%|▊         | 322/3753 [25:49<4:07:40,  4.33s/it]  9%|▊         | 323/3753 [25:52<3:56:38,  4.14s/it]  9%|▊         | 324/3753 [26:00<4:52:17,  5.11s/it]  9%|▊         | 325/3753 [26:04<4:44:51,  4.99s/it]  9%|▊         | 326/3753 [26:08<4:20:58,  4.57s/it]  9%|▊         | 327/3753 [26:12<4:11:48,  4.41s/it]  9%|▊         | 328/3753 [26:16<4:04:13,  4.28s/it]  9%|▉         | 329/3753 [26:20<4:08:52,  4.36s/it]  9%|▉         | 330/3753 [26:26<4:20:56,  4.57s/it]{'loss': 29.9287, 'grad_norm': 574.8649291992188, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 5.366734027862549, 'weight_rejected': 0.22135066986083984, 'kl_term_chosen': -4.505195617675781, 'epoch': 0.08794137241838774}
                                                    {'loss': 29.9287, 'grad_norm': 574.8649291992188, 'learning_rate': 8.75e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 5.366734027862549, 'weight_rejected': 0.22135066986083984, 'kl_term_chosen': -4.505195617675781, 'epoch': 0.09}
  9%|▉         | 330/3753 [26:26<4:20:56,  4.57s/it]  9%|▉         | 331/3753 [26:30<4:12:23,  4.43s/it]  9%|▉         | 332/3753 [26:33<4:02:44,  4.26s/it]  9%|▉         | 333/3753 [26:38<4:03:48,  4.28s/it]  9%|▉         | 334/3753 [26:46<5:04:17,  5.34s/it]  9%|▉         | 335/3753 [26:50<4:55:58,  5.20s/it]  9%|▉         | 336/3753 [26:54<4:33:12,  4.80s/it]  9%|▉         | 337/3753 [26:59<4:28:57,  4.72s/it]  9%|▉         | 338/3753 [27:02<4:06:28,  4.33s/it]  9%|▉         | 339/3753 [27:06<3:53:37,  4.11s/it]  9%|▉         | 340/3753 [27:10<3:59:58,  4.22s/it]{'loss': 30.0276, 'grad_norm': 344.8683166503906, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 7.6732497215271, 'weight_rejected': 0.7826625108718872, 'kl_term_chosen': -7.429607391357422, 'epoch': 0.09060626249167222}
                                                    {'loss': 30.0276, 'grad_norm': 344.8683166503906, 'learning_rate': 9.01595744680851e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 7.6732497215271, 'weight_rejected': 0.7826625108718872, 'kl_term_chosen': -7.429607391357422, 'epoch': 0.09}
  9%|▉         | 340/3753 [27:10<3:59:58,  4.22s/it]  9%|▉         | 341/3753 [27:14<3:54:47,  4.13s/it]  9%|▉         | 342/3753 [27:18<3:55:12,  4.14s/it]  9%|▉         | 343/3753 [27:23<4:01:01,  4.24s/it]  9%|▉         | 344/3753 [27:27<3:53:47,  4.11s/it]  9%|▉         | 345/3753 [27:32<4:18:48,  4.56s/it]  9%|▉         | 346/3753 [27:37<4:13:11,  4.46s/it]  9%|▉         | 347/3753 [27:41<4:17:13,  4.53s/it]  9%|▉         | 348/3753 [27:46<4:28:42,  4.73s/it]  9%|▉         | 349/3753 [27:50<4:08:10,  4.37s/it]  9%|▉         | 350/3753 [27:54<4:09:27,  4.40s/it]{'loss': 77.3737, 'grad_norm': 469.96160888671875, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.217717170715332, 'weight_rejected': 0.2186693549156189, 'kl_term_chosen': 6.0521240234375, 'epoch': 0.09327115256495669}
                                                    {'loss': 77.3737, 'grad_norm': 469.96160888671875, 'learning_rate': 9.281914893617021e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -5.217717170715332, 'weight_rejected': 0.2186693549156189, 'kl_term_chosen': 6.0521240234375, 'epoch': 0.09}
  9%|▉         | 350/3753 [27:55<4:09:27,  4.40s/it]  9%|▉         | 351/3753 [27:59<4:03:28,  4.29s/it]  9%|▉         | 352/3753 [28:02<3:49:19,  4.05s/it]  9%|▉         | 353/3753 [28:06<3:54:06,  4.13s/it]  9%|▉         | 354/3753 [28:11<3:56:09,  4.17s/it]  9%|▉         | 355/3753 [28:16<4:25:51,  4.69s/it]  9%|▉         | 356/3753 [28:21<4:19:15,  4.58s/it] 10%|▉         | 357/3753 [28:25<4:15:25,  4.51s/it] 10%|▉         | 358/3753 [28:30<4:14:46,  4.50s/it] 10%|▉         | 359/3753 [28:34<4:11:27,  4.45s/it] 10%|▉         | 360/3753 [28:38<3:56:45,  4.19s/it]{'loss': 80.6535, 'grad_norm': 142.6949920654297, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.1798350811004639, 'weight_chosen': -17.91190528869629, 'weight_rejected': 0.16667540371418, 'kl_term_chosen': 18.456222534179688, 'epoch': 0.09593604263824117}
                                                    {'loss': 80.6535, 'grad_norm': 142.6949920654297, 'learning_rate': 9.54787234042553e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 1.1798350811004639, 'weight_chosen': -17.91190528869629, 'weight_rejected': 0.16667540371418, 'kl_term_chosen': 18.456222534179688, 'epoch': 0.1}
 10%|▉         | 360/3753 [28:38<3:56:45,  4.19s/it] 10%|▉         | 361/3753 [28:42<4:01:32,  4.27s/it] 10%|▉         | 362/3753 [28:46<4:02:49,  4.30s/it] 10%|▉         | 363/3753 [28:51<4:02:57,  4.30s/it] 10%|▉         | 364/3753 [28:55<4:09:43,  4.42s/it] 10%|▉         | 365/3753 [28:59<3:54:51,  4.16s/it] 10%|▉         | 366/3753 [29:02<3:40:33,  3.91s/it] 10%|▉         | 367/3753 [29:06<3:44:19,  3.97s/it] 10%|▉         | 368/3753 [29:11<3:58:08,  4.22s/it] 10%|▉         | 369/3753 [29:16<4:05:39,  4.36s/it] 10%|▉         | 370/3753 [29:20<4:07:03,  4.38s/it]{'loss': 44.8928, 'grad_norm': 1110.4146728515625, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.7472221851348877, 'weight_rejected': 0.20561504364013672, 'kl_term_chosen': -1.8829116821289062, 'epoch': 0.09860093271152565}
                                                    {'loss': 44.8928, 'grad_norm': 1110.4146728515625, 'learning_rate': 9.813829787234042e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.7472221851348877, 'weight_rejected': 0.20561504364013672, 'kl_term_chosen': -1.8829116821289062, 'epoch': 0.1}
 10%|▉         | 370/3753 [29:20<4:07:03,  4.38s/it] 10%|▉         | 371/3753 [29:24<3:51:34,  4.11s/it] 10%|▉         | 372/3753 [29:28<3:58:50,  4.24s/it] 10%|▉         | 373/3753 [29:32<3:53:18,  4.14s/it] 10%|▉         | 374/3753 [29:40<4:46:33,  5.09s/it] 10%|▉         | 375/3753 [29:45<4:55:01,  5.24s/it] 10%|█         | 376/3753 [29:54<6:00:12,  6.40s/it] 10%|█         | 377/3753 [30:01<5:58:39,  6.37s/it] 10%|█         | 378/3753 [30:04<5:11:40,  5.54s/it] 10%|█         | 379/3753 [30:08<4:42:45,  5.03s/it] 10%|█         | 380/3753 [30:13<4:41:20,  5.00s/it]{'loss': 47.8692, 'grad_norm': 120.00444793701172, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.330761432647705, 'weight_rejected': 0.02595735713839531, 'kl_term_chosen': 5.2911224365234375, 'epoch': 0.10126582278481013}
                                                    {'loss': 47.8692, 'grad_norm': 120.00444793701172, 'learning_rate': 9.999980527583044e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.330761432647705, 'weight_rejected': 0.02595735713839531, 'kl_term_chosen': 5.2911224365234375, 'epoch': 0.1}
 10%|█         | 380/3753 [30:13<4:41:20,  5.00s/it] 10%|█         | 381/3753 [30:17<4:29:10,  4.79s/it] 10%|█         | 382/3753 [30:22<4:26:40,  4.75s/it] 10%|█         | 383/3753 [30:26<4:10:47,  4.47s/it] 10%|█         | 384/3753 [30:31<4:22:42,  4.68s/it] 10%|█         | 385/3753 [30:41<5:57:13,  6.36s/it] 10%|█         | 386/3753 [30:45<5:08:43,  5.50s/it] 10%|█         | 387/3753 [30:49<4:50:59,  5.19s/it] 10%|█         | 388/3753 [30:54<4:39:23,  4.98s/it] 10%|█         | 389/3753 [30:58<4:30:09,  4.82s/it] 10%|█         | 390/3753 [31:04<4:52:01,  5.21s/it]{'loss': 47.0894, 'grad_norm': 354.687744140625, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.32224154472351074, 'weight_chosen': 2.420863628387451, 'weight_rejected': 0.8164063692092896, 'kl_term_chosen': -1.7820281982421875, 'epoch': 0.1039307128580946}
                                                    {'loss': 47.0894, 'grad_norm': 354.687744140625, 'learning_rate': 9.999634355500922e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.32224154472351074, 'weight_chosen': 2.420863628387451, 'weight_rejected': 0.8164063692092896, 'kl_term_chosen': -1.7820281982421875, 'epoch': 0.1}
 10%|█         | 390/3753 [31:04<4:52:01,  5.21s/it] 10%|█         | 391/3753 [31:09<4:43:04,  5.05s/it] 10%|█         | 392/3753 [31:13<4:24:29,  4.72s/it] 10%|█         | 393/3753 [31:18<4:29:01,  4.80s/it] 10%|█         | 394/3753 [31:22<4:18:05,  4.61s/it] 11%|█         | 395/3753 [31:27<4:18:15,  4.61s/it] 11%|█         | 396/3753 [31:36<5:31:47,  5.93s/it] 11%|█         | 397/3753 [31:39<4:49:44,  5.18s/it] 11%|█         | 398/3753 [31:45<4:55:50,  5.29s/it] 11%|█         | 399/3753 [31:51<5:07:49,  5.51s/it] 11%|█         | 400/3753 [31:55<4:45:14,  5.10s/it]{'loss': 77.4223, 'grad_norm': 770.4779052734375, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.599851608276367, 'weight_rejected': 0.25091278553009033, 'kl_term_chosen': 5.29498291015625, 'epoch': 0.10659560293137908}
                                                    {'loss': 77.4223, 'grad_norm': 770.4779052734375, 'learning_rate': 9.998855497526103e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -4.599851608276367, 'weight_rejected': 0.25091278553009033, 'kl_term_chosen': 5.29498291015625, 'epoch': 0.11}
 11%|█         | 400/3753 [31:55<4:45:14,  5.10s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 11%|█         | 401/3753 [32:54<19:53:31, 21.36s/it] 11%|█         | 402/3753 [32:59<15:14:24, 16.37s/it] 11%|█         | 403/3753 [33:02<11:34:49, 12.44s/it] 11%|█         | 404/3753 [33:06<9:14:19,  9.93s/it]  11%|█         | 405/3753 [33:11<7:57:52,  8.56s/it] 11%|█         | 406/3753 [33:16<6:46:54,  7.29s/it] 11%|█         | 407/3753 [33:20<5:48:11,  6.24s/it] 11%|█         | 408/3753 [33:25<5:28:29,  5.89s/it] 11%|█         | 409/3753 [33:29<4:56:21,  5.32s/it] 11%|█         | 410/3753 [33:33<4:39:19,  5.01s/it]{'loss': 95.2377, 'grad_norm': 254.20455932617188, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 12.217577934265137, 'weight_rejected': 0.28776782751083374, 'kl_term_chosen': -11.570671081542969, 'epoch': 0.10926049300466356}
                                                    {'loss': 95.2377, 'grad_norm': 254.20455932617188, 'learning_rate': 9.997644021063695e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 12.217577934265137, 'weight_rejected': 0.28776782751083374, 'kl_term_chosen': -11.570671081542969, 'epoch': 0.11}
 11%|█         | 410/3753 [33:33<4:39:19,  5.01s/it] 11%|█         | 411/3753 [33:38<4:41:59,  5.06s/it] 11%|█         | 412/3753 [33:42<4:22:31,  4.71s/it] 11%|█         | 413/3753 [33:48<4:36:45,  4.97s/it] 11%|█         | 414/3753 [33:53<4:37:05,  4.98s/it] 11%|█         | 415/3753 [33:56<4:18:38,  4.65s/it] 11%|█         | 416/3753 [34:01<4:16:17,  4.61s/it] 11%|█         | 417/3753 [34:05<4:05:31,  4.42s/it] 11%|█         | 418/3753 [34:09<3:57:33,  4.27s/it] 11%|█         | 419/3753 [34:13<3:52:08,  4.18s/it] 11%|█         | 420/3753 [34:17<3:47:57,  4.10s/it]{'loss': 57.899, 'grad_norm': 505.07281494140625, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -14.447522163391113, 'weight_rejected': 0.2727987766265869, 'kl_term_chosen': 15.098876953125, 'epoch': 0.11192538307794804}
                                                    {'loss': 57.899, 'grad_norm': 505.07281494140625, 'learning_rate': 9.99600003095912e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -14.447522163391113, 'weight_rejected': 0.2727987766265869, 'kl_term_chosen': 15.098876953125, 'epoch': 0.11}
 11%|█         | 420/3753 [34:17<3:47:57,  4.10s/it] 11%|█         | 421/3753 [34:21<3:52:10,  4.18s/it] 11%|█         | 422/3753 [34:25<3:53:32,  4.21s/it] 11%|█▏        | 423/3753 [34:29<3:47:12,  4.09s/it] 11%|█▏        | 424/3753 [34:32<3:30:28,  3.79s/it] 11%|█▏        | 425/3753 [34:37<3:37:29,  3.92s/it] 11%|█▏        | 426/3753 [34:41<3:44:20,  4.05s/it] 11%|█▏        | 427/3753 [34:45<3:53:21,  4.21s/it] 11%|█▏        | 428/3753 [34:50<3:58:57,  4.31s/it] 11%|█▏        | 429/3753 [34:54<3:55:35,  4.25s/it] 11%|█▏        | 430/3753 [34:59<4:06:09,  4.44s/it]{'loss': 53.1241, 'grad_norm': 136.77467346191406, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.10210655629634857, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.7044873237609863, 'weight_rejected': 0.27125170826911926, 'kl_term_chosen': -1.140869140625, 'epoch': 0.1145902731512325}
                                                    {'loss': 53.1241, 'grad_norm': 136.77467346191406, 'learning_rate': 9.99392366948904e-07, 'mean_ratio_chosen': 0.10210655629634857, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.7044873237609863, 'weight_rejected': 0.27125170826911926, 'kl_term_chosen': -1.140869140625, 'epoch': 0.11}
 11%|█▏        | 430/3753 [34:59<4:06:09,  4.44s/it] 11%|█▏        | 431/3753 [35:03<3:56:44,  4.28s/it] 12%|█▏        | 432/3753 [35:11<5:03:49,  5.49s/it] 12%|█▏        | 433/3753 [35:15<4:43:21,  5.12s/it] 12%|█▏        | 434/3753 [35:19<4:23:25,  4.76s/it] 12%|█▏        | 435/3753 [35:23<4:07:06,  4.47s/it] 12%|█▏        | 436/3753 [35:28<4:05:11,  4.44s/it] 12%|█▏        | 437/3753 [35:32<4:02:45,  4.39s/it] 12%|█▏        | 438/3753 [35:37<4:13:44,  4.59s/it] 12%|█▏        | 439/3753 [35:41<4:11:21,  4.55s/it] 12%|█▏        | 440/3753 [35:45<4:04:18,  4.42s/it]{'loss': 43.7337, 'grad_norm': 349.82867431640625, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.5858187675476074, 'weight_rejected': 0.048136770725250244, 'kl_term_chosen': 4.54046630859375, 'epoch': 0.11725516322451698}
                                                    {'loss': 43.7337, 'grad_norm': 349.82867431640625, 'learning_rate': 9.991415116349067e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.5858187675476074, 'weight_rejected': 0.048136770725250244, 'kl_term_chosen': 4.54046630859375, 'epoch': 0.12}
 12%|█▏        | 440/3753 [35:46<4:04:18,  4.42s/it] 12%|█▏        | 441/3753 [35:51<4:27:35,  4.85s/it] 12%|█▏        | 442/3753 [35:56<4:25:54,  4.82s/it] 12%|█▏        | 443/3753 [35:59<3:46:53,  4.11s/it] 12%|█▏        | 444/3753 [36:04<4:02:39,  4.40s/it] 12%|█▏        | 445/3753 [36:07<3:50:45,  4.19s/it] 12%|█▏        | 446/3753 [36:12<3:57:52,  4.32s/it] 12%|█▏        | 447/3753 [36:16<3:58:31,  4.33s/it] 12%|█▏        | 448/3753 [36:20<3:44:12,  4.07s/it] 12%|█▏        | 449/3753 [36:25<3:57:45,  4.32s/it] 12%|█▏        | 450/3753 [36:29<4:01:17,  4.38s/it]{'loss': 44.5722, 'grad_norm': 285.7294921875, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 2.351118803024292, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': -1.4578094482421875, 'epoch': 0.11992005329780146}
                                                    {'loss': 44.5722, 'grad_norm': 285.7294921875, 'learning_rate': 9.988474588638185e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': 2.351118803024292, 'weight_rejected': 0.05582314357161522, 'kl_term_chosen': -1.4578094482421875, 'epoch': 0.12}
 12%|█▏        | 450/3753 [36:29<4:01:17,  4.38s/it] 12%|█▏        | 451/3753 [36:33<4:00:29,  4.37s/it] 12%|█▏        | 452/3753 [36:39<4:16:08,  4.66s/it] 12%|█▏        | 453/3753 [36:42<3:56:53,  4.31s/it] 12%|█▏        | 454/3753 [36:48<4:17:48,  4.69s/it] 12%|█▏        | 455/3753 [36:52<4:09:04,  4.53s/it] 12%|█▏        | 456/3753 [36:58<4:36:24,  5.03s/it] 12%|█▏        | 457/3753 [37:02<4:23:32,  4.80s/it] 12%|█▏        | 458/3753 [37:06<4:07:56,  4.51s/it] 12%|█▏        | 459/3753 [37:11<4:03:23,  4.43s/it] 12%|█▏        | 460/3753 [37:16<4:22:56,  4.79s/it]{'loss': 41.9985, 'grad_norm': 556.9376831054688, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -23.91114044189453, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': 24.829620361328125, 'epoch': 0.12258494337108594}
                                                    {'loss': 41.9985, 'grad_norm': 556.9376831054688, 'learning_rate': 9.985102340839976e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -23.91114044189453, 'weight_rejected': 0.04084571450948715, 'kl_term_chosen': 24.829620361328125, 'epoch': 0.12}
 12%|█▏        | 460/3753 [37:16<4:22:56,  4.79s/it] 12%|█▏        | 461/3753 [37:20<4:02:04,  4.41s/it] 12%|█▏        | 462/3753 [37:23<3:38:17,  3.98s/it] 12%|█▏        | 463/3753 [37:27<3:46:19,  4.13s/it] 12%|█▏        | 464/3753 [37:31<3:47:16,  4.15s/it] 12%|█▏        | 465/3753 [37:35<3:45:47,  4.12s/it] 12%|█▏        | 466/3753 [37:40<3:47:36,  4.15s/it] 12%|█▏        | 467/3753 [37:44<3:51:04,  4.22s/it] 12%|█▏        | 468/3753 [37:52<4:53:17,  5.36s/it] 12%|█▏        | 469/3753 [37:57<4:54:00,  5.37s/it] 13%|█▎        | 470/3753 [38:03<5:03:01,  5.54s/it]{'loss': 71.3518, 'grad_norm': 348.1440734863281, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -37.00168991088867, 'weight_rejected': 0.08151976019144058, 'kl_term_chosen': 37.946685791015625, 'epoch': 0.1252498334443704}
                                                    {'loss': 71.3518, 'grad_norm': 348.1440734863281, 'learning_rate': 9.981298664800593e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -37.00168991088867, 'weight_rejected': 0.08151976019144058, 'kl_term_chosen': 37.946685791015625, 'epoch': 0.13}
 13%|█▎        | 470/3753 [38:03<5:03:01,  5.54s/it] 13%|█▎        | 471/3753 [38:09<5:04:47,  5.57s/it] 13%|█▎        | 472/3753 [38:13<4:31:49,  4.97s/it] 13%|█▎        | 473/3753 [38:16<4:01:25,  4.42s/it] 13%|█▎        | 474/3753 [38:20<4:02:22,  4.44s/it] 13%|█▎        | 475/3753 [38:25<4:04:11,  4.47s/it] 13%|█▎        | 476/3753 [38:29<3:56:37,  4.33s/it] 13%|█▎        | 477/3753 [38:33<3:56:15,  4.33s/it] 13%|█▎        | 478/3753 [38:37<3:53:17,  4.27s/it] 13%|█▎        | 479/3753 [38:43<4:20:44,  4.78s/it] 13%|█▎        | 480/3753 [38:48<4:19:14,  4.75s/it]{'loss': 68.4261, 'grad_norm': 0.0, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 17.58444595336914, 'weight_rejected': 0.23792988061904907, 'kl_term_chosen': -17.007904052734375, 'epoch': 0.1279147235176549}
                                                    {'loss': 68.4261, 'grad_norm': 0.0, 'learning_rate': 9.9770638897035e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 17.58444595336914, 'weight_rejected': 0.23792988061904907, 'kl_term_chosen': -17.007904052734375, 'epoch': 0.13}
 13%|█▎        | 480/3753 [38:48<4:19:14,  4.75s/it] 13%|█▎        | 481/3753 [38:53<4:22:40,  4.82s/it] 13%|█▎        | 482/3753 [38:57<4:05:01,  4.49s/it] 13%|█▎        | 483/3753 [39:00<3:54:44,  4.31s/it] 13%|█▎        | 484/3753 [39:05<3:52:02,  4.26s/it] 13%|█▎        | 485/3753 [39:08<3:41:38,  4.07s/it] 13%|█▎        | 486/3753 [39:13<3:58:49,  4.39s/it] 13%|█▎        | 487/3753 [39:18<4:07:08,  4.54s/it] 13%|█▎        | 488/3753 [39:22<3:56:07,  4.34s/it] 13%|█▎        | 489/3753 [39:27<4:03:26,  4.48s/it] 13%|█▎        | 490/3753 [39:33<4:22:56,  4.83s/it]{'loss': 54.8606, 'grad_norm': 572.1514892578125, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.062330961227417, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': 4.006507873535156, 'epoch': 0.13057961359093936}
                                                    {'loss': 54.8606, 'grad_norm': 572.1514892578125, 'learning_rate': 9.972398382040988e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -3.062330961227417, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': 4.006507873535156, 'epoch': 0.13}
 13%|█▎        | 490/3753 [39:33<4:22:56,  4.83s/it] 13%|█▎        | 491/3753 [39:38<4:24:07,  4.86s/it] 13%|█▎        | 492/3753 [39:41<4:06:14,  4.53s/it] 13%|█▎        | 493/3753 [39:51<5:35:47,  6.18s/it] 13%|█▎        | 494/3753 [39:55<4:58:48,  5.50s/it] 13%|█▎        | 495/3753 [39:59<4:28:55,  4.95s/it] 13%|█▎        | 496/3753 [40:04<4:27:37,  4.93s/it] 13%|█▎        | 497/3753 [40:07<4:06:43,  4.55s/it] 13%|█▎        | 498/3753 [40:15<4:59:44,  5.53s/it] 13%|█▎        | 499/3753 [40:22<5:13:31,  5.78s/it] 13%|█▎        | 500/3753 [40:26<4:55:22,  5.45s/it]{'loss': 49.0472, 'grad_norm': 0.0, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 21.126220703125, 'weight_rejected': 0.22270013391971588, 'kl_term_chosen': -20.483787536621094, 'epoch': 0.13324450366422386}
                                                    {'loss': 49.0472, 'grad_norm': 0.0, 'learning_rate': 9.967302545582453e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 21.126220703125, 'weight_rejected': 0.22270013391971588, 'kl_term_chosen': -20.483787536621094, 'epoch': 0.13}
 13%|█▎        | 500/3753 [40:26<4:55:22,  5.45s/it] 13%|█▎        | 501/3753 [40:31<4:39:49,  5.16s/it] 13%|█▎        | 502/3753 [40:39<5:26:39,  6.03s/it] 13%|█▎        | 503/3753 [40:43<4:58:55,  5.52s/it] 13%|█▎        | 504/3753 [40:47<4:33:54,  5.06s/it] 13%|█▎        | 505/3753 [40:51<4:14:31,  4.70s/it] 13%|█▎        | 506/3753 [40:55<3:59:28,  4.43s/it] 14%|█▎        | 507/3753 [41:00<4:14:47,  4.71s/it] 14%|█▎        | 508/3753 [41:05<4:22:30,  4.85s/it] 14%|█▎        | 509/3753 [41:09<4:08:08,  4.59s/it] 14%|█▎        | 510/3753 [41:14<4:07:29,  4.58s/it]{'loss': 57.7292, 'grad_norm': 0.0, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -4.613949775695801, 'weight_rejected': 0.03358950838446617, 'kl_term_chosen': 5.5699310302734375, 'epoch': 0.13590939373750832}
                                                    {'loss': 57.7292, 'grad_norm': 0.0, 'learning_rate': 9.961776821339456e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -4.613949775695801, 'weight_rejected': 0.03358950838446617, 'kl_term_chosen': 5.5699310302734375, 'epoch': 0.14}
 14%|█▎        | 510/3753 [41:14<4:07:29,  4.58s/it] 14%|█▎        | 511/3753 [41:18<4:05:39,  4.55s/it] 14%|█▎        | 512/3753 [41:22<3:54:51,  4.35s/it] 14%|█▎        | 513/3753 [41:30<4:46:46,  5.31s/it] 14%|█▎        | 514/3753 [41:35<4:38:25,  5.16s/it] 14%|█▎        | 515/3753 [41:40<4:37:07,  5.14s/it] 14%|█▎        | 516/3753 [41:44<4:23:43,  4.89s/it] 14%|█▍        | 517/3753 [41:48<4:09:45,  4.63s/it] 14%|█▍        | 518/3753 [41:52<4:04:08,  4.53s/it] 14%|█▍        | 519/3753 [41:57<4:09:41,  4.63s/it] 14%|█▍        | 520/3753 [42:02<4:19:59,  4.83s/it]{'loss': 68.5136, 'grad_norm': 546.7438354492188, 'learning_rate': 9.955821687527552e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -32.09971237182617, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 33.02275085449219, 'epoch': 0.13857428381079281}
                                                    {'loss': 68.5136, 'grad_norm': 546.7438354492188, 'learning_rate': 9.955821687527552e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -32.09971237182617, 'weight_rejected': 0.052618950605392456, 'kl_term_chosen': 33.02275085449219, 'epoch': 0.14}
 14%|█▍        | 520/3753 [42:03<4:19:59,  4.83s/it] 14%|█▍        | 521/3753 [42:07<4:12:28,  4.69s/it] 14%|█▍        | 522/3753 [42:11<4:10:08,  4.65s/it] 14%|█▍        | 523/3753 [42:17<4:29:03,  5.00s/it] 14%|█▍        | 524/3753 [42:22<4:27:20,  4.97s/it] 14%|█▍        | 525/3753 [42:26<4:11:09,  4.67s/it] 14%|█▍        | 526/3753 [42:29<3:47:38,  4.23s/it] 14%|█▍        | 527/3753 [42:33<3:38:14,  4.06s/it] 14%|█▍        | 528/3753 [42:38<3:50:07,  4.28s/it] 14%|█▍        | 529/3753 [42:41<3:38:04,  4.06s/it] 14%|█▍        | 530/3753 [42:46<3:43:11,  4.16s/it]{'loss': 86.0868, 'grad_norm': 53.049556732177734, 'learning_rate': 9.94943765952491e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.454280853271484, 'weight_rejected': 0.332852303981781, 'kl_term_chosen': -11.018379211425781, 'epoch': 0.14123917388407728}
                                                    {'loss': 86.0868, 'grad_norm': 53.049556732177734, 'learning_rate': 9.94943765952491e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.454280853271484, 'weight_rejected': 0.332852303981781, 'kl_term_chosen': -11.018379211425781, 'epoch': 0.14}
 14%|█▍        | 530/3753 [42:46<3:43:11,  4.16s/it] 14%|█▍        | 531/3753 [42:49<3:31:32,  3.94s/it] 14%|█▍        | 532/3753 [42:53<3:38:35,  4.07s/it] 14%|█▍        | 533/3753 [42:58<3:51:34,  4.32s/it] 14%|█▍        | 534/3753 [43:02<3:40:16,  4.11s/it] 14%|█▍        | 535/3753 [43:07<3:49:51,  4.29s/it] 14%|█▍        | 536/3753 [43:11<3:54:12,  4.37s/it] 14%|█▍        | 537/3753 [43:16<4:00:39,  4.49s/it] 14%|█▍        | 538/3753 [43:19<3:41:31,  4.13s/it] 14%|█▍        | 539/3753 [43:23<3:34:50,  4.01s/it] 14%|█▍        | 540/3753 [43:26<3:21:49,  3.77s/it]{'loss': 89.6406, 'grad_norm': 166.7926788330078, 'learning_rate': 9.942625289827702e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -10.111302375793457, 'weight_rejected': 0.1233656257390976, 'kl_term_chosen': 11.039710998535156, 'epoch': 0.14390406395736177}
                                                    {'loss': 89.6406, 'grad_norm': 166.7926788330078, 'learning_rate': 9.942625289827702e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -10.111302375793457, 'weight_rejected': 0.1233656257390976, 'kl_term_chosen': 11.039710998535156, 'epoch': 0.14}
 14%|█▍        | 540/3753 [43:26<3:21:49,  3.77s/it] 14%|█▍        | 541/3753 [43:30<3:24:36,  3.82s/it] 14%|█▍        | 542/3753 [43:34<3:26:43,  3.86s/it] 14%|█▍        | 543/3753 [43:37<3:15:11,  3.65s/it] 14%|█▍        | 544/3753 [43:42<3:28:47,  3.90s/it] 15%|█▍        | 545/3753 [43:46<3:31:47,  3.96s/it] 15%|█▍        | 546/3753 [43:50<3:26:49,  3.87s/it] 15%|█▍        | 547/3753 [43:55<3:44:26,  4.20s/it] 15%|█▍        | 548/3753 [44:02<4:34:39,  5.14s/it] 15%|█▍        | 549/3753 [44:06<4:14:51,  4.77s/it] 15%|█▍        | 550/3753 [44:11<4:18:13,  4.84s/it]{'loss': 88.5825, 'grad_norm': 1210.748779296875, 'learning_rate': 9.935385168002298e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -31.3001651763916, 'weight_rejected': 0.07585817575454712, 'kl_term_chosen': 32.2364501953125, 'epoch': 0.14656895403064624}
                                                    {'loss': 88.5825, 'grad_norm': 1210.748779296875, 'learning_rate': 9.935385168002298e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -31.3001651763916, 'weight_rejected': 0.07585817575454712, 'kl_term_chosen': 32.2364501953125, 'epoch': 0.15}
 15%|█▍        | 550/3753 [44:11<4:18:13,  4.84s/it] 15%|█▍        | 551/3753 [44:15<4:13:59,  4.76s/it] 15%|█▍        | 552/3753 [44:19<3:56:19,  4.43s/it] 15%|█▍        | 553/3753 [44:23<3:47:50,  4.27s/it] 15%|█▍        | 554/3753 [44:27<3:50:21,  4.32s/it] 15%|█▍        | 555/3753 [44:32<3:51:26,  4.34s/it] 15%|█▍        | 556/3753 [44:36<3:51:16,  4.34s/it] 15%|█▍        | 557/3753 [44:42<4:16:24,  4.81s/it] 15%|█▍        | 558/3753 [44:46<4:10:23,  4.70s/it] 15%|█▍        | 559/3753 [44:51<4:02:16,  4.55s/it] 15%|█▍        | 560/3753 [44:54<3:48:32,  4.29s/it]{'loss': 58.4202, 'grad_norm': 0.0, 'learning_rate': 9.927717920634233e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.279644966125488, 'weight_rejected': 0.18713268637657166, 'kl_term_chosen': 9.157958984375, 'epoch': 0.1492338441039307}
                                                    {'loss': 58.4202, 'grad_norm': 0.0, 'learning_rate': 9.927717920634233e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -8.279644966125488, 'weight_rejected': 0.18713268637657166, 'kl_term_chosen': 9.157958984375, 'epoch': 0.15}
 15%|█▍        | 560/3753 [44:54<3:48:32,  4.29s/it] 15%|█▍        | 561/3753 [44:58<3:39:23,  4.12s/it] 15%|█▍        | 562/3753 [45:04<4:04:30,  4.60s/it] 15%|█▌        | 563/3753 [45:08<3:57:30,  4.47s/it] 15%|█▌        | 564/3753 [45:12<3:52:34,  4.38s/it] 15%|█▌        | 565/3753 [45:17<3:59:11,  4.50s/it] 15%|█▌        | 566/3753 [45:21<3:56:36,  4.45s/it] 15%|█▌        | 567/3753 [45:26<4:03:14,  4.58s/it] 15%|█▌        | 568/3753 [45:34<4:59:54,  5.65s/it] 15%|█▌        | 569/3753 [45:39<4:43:11,  5.34s/it] 15%|█▌        | 570/3753 [45:42<4:13:50,  4.78s/it]{'loss': 30.0082, 'grad_norm': 789.47607421875, 'learning_rate': 9.919624211273986e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.5941009521484375, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': -4.6234130859375, 'epoch': 0.1518987341772152}
                                                    {'loss': 30.0082, 'grad_norm': 789.47607421875, 'learning_rate': 9.919624211273986e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 5.5941009521484375, 'weight_rejected': 0.054198723286390305, 'kl_term_chosen': -4.6234130859375, 'epoch': 0.15}
 15%|█▌        | 570/3753 [45:42<4:13:50,  4.78s/it] 15%|█▌        | 571/3753 [45:48<4:22:15,  4.95s/it] 15%|█▌        | 572/3753 [45:51<3:57:59,  4.49s/it] 15%|█▌        | 573/3753 [45:55<3:53:54,  4.41s/it] 15%|█▌        | 574/3753 [45:59<3:50:05,  4.34s/it] 15%|█▌        | 575/3753 [46:08<4:48:26,  5.45s/it] 15%|█▌        | 576/3753 [46:12<4:31:57,  5.14s/it] 15%|█▌        | 577/3753 [46:17<4:23:02,  4.97s/it] 15%|█▌        | 578/3753 [46:21<4:20:48,  4.93s/it] 15%|█▌        | 579/3753 [46:25<3:56:46,  4.48s/it] 15%|█▌        | 580/3753 [46:29<3:55:06,  4.45s/it]{'loss': 43.8987, 'grad_norm': 132.54920959472656, 'learning_rate': 9.911104740379551e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.308588981628418, 'weight_rejected': 0.8499711751937866, 'kl_term_chosen': -11.198883056640625, 'epoch': 0.15456362425049966}
                                                    {'loss': 43.8987, 'grad_norm': 132.54920959472656, 'learning_rate': 9.911104740379551e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.308588981628418, 'weight_rejected': 0.8499711751937866, 'kl_term_chosen': -11.198883056640625, 'epoch': 0.15}
 15%|█▌        | 580/3753 [46:29<3:55:06,  4.45s/it] 15%|█▌        | 581/3753 [46:33<3:46:37,  4.29s/it] 16%|█▌        | 582/3753 [46:38<3:50:51,  4.37s/it] 16%|█▌        | 583/3753 [46:41<3:40:48,  4.18s/it] 16%|█▌        | 584/3753 [46:45<3:25:31,  3.89s/it] 16%|█▌        | 585/3753 [46:49<3:30:46,  3.99s/it] 16%|█▌        | 586/3753 [46:53<3:30:42,  3.99s/it] 16%|█▌        | 587/3753 [46:57<3:41:25,  4.20s/it] 16%|█▌        | 588/3753 [47:02<3:48:28,  4.33s/it] 16%|█▌        | 589/3753 [47:08<4:18:29,  4.90s/it] 16%|█▌        | 590/3753 [47:12<3:56:04,  4.48s/it]{'loss': 49.0116, 'grad_norm': 305.5936279296875, 'learning_rate': 9.902160245255826e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -22.95636749267578, 'weight_rejected': 0.12592275440692902, 'kl_term_chosen': 23.8304443359375, 'epoch': 0.15722851432378415}
                                                    {'loss': 49.0116, 'grad_norm': 305.5936279296875, 'learning_rate': 9.902160245255826e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -22.95636749267578, 'weight_rejected': 0.12592275440692902, 'kl_term_chosen': 23.8304443359375, 'epoch': 0.16}
 16%|█▌        | 590/3753 [47:12<3:56:04,  4.48s/it] 16%|█▌        | 591/3753 [47:16<3:55:11,  4.46s/it] 16%|█▌        | 592/3753 [47:20<3:47:35,  4.32s/it] 16%|█▌        | 593/3753 [47:26<4:03:41,  4.63s/it] 16%|█▌        | 594/3753 [47:30<3:55:46,  4.48s/it] 16%|█▌        | 595/3753 [47:33<3:43:58,  4.26s/it] 16%|█▌        | 596/3753 [47:38<3:42:01,  4.22s/it] 16%|█▌        | 597/3753 [47:41<3:34:19,  4.07s/it] 16%|█▌        | 598/3753 [47:46<3:39:26,  4.17s/it] 16%|█▌        | 599/3753 [47:50<3:48:41,  4.35s/it] 16%|█▌        | 600/3753 [47:56<4:01:27,  4.59s/it]{'loss': 70.9719, 'grad_norm': 861.3297729492188, 'learning_rate': 9.892791499990784e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -31.601408004760742, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 32.56294250488281, 'epoch': 0.15989340439706862}
                                                    {'loss': 70.9719, 'grad_norm': 861.3297729492188, 'learning_rate': 9.892791499990784e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -31.601408004760742, 'weight_rejected': 0.08509904146194458, 'kl_term_chosen': 32.56294250488281, 'epoch': 0.16}
 16%|█▌        | 600/3753 [47:56<4:01:27,  4.59s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 16%|█▌        | 601/3753 [48:56<18:43:34, 21.39s/it] 16%|█▌        | 602/3753 [49:01<14:16:04, 16.30s/it] 16%|█▌        | 603/3753 [49:06<11:20:48, 12.97s/it] 16%|█▌        | 604/3753 [49:10<8:59:50, 10.29s/it]  16%|█▌        | 605/3753 [49:14<7:21:49,  8.42s/it] 16%|█▌        | 606/3753 [49:18<6:17:17,  7.19s/it] 16%|█▌        | 607/3753 [49:22<5:17:59,  6.06s/it] 16%|█▌        | 608/3753 [49:26<4:49:59,  5.53s/it] 16%|█▌        | 609/3753 [49:31<4:37:58,  5.30s/it] 16%|█▋        | 610/3753 [49:34<4:05:52,  4.69s/it]{'loss': 79.9456, 'grad_norm': 703.8623657226562, 'learning_rate': 9.882999315388504e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -33.37881088256836, 'weight_rejected': 0.14033624529838562, 'kl_term_chosen': 34.2164306640625, 'epoch': 0.1625582944703531}
                                                    {'loss': 79.9456, 'grad_norm': 703.8623657226562, 'learning_rate': 9.882999315388504e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -33.37881088256836, 'weight_rejected': 0.14033624529838562, 'kl_term_chosen': 34.2164306640625, 'epoch': 0.16}
 16%|█▋        | 610/3753 [49:34<4:05:52,  4.69s/it] 16%|█▋        | 611/3753 [49:37<3:38:58,  4.18s/it]