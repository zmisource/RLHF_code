nohup: ignoring input
[W929 16:01:58.936061305 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W929 16:02:03.694161586 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W929 16:02:03.704117982 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W929 16:02:03.709704194 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W929 16:02:03.711567965 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank3]:[W929 16:02:04.529346092 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank2]:[W929 16:02:04.544058403 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank1]:[W929 16:02:04.546681236 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 89.07it/s]
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[rank0]:[W929 16:02:04.751043015 ProcessGroupNCCL.cpp:5023] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 as device used by this process is currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. You can specify device_id in init_process_group() to force use of a particular device.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 781.83it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 806.98it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 818.16it/s]
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
Epoch 1/3:   0%|          | 0/15009 [00:00<?, ?it/s]Epoch 1/3:   0%|          | 1/15009 [00:01<5:41:32,  1.37s/it]Epoch 1/3:   0%|          | 2/15009 [00:03<6:26:10,  1.54s/it]Epoch 1/3:   0%|          | 3/15009 [00:06<10:00:18,  2.40s/it]Epoch 1/3:   0%|          | 4/15009 [00:08<9:19:34,  2.24s/it] Epoch 1/3:   0%|          | 5/15009 [00:10<8:46:12,  2.10s/it]Epoch 1/3:   0%|          | 6/15009 [00:12<9:23:14,  2.25s/it]Epoch 1/3:   0%|          | 7/15009 [00:15<9:22:01,  2.25s/it]Epoch 1/3:   0%|          | 8/15009 [00:17<9:46:58,  2.35s/it]Epoch 1/3:   0%|          | 9/15009 [00:18<8:02:03,  1.93s/it]Epoch 1/3:   0%|          | 10/15009 [00:20<7:42:05,  1.85s/it]Epoch 1/3:   0%|          | 10/15009 [00:20<7:42:05,  1.85s/it, loss=1.01e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-16.5, weight_rejected=33.9, grad_norm=1.6e+3]Epoch 1/3:   0%|          | 11/15009 [00:21<7:09:09,  1.72s/it, loss=1.01e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-16.5, weight_rejected=33.9, grad_norm=1.6e+3]Epoch 1/3:   0%|          | 12/15009 [00:22<5:52:04,  1.41s/it, loss=1.01e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-16.5, weight_rejected=33.9, grad_norm=1.6e+3]Epoch 1/3:   0%|          | 13/15009 [00:24<6:59:11,  1.68s/it, loss=1.01e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-16.5, weight_rejected=33.9, grad_norm=1.6e+3]Epoch 1/3:   0%|          | 14/15009 [00:26<6:46:43,  1.63s/it, loss=1.01e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-16.5, weight_rejected=33.9, grad_norm=1.6e+3]Epoch 1/3:   0%|          | 15/15009 [00:27<6:39:49,  1.60s/it, loss=1.01e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-16.5, weight_rejected=33.9, grad_norm=1.6e+3]Epoch 1/3:   0%|          | 16/15009 [00:30<7:30:12,  1.80s/it, loss=1.01e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-16.5, weight_rejected=33.9, grad_norm=1.6e+3]Epoch 1/3:   0%|          | 17/15009 [00:31<7:29:08,  1.80s/it, loss=1.01e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-16.5, weight_rejected=33.9, grad_norm=1.6e+3]Epoch 1/3:   0%|          | 18/15009 [00:33<7:34:37,  1.82s/it, loss=1.01e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-16.5, weight_rejected=33.9, grad_norm=1.6e+3]Epoch 1/3:   0%|          | 19/15009 [00:35<6:59:49,  1.68s/it, loss=1.01e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-16.5, weight_rejected=33.9, grad_norm=1.6e+3]Epoch 1/3:   0%|          | 20/15009 [00:36<6:29:43,  1.56s/it, loss=1.01e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-16.5, weight_rejected=33.9, grad_norm=1.6e+3]Epoch 1/3:   0%|          | 20/15009 [00:36<6:29:43,  1.56s/it, loss=1.57e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-11.5, weight_rejected=66.6, grad_norm=0.663] Epoch 1/3:   0%|          | 21/15009 [00:38<7:18:21,  1.75s/it, loss=1.57e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-11.5, weight_rejected=66.6, grad_norm=0.663]Epoch 1/3:   0%|          | 22/15009 [00:39<6:41:43,  1.61s/it, loss=1.57e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-11.5, weight_rejected=66.6, grad_norm=0.663]Epoch 1/3:   0%|          | 23/15009 [00:41<6:49:26,  1.64s/it, loss=1.57e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-11.5, weight_rejected=66.6, grad_norm=0.663]Epoch 1/3:   0%|          | 24/15009 [00:43<7:06:28,  1.71s/it, loss=1.57e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-11.5, weight_rejected=66.6, grad_norm=0.663]Epoch 1/3:   0%|          | 25/15009 [00:45<7:19:57,  1.76s/it, loss=1.57e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-11.5, weight_rejected=66.6, grad_norm=0.663]Epoch 1/3:   0%|          | 26/15009 [00:47<7:47:54,  1.87s/it, loss=1.57e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-11.5, weight_rejected=66.6, grad_norm=0.663]Epoch 1/3:   0%|          | 27/15009 [00:49<8:01:21,  1.93s/it, loss=1.57e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-11.5, weight_rejected=66.6, grad_norm=0.663]Epoch 1/3:   0%|          | 28/15009 [00:50<7:14:12,  1.74s/it, loss=1.57e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-11.5, weight_rejected=66.6, grad_norm=0.663]Epoch 1/3:   0%|          | 29/15009 [00:53<7:51:57,  1.89s/it, loss=1.57e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-11.5, weight_rejected=66.6, grad_norm=0.663]Epoch 1/3:   0%|          | 30/15009 [00:55<8:05:58,  1.95s/it, loss=1.57e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-11.5, weight_rejected=66.6, grad_norm=0.663]Epoch 1/3:   0%|          | 30/15009 [00:55<8:05:58,  1.95s/it, loss=716, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-17.3, weight_rejected=18.3, grad_norm=2.31e+3]  Epoch 1/3:   0%|          | 31/15009 [00:57<8:36:29,  2.07s/it, loss=716, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-17.3, weight_rejected=18.3, grad_norm=2.31e+3]Epoch 1/3:   0%|          | 32/15009 [01:00<9:41:29,  2.33s/it, loss=716, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-17.3, weight_rejected=18.3, grad_norm=2.31e+3]Epoch 1/3:   0%|          | 33/15009 [01:02<9:05:09,  2.18s/it, loss=716, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-17.3, weight_rejected=18.3, grad_norm=2.31e+3]Epoch 1/3:   0%|          | 34/15009 [01:05<9:50:18,  2.37s/it, loss=716, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-17.3, weight_rejected=18.3, grad_norm=2.31e+3]Epoch 1/3:   0%|          | 35/15009 [01:06<9:08:58,  2.20s/it, loss=716, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-17.3, weight_rejected=18.3, grad_norm=2.31e+3]Epoch 1/3:   0%|          | 36/15009 [01:08<8:31:44,  2.05s/it, loss=716, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-17.3, weight_rejected=18.3, grad_norm=2.31e+3]Epoch 1/3:   0%|          | 37/15009 [01:10<8:54:23,  2.14s/it, loss=716, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-17.3, weight_rejected=18.3, grad_norm=2.31e+3]Epoch 1/3:   0%|          | 38/15009 [01:12<8:44:30,  2.10s/it, loss=716, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-17.3, weight_rejected=18.3, grad_norm=2.31e+3]Epoch 1/3:   0%|          | 39/15009 [01:14<8:17:12,  1.99s/it, loss=716, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-17.3, weight_rejected=18.3, grad_norm=2.31e+3]Epoch 1/3:   0%|          | 40/15009 [01:16<8:34:40,  2.06s/it, loss=716, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-17.3, weight_rejected=18.3, grad_norm=2.31e+3]Epoch 1/3:   0%|          | 40/15009 [01:16<8:34:40,  2.06s/it, loss=1.43e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-35.1, weight_rejected=36.3, grad_norm=1.04e+3]Epoch 1/3:   0%|          | 41/15009 [01:18<8:08:21,  1.96s/it, loss=1.43e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-35.1, weight_rejected=36.3, grad_norm=1.04e+3]Epoch 1/3:   0%|          | 42/15009 [01:21<8:48:42,  2.12s/it, loss=1.43e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-35.1, weight_rejected=36.3, grad_norm=1.04e+3]Epoch 1/3:   0%|          | 43/15009 [01:23<8:52:56,  2.14s/it, loss=1.43e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-35.1, weight_rejected=36.3, grad_norm=1.04e+3]Epoch 1/3:   0%|          | 44/15009 [01:25<8:35:14,  2.07s/it, loss=1.43e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-35.1, weight_rejected=36.3, grad_norm=1.04e+3]Epoch 1/3:   0%|          | 45/15009 [01:27<8:29:08,  2.04s/it, loss=1.43e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-35.1, weight_rejected=36.3, grad_norm=1.04e+3]Epoch 1/3:   0%|          | 46/15009 [01:29<8:21:13,  2.01s/it, loss=1.43e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-35.1, weight_rejected=36.3, grad_norm=1.04e+3]Epoch 1/3:   0%|          | 47/15009 [01:31<8:24:42,  2.02s/it, loss=1.43e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-35.1, weight_rejected=36.3, grad_norm=1.04e+3]Epoch 1/3:   0%|          | 48/15009 [01:32<7:38:16,  1.84s/it, loss=1.43e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-35.1, weight_rejected=36.3, grad_norm=1.04e+3]Epoch 1/3:   0%|          | 49/15009 [01:34<7:47:11,  1.87s/it, loss=1.43e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-35.1, weight_rejected=36.3, grad_norm=1.04e+3]Epoch 1/3:   0%|          | 50/15009 [01:36<8:24:57,  2.03s/it, loss=1.43e+3, mean_ratio_chosen=20.1, mean_ratio_rejected=20.1, weight_chosen=-35.1, weight_rejected=36.3, grad_norm=1.04e+3]Epoch 1/3:   0%|          | 50/15009 [01:36<8:24:57,  2.03s/it, loss=-0.226, mean_ratio_chosen=0.849, mean_ratio_rejected=0.785, weight_chosen=0.631, weight_rejected=0.395, grad_norm=688]  Epoch 1/3:   0%|          | 51/15009 [01:38<7:53:57,  1.90s/it, loss=-0.226, mean_ratio_chosen=0.849, mean_ratio_rejected=0.785, weight_chosen=0.631, weight_rejected=0.395, grad_norm=688]Epoch 1/3:   0%|          | 52/15009 [01:40<7:57:44,  1.92s/it, loss=-0.226, mean_ratio_chosen=0.849, mean_ratio_rejected=0.785, weight_chosen=0.631, weight_rejected=0.395, grad_norm=688]Epoch 1/3:   0%|          | 53/15009 [01:43<8:53:32,  2.14s/it, loss=-0.226, mean_ratio_chosen=0.849, mean_ratio_rejected=0.785, weight_chosen=0.631, weight_rejected=0.395, grad_norm=688]Epoch 1/3:   0%|          | 54/15009 [01:44<7:41:51,  1.85s/it, loss=-0.226, mean_ratio_chosen=0.849, mean_ratio_rejected=0.785, weight_chosen=0.631, weight_rejected=0.395, grad_norm=688]Epoch 1/3:   0%|          | 55/15009 [01:46<8:02:11,  1.93s/it, loss=-0.226, mean_ratio_chosen=0.849, mean_ratio_rejected=0.785, weight_chosen=0.631, weight_rejected=0.395, grad_norm=688]Epoch 1/3:   0%|          | 56/15009 [01:48<8:00:43,  1.93s/it, loss=-0.226, mean_ratio_chosen=0.849, mean_ratio_rejected=0.785, weight_chosen=0.631, weight_rejected=0.395, grad_norm=688]Epoch 1/3:   0%|          | 57/15009 [01:49<7:27:39,  1.80s/it, loss=-0.226, mean_ratio_chosen=0.849, mean_ratio_rejected=0.785, weight_chosen=0.631, weight_rejected=0.395, grad_norm=688]Epoch 1/3:   0%|          | 58/15009 [01:51<7:35:39,  1.83s/it, loss=-0.226, mean_ratio_chosen=0.849, mean_ratio_rejected=0.785, weight_chosen=0.631, weight_rejected=0.395, grad_norm=688]Epoch 1/3:   0%|          | 59/15009 [01:54<8:10:57,  1.97s/it, loss=-0.226, mean_ratio_chosen=0.849, mean_ratio_rejected=0.785, weight_chosen=0.631, weight_rejected=0.395, grad_norm=688]Epoch 1/3:   0%|          | 60/15009 [01:55<7:16:52,  1.75s/it, loss=-0.226, mean_ratio_chosen=0.849, mean_ratio_rejected=0.785, weight_chosen=0.631, weight_rejected=0.395, grad_norm=688]Epoch 1/3:   0%|          | 60/15009 [01:55<7:16:52,  1.75s/it, loss=-0.449, mean_ratio_chosen=0.954, mean_ratio_rejected=0.659, weight_chosen=0.717, weight_rejected=0.356, grad_norm=1.61e+3]Epoch 1/3:   0%|          | 61/15009 [01:57<7:49:53,  1.89s/it, loss=-0.449, mean_ratio_chosen=0.954, mean_ratio_rejected=0.659, weight_chosen=0.717, weight_rejected=0.356, grad_norm=1.61e+3]Epoch 1/3:   0%|          | 62/15009 [01:58<7:18:58,  1.76s/it, loss=-0.449, mean_ratio_chosen=0.954, mean_ratio_rejected=0.659, weight_chosen=0.717, weight_rejected=0.356, grad_norm=1.61e+3]Epoch 1/3:   0%|          | 63/15009 [02:01<8:18:16,  2.00s/it, loss=-0.449, mean_ratio_chosen=0.954, mean_ratio_rejected=0.659, weight_chosen=0.717, weight_rejected=0.356, grad_norm=1.61e+3]Epoch 1/3:   0%|          | 64/15009 [02:02<7:10:41,  1.73s/it, loss=-0.449, mean_ratio_chosen=0.954, mean_ratio_rejected=0.659, weight_chosen=0.717, weight_rejected=0.356, grad_norm=1.61e+3]Epoch 1/3:   0%|          | 65/15009 [02:03<6:17:11,  1.51s/it, loss=-0.449, mean_ratio_chosen=0.954, mean_ratio_rejected=0.659, weight_chosen=0.717, weight_rejected=0.356, grad_norm=1.61e+3]Epoch 1/3:   0%|          | 66/15009 [02:04<5:39:25,  1.36s/it, loss=-0.449, mean_ratio_chosen=0.954, mean_ratio_rejected=0.659, weight_chosen=0.717, weight_rejected=0.356, grad_norm=1.61e+3][rank0]: Traceback (most recent call last):
[rank0]:   File "/code/train_precomputed.py", line 287, in <module>
[rank0]:     main(args)
[rank0]:   File "/code/train_precomputed.py", line 213, in main
[rank0]:     accelerator.backward(loss)
[rank0]:   File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py", line 2734, in backward
[rank0]:     loss.backward(**kwargs)
[rank0]:   File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/_tensor.py", line 647, in backward
[rank0]:     torch.autograd.backward(
[rank0]:   File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/autograd/__init__.py", line 354, in backward
[rank0]:     _engine_run_backward(
[rank0]:   File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/autograd/graph.py", line 829, in _engine_run_backward
[rank0]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 689, in _pre_backward_hook
[rank0]:     _prefetch_handle(state, handle, _PrefetchMode.BACKWARD)
[rank0]:   File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 1229, in _prefetch_handle
[rank0]:     _unshard(state, handle, state._unshard_stream, state._pre_unshard_stream)
[rank0]:   File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_runtime_utils.py", line 301, in _unshard
[rank0]:     handle.unshard()
[rank0]:   File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py", line 1345, in unshard
[rank0]:     unsharded_flat_param = self._alloc_padded_unsharded_flat_param()
[rank0]:                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_flat_param.py", line 1372, in _alloc_padded_unsharded_flat_param
[rank0]:     _alloc_storage(unsharded_flat_param, flat_param._padded_unsharded_size)  # type: ignore[attr-defined]
[rank0]:     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/utils.py", line 179, in _alloc_storage
[rank0]:     tensor._typed_storage()._resize_(size.numel())
[rank0]:   File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/storage.py", line 1263, in _resize_
[rank0]:     self._untyped_storage.resize_(size * self._element_size())
[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 418.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 410.94 MiB is free. Process 3088487 has 78.84 GiB memory in use. Of the allocated memory 76.36 GiB is allocated by PyTorch, and 1.58 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Epoch 1/3:   0%|          | 66/15009 [02:06<7:58:45,  1.92s/it, loss=-0.449, mean_ratio_chosen=0.954, mean_ratio_rejected=0.659, weight_chosen=0.717, weight_rejected=0.356, grad_norm=1.61e+3]
W0929 16:04:15.227000 481328 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 481599 closing signal SIGTERM
W0929 16:04:15.228000 481328 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 481600 closing signal SIGTERM
W0929 16:04:15.230000 481328 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 481601 closing signal SIGTERM
E0929 16:04:15.999000 481328 site-packages/torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 481598) of binary: /root/miniconda3/envs/advan/bin/python3.12
Traceback (most recent call last):
  File "/root/miniconda3/envs/advan/bin/accelerate", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/launch.py", line 1222, in launch_command
    multi_gpu_launcher(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/launch.py", line 853, in multi_gpu_launcher
    distrib_run.run(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 277, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
/code/train_precomputed.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-09-29_16:04:15
  host      : wLDmlp
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 481598)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
