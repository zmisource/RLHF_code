nohup: ignoring input
[W1119 07:37:23.251464794 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 42
设置随机种子为: 42
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 42
设置随机种子为: 42
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 92.11it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.86it/s]
加载作为参考的SFT模型 (Reference Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.61it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.08it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.83it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.79it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.04it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 94.78it/s]
[W1119 07:37:29.762336044 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1119 07:37:29.768807020 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1119 07:37:29.769657295 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1119 07:37:29.773082093 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
初始化 CustomSymPOTrainer...
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
/rlhf_code/code/implement_final_v3_no_kl_term2.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3_no_kl_term2.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:4807: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/planner_helpers.py:418: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  device = getattr(value, "device", None)
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/planner_helpers.py:418: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  device = getattr(value, "device", None)
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/default_planner.py:479: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  and md.size != obj.size()
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/default_planner.py:479: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  and md.size != obj.size()
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/planner_helpers.py:418: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  device = getattr(value, "device", None)
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/planner_helpers.py:418: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  device = getattr(value, "device", None)
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/default_planner.py:479: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  and md.size != obj.size()
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/checkpoint/default_planner.py:479: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  and md.size != obj.size()
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:625: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  param_numel = param.size().numel()
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:625: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  param_numel = param.size().numel()
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:625: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  param_numel = param.size().numel()
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:626: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  dim_0_size = param.size()[0]
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:626: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  dim_0_size = param.size()[0]
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:626: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  dim_0_size = param.size()[0]
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:625: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  param_numel = param.size().numel()
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:626: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  dim_0_size = param.size()[0]
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:652: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor = tensor.narrow(0, 0, param_numel).reshape(param.size())
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:652: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor = tensor.narrow(0, 0, param_numel).reshape(param.size())
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:652: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor = tensor.narrow(0, 0, param_numel).reshape(param.size())
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:652: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor = tensor.narrow(0, 0, param_numel).reshape(param.size())
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /wandb/offline-run-20251119_073759-7m7iupl5
  0%|          | 0/3753 [00:00<?, ?it/s]Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
 16%|█▌        | 601/3753 [00:05<00:26, 120.13it/s] 16%|█▌        | 603/3753 [00:18<00:26, 120.13it/s] 16%|█▌        | 604/3753 [00:19<02:10, 24.17it/s]  16%|█▌        | 605/3753 [00:23<02:52, 18.27it/s] 16%|█▌        | 608/3753 [00:38<02:52, 18.27it/s] 16%|█▌        | 609/3753 [00:39<06:58,  7.51it/s] 16%|█▋        | 610/3753 [00:43<08:04,  6.49it/s]{'loss': 60.8272, 'grad_norm': 459.6363220214844, 'learning_rate': 9.882999315388504e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -11.719829559326172, 'weight_rejected': 0.14033624529838562, 'kl_term_chosen': 12.557449340820312, 'epoch': 0.1625582944703531}
                                                  {'loss': 60.8272, 'grad_norm': 459.6363220214844, 'learning_rate': 9.882999315388504e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -11.719829559326172, 'weight_rejected': 0.14033624529838562, 'kl_term_chosen': 12.557449340820312, 'epoch': 0.16}
 16%|█▋        | 610/3753 [00:43<08:04,  6.49it/s] 16%|█▋        | 612/3753 [00:58<08:03,  6.49it/s] 16%|█▋        | 613/3753 [00:58<15:16,  3.43it/s] 16%|█▋        | 614/3753 [01:04<19:07,  2.74it/s] 16%|█▋        | 616/3753 [01:13<26:35,  1.97it/s] 16%|█▋        | 618/3753 [01:20<34:19,  1.52it/s] 16%|█▋        | 619/3753 [01:23<38:44,  1.35it/s] 17%|█▋        | 620/3753 [01:29<52:26,  1.00s/it]{'loss': 100.0646, 'grad_norm': 977.3023681640625, 'learning_rate': 9.872784538898985e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -34.33155059814453, 'weight_rejected': 0.46295860409736633, 'kl_term_chosen': 34.67225646972656, 'epoch': 0.16522318454363757}
                                                  {'loss': 100.0646, 'grad_norm': 977.3023681640625, 'learning_rate': 9.872784538898985e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': -34.33155059814453, 'weight_rejected': 0.46295860409736633, 'kl_term_chosen': 34.67225646972656, 'epoch': 0.17}
 17%|█▋        | 620/3753 [01:29<52:26,  1.00s/it] 17%|█▋        | 621/3753 [01:37<1:13:01,  1.40s/it] 17%|█▋        | 622/3753 [01:40<1:21:23,  1.56s/it] 17%|█▋        | 623/3753 [01:44<1:33:05,  1.78s/it] 17%|█▋        | 624/3753 [01:48<1:50:09,  2.11s/it] 17%|█▋        | 625/3753 [01:52<2:06:10,  2.42s/it] 17%|█▋        | 626/3753 [01:56<2:21:45,  2.72s/it] 17%|█▋        | 627/3753 [02:03<3:02:01,  3.49s/it] 17%|█▋        | 628/3753 [02:07<3:16:41,  3.78s/it] 17%|█▋        | 629/3753 [02:13<3:33:35,  4.10s/it] 17%|█▋        | 630/3753 [02:17<3:39:47,  4.22s/it]{'loss': 116.468, 'grad_norm': 28.605632781982422, 'learning_rate': 9.86214805454481e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -44.44314956665039, 'weight_rejected': 0.14033624529838562, 'kl_term_chosen': 44.5528564453125, 'epoch': 0.16788807461692204}
                                                    {'loss': 116.468, 'grad_norm': 28.605632781982422, 'learning_rate': 9.86214805454481e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -44.44314956665039, 'weight_rejected': 0.14033624529838562, 'kl_term_chosen': 44.5528564453125, 'epoch': 0.17}
 17%|█▋        | 630/3753 [02:17<3:39:47,  4.22s/it] 17%|█▋        | 631/3753 [02:22<3:52:08,  4.46s/it] 17%|█▋        | 632/3753 [02:26<3:47:34,  4.38s/it] 17%|█▋        | 633/3753 [02:32<4:09:33,  4.80s/it] 17%|█▋        | 634/3753 [02:37<4:02:35,  4.67s/it] 17%|█▋        | 635/3753 [02:40<3:45:27,  4.34s/it] 17%|█▋        | 636/3753 [02:45<3:54:06,  4.51s/it] 17%|█▋        | 637/3753 [02:49<3:40:07,  4.24s/it] 17%|█▋        | 638/3753 [02:52<3:33:13,  4.11s/it] 17%|█▋        | 639/3753 [03:02<4:51:02,  5.61s/it] 17%|█▋        | 640/3753 [03:06<4:27:09,  5.15s/it]{'loss': 113.7349, 'grad_norm': 0.0, 'learning_rate': 9.851090782844644e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -29.564411163330078, 'weight_rejected': 0.07696083933115005, 'kl_term_chosen': 30.50775909423828, 'epoch': 0.17055296469020653}
                                                    {'loss': 113.7349, 'grad_norm': 0.0, 'learning_rate': 9.851090782844644e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -29.564411163330078, 'weight_rejected': 0.07696083933115005, 'kl_term_chosen': 30.50775909423828, 'epoch': 0.17}
 17%|█▋        | 640/3753 [03:06<4:27:09,  5.15s/it] 17%|█▋        | 641/3753 [03:13<5:03:40,  5.85s/it] 17%|█▋        | 642/3753 [03:21<5:41:58,  6.60s/it] 17%|█▋        | 643/3753 [03:26<5:06:31,  5.91s/it] 17%|█▋        | 644/3753 [03:30<4:41:50,  5.44s/it] 17%|█▋        | 645/3753 [03:35<4:26:09,  5.14s/it] 17%|█▋        | 646/3753 [03:38<4:02:54,  4.69s/it] 17%|█▋        | 647/3753 [03:43<3:59:59,  4.64s/it] 17%|█▋        | 648/3753 [03:46<3:37:11,  4.20s/it] 17%|█▋        | 649/3753 [03:50<3:39:10,  4.24s/it] 17%|█▋        | 650/3753 [03:54<3:28:20,  4.03s/it]{'loss': 97.7783, 'grad_norm': 1253.3111572265625, 'learning_rate': 9.839613680733559e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.334657669067383, 'weight_rejected': 0.33982762694358826, 'kl_term_chosen': 8.08812427520752, 'epoch': 0.173217854763491}
                                                    {'loss': 97.7783, 'grad_norm': 1253.3111572265625, 'learning_rate': 9.839613680733559e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -7.334657669067383, 'weight_rejected': 0.33982762694358826, 'kl_term_chosen': 8.08812427520752, 'epoch': 0.17}
 17%|█▋        | 650/3753 [03:54<3:28:20,  4.03s/it] 17%|█▋        | 651/3753 [04:02<4:39:59,  5.42s/it] 17%|█▋        | 652/3753 [04:08<4:43:13,  5.48s/it] 17%|█▋        | 653/3753 [04:14<4:48:58,  5.59s/it] 17%|█▋        | 654/3753 [04:23<5:46:15,  6.70s/it] 17%|█▋        | 655/3753 [04:27<5:00:41,  5.82s/it] 17%|█▋        | 656/3753 [04:31<4:32:21,  5.28s/it] 18%|█▊        | 657/3753 [04:35<4:08:12,  4.81s/it] 18%|█▊        | 658/3753 [04:41<4:32:54,  5.29s/it] 18%|█▊        | 659/3753 [04:45<4:12:14,  4.89s/it] 18%|█▊        | 660/3753 [04:50<4:07:29,  4.80s/it]{'loss': 60.0953, 'grad_norm': 903.7286376953125, 'learning_rate': 9.827717741480229e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 7.59563684463501, 'weight_rejected': 0.42919009923934937, 'kl_term_chosen': -7.548912048339844, 'epoch': 0.1758827448367755}
                                                    {'loss': 60.0953, 'grad_norm': 903.7286376953125, 'learning_rate': 9.827717741480229e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 7.59563684463501, 'weight_rejected': 0.42919009923934937, 'kl_term_chosen': -7.548912048339844, 'epoch': 0.18}
 18%|█▊        | 660/3753 [04:50<4:07:29,  4.80s/it] 18%|█▊        | 661/3753 [04:53<3:49:22,  4.45s/it] 18%|█▊        | 662/3753 [05:01<4:41:50,  5.47s/it] 18%|█▊        | 663/3753 [05:04<4:01:50,  4.70s/it] 18%|█▊        | 664/3753 [05:09<3:59:50,  4.66s/it] 18%|█▊        | 665/3753 [05:15<4:28:04,  5.21s/it] 18%|█▊        | 666/3753 [05:20<4:22:16,  5.10s/it] 18%|█▊        | 667/3753 [05:23<3:58:23,  4.63s/it] 18%|█▊        | 668/3753 [05:27<3:44:38,  4.37s/it] 18%|█▊        | 669/3753 [05:32<3:50:00,  4.47s/it] 18%|█▊        | 670/3753 [05:37<4:01:29,  4.70s/it]{'loss': 12.2453, 'grad_norm': 512.5881958007812, 'learning_rate': 9.815403994600958e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.297451972961426, 'weight_rejected': 0.07696083933115005, 'kl_term_chosen': 7.225860595703125, 'epoch': 0.17854763491005995}
                                                    {'loss': 12.2453, 'grad_norm': 512.5881958007812, 'learning_rate': 9.815403994600958e-07, 'mean_ratio_chosen': 9.974181175231934, 'mean_ratio_rejected': 9.974181175231934, 'weight_chosen': -6.297451972961426, 'weight_rejected': 0.07696083933115005, 'kl_term_chosen': 7.225860595703125, 'epoch': 0.18}
 18%|█▊        | 670/3753 [05:37<4:01:29,  4.70s/it] 18%|█▊        | 671/3753 [05:41<3:46:50,  4.42s/it] 18%|█▊        | 672/3753 [05:52<5:25:12,  6.33s/it] 18%|█▊        | 673/3753 [05:55<4:43:37,  5.53s/it] 18%|█▊        | 674/3753 [06:03<5:12:13,  6.08s/it] 18%|█▊        | 675/3753 [06:07<4:45:36,  5.57s/it] 18%|█▊        | 676/3753 [06:12<4:31:34,  5.30s/it] 18%|█▊        | 677/3753 [06:17<4:25:04,  5.17s/it] 18%|█▊        | 678/3753 [06:21<4:06:10,  4.80s/it] 18%|█▊        | 679/3753 [06:30<5:17:06,  6.19s/it] 18%|█▊        | 680/3753 [06:34<4:47:19,  5.61s/it]{'loss': 9.6429, 'grad_norm': 647.5733032226562, 'learning_rate': 9.80267350577059e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 52.71949005126953, 'weight_rejected': 0.2689414322376251, 'kl_term_chosen': -51.99696350097656, 'epoch': 0.18121252498334445}
                                                    {'loss': 9.6429, 'grad_norm': 647.5733032226562, 'learning_rate': 9.80267350577059e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 52.71949005126953, 'weight_rejected': 0.2689414322376251, 'kl_term_chosen': -51.99696350097656, 'epoch': 0.18}
 18%|█▊        | 680/3753 [06:34<4:47:19,  5.61s/it] 18%|█▊        | 681/3753 [06:40<4:41:35,  5.50s/it] 18%|█▊        | 682/3753 [06:48<5:19:51,  6.25s/it] 18%|█▊        | 683/3753 [06:52<4:49:48,  5.66s/it] 18%|█▊        | 684/3753 [06:56<4:23:39,  5.15s/it] 18%|█▊        | 685/3753 [07:01<4:20:10,  5.09s/it] 18%|█▊        | 686/3753 [07:05<4:11:49,  4.93s/it] 18%|█▊        | 687/3753 [07:09<3:54:01,  4.58s/it] 18%|█▊        | 688/3753 [07:16<4:24:44,  5.18s/it] 18%|█▊        | 689/3753 [07:20<4:14:57,  4.99s/it] 18%|█▊        | 690/3753 [07:26<4:32:17,  5.33s/it]{'loss': 4.7593, 'grad_norm': 43.746482849121094, 'learning_rate': 9.78952737673028e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 52.01451110839844, 'weight_rejected': 0.07696083933115005, 'kl_term_chosen': -51.24542999267578, 'epoch': 0.1838774150566289}
                                                    {'loss': 4.7593, 'grad_norm': 43.746482849121094, 'learning_rate': 9.78952737673028e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 52.01451110839844, 'weight_rejected': 0.07696083933115005, 'kl_term_chosen': -51.24542999267578, 'epoch': 0.18}
 18%|█▊        | 690/3753 [07:26<4:32:17,  5.33s/it] 18%|█▊        | 691/3753 [07:31<4:15:29,  5.01s/it] 18%|█▊        | 692/3753 [07:34<3:48:15,  4.47s/it] 18%|█▊        | 693/3753 [07:40<4:21:53,  5.14s/it] 18%|█▊        | 694/3753 [07:47<4:47:17,  5.63s/it] 19%|█▊        | 695/3753 [07:52<4:31:37,  5.33s/it] 19%|█▊        | 696/3753 [07:56<4:13:22,  4.97s/it] 19%|█▊        | 697/3753 [08:00<3:57:35,  4.66s/it] 19%|█▊        | 698/3753 [08:05<4:03:37,  4.78s/it] 19%|█▊        | 699/3753 [08:10<4:07:15,  4.86s/it] 19%|█▊        | 700/3753 [08:14<3:54:10,  4.60s/it]{'loss': -1.2, 'grad_norm': 0.0, 'learning_rate': 9.775966745192144e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 43.90663528442383, 'weight_rejected': 0.17441026866436005, 'kl_term_chosen': -42.951988220214844, 'epoch': 0.18654230512991338}
                                                    {'loss': -1.2, 'grad_norm': 0.0, 'learning_rate': 9.775966745192144e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 43.90663528442383, 'weight_rejected': 0.17441026866436005, 'kl_term_chosen': -42.951988220214844, 'epoch': 0.19}
 19%|█▊        | 700/3753 [08:14<3:54:10,  4.60s/it] 19%|█▊        | 701/3753 [08:19<3:53:57,  4.60s/it] 19%|█▊        | 702/3753 [08:22<3:35:59,  4.25s/it] 19%|█▊        | 703/3753 [08:26<3:36:27,  4.26s/it] 19%|█▉        | 704/3753 [08:31<3:48:35,  4.50s/it] 19%|█▉        | 705/3753 [08:36<3:56:13,  4.65s/it] 19%|█▉        | 706/3753 [08:42<4:04:23,  4.81s/it] 19%|█▉        | 707/3753 [08:46<3:51:11,  4.55s/it] 19%|█▉        | 708/3753 [08:50<3:48:36,  4.50s/it] 19%|█▉        | 709/3753 [08:55<3:59:04,  4.71s/it] 19%|█▉        | 710/3753 [08:59<3:44:17,  4.42s/it]{'loss': -0.8878, 'grad_norm': 502.89886474609375, 'learning_rate': 9.761992784740795e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 29.07125473022461, 'weight_rejected': 0.03963883966207504, 'kl_term_chosen': -28.90239715576172, 'epoch': 0.18920719520319787}
                                                    {'loss': -0.8878, 'grad_norm': 502.89886474609375, 'learning_rate': 9.761992784740795e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 29.07125473022461, 'weight_rejected': 0.03963883966207504, 'kl_term_chosen': -28.90239715576172, 'epoch': 0.19}
 19%|█▉        | 710/3753 [08:59<3:44:17,  4.42s/it] 19%|█▉        | 711/3753 [09:02<3:29:30,  4.13s/it] 19%|█▉        | 712/3753 [09:08<3:54:29,  4.63s/it] 19%|█▉        | 713/3753 [09:12<3:49:04,  4.52s/it] 19%|█▉        | 714/3753 [09:17<3:45:27,  4.45s/it] 19%|█▉        | 715/3753 [09:23<4:15:47,  5.05s/it] 19%|█▉        | 716/3753 [09:28<4:14:23,  5.03s/it] 19%|█▉        | 717/3753 [09:33<4:13:48,  5.02s/it] 19%|█▉        | 718/3753 [09:38<4:04:17,  4.83s/it] 19%|█▉        | 719/3753 [09:41<3:47:15,  4.49s/it] 19%|█▉        | 720/3753 [09:45<3:39:08,  4.34s/it]{'loss': 0.0079, 'grad_norm': 0.0, 'learning_rate': 9.747606704731785e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 63.650665283203125, 'weight_rejected': 0.24508501589298248, 'kl_term_chosen': -62.7977294921875, 'epoch': 0.19187208527648233}
                                                    {'loss': 0.0079, 'grad_norm': 0.0, 'learning_rate': 9.747606704731785e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 63.650665283203125, 'weight_rejected': 0.24508501589298248, 'kl_term_chosen': -62.7977294921875, 'epoch': 0.19}
 19%|█▉        | 720/3753 [09:45<3:39:08,  4.34s/it] 19%|█▉        | 721/3753 [09:49<3:30:21,  4.16s/it] 19%|█▉        | 722/3753 [09:55<3:57:45,  4.71s/it] 19%|█▉        | 723/3753 [10:00<4:09:09,  4.93s/it] 19%|█▉        | 724/3753 [10:05<4:00:48,  4.77s/it] 19%|█▉        | 725/3753 [10:10<4:08:25,  4.92s/it] 19%|█▉        | 726/3753 [10:13<3:36:19,  4.29s/it] 19%|█▉        | 727/3753 [10:17<3:39:27,  4.35s/it] 19%|█▉        | 728/3753 [10:22<3:50:24,  4.57s/it] 19%|█▉        | 729/3753 [10:26<3:41:43,  4.40s/it] 19%|█▉        | 730/3753 [10:30<3:32:52,  4.22s/it]{'loss': -2.6432, 'grad_norm': 0.0, 'learning_rate': 9.732809750186936e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 85.74134063720703, 'weight_rejected': 0.45423004031181335, 'kl_term_chosen': -84.86386108398438, 'epoch': 0.19453697534976683}
                                                    {'loss': -2.6432, 'grad_norm': 0.0, 'learning_rate': 9.732809750186936e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 85.74134063720703, 'weight_rejected': 0.45423004031181335, 'kl_term_chosen': -84.86386108398438, 'epoch': 0.19}
 19%|█▉        | 730/3753 [10:30<3:32:52,  4.22s/it] 19%|█▉        | 731/3753 [10:38<4:30:45,  5.38s/it] 20%|█▉        | 732/3753 [10:43<4:18:24,  5.13s/it] 20%|█▉        | 733/3753 [10:47<4:07:48,  4.92s/it] 20%|█▉        | 734/3753 [10:52<4:08:49,  4.95s/it] 20%|█▉        | 735/3753 [10:56<3:42:20,  4.42s/it] 20%|█▉        | 736/3753 [10:59<3:34:01,  4.26s/it] 20%|█▉        | 737/3753 [11:03<3:29:42,  4.17s/it] 20%|█▉        | 738/3753 [11:09<3:46:14,  4.50s/it] 20%|█▉        | 739/3753 [11:13<3:36:57,  4.32s/it] 20%|█▉        | 740/3753 [11:17<3:35:14,  4.29s/it]{'loss': -3.8911, 'grad_norm': 173.36380004882812, 'learning_rate': 9.717603201686589e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 136.52490234375, 'weight_rejected': 0.34953272342681885, 'kl_term_chosen': -136.08346557617188, 'epoch': 0.1972018654230513}
                                                    {'loss': -3.8911, 'grad_norm': 173.36380004882812, 'learning_rate': 9.717603201686589e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 136.52490234375, 'weight_rejected': 0.34953272342681885, 'kl_term_chosen': -136.08346557617188, 'epoch': 0.2}
 20%|█▉        | 740/3753 [11:17<3:35:14,  4.29s/it] 20%|█▉        | 741/3753 [11:20<3:24:55,  4.08s/it] 20%|█▉        | 742/3753 [11:24<3:23:18,  4.05s/it] 20%|█▉        | 743/3753 [11:28<3:19:45,  3.98s/it] 20%|█▉        | 744/3753 [11:33<3:27:34,  4.14s/it] 20%|█▉        | 745/3753 [11:36<3:12:46,  3.85s/it] 20%|█▉        | 746/3753 [11:40<3:18:24,  3.96s/it] 20%|█▉        | 747/3753 [11:45<3:26:20,  4.12s/it] 20%|█▉        | 748/3753 [11:49<3:31:10,  4.22s/it] 20%|█▉        | 749/3753 [11:54<3:37:51,  4.35s/it] 20%|█▉        | 750/3753 [11:58<3:33:29,  4.27s/it]{'loss': -3.934, 'grad_norm': 0.0, 'learning_rate': 9.701988375258787e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.03549575805664, 'weight_rejected': 0.19072403013706207, 'kl_term_chosen': -10.190574645996094, 'epoch': 0.19986675549633579}
                                                    {'loss': -3.934, 'grad_norm': 0.0, 'learning_rate': 9.701988375258787e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.03549575805664, 'weight_rejected': 0.19072403013706207, 'kl_term_chosen': -10.190574645996094, 'epoch': 0.2}
 20%|█▉        | 750/3753 [11:58<3:33:29,  4.27s/it] 20%|██        | 751/3753 [12:02<3:34:04,  4.28s/it] 20%|██        | 752/3753 [12:06<3:29:18,  4.18s/it] 20%|██        | 753/3753 [12:09<3:08:52,  3.78s/it] 20%|██        | 754/3753 [12:14<3:23:13,  4.07s/it] 20%|██        | 755/3753 [12:18<3:30:45,  4.22s/it] 20%|██        | 756/3753 [12:22<3:20:31,  4.01s/it] 20%|██        | 757/3753 [12:25<3:17:08,  3.95s/it] 20%|██        | 758/3753 [12:29<3:13:49,  3.88s/it] 20%|██        | 759/3753 [12:35<3:35:34,  4.32s/it] 20%|██        | 760/3753 [12:42<4:21:31,  5.24s/it]{'loss': -6.3603, 'grad_norm': 0.0, 'learning_rate': 9.68596662226538e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 64.22134399414062, 'weight_rejected': 0.12940272688865662, 'kl_term_chosen': -63.2950439453125, 'epoch': 0.20253164556962025}
                                                    {'loss': -6.3603, 'grad_norm': 0.0, 'learning_rate': 9.68596662226538e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 64.22134399414062, 'weight_rejected': 0.12940272688865662, 'kl_term_chosen': -63.2950439453125, 'epoch': 0.2}
 20%|██        | 760/3753 [12:42<4:21:31,  5.24s/it] 20%|██        | 761/3753 [12:46<4:10:21,  5.02s/it] 20%|██        | 762/3753 [12:51<4:08:20,  4.98s/it] 20%|██        | 763/3753 [12:57<4:12:53,  5.07s/it] 20%|██        | 764/3753 [13:01<4:02:37,  4.87s/it] 20%|██        | 765/3753 [13:07<4:12:25,  5.07s/it] 20%|██        | 766/3753 [13:10<3:54:47,  4.72s/it] 20%|██        | 767/3753 [13:19<4:47:59,  5.79s/it] 20%|██        | 768/3753 [13:24<4:39:43,  5.62s/it] 20%|██        | 769/3753 [13:32<5:15:40,  6.35s/it] 21%|██        | 770/3753 [13:35<4:32:28,  5.48s/it]{'loss': -7.9039, 'grad_norm': 0.0, 'learning_rate': 9.66953932928506e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 195.59259033203125, 'weight_rejected': 0.16885694861412048, 'kl_term_chosen': -194.816650390625, 'epoch': 0.20519653564290474}
                                                    {'loss': -7.9039, 'grad_norm': 0.0, 'learning_rate': 9.66953932928506e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 195.59259033203125, 'weight_rejected': 0.16885694861412048, 'kl_term_chosen': -194.816650390625, 'epoch': 0.21}
 21%|██        | 770/3753 [13:36<4:32:28,  5.48s/it] 21%|██        | 771/3753 [13:41<4:29:01,  5.41s/it] 21%|██        | 772/3753 [13:44<4:00:12,  4.83s/it] 21%|██        | 773/3753 [13:48<3:47:10,  4.57s/it] 21%|██        | 774/3753 [13:53<3:54:50,  4.73s/it] 21%|██        | 775/3753 [13:57<3:39:51,  4.43s/it] 21%|██        | 776/3753 [14:01<3:40:14,  4.44s/it] 21%|██        | 777/3753 [14:06<3:35:03,  4.34s/it] 21%|██        | 778/3753 [14:10<3:33:25,  4.30s/it] 21%|██        | 779/3753 [14:14<3:31:54,  4.28s/it] 21%|██        | 780/3753 [14:20<3:51:09,  4.66s/it]{'loss': -7.7004, 'grad_norm': 0.0, 'learning_rate': 9.652707917993383e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 176.71876525878906, 'weight_rejected': 0.3380771279335022, 'kl_term_chosen': -176.08444213867188, 'epoch': 0.2078614257161892}
                                                    {'loss': -7.7004, 'grad_norm': 0.0, 'learning_rate': 9.652707917993383e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 176.71876525878906, 'weight_rejected': 0.3380771279335022, 'kl_term_chosen': -176.08444213867188, 'epoch': 0.21}
 21%|██        | 780/3753 [14:20<3:51:09,  4.66s/it] 21%|██        | 781/3753 [14:25<4:00:28,  4.85s/it] 21%|██        | 782/3753 [14:29<3:49:32,  4.64s/it] 21%|██        | 783/3753 [14:35<4:11:48,  5.09s/it] 21%|██        | 784/3753 [14:39<3:51:15,  4.67s/it] 21%|██        | 785/3753 [14:42<3:35:01,  4.35s/it] 21%|██        | 786/3753 [14:46<3:24:12,  4.13s/it] 21%|██        | 787/3753 [14:51<3:30:25,  4.26s/it] 21%|██        | 788/3753 [14:55<3:28:39,  4.22s/it] 21%|██        | 789/3753 [14:59<3:33:39,  4.33s/it] 21%|██        | 790/3753 [15:03<3:27:59,  4.21s/it]{'loss': -6.8132, 'grad_norm': 0.0, 'learning_rate': 9.635473845039716e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 46.251792907714844, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': -45.304412841796875, 'epoch': 0.21052631578947367}
                                                    {'loss': -6.8132, 'grad_norm': 0.0, 'learning_rate': 9.635473845039716e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 46.251792907714844, 'weight_rejected': 0.05033063143491745, 'kl_term_chosen': -45.304412841796875, 'epoch': 0.21}
 21%|██        | 790/3753 [15:03<3:27:59,  4.21s/it] 21%|██        | 791/3753 [15:07<3:23:21,  4.12s/it] 21%|██        | 792/3753 [15:12<3:28:30,  4.23s/it] 21%|██        | 793/3753 [15:16<3:30:05,  4.26s/it] 21%|██        | 794/3753 [15:23<4:09:20,  5.06s/it] 21%|██        | 795/3753 [15:27<4:00:14,  4.87s/it] 21%|██        | 796/3753 [15:32<4:02:17,  4.92s/it] 21%|██        | 797/3753 [15:37<4:01:04,  4.89s/it] 21%|██▏       | 798/3753 [15:41<3:45:30,  4.58s/it] 21%|██▏       | 799/3753 [15:46<3:54:42,  4.77s/it] 21%|██▏       | 800/3753 [15:51<3:47:37,  4.62s/it]{'loss': -7.2509, 'grad_norm': 0.0, 'learning_rate': 9.617838601921176e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 57.303226470947266, 'weight_rejected': 0.8322367072105408, 'kl_term_chosen': -56.70538330078125, 'epoch': 0.21319120586275817}
                                                    {'loss': -7.2509, 'grad_norm': 0.0, 'learning_rate': 9.617838601921176e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 57.303226470947266, 'weight_rejected': 0.8322367072105408, 'kl_term_chosen': -56.70538330078125, 'epoch': 0.21}
 21%|██▏       | 800/3753 [15:51<3:47:37,  4.62s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 21%|██▏       | 801/3753 [16:59<19:34:04, 23.86s/it] 21%|██▏       | 802/3753 [17:04<14:46:21, 18.02s/it] 21%|██▏       | 803/3753 [17:07<11:14:54, 13.73s/it] 21%|██▏       | 804/3753 [17:11<8:49:37, 10.78s/it]  21%|██▏       | 805/3753 [17:15<7:11:28,  8.78s/it] 21%|██▏       | 806/3753 [17:20<6:06:30,  7.46s/it] 22%|██▏       | 807/3753 [17:25<5:35:03,  6.82s/it] 22%|██▏       | 808/3753 [17:29<4:50:48,  5.92s/it] 22%|██▏       | 809/3753 [17:34<4:44:30,  5.80s/it] 22%|██▏       | 810/3753 [17:37<4:00:54,  4.91s/it]{'loss': -6.9391, 'grad_norm': 0.0, 'learning_rate': 9.599803714853558e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 65.59654235839844, 'weight_rejected': 0.09138210862874985, 'kl_term_chosen': -64.72506713867188, 'epoch': 0.21585609593604263}
                                                    {'loss': -6.9391, 'grad_norm': 0.0, 'learning_rate': 9.599803714853558e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 65.59654235839844, 'weight_rejected': 0.09138210862874985, 'kl_term_chosen': -64.72506713867188, 'epoch': 0.22}
 22%|██▏       | 810/3753 [17:37<4:00:54,  4.91s/it] 22%|██▏       | 811/3753 [17:42<3:54:50,  4.79s/it] 22%|██▏       | 812/3753 [17:46<3:40:51,  4.51s/it]