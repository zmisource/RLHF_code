nohup: ignoring input
[W1216 10:57:28.158470494 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
⚙️  Running in WANDB offline mode
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
设置随机种子为: 42
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
从磁盘加载数据集 (注意: 数据集中不再需要 ref_logp)...
加载用于训练的策略模型 (Policy Model)...
加载用于训练的策略模型 (Policy Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 84.28it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.21it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.32it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 89.08it/s]
加载作为参考的SFT模型 (Reference Model)...
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 86.62it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 93.21it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 96.28it/s]
Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 88.85it/s]
[W1216 10:57:34.735163224 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1216 10:57:34.739307007 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1216 10:57:34.745656692 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
[W1216 10:57:34.747180437 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [::ffff:127.0.0.1]:29500 (errno: 97 - Address family not supported by protocol).
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
初始化 CustomSymPOTrainer...
/rlhf_code/code/implement_final_v3.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSymPOTrainer.__init__`. Use `processing_class` instead.
  super().__init__(model=model, args=args, **kwargs)
Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
开始分布式训练...
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128009}.
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaForCausalLM because mixed precision turned on in FSDP. Affects: model.embed_tokens.weight, model.norm.weight, lm_head.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1962: UserWarning: Upcasted low precision parameters in LlamaDecoderLayer because mixed precision turned on in FSDP. Affects: self_attn.q_proj.weight, self_attn.k_proj.weight, self_attn.v_proj.weight, self_attn.o_proj.weight, mlp.gate_proj.weight, mlp.up_proj.weight, mlp.down_proj.weight, input_layernorm.weight, post_attention_layernorm.weight.
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/accelerator.py:1968: UserWarning: FSDP upcast of low precision parameters may affect the precision of model checkpoints.
  warnings.warn(
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /wandb/offline-run-20251216_105745-06jpyosl
  0%|          | 0/3743 [00:00<?, ?it/s]--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -48.5
Sample 0 - pi_logp_chosen:  -48.19110107421875
Difference: 0.30889892578125
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -50.5
Sample 0 - pi_logp_chosen:  -50.17200469970703
Difference: 0.32799530029296875
---------------------------------
Sample 0 - ref_logp_chosen: -72.5
Sample 0 - pi_logp_chosen:  -72.23435974121094
Difference: 0.2656402587890625
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -164.0
Sample 0 - pi_logp_chosen:  -164.82467651367188
Difference: -0.824676513671875
---------------------------------
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
Could not estimate the number of tokens of the input, floating-point operations will not be computed
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -202.0
Sample 0 - pi_logp_chosen:  -201.9729766845703
Difference: 0.0270233154296875
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -210.0
Sample 0 - pi_logp_chosen:  -209.87814331054688
Difference: 0.121856689453125
---------------------------------
Sample 0 - ref_logp_chosen: -193.0
Sample 0 - pi_logp_chosen:  -191.9381103515625
Difference: 1.0618896484375
---------------------------------
Sample 0 - ref_logp_chosen: -340.0
Sample 0 - pi_logp_chosen:  -339.3873291015625
Difference: 0.6126708984375
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -39.5
Sample 0 - pi_logp_chosen:  -39.76247787475586
Difference: -0.2624778747558594
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -250.0
Sample 0 - pi_logp_chosen:  -251.0724639892578
Difference: -1.0724639892578125
---------------------------------
--- Sanity Check at Step 0 ---
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -55.75
Sample 0 - pi_logp_chosen:  -56.33271026611328
Difference: -0.5827102661132812
---------------------------------
Sample 0 - ref_logp_chosen: -118.0
Sample 0 - pi_logp_chosen:  -117.84983825683594
Difference: 0.1501617431640625
---------------------------------
--- Sanity Check at Step 0 ------ Sanity Check at Step 0 ---

--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -69.5
Sample 0 - pi_logp_chosen:  -69.90039825439453
Difference: -0.40039825439453125Sample 0 - ref_logp_chosen: -77.5
---------------------------------
Sample 0 - ref_logp_chosen: -69.0

Sample 0 - pi_logp_chosen:  -69.32749938964844
Difference: -0.3274993896484375
---------------------------------
Sample 0 - pi_logp_chosen:  -78.01214599609375
Difference: -0.51214599609375
---------------------------------
--- Sanity Check at Step 0 ---
Sample 0 - ref_logp_chosen: -89.0
Sample 0 - pi_logp_chosen:  -89.27076721191406
Difference: -0.2707672119140625
---------------------------------
  0%|          | 1/3743 [00:04<5:09:48,  4.97s/it]{'loss': 1.0399, 'grad_norm': 5796.93701171875, 'learning_rate': 0.0, 'mean_ratio_chosen': 0.5992082953453064, 'mean_ratio_rejected': 1.012220025062561, 'weight_chosen': 0.7500918507575989, 'weight_rejected': 0.5032044649124146, 'kl_term_chosen': -0.256072998046875, 'kl_term_rejected': 0.006072998046875, 'epoch': 0.00026721891909947226}
                                                  {'loss': 1.0399, 'grad_norm': 5796.93701171875, 'learning_rate': 0.0, 'mean_ratio_chosen': 0.5992082953453064, 'mean_ratio_rejected': 1.012220025062561, 'weight_chosen': 0.7500918507575989, 'weight_rejected': 0.5032044649124146, 'kl_term_chosen': -0.256072998046875, 'kl_term_rejected': 0.006072998046875, 'epoch': 0.0}
  0%|          | 1/3743 [00:05<5:09:48,  4.97s/it]  0%|          | 2/3743 [00:09<5:03:51,  4.87s/it]  0%|          | 3/3743 [00:15<5:17:27,  5.09s/it]  0%|          | 4/3743 [00:20<5:12:18,  5.01s/it]  0%|          | 5/3743 [00:24<5:07:07,  4.93s/it]  0%|          | 6/3743 [00:29<5:06:58,  4.93s/it]  0%|          | 7/3743 [00:34<4:54:01,  4.72s/it]  0%|          | 8/3743 [00:38<4:39:57,  4.50s/it]  0%|          | 9/3743 [00:41<4:12:37,  4.06s/it]  0%|          | 10/3743 [00:44<3:56:07,  3.80s/it]{'loss': 0.4692, 'grad_norm': 1670.7540283203125, 'learning_rate': 2.4e-08, 'mean_ratio_chosen': 2.449774742126465, 'mean_ratio_rejected': 0.27130696177482605, 'weight_chosen': 0.043213844299316406, 'weight_rejected': -0.15536469221115112, 'kl_term_chosen': 0.447998046875, 'kl_term_rejected': -0.652252197265625, 'epoch': 0.0026721891909947224}
                                                   {'loss': 0.4692, 'grad_norm': 1670.7540283203125, 'learning_rate': 2.4e-08, 'mean_ratio_chosen': 2.449774742126465, 'mean_ratio_rejected': 0.27130696177482605, 'weight_chosen': 0.043213844299316406, 'weight_rejected': -0.15536469221115112, 'kl_term_chosen': 0.447998046875, 'kl_term_rejected': -0.652252197265625, 'epoch': 0.0}
  0%|          | 10/3743 [00:44<3:56:07,  3.80s/it]  0%|          | 11/3743 [00:48<4:07:23,  3.98s/it]  0%|          | 12/3743 [00:54<4:40:16,  4.51s/it]  0%|          | 13/3743 [00:57<4:12:10,  4.06s/it]  0%|          | 14/3743 [01:03<4:51:33,  4.69s/it]  0%|          | 15/3743 [01:07<4:29:43,  4.34s/it]  0%|          | 16/3743 [01:11<4:36:50,  4.46s/it]  0%|          | 17/3743 [01:20<5:52:10,  5.67s/it]  0%|          | 18/3743 [01:28<6:46:08,  6.54s/it]  1%|          | 19/3743 [01:34<6:19:55,  6.12s/it]  1%|          | 20/3743 [01:39<6:03:05,  5.85s/it]{'loss': 0.7374, 'grad_norm': 3421.96435546875, 'learning_rate': 5.0666666666666664e-08, 'mean_ratio_chosen': 0.41313859820365906, 'mean_ratio_rejected': 0.48039132356643677, 'weight_chosen': 0.939971923828125, 'weight_rejected': 0.132080078125, 'kl_term_chosen': -0.441986083984375, 'kl_term_rejected': -0.3665771484375, 'epoch': 0.005344378381989445}
                                                   {'loss': 0.7374, 'grad_norm': 3421.96435546875, 'learning_rate': 5.0666666666666664e-08, 'mean_ratio_chosen': 0.41313859820365906, 'mean_ratio_rejected': 0.48039132356643677, 'weight_chosen': 0.939971923828125, 'weight_rejected': 0.132080078125, 'kl_term_chosen': -0.441986083984375, 'kl_term_rejected': -0.3665771484375, 'epoch': 0.01}
  1%|          | 20/3743 [01:39<6:03:05,  5.85s/it]  1%|          | 21/3743 [01:47<6:42:53,  6.49s/it]  1%|          | 22/3743 [01:53<6:36:54,  6.40s/it]  1%|          | 23/3743 [01:57<5:50:50,  5.66s/it]  1%|          | 24/3743 [02:01<5:26:48,  5.27s/it]  1%|          | 25/3743 [02:05<5:03:16,  4.89s/it]  1%|          | 26/3743 [02:09<4:50:11,  4.68s/it]  1%|          | 27/3743 [02:15<5:02:57,  4.89s/it]  1%|          | 28/3743 [02:18<4:36:02,  4.46s/it]  1%|          | 29/3743 [02:23<4:44:27,  4.60s/it]  1%|          | 30/3743 [02:27<4:37:57,  4.49s/it]{'loss': 0.1869, 'grad_norm': 2105.021240234375, 'learning_rate': 7.733333333333334e-08, 'mean_ratio_chosen': 0.704060435295105, 'mean_ratio_rejected': 0.4777451157569885, 'weight_chosen': 0.6720886826515198, 'weight_rejected': 0.12699899077415466, 'kl_term_chosen': -0.175445556640625, 'kl_term_rejected': -0.3693389892578125, 'epoch': 0.008016567572984168}
                                                   {'loss': 0.1869, 'grad_norm': 2105.021240234375, 'learning_rate': 7.733333333333334e-08, 'mean_ratio_chosen': 0.704060435295105, 'mean_ratio_rejected': 0.4777451157569885, 'weight_chosen': 0.6720886826515198, 'weight_rejected': 0.12699899077415466, 'kl_term_chosen': -0.175445556640625, 'kl_term_rejected': -0.3693389892578125, 'epoch': 0.01}
  1%|          | 30/3743 [02:28<4:37:57,  4.49s/it]  1%|          | 31/3743 [02:31<4:26:22,  4.31s/it]  1%|          | 32/3743 [02:37<4:42:17,  4.56s/it]  1%|          | 33/3743 [02:41<4:48:16,  4.66s/it]  1%|          | 34/3743 [02:45<4:33:45,  4.43s/it]  1%|          | 35/3743 [02:54<5:47:45,  5.63s/it]  1%|          | 36/3743 [02:59<5:47:46,  5.63s/it]  1%|          | 37/3743 [03:03<5:12:34,  5.06s/it]  1%|          | 38/3743 [03:08<5:11:46,  5.05s/it]  1%|          | 39/3743 [03:13<5:08:17,  4.99s/it]  1%|          | 40/3743 [03:17<4:54:22,  4.77s/it]{'loss': -0.1468, 'grad_norm': 1212.6043701171875, 'learning_rate': 1.0399999999999999e-07, 'mean_ratio_chosen': 0.191550612449646, 'mean_ratio_rejected': 0.296188622713089, 'weight_chosen': 1.3231277465820312, 'weight_rejected': -0.1116141676902771, 'kl_term_chosen': -0.8263015747070312, 'kl_term_rejected': -0.6083793640136719, 'epoch': 0.01068875676397889}
                                                   {'loss': -0.1468, 'grad_norm': 1212.6043701171875, 'learning_rate': 1.0399999999999999e-07, 'mean_ratio_chosen': 0.191550612449646, 'mean_ratio_rejected': 0.296188622713089, 'weight_chosen': 1.3231277465820312, 'weight_rejected': -0.1116141676902771, 'kl_term_chosen': -0.8263015747070312, 'kl_term_rejected': -0.6083793640136719, 'epoch': 0.01}
  1%|          | 40/3743 [03:17<4:54:22,  4.77s/it]  1%|          | 41/3743 [03:21<4:31:49,  4.41s/it]  1%|          | 42/3743 [03:25<4:28:45,  4.36s/it]  1%|          | 43/3743 [03:33<5:41:41,  5.54s/it]  1%|          | 44/3743 [03:39<5:42:54,  5.56s/it]  1%|          | 45/3743 [03:43<5:16:58,  5.14s/it]  1%|          | 46/3743 [03:50<5:50:23,  5.69s/it]  1%|▏         | 47/3743 [03:55<5:38:24,  5.49s/it]  1%|▏         | 48/3743 [04:01<5:38:35,  5.50s/it]  1%|▏         | 49/3743 [04:04<5:08:31,  5.01s/it]  1%|▏         | 50/3743 [04:09<5:08:28,  5.01s/it]{'loss': -0.0758, 'grad_norm': 1020.7750854492188, 'learning_rate': 1.3066666666666665e-07, 'mean_ratio_chosen': 1.5415095090866089, 'mean_ratio_rejected': 1.2552095651626587, 'weight_chosen': 0.2830696105957031, 'weight_rejected': 0.6131324768066406, 'kl_term_chosen': 0.21638107299804688, 'kl_term_rejected': 0.11365127563476562, 'epoch': 0.013360945954973611}
                                                   {'loss': -0.0758, 'grad_norm': 1020.7750854492188, 'learning_rate': 1.3066666666666665e-07, 'mean_ratio_chosen': 1.5415095090866089, 'mean_ratio_rejected': 1.2552095651626587, 'weight_chosen': 0.2830696105957031, 'weight_rejected': 0.6131324768066406, 'kl_term_chosen': 0.21638107299804688, 'kl_term_rejected': 0.11365127563476562, 'epoch': 0.01}
  1%|▏         | 50/3743 [04:10<5:08:28,  5.01s/it]  1%|▏         | 51/3743 [04:21<7:04:17,  6.90s/it]  1%|▏         | 52/3743 [04:25<6:12:14,  6.05s/it]  1%|▏         | 53/3743 [04:29<5:32:55,  5.41s/it]  1%|▏         | 54/3743 [04:32<5:00:45,  4.89s/it]  1%|▏         | 55/3743 [04:36<4:39:18,  4.54s/it]  1%|▏         | 56/3743 [04:43<5:28:55,  5.35s/it]  2%|▏         | 57/3743 [04:47<5:04:15,  4.95s/it]  2%|▏         | 58/3743 [04:52<4:59:50,  4.88s/it]  2%|▏         | 59/3743 [04:57<4:59:05,  4.87s/it]  2%|▏         | 60/3743 [05:03<5:10:21,  5.06s/it]{'loss': 0.1584, 'grad_norm': 1676.8485107421875, 'learning_rate': 1.573333333333333e-07, 'mean_ratio_chosen': 1.0258408784866333, 'mean_ratio_rejected': 1.0260170698165894, 'weight_chosen': 0.48553466796875, 'weight_rejected': 0.5108890533447266, 'kl_term_chosen': 0.01275634765625, 'kl_term_rejected': 0.012842178344726562, 'epoch': 0.016033135145968335}
                                                   {'loss': 0.1584, 'grad_norm': 1676.8485107421875, 'learning_rate': 1.573333333333333e-07, 'mean_ratio_chosen': 1.0258408784866333, 'mean_ratio_rejected': 1.0260170698165894, 'weight_chosen': 0.48553466796875, 'weight_rejected': 0.5108890533447266, 'kl_term_chosen': 0.01275634765625, 'kl_term_rejected': 0.012842178344726562, 'epoch': 0.02}
  2%|▏         | 60/3743 [05:03<5:10:21,  5.06s/it]  2%|▏         | 61/3743 [05:11<6:13:23,  6.08s/it]  2%|▏         | 62/3743 [05:14<5:23:01,  5.27s/it]  2%|▏         | 63/3743 [05:18<4:54:07,  4.80s/it]  2%|▏         | 64/3743 [05:23<4:52:04,  4.76s/it]  2%|▏         | 65/3743 [05:27<4:40:19,  4.57s/it]  2%|▏         | 66/3743 [05:32<4:46:32,  4.68s/it]  2%|▏         | 67/3743 [05:36<4:29:48,  4.40s/it]  2%|▏         | 68/3743 [05:40<4:34:14,  4.48s/it]  2%|▏         | 69/3743 [05:47<5:10:01,  5.06s/it]  2%|▏         | 70/3743 [05:52<5:19:56,  5.23s/it]{'loss': -0.0178, 'grad_norm': 1241.859375, 'learning_rate': 1.8399999999999998e-07, 'mean_ratio_chosen': 0.6558960676193237, 'mean_ratio_rejected': 1.887242078781128, 'weight_chosen': 0.7078247666358948, 'weight_rejected': 0.8151168823242188, 'kl_term_chosen': -0.21087646484375, 'kl_term_rejected': 0.31755828857421875, 'epoch': 0.018705324336963057}
                                                   {'loss': -0.0178, 'grad_norm': 1241.859375, 'learning_rate': 1.8399999999999998e-07, 'mean_ratio_chosen': 0.6558960676193237, 'mean_ratio_rejected': 1.887242078781128, 'weight_chosen': 0.7078247666358948, 'weight_rejected': 0.8151168823242188, 'kl_term_chosen': -0.21087646484375, 'kl_term_rejected': 0.31755828857421875, 'epoch': 0.02}
  2%|▏         | 70/3743 [05:52<5:19:56,  5.23s/it]  2%|▏         | 71/3743 [05:56<4:54:15,  4.81s/it]  2%|▏         | 72/3743 [06:01<4:47:56,  4.71s/it]  2%|▏         | 73/3743 [06:09<5:52:50,  5.77s/it]  2%|▏         | 74/3743 [06:17<6:35:09,  6.46s/it]  2%|▏         | 75/3743 [06:23<6:20:54,  6.23s/it]  2%|▏         | 76/3743 [06:26<5:32:37,  5.44s/it]  2%|▏         | 77/3743 [06:30<5:10:51,  5.09s/it]  2%|▏         | 78/3743 [06:36<5:23:08,  5.29s/it]  2%|▏         | 79/3743 [06:42<5:26:07,  5.34s/it]  2%|▏         | 80/3743 [06:46<5:07:39,  5.04s/it]{'loss': 0.0687, 'grad_norm': 1413.7044677734375, 'learning_rate': 2.1066666666666665e-07, 'mean_ratio_chosen': 0.4060018062591553, 'mean_ratio_rejected': 1.7749029397964478, 'weight_chosen': 0.9471893906593323, 'weight_rejected': 0.7847366333007812, 'kl_term_chosen': -0.4506988525390625, 'kl_term_rejected': 0.28687286376953125, 'epoch': 0.02137751352795778}
                                                   {'loss': 0.0687, 'grad_norm': 1413.7044677734375, 'learning_rate': 2.1066666666666665e-07, 'mean_ratio_chosen': 0.4060018062591553, 'mean_ratio_rejected': 1.7749029397964478, 'weight_chosen': 0.9471893906593323, 'weight_rejected': 0.7847366333007812, 'kl_term_chosen': -0.4506988525390625, 'kl_term_rejected': 0.28687286376953125, 'epoch': 0.02}
  2%|▏         | 80/3743 [06:46<5:07:39,  5.04s/it]  2%|▏         | 81/3743 [06:50<4:45:35,  4.68s/it]  2%|▏         | 82/3743 [06:55<4:53:05,  4.80s/it]  2%|▏         | 83/3743 [06:59<4:38:26,  4.56s/it]  2%|▏         | 84/3743 [07:03<4:32:07,  4.46s/it]  2%|▏         | 85/3743 [07:08<4:31:23,  4.45s/it]  2%|▏         | 86/3743 [07:12<4:37:03,  4.55s/it]  2%|▏         | 87/3743 [07:17<4:30:23,  4.44s/it]  2%|▏         | 88/3743 [07:21<4:29:27,  4.42s/it]  2%|▏         | 89/3743 [07:25<4:24:55,  4.35s/it]  2%|▏         | 90/3743 [07:28<4:07:38,  4.07s/it]{'loss': 0.1301, 'grad_norm': 1816.461669921875, 'learning_rate': 2.3733333333333334e-07, 'mean_ratio_chosen': 0.7733534574508667, 'mean_ratio_rejected': 1.565820574760437, 'weight_chosen': 0.6248474717140198, 'weight_rejected': 0.7208482027053833, 'kl_term_chosen': -0.128509521484375, 'kl_term_rejected': 0.22420501708984375, 'epoch': 0.0240497027189525}
                                                   {'loss': 0.1301, 'grad_norm': 1816.461669921875, 'learning_rate': 2.3733333333333334e-07, 'mean_ratio_chosen': 0.7733534574508667, 'mean_ratio_rejected': 1.565820574760437, 'weight_chosen': 0.6248474717140198, 'weight_rejected': 0.7208482027053833, 'kl_term_chosen': -0.128509521484375, 'kl_term_rejected': 0.22420501708984375, 'epoch': 0.02}
  2%|▏         | 90/3743 [07:29<4:07:38,  4.07s/it]  2%|▏         | 91/3743 [07:33<4:19:32,  4.26s/it]  2%|▏         | 92/3743 [07:39<4:44:56,  4.68s/it]  2%|▏         | 93/3743 [07:42<4:23:44,  4.34s/it]  3%|▎         | 94/3743 [07:48<4:38:36,  4.58s/it]  3%|▎         | 95/3743 [07:52<4:36:14,  4.54s/it]  3%|▎         | 96/3743 [07:56<4:35:05,  4.53s/it]  3%|▎         | 97/3743 [08:00<4:20:32,  4.29s/it]  3%|▎         | 98/3743 [08:04<4:11:49,  4.15s/it]  3%|▎         | 99/3743 [08:08<4:16:29,  4.22s/it]  3%|▎         | 100/3743 [08:14<4:33:35,  4.51s/it]{'loss': 0.1034, 'grad_norm': 1262.767333984375, 'learning_rate': 2.64e-07, 'mean_ratio_chosen': 0.4231037199497223, 'mean_ratio_rejected': 0.23658758401870728, 'weight_chosen': 0.9202437996864319, 'weight_rejected': -0.22737032175064087, 'kl_term_chosen': -0.4300689697265625, 'kl_term_rejected': -0.7207183837890625, 'epoch': 0.026721891909947223}
                                                    {'loss': 0.1034, 'grad_norm': 1262.767333984375, 'learning_rate': 2.64e-07, 'mean_ratio_chosen': 0.4231037199497223, 'mean_ratio_rejected': 0.23658758401870728, 'weight_chosen': 0.9202437996864319, 'weight_rejected': -0.22737032175064087, 'kl_term_chosen': -0.4300689697265625, 'kl_term_rejected': -0.7207183837890625, 'epoch': 0.03}
  3%|▎         | 100/3743 [08:14<4:33:35,  4.51s/it]  3%|▎         | 101/3743 [08:17<4:20:08,  4.29s/it]  3%|▎         | 102/3743 [08:21<4:14:53,  4.20s/it]  3%|▎         | 103/3743 [08:28<4:54:13,  4.85s/it]  3%|▎         | 104/3743 [08:31<4:33:09,  4.50s/it]  3%|▎         | 105/3743 [08:35<4:18:55,  4.27s/it]  3%|▎         | 106/3743 [08:40<4:26:17,  4.39s/it]  3%|▎         | 107/3743 [08:44<4:19:27,  4.28s/it]  3%|▎         | 108/3743 [08:48<4:18:23,  4.26s/it]  3%|▎         | 109/3743 [08:53<4:26:50,  4.41s/it]  3%|▎         | 110/3743 [08:57<4:19:28,  4.29s/it]{'loss': 0.0824, 'grad_norm': 3903.504150390625, 'learning_rate': 2.906666666666667e-07, 'mean_ratio_chosen': 0.4699402153491974, 'mean_ratio_rejected': 0.9887568950653076, 'weight_chosen': 0.8759117126464844, 'weight_rejected': 0.49333953857421875, 'kl_term_chosen': -0.3775749206542969, 'kl_term_rejected': -0.00565338134765625, 'epoch': 0.029394081100941948}
                                                    {'loss': 0.0824, 'grad_norm': 3903.504150390625, 'learning_rate': 2.906666666666667e-07, 'mean_ratio_chosen': 0.4699402153491974, 'mean_ratio_rejected': 0.9887568950653076, 'weight_chosen': 0.8759117126464844, 'weight_rejected': 0.49333953857421875, 'kl_term_chosen': -0.3775749206542969, 'kl_term_rejected': -0.00565338134765625, 'epoch': 0.03}
  3%|▎         | 110/3743 [08:57<4:19:28,  4.29s/it]  3%|▎         | 111/3743 [09:01<4:16:12,  4.23s/it]  3%|▎         | 112/3743 [09:05<4:11:47,  4.16s/it]  3%|▎         | 113/3743 [09:09<4:17:34,  4.26s/it]  3%|▎         | 114/3743 [09:13<4:09:06,  4.12s/it]  3%|▎         | 115/3743 [09:17<4:03:53,  4.03s/it]  3%|▎         | 116/3743 [09:21<4:06:54,  4.08s/it]  3%|▎         | 117/3743 [09:25<4:06:27,  4.08s/it]  3%|▎         | 118/3743 [09:29<3:59:33,  3.97s/it]  3%|▎         | 119/3743 [09:33<3:53:00,  3.86s/it]  3%|▎         | 120/3743 [09:36<3:47:11,  3.76s/it]{'loss': -0.0326, 'grad_norm': 1728.6923828125, 'learning_rate': 3.173333333333333e-07, 'mean_ratio_chosen': 0.32051780819892883, 'mean_ratio_rejected': 2.192615509033203, 'weight_chosen': 1.06732177734375, 'weight_rejected': 0.889556884765625, 'kl_term_chosen': -0.56890869140625, 'kl_term_rejected': 0.392547607421875, 'epoch': 0.03206627029193667}
                                                    {'loss': -0.0326, 'grad_norm': 1728.6923828125, 'learning_rate': 3.173333333333333e-07, 'mean_ratio_chosen': 0.32051780819892883, 'mean_ratio_rejected': 2.192615509033203, 'weight_chosen': 1.06732177734375, 'weight_rejected': 0.889556884765625, 'kl_term_chosen': -0.56890869140625, 'kl_term_rejected': 0.392547607421875, 'epoch': 0.03}
  3%|▎         | 120/3743 [09:36<3:47:11,  3.76s/it]  3%|▎         | 121/3743 [09:41<4:02:29,  4.02s/it]  3%|▎         | 122/3743 [09:45<4:03:53,  4.04s/it]  3%|▎         | 123/3743 [09:51<4:42:44,  4.69s/it]  3%|▎         | 124/3743 [09:55<4:21:11,  4.33s/it]  3%|▎         | 125/3743 [09:59<4:31:14,  4.50s/it]  3%|▎         | 126/3743 [10:03<4:15:51,  4.24s/it]  3%|▎         | 127/3743 [10:07<4:15:17,  4.24s/it]  3%|▎         | 128/3743 [10:11<4:04:36,  4.06s/it]  3%|▎         | 129/3743 [10:15<4:00:27,  3.99s/it]  3%|▎         | 130/3743 [10:19<3:59:31,  3.98s/it]{'loss': 0.2311, 'grad_norm': 727.46728515625, 'learning_rate': 3.4399999999999996e-07, 'mean_ratio_chosen': 1.0028574466705322, 'mean_ratio_rejected': 1.0425283908843994, 'weight_chosen': 0.495643675327301, 'weight_rejected': 0.5185661315917969, 'kl_term_chosen': 0.00142669677734375, 'kl_term_rejected': 0.020824432373046875, 'epoch': 0.03473845948293139}
                                                    {'loss': 0.2311, 'grad_norm': 727.46728515625, 'learning_rate': 3.4399999999999996e-07, 'mean_ratio_chosen': 1.0028574466705322, 'mean_ratio_rejected': 1.0425283908843994, 'weight_chosen': 0.495643675327301, 'weight_rejected': 0.5185661315917969, 'kl_term_chosen': 0.00142669677734375, 'kl_term_rejected': 0.020824432373046875, 'epoch': 0.03}
  3%|▎         | 130/3743 [10:19<3:59:31,  3.98s/it]  3%|▎         | 131/3743 [10:23<4:00:45,  4.00s/it]  4%|▎         | 132/3743 [10:27<4:06:28,  4.10s/it]  4%|▎         | 133/3743 [10:32<4:15:36,  4.25s/it]  4%|▎         | 134/3743 [10:36<4:14:33,  4.23s/it]  4%|▎         | 135/3743 [10:40<4:05:26,  4.08s/it]  4%|▎         | 136/3743 [10:43<3:52:25,  3.87s/it]  4%|▎         | 137/3743 [10:48<4:09:21,  4.15s/it]  4%|▎         | 138/3743 [10:54<4:42:09,  4.70s/it]  4%|▎         | 139/3743 [10:58<4:35:14,  4.58s/it]  4%|▎         | 140/3743 [11:03<4:49:24,  4.82s/it]{'loss': 0.0766, 'grad_norm': 1105.727294921875, 'learning_rate': 3.7066666666666665e-07, 'mean_ratio_chosen': 0.654022216796875, 'mean_ratio_rejected': 0.6467183828353882, 'weight_chosen': 0.7116661071777344, 'weight_rejected': 0.2811927795410156, 'kl_term_chosen': -0.21230697631835938, 'kl_term_rejected': -0.21792221069335938, 'epoch': 0.037410648673926114}
                                                    {'loss': 0.0766, 'grad_norm': 1105.727294921875, 'learning_rate': 3.7066666666666665e-07, 'mean_ratio_chosen': 0.654022216796875, 'mean_ratio_rejected': 0.6467183828353882, 'weight_chosen': 0.7116661071777344, 'weight_rejected': 0.2811927795410156, 'kl_term_chosen': -0.21230697631835938, 'kl_term_rejected': -0.21792221069335938, 'epoch': 0.04}
  4%|▎         | 140/3743 [11:04<4:49:24,  4.82s/it]  4%|▍         | 141/3743 [11:06<4:16:37,  4.27s/it]  4%|▍         | 142/3743 [11:11<4:19:06,  4.32s/it]  4%|▍         | 143/3743 [11:16<4:25:17,  4.42s/it]  4%|▍         | 144/3743 [11:19<4:14:36,  4.24s/it]  4%|▍         | 145/3743 [11:24<4:27:08,  4.45s/it]  4%|▍         | 146/3743 [11:30<4:56:32,  4.95s/it]  4%|▍         | 147/3743 [11:35<4:40:58,  4.69s/it]  4%|▍         | 148/3743 [11:39<4:42:06,  4.71s/it]  4%|▍         | 149/3743 [11:44<4:46:38,  4.79s/it]  4%|▍         | 150/3743 [11:48<4:33:52,  4.57s/it]{'loss': 0.0464, 'grad_norm': 1043.48291015625, 'learning_rate': 3.973333333333333e-07, 'mean_ratio_chosen': 0.6207910180091858, 'mean_ratio_rejected': 0.8201336860656738, 'weight_chosen': 0.736427366733551, 'weight_rejected': 0.3967057168483734, 'kl_term_chosen': -0.23838043212890625, 'kl_term_rejected': -0.09914398193359375, 'epoch': 0.04008283786492084}
                                                    {'loss': 0.0464, 'grad_norm': 1043.48291015625, 'learning_rate': 3.973333333333333e-07, 'mean_ratio_chosen': 0.6207910180091858, 'mean_ratio_rejected': 0.8201336860656738, 'weight_chosen': 0.736427366733551, 'weight_rejected': 0.3967057168483734, 'kl_term_chosen': -0.23838043212890625, 'kl_term_rejected': -0.09914398193359375, 'epoch': 0.04}
  4%|▍         | 150/3743 [11:48<4:33:52,  4.57s/it]  4%|▍         | 151/3743 [11:52<4:25:18,  4.43s/it]  4%|▍         | 152/3743 [11:57<4:22:18,  4.38s/it]  4%|▍         | 153/3743 [12:02<4:36:05,  4.61s/it]  4%|▍         | 154/3743 [12:06<4:24:51,  4.43s/it]  4%|▍         | 155/3743 [12:10<4:19:36,  4.34s/it]  4%|▍         | 156/3743 [12:14<4:07:04,  4.13s/it]  4%|▍         | 157/3743 [12:18<4:13:21,  4.24s/it]  4%|▍         | 158/3743 [12:22<4:12:24,  4.22s/it]  4%|▍         | 159/3743 [12:26<4:09:20,  4.17s/it]  4%|▍         | 160/3743 [12:30<4:06:03,  4.12s/it]{'loss': 0.2262, 'grad_norm': 2890.009521484375, 'learning_rate': 4.24e-07, 'mean_ratio_chosen': 0.5678039789199829, 'mean_ratio_rejected': 1.0252189636230469, 'weight_chosen': 0.7775576710700989, 'weight_rejected': 0.5088826417922974, 'kl_term_chosen': -0.282989501953125, 'kl_term_rejected': 0.012453079223632812, 'epoch': 0.04275502705591556}
                                                    {'loss': 0.2262, 'grad_norm': 2890.009521484375, 'learning_rate': 4.24e-07, 'mean_ratio_chosen': 0.5678039789199829, 'mean_ratio_rejected': 1.0252189636230469, 'weight_chosen': 0.7775576710700989, 'weight_rejected': 0.5088826417922974, 'kl_term_chosen': -0.282989501953125, 'kl_term_rejected': 0.012453079223632812, 'epoch': 0.04}
  4%|▍         | 160/3743 [12:30<4:06:03,  4.12s/it]  4%|▍         | 161/3743 [12:35<4:14:35,  4.26s/it]  4%|▍         | 162/3743 [12:39<4:09:26,  4.18s/it]  4%|▍         | 163/3743 [12:42<3:48:45,  3.83s/it]  4%|▍         | 164/3743 [12:46<3:47:34,  3.82s/it]  4%|▍         | 165/3743 [12:51<4:22:20,  4.40s/it]  4%|▍         | 166/3743 [12:55<4:13:44,  4.26s/it]  4%|▍         | 167/3743 [13:01<4:40:06,  4.70s/it]  4%|▍         | 168/3743 [13:06<4:36:19,  4.64s/it]  5%|▍         | 169/3743 [13:10<4:31:08,  4.55s/it]  5%|▍         | 170/3743 [13:14<4:26:48,  4.48s/it]{'loss': 0.2687, 'grad_norm': 7199.02197265625, 'learning_rate': 4.506666666666666e-07, 'mean_ratio_chosen': 1.3563252687454224, 'mean_ratio_rejected': 0.6153164505958557, 'weight_chosen': 0.34260594844818115, 'weight_rejected': 0.2502942979335785, 'kl_term_chosen': 0.1523895263671875, 'kl_term_rejected': -0.24280929565429688, 'epoch': 0.04542721624691028}
                                                    {'loss': 0.2687, 'grad_norm': 7199.02197265625, 'learning_rate': 4.506666666666666e-07, 'mean_ratio_chosen': 1.3563252687454224, 'mean_ratio_rejected': 0.6153164505958557, 'weight_chosen': 0.34260594844818115, 'weight_rejected': 0.2502942979335785, 'kl_term_chosen': 0.1523895263671875, 'kl_term_rejected': -0.24280929565429688, 'epoch': 0.05}
  5%|▍         | 170/3743 [13:14<4:26:48,  4.48s/it]  5%|▍         | 171/3743 [13:19<4:31:11,  4.56s/it]  5%|▍         | 172/3743 [13:23<4:26:15,  4.47s/it]  5%|▍         | 173/3743 [13:32<5:39:50,  5.71s/it]  5%|▍         | 174/3743 [13:35<4:56:46,  4.99s/it]  5%|▍         | 175/3743 [13:40<4:44:33,  4.79s/it]  5%|▍         | 176/3743 [13:48<5:42:58,  5.77s/it]  5%|▍         | 177/3743 [13:53<5:37:21,  5.68s/it]  5%|▍         | 178/3743 [13:59<5:37:01,  5.67s/it]  5%|▍         | 179/3743 [14:04<5:22:12,  5.42s/it]  5%|▍         | 180/3743 [14:07<4:42:34,  4.76s/it]{'loss': 0.4991, 'grad_norm': 812.530029296875, 'learning_rate': 4.773333333333333e-07, 'mean_ratio_chosen': 1.2543575763702393, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.38272106647491455, 'weight_rejected': -0.897933840751648, 'kl_term_chosen': 0.113311767578125, 'kl_term_rejected': -1.3939666748046875, 'epoch': 0.048099405437905}
                                                    {'loss': 0.4991, 'grad_norm': 812.530029296875, 'learning_rate': 4.773333333333333e-07, 'mean_ratio_chosen': 1.2543575763702393, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 0.38272106647491455, 'weight_rejected': -0.897933840751648, 'kl_term_chosen': 0.113311767578125, 'kl_term_rejected': -1.3939666748046875, 'epoch': 0.05}
  5%|▍         | 180/3743 [14:07<4:42:34,  4.76s/it]  5%|▍         | 181/3743 [14:15<5:45:52,  5.83s/it]  5%|▍         | 182/3743 [14:23<6:16:04,  6.34s/it]  5%|▍         | 183/3743 [14:27<5:47:08,  5.85s/it]  5%|▍         | 184/3743 [14:32<5:26:10,  5.50s/it]  5%|▍         | 185/3743 [14:36<5:01:02,  5.08s/it]  5%|▍         | 186/3743 [14:40<4:38:34,  4.70s/it]  5%|▍         | 187/3743 [14:44<4:31:11,  4.58s/it]  5%|▌         | 188/3743 [14:57<6:49:02,  6.90s/it]  5%|▌         | 189/3743 [15:01<6:02:27,  6.12s/it]  5%|▌         | 190/3743 [15:05<5:21:23,  5.43s/it]{'loss': 0.3716, 'grad_norm': 1039.8543701171875, 'learning_rate': 5.04e-07, 'mean_ratio_chosen': 0.5585746765136719, 'mean_ratio_rejected': 0.3633994162082672, 'weight_chosen': 0.7826249003410339, 'weight_rejected': -0.017133325338363647, 'kl_term_chosen': -0.2911834716796875, 'kl_term_rejected': -0.5061264038085938, 'epoch': 0.05077159462889973}
                                                    {'loss': 0.3716, 'grad_norm': 1039.8543701171875, 'learning_rate': 5.04e-07, 'mean_ratio_chosen': 0.5585746765136719, 'mean_ratio_rejected': 0.3633994162082672, 'weight_chosen': 0.7826249003410339, 'weight_rejected': -0.017133325338363647, 'kl_term_chosen': -0.2911834716796875, 'kl_term_rejected': -0.5061264038085938, 'epoch': 0.05}
  5%|▌         | 190/3743 [15:05<5:21:23,  5.43s/it]  5%|▌         | 191/3743 [15:09<4:53:19,  4.95s/it]  5%|▌         | 192/3743 [15:12<4:32:07,  4.60s/it]  5%|▌         | 193/3743 [15:20<5:26:26,  5.52s/it]  5%|▌         | 194/3743 [15:25<5:15:31,  5.33s/it]  5%|▌         | 195/3743 [15:30<5:07:52,  5.21s/it]  5%|▌         | 196/3743 [15:36<5:23:03,  5.46s/it]  5%|▌         | 197/3743 [15:40<4:52:49,  4.95s/it]  5%|▌         | 198/3743 [15:47<5:42:31,  5.80s/it]  5%|▌         | 199/3743 [15:53<5:31:57,  5.62s/it]  5%|▌         | 200/3743 [15:58<5:24:43,  5.50s/it]{'loss': 0.3713, 'grad_norm': 3632.832275390625, 'learning_rate': 5.306666666666665e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.7639704942703247, 'weight_chosen': 1.682098388671875, 'weight_rejected': 0.3625793755054474, 'kl_term_chosen': -1.183258056640625, 'kl_term_rejected': -0.134613037109375, 'epoch': 0.053443783819894446}
                                                    {'loss': 0.3713, 'grad_norm': 3632.832275390625, 'learning_rate': 5.306666666666665e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.7639704942703247, 'weight_chosen': 1.682098388671875, 'weight_rejected': 0.3625793755054474, 'kl_term_chosen': -1.183258056640625, 'kl_term_rejected': -0.134613037109375, 'epoch': 0.05}
  5%|▌         | 200/3743 [15:58<5:24:43,  5.50s/it]  5%|▌         | 201/3743 [16:02<5:09:15,  5.24s/it]  5%|▌         | 202/3743 [16:06<4:40:53,  4.76s/it]  5%|▌         | 203/3743 [16:10<4:22:10,  4.44s/it]  5%|▌         | 204/3743 [16:13<3:59:15,  4.06s/it]  5%|▌         | 205/3743 [16:17<4:03:47,  4.13s/it]  6%|▌         | 206/3743 [16:25<5:13:10,  5.31s/it]  6%|▌         | 207/3743 [16:29<4:47:21,  4.88s/it]  6%|▌         | 208/3743 [16:35<5:06:58,  5.21s/it]  6%|▌         | 209/3743 [16:39<4:48:02,  4.89s/it]  6%|▌         | 210/3743 [16:44<4:41:29,  4.78s/it]{'loss': 0.4489, 'grad_norm': 1050.98828125, 'learning_rate': 5.573333333333333e-07, 'mean_ratio_chosen': 0.8685632348060608, 'mean_ratio_rejected': 0.25064048171043396, 'weight_chosen': 0.5660020112991333, 'weight_rejected': -0.19412606954574585, 'kl_term_chosen': -0.07045745849609375, 'kl_term_rejected': -0.6918678283691406, 'epoch': 0.05611597301088917}
                                                    {'loss': 0.4489, 'grad_norm': 1050.98828125, 'learning_rate': 5.573333333333333e-07, 'mean_ratio_chosen': 0.8685632348060608, 'mean_ratio_rejected': 0.25064048171043396, 'weight_chosen': 0.5660020112991333, 'weight_rejected': -0.19412606954574585, 'kl_term_chosen': -0.07045745849609375, 'kl_term_rejected': -0.6918678283691406, 'epoch': 0.06}
  6%|▌         | 210/3743 [16:44<4:41:29,  4.78s/it]  6%|▌         | 211/3743 [16:47<4:17:24,  4.37s/it]  6%|▌         | 212/3743 [16:51<4:14:26,  4.32s/it]  6%|▌         | 213/3743 [16:55<4:07:54,  4.21s/it]  6%|▌         | 214/3743 [17:00<4:08:37,  4.23s/it]  6%|▌         | 215/3743 [17:05<4:33:18,  4.65s/it]  6%|▌         | 216/3743 [17:10<4:28:33,  4.57s/it]  6%|▌         | 217/3743 [17:13<4:10:53,  4.27s/it]  6%|▌         | 218/3743 [17:17<4:06:39,  4.20s/it]  6%|▌         | 219/3743 [17:21<3:51:18,  3.94s/it]  6%|▌         | 220/3743 [17:26<4:15:26,  4.35s/it]{'loss': 0.4326, 'grad_norm': 1283.2423095703125, 'learning_rate': 5.839999999999999e-07, 'mean_ratio_chosen': 0.23513901233673096, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.2232398986816406, 'weight_rejected': -0.7239971160888672, 'kl_term_chosen': -0.7237892150878906, 'kl_term_rejected': -1.2234783172607422, 'epoch': 0.058788162201883896}
                                                    {'loss': 0.4326, 'grad_norm': 1283.2423095703125, 'learning_rate': 5.839999999999999e-07, 'mean_ratio_chosen': 0.23513901233673096, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.2232398986816406, 'weight_rejected': -0.7239971160888672, 'kl_term_chosen': -0.7237892150878906, 'kl_term_rejected': -1.2234783172607422, 'epoch': 0.06}
  6%|▌         | 220/3743 [17:26<4:15:26,  4.35s/it]  6%|▌         | 221/3743 [17:31<4:26:46,  4.54s/it]  6%|▌         | 222/3743 [17:35<4:25:03,  4.52s/it]  6%|▌         | 223/3743 [17:39<4:10:47,  4.27s/it]  6%|▌         | 224/3743 [17:43<4:00:09,  4.09s/it]  6%|▌         | 225/3743 [17:47<4:01:34,  4.12s/it]  6%|▌         | 226/3743 [17:51<4:00:23,  4.10s/it]  6%|▌         | 227/3743 [17:56<4:20:26,  4.44s/it]  6%|▌         | 228/3743 [18:00<4:14:21,  4.34s/it]  6%|▌         | 229/3743 [18:04<4:06:25,  4.21s/it]  6%|▌         | 230/3743 [18:08<3:57:18,  4.05s/it]{'loss': 0.2476, 'grad_norm': 8419.14453125, 'learning_rate': 6.106666666666666e-07, 'mean_ratio_chosen': 0.1353745311498642, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.4974746704101562, 'weight_rejected': -0.89263916015625, 'kl_term_chosen': -0.9998550415039062, 'kl_term_rejected': -1.3905181884765625, 'epoch': 0.061460351392878615}
                                                    {'loss': 0.2476, 'grad_norm': 8419.14453125, 'learning_rate': 6.106666666666666e-07, 'mean_ratio_chosen': 0.1353745311498642, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.4974746704101562, 'weight_rejected': -0.89263916015625, 'kl_term_chosen': -0.9998550415039062, 'kl_term_rejected': -1.3905181884765625, 'epoch': 0.06}
  6%|▌         | 230/3743 [18:08<3:57:18,  4.05s/it]  6%|▌         | 231/3743 [18:15<4:56:30,  5.07s/it]  6%|▌         | 232/3743 [18:19<4:31:00,  4.63s/it]  6%|▌         | 233/3743 [18:24<4:35:12,  4.70s/it]  6%|▋         | 234/3743 [18:28<4:26:14,  4.55s/it]  6%|▋         | 235/3743 [18:32<4:24:39,  4.53s/it]  6%|▋         | 236/3743 [18:36<4:06:09,  4.21s/it]  6%|▋         | 237/3743 [18:40<4:04:29,  4.18s/it]  6%|▋         | 238/3743 [18:44<4:03:26,  4.17s/it]  6%|▋         | 239/3743 [18:53<5:25:05,  5.57s/it]  6%|▋         | 240/3743 [18:56<4:45:49,  4.90s/it]{'loss': 1.1462, 'grad_norm': 2187.961181640625, 'learning_rate': 6.373333333333333e-07, 'mean_ratio_chosen': 0.6498590707778931, 'mean_ratio_rejected': 0.12051303684711456, 'weight_chosen': 0.7137298583984375, 'weight_rejected': -0.5589752197265625, 'kl_term_chosen': -0.2154998779296875, 'kl_term_rejected': -1.0579986572265625, 'epoch': 0.06413254058387334}
                                                    {'loss': 1.1462, 'grad_norm': 2187.961181640625, 'learning_rate': 6.373333333333333e-07, 'mean_ratio_chosen': 0.6498590707778931, 'mean_ratio_rejected': 0.12051303684711456, 'weight_chosen': 0.7137298583984375, 'weight_rejected': -0.5589752197265625, 'kl_term_chosen': -0.2154998779296875, 'kl_term_rejected': -1.0579986572265625, 'epoch': 0.06}
  6%|▋         | 240/3743 [18:56<4:45:49,  4.90s/it]  6%|▋         | 241/3743 [19:00<4:26:43,  4.57s/it]  6%|▋         | 242/3743 [19:04<4:21:02,  4.47s/it]  6%|▋         | 243/3743 [19:10<4:41:45,  4.83s/it]  7%|▋         | 244/3743 [19:15<4:36:33,  4.74s/it]  7%|▋         | 245/3743 [19:19<4:28:51,  4.61s/it]  7%|▋         | 246/3743 [19:23<4:23:01,  4.51s/it]  7%|▋         | 247/3743 [19:26<3:59:08,  4.10s/it]  7%|▋         | 248/3743 [19:31<4:08:14,  4.26s/it]  7%|▋         | 249/3743 [19:36<4:14:06,  4.36s/it]  7%|▋         | 250/3743 [19:41<4:27:02,  4.59s/it]{'loss': 0.042, 'grad_norm': 942.022705078125, 'learning_rate': 6.64e-07, 'mean_ratio_chosen': 0.38245970010757446, 'mean_ratio_rejected': 0.49481502175331116, 'weight_chosen': 0.9777889847755432, 'weight_rejected': 0.14671897888183594, 'kl_term_chosen': -0.48056602478027344, 'kl_term_rejected': -0.35178565979003906, 'epoch': 0.06680472977486807}
                                                    {'loss': 0.042, 'grad_norm': 942.022705078125, 'learning_rate': 6.64e-07, 'mean_ratio_chosen': 0.38245970010757446, 'mean_ratio_rejected': 0.49481502175331116, 'weight_chosen': 0.9777889847755432, 'weight_rejected': 0.14671897888183594, 'kl_term_chosen': -0.48056602478027344, 'kl_term_rejected': -0.35178565979003906, 'epoch': 0.07}
  7%|▋         | 250/3743 [19:41<4:27:02,  4.59s/it]  7%|▋         | 251/3743 [19:44<4:09:35,  4.29s/it]  7%|▋         | 252/3743 [19:49<4:09:13,  4.28s/it]  7%|▋         | 253/3743 [19:55<4:38:07,  4.78s/it]  7%|▋         | 254/3743 [19:58<4:20:30,  4.48s/it]  7%|▋         | 255/3743 [20:05<4:55:32,  5.08s/it]  7%|▋         | 256/3743 [20:08<4:24:29,  4.55s/it]  7%|▋         | 257/3743 [20:15<5:02:09,  5.20s/it]  7%|▋         | 258/3743 [20:19<4:43:13,  4.88s/it]  7%|▋         | 259/3743 [20:24<4:47:54,  4.96s/it]  7%|▋         | 260/3743 [20:29<4:47:56,  4.96s/it]{'loss': 0.6202, 'grad_norm': 952.4093627929688, 'learning_rate': 6.906666666666666e-07, 'mean_ratio_chosen': 1.222709059715271, 'mean_ratio_rejected': 0.474265992641449, 'weight_chosen': 0.39903831481933594, 'weight_rejected': 0.12651824951171875, 'kl_term_chosen': 0.10053443908691406, 'kl_term_rejected': -0.37299346923828125, 'epoch': 0.06947691896586278}
                                                    {'loss': 0.6202, 'grad_norm': 952.4093627929688, 'learning_rate': 6.906666666666666e-07, 'mean_ratio_chosen': 1.222709059715271, 'mean_ratio_rejected': 0.474265992641449, 'weight_chosen': 0.39903831481933594, 'weight_rejected': 0.12651824951171875, 'kl_term_chosen': 0.10053443908691406, 'kl_term_rejected': -0.37299346923828125, 'epoch': 0.07}
  7%|▋         | 260/3743 [20:29<4:47:56,  4.96s/it]  7%|▋         | 261/3743 [20:33<4:32:54,  4.70s/it]  7%|▋         | 262/3743 [20:39<4:55:26,  5.09s/it]  7%|▋         | 263/3743 [20:43<4:29:35,  4.65s/it]  7%|▋         | 264/3743 [20:48<4:41:23,  4.85s/it]  7%|▋         | 265/3743 [20:53<4:35:01,  4.74s/it]  7%|▋         | 266/3743 [20:57<4:32:49,  4.71s/it]  7%|▋         | 267/3743 [21:01<4:24:31,  4.57s/it]  7%|▋         | 268/3743 [21:05<4:10:09,  4.32s/it]  7%|▋         | 269/3743 [21:10<4:13:38,  4.38s/it]  7%|▋         | 270/3743 [21:14<4:04:18,  4.22s/it]{'loss': 0.6627, 'grad_norm': 831.4683837890625, 'learning_rate': 7.173333333333333e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.5793609619140625, 'weight_rejected': -2.07794189453125, 'kl_term_chosen': -2.0819854736328125, 'kl_term_rejected': -2.574462890625, 'epoch': 0.0721491081568575}
                                                    {'loss': 0.6627, 'grad_norm': 831.4683837890625, 'learning_rate': 7.173333333333333e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.5793609619140625, 'weight_rejected': -2.07794189453125, 'kl_term_chosen': -2.0819854736328125, 'kl_term_rejected': -2.574462890625, 'epoch': 0.07}
  7%|▋         | 270/3743 [21:14<4:04:18,  4.22s/it]  7%|▋         | 271/3743 [21:19<4:33:44,  4.73s/it]  7%|▋         | 272/3743 [21:25<4:51:10,  5.03s/it]  7%|▋         | 273/3743 [21:29<4:32:57,  4.72s/it]  7%|▋         | 274/3743 [21:33<4:23:13,  4.55s/it]  7%|▋         | 275/3743 [21:38<4:18:03,  4.46s/it]  7%|▋         | 276/3743 [21:43<4:35:40,  4.77s/it]  7%|▋         | 277/3743 [21:48<4:45:19,  4.94s/it]  7%|▋         | 278/3743 [21:53<4:41:46,  4.88s/it]  7%|▋         | 279/3743 [21:57<4:19:36,  4.50s/it]  7%|▋         | 280/3743 [22:02<4:23:41,  4.57s/it]{'loss': 0.5589, 'grad_norm': 1890.974609375, 'learning_rate': 7.44e-07, 'mean_ratio_chosen': 0.21468698978424072, 'mean_ratio_rejected': 2.8020029067993164, 'weight_chosen': 1.2662353515625, 'weight_rejected': 1.012420654296875, 'kl_term_chosen': -0.769287109375, 'kl_term_rejected': 0.515167236328125, 'epoch': 0.07482129734785223}
                                                    {'loss': 0.5589, 'grad_norm': 1890.974609375, 'learning_rate': 7.44e-07, 'mean_ratio_chosen': 0.21468698978424072, 'mean_ratio_rejected': 2.8020029067993164, 'weight_chosen': 1.2662353515625, 'weight_rejected': 1.012420654296875, 'kl_term_chosen': -0.769287109375, 'kl_term_rejected': 0.515167236328125, 'epoch': 0.07}
  7%|▋         | 280/3743 [22:02<4:23:41,  4.57s/it]  8%|▊         | 281/3743 [22:07<4:38:33,  4.83s/it]  8%|▊         | 282/3743 [22:12<4:40:48,  4.87s/it]  8%|▊         | 283/3743 [22:16<4:31:32,  4.71s/it]  8%|▊         | 284/3743 [22:20<4:19:00,  4.49s/it]  8%|▊         | 285/3743 [22:24<4:07:53,  4.30s/it]  8%|▊         | 286/3743 [22:28<4:08:31,  4.31s/it]  8%|▊         | 287/3743 [22:32<3:59:27,  4.16s/it]  8%|▊         | 288/3743 [22:37<4:05:39,  4.27s/it]  8%|▊         | 289/3743 [22:40<3:51:43,  4.03s/it]  8%|▊         | 290/3743 [22:44<3:40:22,  3.83s/it]{'loss': 0.1878, 'grad_norm': 2720.66357421875, 'learning_rate': 7.706666666666667e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.9105682373046875, 'weight_rejected': -1.12017822265625, 'kl_term_chosen': -1.4128265380859375, 'kl_term_rejected': -1.61907958984375, 'epoch': 0.07749348653884695}
                                                    {'loss': 0.1878, 'grad_norm': 2720.66357421875, 'learning_rate': 7.706666666666667e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 1.9105682373046875, 'weight_rejected': -1.12017822265625, 'kl_term_chosen': -1.4128265380859375, 'kl_term_rejected': -1.61907958984375, 'epoch': 0.08}
  8%|▊         | 290/3743 [22:44<3:40:22,  3.83s/it]  8%|▊         | 291/3743 [22:48<3:46:21,  3.93s/it]  8%|▊         | 292/3743 [22:52<3:55:11,  4.09s/it]  8%|▊         | 293/3743 [22:56<3:42:31,  3.87s/it]  8%|▊         | 294/3743 [22:59<3:39:09,  3.81s/it]  8%|▊         | 295/3743 [23:03<3:38:13,  3.80s/it]  8%|▊         | 296/3743 [23:09<4:10:11,  4.36s/it]  8%|▊         | 297/3743 [23:13<4:01:24,  4.20s/it]  8%|▊         | 298/3743 [23:17<3:58:31,  4.15s/it]  8%|▊         | 299/3743 [23:21<4:07:35,  4.31s/it]  8%|▊         | 300/3743 [23:25<4:03:17,  4.24s/it]{'loss': 0.7532, 'grad_norm': 2559.391357421875, 'learning_rate': 7.973333333333333e-07, 'mean_ratio_chosen': 5.531635761260986, 'mean_ratio_rejected': 5.4896559715271, 'weight_chosen': -0.35795778036117554, 'weight_rejected': 1.3501815795898438, 'kl_term_chosen': 0.8552417755126953, 'kl_term_rejected': 0.8514328002929688, 'epoch': 0.08016567572984168}
                                                    {'loss': 0.7532, 'grad_norm': 2559.391357421875, 'learning_rate': 7.973333333333333e-07, 'mean_ratio_chosen': 5.531635761260986, 'mean_ratio_rejected': 5.4896559715271, 'weight_chosen': -0.35795778036117554, 'weight_rejected': 1.3501815795898438, 'kl_term_chosen': 0.8552417755126953, 'kl_term_rejected': 0.8514328002929688, 'epoch': 0.08}
  8%|▊         | 300/3743 [23:25<4:03:17,  4.24s/it]  8%|▊         | 301/3743 [23:30<4:05:38,  4.28s/it]  8%|▊         | 302/3743 [23:34<4:10:11,  4.36s/it]  8%|▊         | 303/3743 [23:38<3:58:44,  4.16s/it]  8%|▊         | 304/3743 [23:42<3:53:04,  4.07s/it]  8%|▊         | 305/3743 [23:47<4:08:17,  4.33s/it]  8%|▊         | 306/3743 [23:50<3:52:49,  4.06s/it]  8%|▊         | 307/3743 [23:54<3:49:09,  4.00s/it]  8%|▊         | 308/3743 [23:58<3:46:44,  3.96s/it]  8%|▊         | 309/3743 [24:04<4:25:22,  4.64s/it]  8%|▊         | 310/3743 [24:12<5:29:21,  5.76s/it]{'loss': -0.093, 'grad_norm': 6718.8466796875, 'learning_rate': 8.24e-07, 'mean_ratio_chosen': 2.814128875732422, 'mean_ratio_rejected': 1.5701391696929932, 'weight_chosen': -0.01836395263671875, 'weight_rejected': 0.7247886657714844, 'kl_term_chosen': 0.5173263549804688, 'kl_term_rejected': 0.22558212280273438, 'epoch': 0.08283786492083639}
                                                    {'loss': -0.093, 'grad_norm': 6718.8466796875, 'learning_rate': 8.24e-07, 'mean_ratio_chosen': 2.814128875732422, 'mean_ratio_rejected': 1.5701391696929932, 'weight_chosen': -0.01836395263671875, 'weight_rejected': 0.7247886657714844, 'kl_term_chosen': 0.5173263549804688, 'kl_term_rejected': 0.22558212280273438, 'epoch': 0.08}
  8%|▊         | 310/3743 [24:13<5:29:21,  5.76s/it]  8%|▊         | 311/3743 [24:19<5:34:45,  5.85s/it]  8%|▊         | 312/3743 [24:24<5:30:12,  5.77s/it]  8%|▊         | 313/3743 [24:29<5:10:32,  5.43s/it]  8%|▊         | 314/3743 [24:35<5:23:02,  5.65s/it]  8%|▊         | 315/3743 [24:39<4:47:26,  5.03s/it]  8%|▊         | 316/3743 [24:43<4:35:30,  4.82s/it]  8%|▊         | 317/3743 [24:47<4:23:27,  4.61s/it]  8%|▊         | 318/3743 [24:51<4:13:19,  4.44s/it]  9%|▊         | 319/3743 [24:54<3:51:04,  4.05s/it]  9%|▊         | 320/3743 [24:58<3:50:58,  4.05s/it]{'loss': 0.0346, 'grad_norm': 476.8742980957031, 'learning_rate': 8.506666666666667e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.8494415283203125, 'weight_rejected': -2.544677734375, 'kl_term_chosen': -4.3513336181640625, 'kl_term_rejected': -3.0426025390625, 'epoch': 0.08551005411183112}
                                                    {'loss': 0.0346, 'grad_norm': 476.8742980957031, 'learning_rate': 8.506666666666667e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.8494415283203125, 'weight_rejected': -2.544677734375, 'kl_term_chosen': -4.3513336181640625, 'kl_term_rejected': -3.0426025390625, 'epoch': 0.09}
  9%|▊         | 320/3743 [24:58<3:50:58,  4.05s/it]  9%|▊         | 321/3743 [25:02<3:46:21,  3.97s/it]  9%|▊         | 322/3743 [25:06<3:49:35,  4.03s/it]  9%|▊         | 323/3743 [25:09<3:32:07,  3.72s/it]  9%|▊         | 324/3743 [25:17<4:39:40,  4.91s/it]  9%|▊         | 325/3743 [25:21<4:23:54,  4.63s/it]  9%|▊         | 326/3743 [25:25<4:22:19,  4.61s/it]  9%|▊         | 327/3743 [25:29<4:12:13,  4.43s/it]  9%|▉         | 328/3743 [25:33<4:04:07,  4.29s/it]  9%|▉         | 329/3743 [25:37<3:55:43,  4.14s/it]  9%|▉         | 330/3743 [25:43<4:24:50,  4.66s/it]{'loss': 0.3675, 'grad_norm': 260.3280944824219, 'learning_rate': 8.773333333333332e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.2267327308654785, 'weight_rejected': -1.2902981042861938, 'kl_term_chosen': -3.7398147583007812, 'kl_term_rejected': -1.7651138305664062, 'epoch': 0.08818224330282584}
                                                    {'loss': 0.3675, 'grad_norm': 260.3280944824219, 'learning_rate': 8.773333333333332e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 4.2267327308654785, 'weight_rejected': -1.2902981042861938, 'kl_term_chosen': -3.7398147583007812, 'kl_term_rejected': -1.7651138305664062, 'epoch': 0.09}
  9%|▉         | 330/3743 [25:43<4:24:50,  4.66s/it]  9%|▉         | 331/3743 [25:46<4:03:15,  4.28s/it]  9%|▉         | 332/3743 [25:51<4:13:57,  4.47s/it]  9%|▉         | 333/3743 [25:56<4:22:38,  4.62s/it]  9%|▉         | 334/3743 [26:00<4:00:25,  4.23s/it]  9%|▉         | 335/3743 [26:04<4:00:55,  4.24s/it]  9%|▉         | 336/3743 [26:07<3:46:21,  3.99s/it]  9%|▉         | 337/3743 [26:13<4:18:49,  4.56s/it]  9%|▉         | 338/3743 [26:20<5:05:02,  5.38s/it]  9%|▉         | 339/3743 [26:25<4:46:03,  5.04s/it]  9%|▉         | 340/3743 [26:29<4:30:38,  4.77s/it]{'loss': 5.2003, 'grad_norm': 0.0, 'learning_rate': 9.039999999999999e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.1151161193847656, 'weight_rejected': -1.564157485961914, 'kl_term_chosen': -1.6161537170410156, 'kl_term_rejected': -2.063669204711914, 'epoch': 0.09085443249382057}
                                                    {'loss': 5.2003, 'grad_norm': 0.0, 'learning_rate': 9.039999999999999e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 2.1151161193847656, 'weight_rejected': -1.564157485961914, 'kl_term_chosen': -1.6161537170410156, 'kl_term_rejected': -2.063669204711914, 'epoch': 0.09}
  9%|▉         | 340/3743 [26:29<4:30:38,  4.77s/it]  9%|▉         | 341/3743 [26:33<4:25:07,  4.68s/it]  9%|▉         | 342/3743 [26:37<4:03:09,  4.29s/it]  9%|▉         | 343/3743 [26:41<4:10:49,  4.43s/it]  9%|▉         | 344/3743 [26:45<3:51:23,  4.08s/it]  9%|▉         | 345/3743 [26:49<3:54:45,  4.15s/it]  9%|▉         | 346/3743 [26:53<3:54:24,  4.14s/it]  9%|▉         | 347/3743 [26:57<3:49:23,  4.05s/it]  9%|▉         | 348/3743 [27:03<4:23:19,  4.65s/it]  9%|▉         | 349/3743 [27:07<4:06:03,  4.35s/it]  9%|▉         | 350/3743 [27:11<4:03:23,  4.30s/it]{'loss': -1.2501, 'grad_norm': 0.0, 'learning_rate': 9.306666666666666e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 8.740346908569336, 'weight_rejected': -7.576478958129883, 'kl_term_chosen': -8.241811752319336, 'kl_term_rejected': -8.075197219848633, 'epoch': 0.09352662168481528}
                                                    {'loss': -1.2501, 'grad_norm': 0.0, 'learning_rate': 9.306666666666666e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 8.740346908569336, 'weight_rejected': -7.576478958129883, 'kl_term_chosen': -8.241811752319336, 'kl_term_rejected': -8.075197219848633, 'epoch': 0.09}
  9%|▉         | 350/3743 [27:11<4:03:23,  4.30s/it]  9%|▉         | 351/3743 [27:14<3:47:55,  4.03s/it]  9%|▉         | 352/3743 [27:18<3:38:06,  3.86s/it]  9%|▉         | 353/3743 [27:26<4:48:58,  5.11s/it]  9%|▉         | 354/3743 [27:30<4:36:43,  4.90s/it]  9%|▉         | 355/3743 [27:35<4:42:16,  5.00s/it] 10%|▉         | 356/3743 [27:40<4:35:47,  4.89s/it] 10%|▉         | 357/3743 [27:45<4:33:48,  4.85s/it] 10%|▉         | 358/3743 [27:48<4:11:37,  4.46s/it] 10%|▉         | 359/3743 [27:52<4:03:58,  4.33s/it] 10%|▉         | 360/3743 [27:58<4:31:34,  4.82s/it]{'loss': -1.7194, 'grad_norm': 0.0, 'learning_rate': 9.573333333333333e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 8.246662139892578, 'weight_rejected': -8.153350830078125, 'kl_term_chosen': -7.750324249267578, 'kl_term_rejected': -8.649383544921875, 'epoch': 0.09619881087581}
                                                    {'loss': -1.7194, 'grad_norm': 0.0, 'learning_rate': 9.573333333333333e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 8.246662139892578, 'weight_rejected': -8.153350830078125, 'kl_term_chosen': -7.750324249267578, 'kl_term_rejected': -8.649383544921875, 'epoch': 0.1}
 10%|▉         | 360/3743 [27:58<4:31:34,  4.82s/it] 10%|▉         | 361/3743 [28:02<4:16:49,  4.56s/it] 10%|▉         | 362/3743 [28:10<5:11:27,  5.53s/it] 10%|▉         | 363/3743 [28:15<4:54:12,  5.22s/it] 10%|▉         | 364/3743 [28:19<4:47:03,  5.10s/it] 10%|▉         | 365/3743 [28:23<4:29:31,  4.79s/it] 10%|▉         | 366/3743 [28:30<4:51:06,  5.17s/it] 10%|▉         | 367/3743 [28:33<4:29:19,  4.79s/it] 10%|▉         | 368/3743 [28:38<4:21:50,  4.65s/it] 10%|▉         | 369/3743 [28:42<4:11:43,  4.48s/it] 10%|▉         | 370/3743 [28:47<4:28:29,  4.78s/it]{'loss': -1.8839, 'grad_norm': 0.0, 'learning_rate': 9.84e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 10.010986328125, 'weight_rejected': -10.515968322753906, 'kl_term_chosen': -9.5179443359375, 'kl_term_rejected': -11.012855529785156, 'epoch': 0.09887100006680473}
                                                    {'loss': -1.8839, 'grad_norm': 0.0, 'learning_rate': 9.84e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 10.010986328125, 'weight_rejected': -10.515968322753906, 'kl_term_chosen': -9.5179443359375, 'kl_term_rejected': -11.012855529785156, 'epoch': 0.1}
 10%|▉         | 370/3743 [28:47<4:28:29,  4.78s/it] 10%|▉         | 371/3743 [28:53<4:49:08,  5.14s/it] 10%|▉         | 372/3743 [28:57<4:26:29,  4.74s/it] 10%|▉         | 373/3743 [29:00<4:00:14,  4.28s/it] 10%|▉         | 374/3743 [29:05<4:01:14,  4.30s/it] 10%|█         | 375/3743 [29:08<3:50:20,  4.10s/it] 10%|█         | 376/3743 [29:12<3:37:09,  3.87s/it] 10%|█         | 377/3743 [29:17<3:58:36,  4.25s/it] 10%|█         | 378/3743 [29:21<3:53:22,  4.16s/it] 10%|█         | 379/3743 [29:25<3:55:23,  4.20s/it] 10%|█         | 380/3743 [29:29<3:59:38,  4.28s/it]{'loss': -1.9489, 'grad_norm': 0.0, 'learning_rate': 9.999965197129363e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 8.103496551513672, 'weight_rejected': -13.232704162597656, 'kl_term_chosen': -7.608257293701172, 'kl_term_rejected': -13.730445861816406, 'epoch': 0.10154318925779945}
                                                    {'loss': -1.9489, 'grad_norm': 0.0, 'learning_rate': 9.999965197129363e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 8.103496551513672, 'weight_rejected': -13.232704162597656, 'kl_term_chosen': -7.608257293701172, 'kl_term_rejected': -13.730445861816406, 'epoch': 0.1}
 10%|█         | 380/3743 [29:30<3:59:38,  4.28s/it] 10%|█         | 381/3743 [29:36<4:31:32,  4.85s/it] 10%|█         | 382/3743 [29:40<4:15:44,  4.57s/it] 10%|█         | 383/3743 [29:43<4:02:26,  4.33s/it] 10%|█         | 384/3743 [29:48<4:06:42,  4.41s/it] 10%|█         | 385/3743 [29:52<3:59:55,  4.29s/it] 10%|█         | 386/3743 [29:56<3:52:38,  4.16s/it] 10%|█         | 387/3743 [30:00<3:46:19,  4.05s/it] 10%|█         | 388/3743 [30:04<3:48:31,  4.09s/it] 10%|█         | 389/3743 [30:08<3:49:54,  4.11s/it] 10%|█         | 390/3743 [30:16<4:55:27,  5.29s/it]{'loss': -1.9566, 'grad_norm': 0.0, 'learning_rate': 9.999573670398804e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 10.462249755859375, 'weight_rejected': -10.712600708007812, 'kl_term_chosen': -9.963958740234375, 'kl_term_rejected': -11.211257934570312, 'epoch': 0.10421537844879418}
                                                    {'loss': -1.9566, 'grad_norm': 0.0, 'learning_rate': 9.999573670398804e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 10.462249755859375, 'weight_rejected': -10.712600708007812, 'kl_term_chosen': -9.963958740234375, 'kl_term_rejected': -11.211257934570312, 'epoch': 0.1}
 10%|█         | 390/3743 [30:16<4:55:27,  5.29s/it] 10%|█         | 391/3743 [30:20<4:41:33,  5.04s/it] 10%|█         | 392/3743 [30:29<5:37:38,  6.05s/it] 10%|█         | 393/3743 [30:32<4:57:05,  5.32s/it] 11%|█         | 394/3743 [30:37<4:39:25,  5.01s/it] 11%|█         | 395/3743 [30:42<4:39:11,  5.00s/it] 11%|█         | 396/3743 [30:45<4:17:17,  4.61s/it] 11%|█         | 397/3743 [30:49<3:54:16,  4.20s/it] 11%|█         | 398/3743 [30:54<4:06:21,  4.42s/it] 11%|█         | 399/3743 [30:57<3:56:24,  4.24s/it] 11%|█         | 400/3743 [31:01<3:52:01,  4.16s/it]{'loss': -1.9384, 'grad_norm': 0.0, 'learning_rate': 9.998747147528373e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 9.905723571777344, 'weight_rejected': -8.363975524902344, 'kl_term_chosen': -9.410911560058594, 'kl_term_rejected': -8.857566833496094, 'epoch': 0.10688756763978889}
                                                    {'loss': -1.9384, 'grad_norm': 0.0, 'learning_rate': 9.998747147528373e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 9.905723571777344, 'weight_rejected': -8.363975524902344, 'kl_term_chosen': -9.410911560058594, 'kl_term_rejected': -8.857566833496094, 'epoch': 0.11}
 11%|█         | 400/3743 [31:01<3:52:01,  4.16s/it] 11%|█         | 401/3743 [31:05<3:49:02,  4.11s/it] 11%|█         | 402/3743 [31:09<3:39:41,  3.95s/it] 11%|█         | 403/3743 [31:13<3:42:40,  4.00s/it] 11%|█         | 404/3743 [31:18<3:54:51,  4.22s/it] 11%|█         | 405/3743 [31:21<3:46:20,  4.07s/it] 11%|█         | 406/3743 [31:28<4:18:49,  4.65s/it] 11%|█         | 407/3743 [31:31<4:07:23,  4.45s/it] 11%|█         | 408/3743 [31:36<4:04:49,  4.40s/it] 11%|█         | 409/3743 [31:40<4:01:38,  4.35s/it] 11%|█         | 410/3743 [31:44<4:00:15,  4.33s/it]{'loss': -1.9852, 'grad_norm': 0.0, 'learning_rate': 9.997485700431054e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 9.112297058105469, 'weight_rejected': -11.306446075439453, 'kl_term_chosen': -8.612968444824219, 'kl_term_rejected': -11.805896759033203, 'epoch': 0.10955975683078362}
                                                    {'loss': -1.9852, 'grad_norm': 0.0, 'learning_rate': 9.997485700431054e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 9.112297058105469, 'weight_rejected': -11.306446075439453, 'kl_term_chosen': -8.612968444824219, 'kl_term_rejected': -11.805896759033203, 'epoch': 0.11}
 11%|█         | 410/3743 [31:44<4:00:15,  4.33s/it] 11%|█         | 411/3743 [31:49<4:06:33,  4.44s/it] 11%|█         | 412/3743 [31:53<3:56:49,  4.27s/it] 11%|█         | 413/3743 [31:58<4:04:30,  4.41s/it] 11%|█         | 414/3743 [32:02<4:09:21,  4.49s/it] 11%|█         | 415/3743 [32:08<4:37:12,  5.00s/it] 11%|█         | 416/3743 [32:13<4:35:56,  4.98s/it] 11%|█         | 417/3743 [32:20<4:55:03,  5.32s/it] 11%|█         | 418/3743 [32:25<4:54:50,  5.32s/it] 11%|█         | 419/3743 [32:29<4:42:45,  5.10s/it] 11%|█         | 420/3743 [32:33<4:22:21,  4.74s/it]{'loss': -1.9829, 'grad_norm': 0.0, 'learning_rate': 9.995789438861126e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 7.530235290527344, 'weight_rejected': -11.299781799316406, 'kl_term_chosen': -7.034019470214844, 'kl_term_rejected': -11.795021057128906, 'epoch': 0.11223194602177834}
                                                    {'loss': -1.9829, 'grad_norm': 0.0, 'learning_rate': 9.995789438861126e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 7.530235290527344, 'weight_rejected': -11.299781799316406, 'kl_term_chosen': -7.034019470214844, 'kl_term_rejected': -11.795021057128906, 'epoch': 0.11}
 11%|█         | 420/3743 [32:33<4:22:21,  4.74s/it] 11%|█         | 421/3743 [32:38<4:27:13,  4.83s/it] 11%|█▏        | 422/3743 [32:43<4:18:11,  4.66s/it] 11%|█▏        | 423/3743 [32:46<3:51:17,  4.18s/it] 11%|█▏        | 424/3743 [32:50<4:00:56,  4.36s/it] 11%|█▏        | 425/3743 [32:54<3:49:56,  4.16s/it] 11%|█▏        | 426/3743 [32:59<3:58:13,  4.31s/it] 11%|█▏        | 427/3743 [33:03<3:50:49,  4.18s/it] 11%|█▏        | 428/3743 [33:07<3:52:43,  4.21s/it] 11%|█▏        | 429/3743 [33:11<3:49:46,  4.16s/it] 11%|█▏        | 430/3743 [33:19<4:46:41,  5.19s/it]{'loss': -1.9881, 'grad_norm': 0.0, 'learning_rate': 9.993658510404621e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.450397491455078, 'weight_rejected': -10.700023651123047, 'kl_term_chosen': -10.954151153564453, 'kl_term_rejected': -11.193477630615234, 'epoch': 0.11490413521277307}
                                                    {'loss': -1.9881, 'grad_norm': 0.0, 'learning_rate': 9.993658510404621e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 11.450397491455078, 'weight_rejected': -10.700023651123047, 'kl_term_chosen': -10.954151153564453, 'kl_term_rejected': -11.193477630615234, 'epoch': 0.11}
 11%|█▏        | 430/3743 [33:19<4:46:41,  5.19s/it] 12%|█▏        | 431/3743 [33:23<4:29:58,  4.89s/it] 12%|█▏        | 432/3743 [33:27<4:17:43,  4.67s/it] 12%|█▏        | 433/3743 [33:32<4:16:50,  4.66s/it] 12%|█▏        | 434/3743 [33:36<4:09:11,  4.52s/it] 12%|█▏        | 435/3743 [33:40<4:01:26,  4.38s/it] 12%|█▏        | 436/3743 [33:45<4:07:51,  4.50s/it] 12%|█▏        | 437/3743 [33:48<3:54:50,  4.26s/it] 12%|█▏        | 438/3743 [33:53<3:54:36,  4.26s/it] 12%|█▏        | 439/3743 [33:56<3:42:00,  4.03s/it] 12%|█▏        | 440/3743 [34:03<4:34:10,  4.98s/it]{'loss': -1.9872, 'grad_norm': 0.0, 'learning_rate': 9.991093100466482e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 9.916194915771484, 'weight_rejected': -11.62911605834961, 'kl_term_chosen': -9.42000961303711, 'kl_term_rejected': -12.12484359741211, 'epoch': 0.11757632440376779}
                                                    {'loss': -1.9872, 'grad_norm': 0.0, 'learning_rate': 9.991093100466482e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 9.916194915771484, 'weight_rejected': -11.62911605834961, 'kl_term_chosen': -9.42000961303711, 'kl_term_rejected': -12.12484359741211, 'epoch': 0.12}
 12%|█▏        | 440/3743 [34:03<4:34:10,  4.98s/it] 12%|█▏        | 441/3743 [34:07<4:19:37,  4.72s/it] 12%|█▏        | 442/3743 [34:12<4:19:35,  4.72s/it] 12%|█▏        | 443/3743 [34:17<4:17:07,  4.67s/it] 12%|█▏        | 444/3743 [34:22<4:21:46,  4.76s/it] 12%|█▏        | 445/3743 [34:26<4:09:33,  4.54s/it] 12%|█▏        | 446/3743 [34:30<4:03:48,  4.44s/it] 12%|█▏        | 447/3743 [34:34<4:02:22,  4.41s/it] 12%|█▏        | 448/3743 [34:40<4:17:16,  4.68s/it] 12%|█▏        | 449/3743 [34:43<4:05:41,  4.48s/it] 12%|█▏        | 450/3743 [34:52<5:04:03,  5.54s/it]{'loss': -1.984, 'grad_norm': 0.0, 'learning_rate': 9.98809343225442e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 9.68011474609375, 'weight_rejected': -11.48590087890625, 'kl_term_chosen': -9.18505859375, 'kl_term_rejected': -11.98077392578125, 'epoch': 0.1202485135947625}
                                                    {'loss': -1.984, 'grad_norm': 0.0, 'learning_rate': 9.98809343225442e-07, 'mean_ratio_chosen': 0.10025884956121445, 'mean_ratio_rejected': 0.10025884956121445, 'weight_chosen': 9.68011474609375, 'weight_rejected': -11.48590087890625, 'kl_term_chosen': -9.18505859375, 'kl_term_rejected': -11.98077392578125, 'epoch': 0.12}
 12%|█▏        | 450/3743 [34:52<5:04:03,  5.54s/it]/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py:678: FutureWarning: FSDP.state_dict_type() and FSDP.set_state_dict_type() are being deprecated. Please use APIs, get_state_dict() and set_state_dict(), which can support different parallelisms, FSDP1, FSDP2, DDP. API doc: https://pytorch.org/docs/stable/distributed.checkpoint.html#torch.distributed.checkpoint.state_dict.get_state_dict .Tutorial: https://pytorch.org/tutorials/recipes/distributed_checkpoint_recipe.html .
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:860: UserWarning: `_get_pg_default_device` will be deprecated, it only stays for backward-compatiblity reason. If you need to find a device for object collectives, please use `_get_object_coll_device`. If you need to query the device types supported by group, please use `_device_capability(group)`. 
  warnings.warn(
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:722: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  local_shape = tensor.shape
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:739: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.shape,
/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/fsdp/_state_dict_utils.py:741: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.
  tensor.dtype,
 12%|█▏        | 451/3743 [35:55<21:01:35, 22.99s/it] 12%|█▏        | 452/3743 [36:00<15:57:30, 17.46s/it] 12%|█▏        | 453/3743 [36:03<12:08:38, 13.29s/it] 12%|█▏        | 454/3743 [36:07<9:28:34, 10.37s/it]  12%|█▏        | 455/3743 [36:11<7:52:37,  8.62s/it]W1216 11:34:02.921000 13066 site-packages/torch/distributed/elastic/agent/server/api.py:723] Received 15 death signal, shutting down workers
W1216 11:34:02.922000 13066 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 13174 closing signal SIGTERM
W1216 11:34:02.923000 13066 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 13175 closing signal SIGTERM
W1216 11:34:02.923000 13066 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 13176 closing signal SIGTERM
W1216 11:34:02.923000 13066 site-packages/torch/distributed/elastic/multiprocessing/api.py:900] Sending process 13177 closing signal SIGTERM
Traceback (most recent call last):
  File "/root/miniconda3/envs/advan/bin/accelerate", line 7, in <module>
    sys.exit(main())
             ^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/launch.py", line 1222, in launch_command
    multi_gpu_launcher(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/accelerate/commands/launch.py", line 853, in multi_gpu_launcher
    distrib_run.run(args)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 143, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    result = agent.run()
             ^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/metrics/api.py", line 138, in wrapper
    result = f(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 715, in run
    result = self._invoke_run(role)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/agent/server/api.py", line 879, in _invoke_run
    time.sleep(monitor_interval)
  File "/root/miniconda3/envs/advan/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 13066 got signal: 15
